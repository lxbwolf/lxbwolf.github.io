[{"content":"Linux 中退出码的含义 揭开 Linux 中退出码的神秘面纱。了解什么是退出码，以及为什么和如何使用它们。\n退出码（退出状态）可以告诉我们最后一次执行的命令的状态。在命令结束以后，我们可以知道命令是成功完成的还是以错误结束的。\n其基本思想是，程序返回退出代码 0 时表示执行成功，没有问题。代码 1 或 0 以外的任何代码都被视为不成功。\n退出码除了 0 和 1 外还有很多值，我将在本文介绍它们。\nLinux Shell 中的各种退出码 我们来快速了解一下 Linux Shell 中的主要退出码：\n退出码 解释 0 命令成功执行 1 通用错误代码 2 命令（或参数）使用不当 126 权限被拒绝（或）无法执行 127 未找到命令，或 PATH 错误 128+n 命令被信号从外部终止，或遇到致命错误 130 通过 Ctrl+C 或 SIGINT 终止（终止代码 2 或键盘中断） 143 通过 SIGTERM 终止（默认终止） 255/* 退出码超过了 0-255 的范围，因此重新计算（LCTT 译注：超过 255 后，用退出码对 256 取模） 📋 130（SIGINT 或 ^C）和 143（SIGTERM）等终止信号是非常典型的，它们属于 128+n 信号，其中 n 代表终止码。\n在简单了解了退出码之后，我们来看看它们的用法。\n获取退出码 前一个命令执行的退出码存储在 特殊变量 $? 中。你可以通过运行以下命令来获取：\necho $? 我们在所有演示中都将使用它来获取退出代码。\n请注意，exit 命令支持以带着前一条命令相同的退出码退出。\n退出码 0 退出码 0 表示命令执行无误，这是完成命令的理想状态。\n例如，我们运行这样一条基本命令\nneofetch echo $? 这个退出码 0 表示特定命令已成功执行，仅此而已。让我们再演示几个例子。\n你可以尝试 终止一个进程；它也会返回代码 0。\npkill lxappearance 查看文件内容也会返回退出码 0，这仅意味着 cat 命令执行成功。\n退出码 1 退出码 1 也很常见。它通常表示命令以一般错误结束。\n例如，在没有 sudo 权限的情况下使用 软件包管理器，就会返回代码 1。在 Arch Linux 中，如果我运行下面的命令：\npacman -Sy 它会返回 1， 表示上一条命令运行出错。\n📋 如果你在基于 Ubuntu 的发行版中尝试这样做（不使用 sudo 执行 apt update），运行后会得到错误码 100，表示你是在没有权限的情况下运行 apt。100 不是标准错误码，而是 apt 特有的错误码。\n虽然这是一般的理解，但我们也可以将其解释为 “不被允许的操作”。\n除以 0 等操作也会返回错误码 1。\n退出码 2 这个退出码出现在当执行的命令有语法错误时。滥用命令参数也会导致此错误。\n一般来说，它表示由于使用不当，命令无法执行。\n例如，我在一个本应只有一个连字符的选项上添加了两个连字符，那么此时会出现退出码 2。\ngrep --z file.txt 当权限被拒绝时，比如访问 /root 文件夹，就会出现错误码 2。\n退出码 126 126 是一个特殊的退出码，它用于表示命令或脚本因权限错误而未被执行。\n当你尝试执行没有执行权限的 Shell 脚本时，就会出现这个错误。\n请注意，该退出码只出现在没有足够权限的脚本或命令的“执行”中，这与一般的权限被拒绝错误不同。\n因此，不要把它与你之前看到的退出码为 2 的示例混淆。在那个示例中，运行的是 ls 命令，权限问题出自它试图执行的目录。而本例中权限问题来自脚本本身。\n退出码 127 这是另一个常见的退出码。退出码 127 指的是“未找到命令”。它通常发生在执行的命令有错别字或所需的可执行文件不在 $PATH 变量中时。\n例如，当我尝试执行一个不带路径的脚本时，经常会看到这个错误。\n当你想运行的可执行文件不在 $PATH 变量中时，也会出现退出码 127。你可以通过 在 PATH 变量中添加命令的目录 来纠正这种情况。\n当你输入不存在的命令时，也会得到这样的退出码。\n退出码 128+n 系列 当应用程序或命令因致命错误而终止或执行失败时，将产生 128 系列退出码（128+n），其中 n 为信号编号。\nn 包括所有类型的终止代码，如 SIGTERM、SIGKILL 等。\n退出码 130 或 SIGINT 在通过终止信号 2 或按下 Ctrl+C 中断进程时，会发出 SIGINT（键盘中断信号）。\n因为终止信号是 2，所以我们得到的退出码是 130（128+2）。下面的视频演示了 lxappearance 的中断信号。\n退出码 137 或 SIGKILL SIGKILL（立即终止信号）表示终止信号 9。这是终止应用程序时最不应该使用的方法。\n因为终止信号为 9，因此我们得到的退出代码为 137（128+9）。\n退出码 143 或 SIGTERM SIGTERM 是进程在未指定参数的情况下被杀死时的默认行为。\nSIGTERM 的终止信号为 15，因此该信号的退出码为 143（128+15）。\n还有一些你以前可能不知道的终止信号，它们也有自己类似的退出码。你可以在这里查看它们：\n📋 请注意，如果进程在启动它的同一会话中终止，这些信号可能不会出现。如果要重现这些信号，请从不同的 shell 终止。\n就个人而言，信号 128 是无法重现的。\n当退出码超过了 255 会怎样? 最新版本的 Bash 甚至保留了超过 255 的原始退出码的值，但一般来说，如果代码超过 255，就会被重新计算。\n也就是说，代码 256 会变成 0，257 会变成 1，383 会变成 127，以此类推。为确保更好的兼容性，请将退出码保持在 0 至 255 之间。\n结语 希望你对 Linux Shell 中的退出码有所了解。在排查各种问题时，使用它们会非常方便。\n如果你要在 Shell 脚本中使用这些代码，请确保你了解每个代码的含义，以便更容易地排除故障。\n这就是本文的全部内容。如有遗漏，请在评论区告诉我。\n（题图：MJ/719ff711-1b9f-4aa9-a82e-980704acbdd8）\nvia: https://itsfoss.com/linux-exit-codes/\n作者：Pranav Krishna 选题：lkxed 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2023-08-03T22:12:42+08:00","permalink":"https://lxb.wiki/e28c7f9c/","title":"【译】Linux 中退出码的含义"},{"content":"\nLens Desktop 是一个令人兴奋的 Kubernetes 工作平台。它是基于 OpenLens 资源库的一个定制化发行版本。通过本文来了解下 Lens Desktop 能做什么以及它是如何工作的。\nLens Desktop 是免费的。你可以查看 https://app.k8slens.dev/subscribe 来了解更多内容。Lens Desktop 有如下优势：\n简单高效 —— 你无需学习 kubectl 命令 可视化已有的 Kubernetes 资源 基于开源代码构建 可观测性 —— 实时的统计数据、事件和日志流 错误和警告可以直接在 Lens 仪表盘上看到 支持 EKS、AKS、GKE、Minikube、Rancher、k0s、k3s、OpenShift 强大的社区支持 —— 有 450000 用户，在 GitHub 上共获得 17000 星 Minikube 安装 Minikube 是一个用于本地运行 Kubernetes 的工具。它运行一个单节点的 Kubernetes 集群，这样就可以在 Kubernetes 上进行日常软件开发的实践工作。\n我们将使用 Minikube 并验证 Lens 的用法。首先让我们在基于 Windows 的系统上安装 Minikube。你也可以把它安装在其他操作系统、虚拟机或笔记本电脑上。\n2 核以上 CPU 2GB RAM 20GB 空闲硬盘空间 能连接网络 容器或虚拟机管理器，如 Docker、VirtualBox 在终端或命令提示符处，运行 minikube start 命令：\nminikube start --driver=virtualbox * minikube v1.12.3 on Microsoft Windows 10 Home Single Language 10.0.19044 Build 19044 * Using the virtualbox driver based on existing profile * minikube 1.26.0 is available! Download it: https://github.com/kubernetes/minikube/releases/tag/v1.26.0 * To disable this notice, run: ‘minikube config set WantUpdateNotification false’ * Starting control plane node minikube in cluster minikube * virtualbox “minikube” VM is missing, will recreate. * Creating virtualbox VM (CPUs=2, Memory=3000MB, Disk=20000MB) ... ! This VM is having trouble accessing https://k8s.gcr.io * To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/ * Preparing Kubernetes v1.18.3 on Docker 19.03.12 ... * Verifying Kubernetes components... * Enabled addons: default-storageclass, storage-provisioner * Done! kubectl is now configured to use “minikube” 进入你的 VirtualBox，并验证刚安装的 Minikube 虚拟机功能正常（图 1）。\n使用 minikube status 命令，查看状态是否与下面的输出一致：\nC:\\\u0026gt;minikube status minikube type: Control Plane host: Running kubelet: Running apiserver: Running kubeconfig: Configured 然后，使用 kubectl cluster-info 命令查看 KubeDNS 详情：\nkubectl cluster-info Kubernetes master is running at https://192.168.99.103:8443 KubeDNS is running at https://192.168.99.103:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy 你可以使用 kubectl cluster-info dump 命令来调试和诊断集群问题。\n当 Minikube 安装完成后，安装 kubectl（https://kubernetes.io/docs/tasks/tools/）。它是一个命令行集群，用于对 Kubernetes 集群和 Minikube 执行命令。\n执行 kubectl get nodes 命令获取所有 node 的详情，在本例中是获取 Minikube 的详情：\nC:\\\u0026gt;kubectl get nodes NAME STATUS ROLES AGE VERSION minikube Ready master 7m57s v1.18.3 使用 kubectl get all 命令获取默认命名空间下的所有详情：\nC:\\\u0026gt;kubectl get all NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 7m58s 我们现在已经有一个 Minikube 集群，并准备好了 Kubectl。下一步是安装和配置 Lens，并用示例应用程序来验证。\nLens 的安装和配置 打开 https://k8slens.dev/ ，下载与你的操作系统匹配的安装包。\n然后，参照屏幕上的教程来安装 Lens，安装完成后打开 Lens。你会发现在目录中有一个 minikube（图 3）。\n点击 “minikube” 后，你就进入了 Minikube 的世界，你会爱上它的。\n点击 nodes 获取有关 kubectl get nodes 命令输出的 node 详情。\n现在，你可以使用 Lens 了。\n我们现在部署 https://github.com/GoogleCloudPlatform/microservices-demo，这是一个云原生微服务演示应用程序。它有 11 层的微服务应用，是一个基于网络的电子商务应用。\n下载这个应用程序，把它解压到与 Minikube 相同的目录。\n进入 release 目录，执行以下命令。\nkubectl apply -f kubernetes-manifests.yaml deployment.apps/emailservice created service/emailservice created deployment.apps/checkoutservice created service/checkoutservice created deployment.apps/recommendationservice created service/recommendationservice created deployment.apps/frontend created service/frontend created service/frontend-external created deployment.apps/paymentservice created service/paymentservice created deployment.apps/productcatalogservice created service/productcatalogservice created deployment.apps/cartservice created service/cartservice created deployment.apps/loadgenerator created deployment.apps/currencyservice created service/currencyservice created deployment.apps/shippingservice created service/shippingservice created deployment.apps/redis-cart created service/redis-cart created deployment.apps/adservice created service/adservice created 安装过程现在应该已经开始了，不过它需要一些时间来反映出我们使用了 kubectl 命令。\nkubectl get pods NAME READY STATUS RESTARTS AGE adservice-775d8b9bf5-cp7jr 0/1 Pending 0 8h cartservice-79749895f5-jrq4d 1/1 Running 0 8h checkoutservice-5645bf9c65-882m4 1/1 Running 0 8h currencyservice-545c79d477-8rhg7 1/1 Running 0 8h emailservice-7cc5c74b4f-hk74s 1/1 Running 0 8h frontend-9cdf787f5-klfkh 1/1 Running 1 8h loadgenerator-7b6874cb4c-645v9 1/1 Running 0 8h paymentservice-5f74bc7b87-l4248 1/1 Running 0 8h productcatalogservice-6846f59899-v4q4w 1/1 Running 0 8h recommendationservice-d9c6c8b55-m2x9k 1/1 Running 0 8h redis-cart-57bd646894-v7kfr 0/1 Pending 0 8h shippingservice-8685dd9855-pmgjm 1/1 Running 0 8h 表 1 列出了你可以通过 kubectl 来获取信息的几个命令。\n描述 命令 列出节点 kubectl get node 列出集群中的所有资源 kubectl get all –all-namespaces 列出部署 kubectl get deployment 显示部署的完整状态 kubectl describe deployment \u0026lt;deployment_name\u0026gt; 修改集群上的部署 kubectl edit deployment \u0026lt;deployment_name\u0026gt; 删除部署 kubectl delete deployment \u0026lt;deployment_name\u0026gt; 列出容器荚 kubectl get pod 删除容器荚 kubectl delete pod \u0026lt;pod_name\u0026gt; 显示容器荚的完整状态 kubectl describe pod \u0026lt;pod_name\u0026gt; 在 Shell 中运行一个单容器荚 kubectl exec -it \u0026lt;pod_name\u0026gt; /bin/bash 列出机密信息 kubectl get secrets 列出服务 kubectl get services 列出服务的完整状态 kubectl describe services 修改集群中的服务 kubectl edit services / kubectl edit deployment \u0026lt;deployment_name\u0026gt; 列出命名空间 kubectl get namespace \u0026lt;namespace_name\u0026gt; 打印容器荚日志 kubectl logs \u0026lt;pod_name\u0026gt; 打印容器荚中特定容器的日志 kubectl logs -c \u0026lt;container_name\u0026gt; \u0026lt;pod_name\u0026gt; Lens 不仅可以帮你获取表 1 中列出的所有信息，它还可以获取指定集群的信息。我们还能用 Lens 来对 Kubernetes 资源进行编辑和删除操作。\n我们来看下是如何操作的。在 Workloads 部分选择 Pods（图 6），我们能通过 Lens 来编辑、删除、查看日志、访问 Pod 的终端，这是不是很酷？\n你可以验证 Workloads 区域中所有 deployments（图 7），Workloads 区域中所有 Replicasets （图 8），Config 区域中所有 Secrets （图 9），以及 Network 区域中所有 Services 是否都正常（图 10），\n你可以看到，跳转到所有的资源以及在一个地方高效地查看所有资源就是如此轻松。我们可以用 Lens 修改 YAML 文件，在运行时应用它来查看变更。\n对于配置在不同的云服务商部署的多个集群，我们仍可以用 Lens 来进行观察和故障处理。\n（题图：MJ/069da8c5-9043-46b3-9b14-87a0ffc6bb35）\nvia: https://www.opensourceforu.com/2022/09/monitoring-and-debugging-kubernetes-with-lens-desktop/\n作者：Mitesh Soni 选题：lkxed 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2023-05-05T08:14:34+08:00","permalink":"https://lxb.wiki/e94f2376/","title":"【译】使用 Lens Desktop 监控和调试 Kubernetes"},{"content":" Tekton 是一个用于创建持续集成和持续交付（CI/CD）系统的 Kubernetes 原生开源框架。\nTekton 是一个用于创建持续集成和持续交付（CI/CD）系统的 Kubernetes 原生开源框架。通过对底层实施细节的抽象，它还可以帮助你在多个云供应商或企业内部系统中进行端到端（构建、测试、部署）应用开发。\nTekton 介绍 Tekton 最初被称为 Knative Build，后来被重组为独立的开源项目，有自己的 治理组织，现在是属于 Linux 基金会 的项目。Tekton 提供了一个集群内的容器镜像构建和部署工作流程，换句话说，它是一个 持续集成continuous integration（CI）和 持续交付continuous delivery（CD）服务。它由 Tekton 流水线和几个支持组件如 Tekton CLI、Triggers 和 Catalog 等组成。\nTekton 是一个 Kubernetes 原生应用。它在 Kubernetes 集群中作为扩展被安装和运行，由一套Kubernetes 定制化资源组成，定义了你为流水线创建和复用的构建块。由于 Tekton 是一种 Kubernetes 原生技术，所以它非常容易扩展。当你需要增加你的工作负载时，你只需向你的集群添加节点就可以了。由于其可扩展的设计和社区贡献的组件库，它也很容易定制。\n对于需要 CI/CD 系统来开展工作的开发人员，和为其组织内的开发人员建立 CI/CD 系统的平台工程师，Tekton 是理想选择。\nTekton 组件 构建 CI/CD 流水线的过程非常复杂，因此 Tekton 为每一步都提供工具。以下是 Tekton 提供的主要组件：\n流水线Pipeline： 定义了一组 Kubernetes 自定义资源，作为你用来组装 CI/CD 流水线的构建块。 触发器Triggers：一种 Kubernetes 自定义资源，允许你根据从事件有效载荷中提取的信息来创建流水线。例如，你可以在每次创建 Git 仓库的合并请求时，触发流水线的实例化和执行。 命令行CLI：提供一个名为 tkn 的命令行界面，你可以使用它从终端与 Tekton 进行交互。 仪表盘Dashboard：是 Tekton 流水线的一个基于网页的图形界面，显示流水线的执行信息。 目录Catalog：是一个高质量的、由社区贡献的 Tekton 构建块（任务、流水线等），可在你自己的流水线中使用。 中心Hub：是一个基于网页的图形界面，用于访问 Tekton 目录。 操作员Operator：是一种 Kubernetes 操作员模式，你可以在 Kubernetes 集群中安装、更新、升级和删除 Tekton 项目。 链Chains：是一个 Kubernetes 自定义资源定义Custom Resource Definition（CRD）控制器，使你可以在 Tekton 中处理供应链安全的问题。正在开发中。 结果Results：旨在帮助用户对 CI/CD 工作负载历史进行逻辑分组，并将长期结果的存储从流水线控制器中分离出来。 Tekton 术语 步骤Step：是 CI/CD 工作流程中最基本的实体，例如为 Python 网络应用程序运行一些单元测试或编译一个 Java 程序。Tekton 使用容器镜像执行每个步骤。 任务Task：:** 是按特定顺序排列的步骤的集合。Tekton 以 Kubernetes 容器荚 的形式运行任务，其中每个步骤都成为 容器荚pod 中的一个运行容器。 流水线Pipelines：是按特定顺序排列的任务的集合。Tekton 把所有任务连接成一个 有向无环图directed acyclic graph（DAG），并按顺序执行图。换句话说，它创建了一些 Kubernetes 容器荚，并确保每个容器荚按预期成功运行。 流水线运行PipelineRun：顾名思义，是一条流水线的具体执行。 任务运行TaskRun：是一个任务的具体执行。你可以选择在流水线外运行一次任务运行，可以通过它查看任务中每个步骤执行的具体情况。 创建你的 CI/CD 流水线 开始使用 Tekton 的最简单方法是自己编写一个简单的流水线。如果你每天都在使用 Kubernetes，那你可能对 YAML 很熟悉，这正是 Tekton 流水线的定义方式。下面是一个克隆代码库的简单流水线的例子。\n首先，创建一个 task.yaml 文件，用你喜欢的文本编辑器打开它。这个文件定义了你要执行的 步骤Step。在这个例子中，就是克隆一个仓库，所以我把这个步骤命名为 “clone”。该文件设置了一些环境变量，然后使用一个简单的 shell 脚本来执行克隆。\n接下来是 任务Task。你可以把步骤看作是一个被任务调用的函数，而任务则设置步骤所需的参数和工作空间。\napiVersion: tekton.dev/v1beta1 kind: Task metadata: name: git-clone spec: workspaces: - name: output description: The git repo will be cloned onto the volume backing this Workspace. params: - name: url description: Repository URL to clone from. type: string - name: revision description: Revision to checkout. (branch, tag, sha, ref, etc...) type: string default: \u0026#34;\u0026#34; steps: - name: clone image: \u0026#34;gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/git-init:v0.21.0\u0026#34; env: - name: PARAM_URL value: $(params.url) - name: PARAM_REVISION value: $(params.revision) - name: WORKSPACE_OUTPUT_PATH value: $(workspaces.output.path) script: | #!/usr/bin/env sh set -eu CHECKOUT_DIR=\u0026#34;${WORKSPACE_OUTPUT_PATH}\u0026#34; /ko-app/git-init \\ -url=\u0026#34;${PARAM_URL}\u0026#34; \\ -revision=\u0026#34;${PARAM_REVISION}\u0026#34; \\ -path=\u0026#34;${CHECKOUT_DIR}\u0026#34; cd \u0026#34;${CHECKOUT_DIR}\u0026#34; EXIT_CODE=\u0026#34;$?\u0026#34; if [ \u0026#34;${EXIT_CODE}\u0026#34; != 0 ] ; then exit \u0026#34;${EXIT_CODE}\u0026#34; fi # Verify clone is success by reading readme file. cat ${CHECKOUT_DIR}/README.md 创建第二个文件 pipeline.yaml，并用你喜欢的文本编辑器打开它。这个文件通过设置诸如可以运行和处理任务的工作区等重要参数来定义流水线。\napiVersion: tekton.dev/v1beta1 kind: Pipeline metadata: name: cat-branch-readme spec: params: - name: repo-url type: string description: The git repository URL to clone from. - name: branch-name type: string description: The git branch to clone. workspaces: - name: shared-data description: | This workspace will receive the cloned git repo and be passed to the next Task for the repo\u0026#39;s README.md file to be read. tasks: - name: fetch-repo taskRef: name: git-clone workspaces: - name: output workspace: shared-data params: - name: url value: $(params.repo-url) - name: revision value: $(params.branch-name) 最后，创建一个 pipelinerun.yaml 文件，用喜欢的文本编辑器打开它。这个文件真正的运行流水线。它调用流水线中定义的参数（继而调用任务文件中定义的任务）。\napiVersion: tekton.dev/v1beta1 kind: PipelineRun metadata: name: git-clone-checking-out-a-branch spec: pipelineRef: name: cat-branch-readme workspaces: - name: shared-data volumeClaimTemplate: spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi params: - name: repo-url value: \u0026lt;https://github.com/tektoncd/pipeline.git\u0026gt; - name: branch-name value: release-v0.12.x 把不同工作分在不同的文件中的好处是，git-clone 任务可以在多条流水线中复用。\n例如，假设你想为一个流水线项目做端到端的测试。你可以使用 git-clone 任务 来让每一次测试都基于最新的代码。\n总结 只要你熟悉 Kubernetes，那 Tekton 对你来说就像其他 Kubernetes 原生应用一样简单。它有很多工具可以帮助你创建流水线并与之交互。如果你喜欢自动化，不妨试试 Tekton!\nvia: https://opensource.com/article/21/11/cicd-pipeline-kubernetes-tekton\n作者：Savita Ashture 选题：lujun9972 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2023-04-01T23:09:26Z","permalink":"https://lxb.wiki/2966fc1/","title":"【译】用 Tekton 在 Kubernetes 中编写你的第一条 CI/CD 流水线"},{"content":" 什么是编译原理 编译原理是介绍如何将高级程序设计语言转换成计算机硬件能识别的机器语言，以便计算机进行处理\n编译与计算机程序设计语言的关系 日常开发过程中我们使用的语言一般都是高级语法比如 JAVA、Python、PHP、JavaScript等等，但是计算机只能识别0、1这样的机器码。那么这些高级语言是如何翻译成机器能识别的0、1等呢？这就用的了编译，首先我们通过下面这幅图看下编译与计算机程序语言的关系，有助于我们直观的了解编译的作用。\n注意：每种机器都对应一种汇编语言\n程序设计语言的转换方式 翻译：指把某种语言的源程序，在不改变语义的条件下，转换成另一种语言程序即目标语言程序\n真正的实现有两种方式，编译及解释\n编译：专指由高级语言转换为低级语言，整个程序翻译。常用的例如： c、c++，delphi,Fortran、Pascal、Ada 解释：接受某种高级语言的一个语句输入，进行解释并控制计算机执行，马上得到这个句子的执行结果，然后再接受下一个语句。类似口译，一句一句进行解释。常用的例如：python 解释以源程序作为输入，不产生目标程序，一边解释一边执行。优点：直观易懂，结构简单，易于实现人机对话。缺点：效率低(不产生目标程序，每次都需要重新执行，速度慢) 编译的转换过程 编译-\u0026gt;运行 编译-\u0026gt;汇编-\u0026gt;运行 编译器在语言处理系统中的位置 了解了编译与程序设计语言的关系，那么我们接下来再来看下编译器在语言处理系统中所处位置，如下图\n编译系统的结构 那么机器是如何把高级语言翻译为汇编语言程序或机器语言程序的呢？\n我们先来看下人工进行英文翻译的例子，这里引用的哈工大编译原理中的图示\n图中的中间表示很重要主要起到了一个桥梁的作用，比如图中的中间表示可以使用各种语言表示。\n根据上图可以看出要进行语义分析首先需要划分句子成分，那么我们是如何划分句子成分的呢？\n首先通过词法分析分析出句子中各个单词的词性或者词类 接下来通过语法分析识别出句子中的各类短语从而获得句子的结构 然后进行语义分析根据句子结构分析出句子中各个短语在句子中充当什么成分，从而确定各个名词性成分同各个核心谓语动词间的关系语意关系 最后给出中间表示形式 实际上编译器在工作的时候也是经过了以上几个步骤，我们成为阶段(计算机的逻辑组织方式，在实现过程中多个阶段可能会被组合在一起实现)，可以分为两大部分：分析源语言、生成目标代码,在编译器中他们分别对应编译器的前端和后端两个部分。编译器的结构如下图 了解了编译器的结构，让我们从编译器的前端开始讲起，看看词法分析、语法分析、语义分析等各个阶段都做了什么。 词法分析(扫描) 编译的第一个阶段，从左到右逐行扫描源程序的字符，识别出各个单词(是高级语言中有是在意义的最小语法单元，由字符构成)，确定单词的类型。将识别的单词转换成统一的机内表示即词法单元 简称Token\ntoken:\u0026lt;种别码，属性值\u0026gt;token: \u0026lt;种别码，属性值\u0026gt;\n单词类型 种别 种别码 1 关键字 program、if、else、then\u0026hellip; 一词一码 2 标识符 变量名、数组名、记录名、过程名\u0026hellip; 多词一码 3 常量 整型、浮点型、字符型、布尔型\u0026hellip; 一型一码 4 运算符 算术（+ - * / ++ \u0026ndash;）关系（\u0026gt; \u0026lt; == != \u0026gt;= \u0026lt;=） 逻辑（\u0026amp; | ~） 一词一码或一型一码 5 界限符 ; ( ) = { } 一词一码 名字解释\n一词一码：例如，关键字是唯一的且事先可以确定，为每个关键字分配一个种别码\n多词一码：例如，所有的标示符统一作为一类单词分配同一个种别码，为了区分不同的标示符，用token的第二个分量“属性值”存放不同标示符具体的字面值\n一型一码：不同类型的常量他们的构成方式是不同的，例如，我们为每种类型的常量分配一个种别码，为了区分同一类型下的不同常量，也用token的第二个分量“属性值”存放每个常量具体的值 下面图中是一个词法分析后得到的token序列的例子\n描述词法规则的有效工具是正规式和有限自动机。正规式:用来确定单词是否和程序语言规范。有限自动机：通过有限自动机进行单词和正规式比较\n语法分析(parsing) 语法分析的定义 语法分析器从词法分析器输出的token序列中识别出各类短语，并构造语法分析树(parse tree),语法分析树描述了句子的语法结构\n语法分析的规则 即语法规则又称文法，规定了单词如何构成短语、句子、过程和程序。\n语法规则的标示如下，含义是A定义为B或者C\nBNF:A::=B∣CBNF:A::=B|C\n\u0026lt;句子\u0026gt;::=\u0026lt;主\u0026gt;\u0026lt;谓\u0026gt;\u0026lt;宾\u0026gt;\u0026lt;句子\u0026gt;::=\u0026lt;主\u0026gt;\u0026lt;谓\u0026gt;\u0026lt;宾\u0026gt;\n\u0026lt;主\u0026gt;::=\u0026lt;定\u0026gt;\u0026lt;名\u0026gt;\u0026lt;主\u0026gt;::=\u0026lt;定\u0026gt;\u0026lt;名\u0026gt;\n来看下赋值语句的语法规则：\nA::=V=E E::=T|E+T T::=F|T*F F::=V|(E)|C V::=标示符 C::=常数 即由标示符或者常数的表达式进行加减乘除运算 语法分析的方法 推导(derive)和归约(reduce)\n推导：最左推导、最右推导 归约：最右归约、最左归约,推导的逆过程就是归约 最右推导、最左归约：\n最左推导、最右归约：\n语法树 计算机通过语法树来进行分析，即语法分析过程也可以用一颗倒着的树来标示，这颗树叫语法树。正确的语法树叶子节点数必须是表达式的符号，例如\n赋值语句的分析树：\n变量声明语句的分析树：\n首先看下变量声明语句的文法(文法是由一系列规则构成的)：\n\u0026lt;D\u0026gt; -\u0026gt; \u0026lt;T\u0026gt; \u0026lt;IDS\u0026gt;; \u0026lt;T\u0026gt; -\u0026gt; int | real | char | bool \u0026lt;IDS\u0026gt; -\u0026gt; id | \u0026lt;IDS\u0026gt;, id 语义分析 语义的任务主要有两个\n一. 收集标识符的属性信息 二. 语义检查 变量或过程未经声明就使用 变量或过程名重复声明 运算分量类型不匹配 操作符与操作数之间的类型不匹配 数组下标不是整数 对非数组变量使用数组访问操作符 对非过程名使用过程调用操作符 过程调用的**参数类型或数目不匹配 ** 函数返回类型有误 中间代码生成 通常和语义分析一起实现。对语法分析识别出的各类语法范畴，分析他的含义，进行初步翻译，产生介于源代码和目标代码质检的一种代码\n常用的中间代码表示形式 三地址码 (Three-address Code)：三地址码由类似于汇编语言的指令序列组成，每个指令最多有三个操作数(operand) 语法结构树/语法树 (Syntax Trees) 逆波兰式 三地址指令的表示：\n四元式 (Quadruples)，(op, y, z, x) 三元式 (Triples) 间接三元式(Indirect triples) 下面图中展示了一个中间代码生成的例子 代码优化 对前面生成的中间代码进行加工变换，以便在最后极端产生更为高效的目标代码 ，需要遵循等价变换的原则，优化的方面包括：公共子表达式的提取、合并已知量、删除无用语句、循环优化。\n目标代码生成 把经过优化的中间代码转化成特定机器上的低级语言\n目标代码的形式：\n绝对指令代码：可立即执行的目标代码 汇编指令代码：汇编语言程序，需要经过汇编陈旭汇编后才能运行 可重定位指令代码：先将各目标模块连接起来，确定变量、常数在主存中的位置，装入主存后才能成为可以运行的绝对指令代码 其他 出错处理 如果源程序有错误，编译程序应设法发现错误并报告给用户。由专门的出错处理程序来完成。 错误类型：\n语法错误：在词法分析和语法分析阶段检测出来 语义错误：一般在语义分析阶段检测 逻辑错误：不可检测，比如死循环，一般不处理因为没办法在编译阶段检测出来 遍 指对源程序或源程序的中间结果从头到尾扫描一次，并做有关的加工处理，生成新的中间结果或目标代码。遍与阶段的含义毫无关系\n多遍扫描： 优点：节省内存空间，提高目标代码的质量，使编译的逻辑结构清晰。缺点：编译时间长。在内存许可的情况下还是遍数尽可能少较好 编译程序生成 直接用机器语言编写编译程序 用汇编语言编写编译程序，编译程序核心部分常用汇编语言编写 用高级语言编写编译程序，这也是普遍采用的方法 自编译 编译工具 LEX（语法分析）与YACC(用于自动生成LALR分析表) 移植(同种语言的编译程序在不同类型的机器之 间移植) 在某机器上为某种语言构造编译程序要掌握以下三方面: 源语言 目标语言 编译方法 ","date":"2023-02-24T22:31:55+08:00","permalink":"https://lxb.wiki/a66c6839/","title":"编译原理一"},{"content":" Creative Commons Attribution 4.0 International License (CC BY 4.0)【署名】 注：用户可以复制、发行、展览、表演、放映、广播或通过信息网络传播此作品，但必须按照提交者指定的方式对作品进行署名。\n​\nCreative Commons Attribution-ShareAlike 4.0 International License (CC BY-SA4.0)【署名-相同方式共享】 注：用户可以复制、发行、展览、表演、放映、广播或通过信息网络传播此作品，但必须按照提交者指定的方式对作品进行署名，若改变、转变或变更本作品，必须遵守与本作品相同的授权条款才能传播由本作品产生的演绎作品。\n​\nCreative Commons Attribution-Noncommercial 4.0 International License (CC BY-NC 4.0)【署名-非商业使用】 注：用户可以复制、发行、展览、表演、放映、广播或通过信息网络传播此作品，但必须按照提交者指定的方式对作品进行署名，并且不得为商业目的使用本作品。\n​\nCreative Commons Attribution-Noncommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0) 【署名-非商业使用-相同方式共享】 注：用户可以复制、发行、展览、表演、放映、广播或通过信息网络传播此作品，但必须按照提交者指定的方式对作品进行署名，并且不得为商业目的而使用本作品。若改变、转变或变更本作品，必须遵守与本作品相同的授权条款才能传播由本作品产生的演绎作品。\n​\nCreative Commons Attribution-NoDerivatives 4.0 International License(CC BY-ND 4.0)【署名-禁止演绎】 注：用户可以复制、发行、展览、表演、放映、广播或通过信息网络传播此作品，但必须按照提交者指定的方式对作品进行署名。若用户再混合、转换、或者基于该作品进行创作，则不可以传播由本作品产生的演绎作品。\n​\nCreative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License(CC BY-NC-ND 4.0)【署名-非商业使用-禁止演绎】 注：用户可以复制、发行、展览、表演、放映、广播或通过信息网络传播此作品，但必须按照提交者指定的方式对作品进行署名，并且不得为商业目的使用本作品。若用户再混合、转换、或者基于该作品进行创作，则不可以传播由本作品产生的演绎作品。\n​\nCreative Commons Public Domain Dedication (CC0 1.0) 注：社会公众可以以任何方式、出于任何目的免费使用该作品)。\n","date":"2023-02-05T21:58:44+08:00","permalink":"https://lxb.wiki/c12bcad7/","title":"开放共享协议"},{"content":" 无论你是刚刚开始在你的组织中使用 DevOps，还是仅仅想改善你现有的文化，请考虑这些技巧以及它们与你组织的未来的关系。\n你为什么要构建 DevOps 文化？开发团队和运维团队的精简协作有很多好处。效率是首要目标：提高新软件部署的速度，减少等待的时间。培养同事之间的信任可以提升员工的满意度，激发新的创新，并对盈利能力产生积极的影响。\nDevOps 是一个很广泛的思想，大家的理解也见仁见智。每个公司对于如何实行 DevOps 也各不相同。这种意见的多样性实际上是一件好事 —— 这么多的观点对于建立更强大的团队是很有用的。本指南将探讨在 DevOps 文化中鼓励同事之间更好地合作的最高技巧。\n下面每个部分从不同的视角介绍 DevOps 文化，并探讨了将它引入员工队伍的方法。\n流程的持续发展 DevOps 文化的这一核心原则使它与许多其他类型的工作场所的风气区别开来。DevOps 哲学说，犯错是有积极意义的，因为这表明你在尝试新的想法。\nDevOps 文化的核心是不停地创造。实际上，这意味着当测试结果显示事情由于你的改动而变坏时，不要懊恼。我们要认识到，进化的过程不是线性的，通往成功的道路也从来不是一条直线。\nDevOps 专家 Gene Kim 主张勇于承担风险和进行实验。鼓励你的团队尝试不寻常的任务，以得到新的领悟。\n你的组织应该以利润为导向吗？你能允许你的团队尝试一些新东西（非指个人兴趣项目）吗？持续的流程发展意味着对升级目前的方法持开放态度。优秀的销售领导懂得，结果比出勤率更重要，因此，关注团队的工作方式而不是工作量的多少始终是关键。\n随时提供反馈并积极寻求反馈 成员之间增加信任是蓬勃发展的 DevOps 文化的另一个关键特征。无论你的员工是在学习如何建立联盟网络联系，还是试图设计他们的下一个 用户体验 调查，每个人都应该对他们工作的反馈持开放态度。但是，除非你的团队成员尊重彼此的意见，并相信反馈是本着善意的精神提出的，否则这永远不会发生。\n这种文化听起来可能是很难培养的；事实上，一些公司会比其他公司更努力地实现这一点。诚然，给予和接受反馈的成功很大程度上取决于员工的个性。在招聘过程中，也可以对此进行筛选。\n在你期望员工随时向同事提供反馈并主动寻求反馈之前，你应该以身作则。高管应该以身作则，公开要求公司成员对其战略决策提出探究性问题，并提供相应的反馈。\n不断改进 在同事之间增加对智力信任的基础上，你的团队应该寻找方法来改善其工作。DevOps 的性质意味着软件开发团队将比传统方法更迅速地进行部署。\n这种开放的改进文化可以对开发和运维以外的部门产生积极的影响。你也可以自己去探索企业还有哪些领域会受到积极的影响。\n留意培训和提高技能的机会。即使一个培训课程没有广告上说的那么突出，但有机会与行业专家建立联系，并与未来建立联系，这可以提高你的组织内的思想多样性。\n为以后的开发保存当前的想法 频繁使用的 Git 账户应该是你的 DevOps 工具链的一部分。你可以用 Git 作为软件开发和其他相关项目中产生的脚本的共同仓库。Git 作为 “版本控制” 工具而被熟知，Git 允许程序员保存他们工作的迭代、复用或改进其他人的工作。\n你的目标是能够保留好的想法以供将来使用。某个方法由于某种原因没有成功。然而，那套想法在当时是错误的，并不意味着它在未来永远无法成为有用的东西。\n由于 DevOps 的整个重点在于生产环境中的软件的端到端所有权，因此节省开发的迭代真正支持这一原则。你希望看到对手头的软件测试项目的持续关注和投入。\n一个简单的方法是要求开发者在开发者合同和最终项目报告中包含对未来工作的想法。确保技术服务经理知道他们应该要求提供在建设过程中出现的旁门左道的想法的例子。意识到这些小创新的人越多，在需要的时候就越有可能有人记住一个。\n坐在一起（物理上或逻辑上） 目标是对彼此的工作角色以及它们之间的相互关系有一个共同的理解。你可以通过几个简单的方法实现这一目标，用一句话概括：坐在一起。邀请其他团队参加你们的会议，完整地分享用户反馈报告。一起吃午饭，一起计划虚拟的快乐时光，一般来说，要确保你的同事都在一起。大约 90% 的拥有成熟的 DevOps 协议的团队报告说，他们清楚地了解自己对其他团队的责任，而在不成熟的 DevOps 团队中，只有大约 46% 的工作者清楚地了解自己的责任。\n虽然与志同道合的人结成小团体，只与被雇来执行与你相同任务的员工在一起是很诱人的，但这对整个企业来说是很糟糕的。无论你喜欢与否，所有的人都是多面手，能够在一系列的情况下贡献自己的独特才能。\n密切协作的理念是尊重任何人对其周围正在进行的产品或工作流程提出改进建议的能力。如果你与公司内的其他部门保持一定的距离，你将会错过无数次分享智慧想法的机会。毕竟，你往往在交流中学习得最好。\n致力于自动化 你应该以提高效率和加速流程的名义，寻求将单调的和重复的任务变为自动化。每个行业都有无聊的 —— 说得直白一点，就是愚蠢的 —— 每天或每周都要进行的工作。\n无论是手工将数据从一页复制到另一页，还是手工打出音频记录，每个级别的工作人员都应该坚持让机器在可能的情况下承担这些负担。现实是自动化技术每年都在进步，操作流程也应该如此。自动化测试 对 DevOps 非常关键，它是 CALMS 框架的第二个原则（其中的 “C” 代表 “文化”）。\n你怎样才能实现这一点？邀请员工公开表达他们认为工作的哪些方面可以自动化，然后 —— 这里是关键的部分 —— 支持实现自动化所需的设施。这可能意味着每年花 600 美元订阅一个软件程序、一套完整的企业应用现代化解决方案，或开发人员用两天时间来建立一个在内部使用新工具。\n无论哪种方式，你都应该评估自动化的好处，考虑你可以为每个人节省多少时间。DevOps 的统计数据不断表明，现代公司通过整合这些有益的原则，年复一年地得到了很大的改善。\n探索成功的新工作方式 文化转变不会在一夜之间发生。不过，你越早开始，就越早看到结果。根据我的经验，当变化真正对以前进行了改进时，人们会接受它。DevOps 为这种改进提供了一个框架。无论你是刚刚在你的组织中开始使用 DevOps，还是仅仅想改善你现有的文化，请考虑以上几点以及它们与你组织的未来的关系。\nvia: https://opensource.com/article/23/1/tips-effective-devops-culture\n作者：Yauhen Zaremba 选题：lkxed 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2023-01-30T21:58:33Z","permalink":"https://lxb.wiki/12428ad2/","title":"【译】构建高效的 DevOps 文化的 6 个技巧"},{"content":"蓝绿发布(Blue-Green Deployment) 蓝绿发布提供了一种零宕机的部署方式。不停老版本，部署新版本进行测试，确认OK，将流量切到新版本，然后老版本同时也升级到新版本。始终有两个版本同时在线，有问题可以快速切换。\n蓝绿部署中，一共有两套系统：\n一套是正在提供服务系统，标记为“绿色”； 另一套是准备发布的系统，标记为“蓝色”。 优缺点\n优点：新版本升级和老版本回滚迅速。用户可以灵活控制流量走向\n缺点：成本较高，需要部署两套环境（蓝/绿）\n比如日常运行时，需要10台服务器支撑业务，那么使用蓝绿部署，你就需要购置二十台服务器。\n金丝雀发布/灰度发布(Canary Release) 灰度发布 Gray Release（又名金丝雀发布 Canary Release）\n金丝雀发布有一个有趣的小故事，被称为「金丝雀在矿井」。这个故事用来形象地描述金丝雀发布策略的概念。\n故事背景是在过去的煤矿开采中，矿工们面临着一种危险的情况，即有毒气体的积累。由于无法直接检测到这些气体，矿工们需要一种警报机制来提醒他们是否面临危险。他们找到了一种解决方案：带上一只小小的金丝雀。\n矿工们将金丝雀放入煤矿，如果气体达到了危险的水平，金丝雀会首先受到影响并死亡，从而警示矿工们立即离开矿井以避免危险。这种警报系统保护了矿工的生命安全。\n不停机旧版本，部署新版本，高比例流量（例如：95%）走旧版本，低比例流量（例如：5%）切换到新版本，通过监控观察无问题，逐步扩大范围，最终把所有流量都迁移到新版本上。属无损发布\n在软件开发中，灰度测试通常涉及将新功能或更新推送到一小部分用户，例如5％或10％的用户。\n这些用户将能够使用新功能或更新，而其他用户则不会看到它们。\n通过监视这些用户的反馈和行为，开发人员可以评估新功能或更新的效果，并识别任何问题或错误。\n在Java中，可以使用一些工具来实现灰度测试，例如FeatureToggle和LaunchDarkly。\n这些工具可以帮助开发人员轻松地控制新功能或更新的推出，并监视用户反馈和行为。\n优点：灵活简单，不需要用户标记驱动。安全性高，新版本如果出现问题，只会发生在低比例的流量上\n缺点：成本较高，需要部署稳定/灰度两套环境\nA/B测试 首先需要明确的是，A/B测试和蓝绿部署以及金丝雀，完全是两回事。\n蓝绿部署和金丝雀是发布策略，目标是确保新上线的系统稳定，关注的是新系统的BUG、隐患。\nA/B测试是效果测试，同一时间有多个版本的服务对外服务，这些服务都是经过足够测试，达到了上线标准的服务，有差异但是没有新旧之分（它们上线时可能采用了蓝绿部署的方式）。\nA/B测试关注的是不同版本的服务的实际效果，譬如说转化率、订单情况等。\nA/B测试时，线上同时运行多个版本的服务，这些服务通常会有一些体验上的差异，譬如说页面样式、颜色、操作流程不同。相关人员通过分析各个版本服务的实际效果，选出效果最好的版本。\n在A/B测试中，需要能够控制流量的分配，譬如说，为A版本分配10%的流量，为B版本分配10%的流量，为C版本分配80%的流量。\n滚动发布（Rolling Release） 每次只升级一个或多个服务，通过观察无问题，不断执行这个过程，直到集群中的全部旧版本升级到新版本。属有损发布\nK8S 默认采用了滚动发布\n优点：成本较低，只需要部署一套环境。出现问题影响范围，只限于发生在若干台正在滚动发布的服务上 缺点：停止旧版本的过程中，无法精确计算旧版本是否已经完成它正在执行的工作，需要靠业务自身去判断。旧版本不保留，一旦全部升级完毕后才发现问题，无法快速回滚，必须重新降级部署。发布和回滚需要较长的时间周期 红黑部署(Red-Black Deployment) 这是Netflix采用的部署手段，Netflix的主要基础设施是在AWS上，所以它利用AWS的特性，在部署新的版本时，通过AutoScaling Group用包含新版本应用的AMI的LaunchConfiguration创建新的服务器。测试不通过，找到问题原因后，直接干掉新生成的服务器以及Autoscaling Group就可以，测试通过，则将ELB指向新的服务器集群，然后销毁掉旧的服务器集群以及AutoScaling Group。\n红黑部署的好处是服务始终在线，同时采用不可变部署的方式，也不像蓝绿部署一样得保持冗余的服务始终在线。\n","date":"2023-01-10T21:48:25+08:00","permalink":"https://lxb.wiki/8b49ed57/","title":"几种发布策略"},{"content":"在 Golang 中用于执行命令的库是 os/exec，exec.Command 函数返回一个 Cmd 对象，根据不同的需求，可以将命令的执行分为三种情况\n只执行命令，不获取结果 执行命令，并获取结果（不区分 stdout 和 stderr） 执行命令，并获取结果（区分 stdout 和 stderr） 第一种：只执行命令，不获取结果# 直接调用 Cmd 对象的 Run 函数，返回的只有成功和失败，获取不到任何输出的结果。\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;os/exec\u0026#34; ) func main() { cmd := exec.Command(\u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, \u0026#34;/var/log/\u0026#34;) err := cmd.Run() if err != nil { log.Fatalf(\u0026#34;cmd.Run() failed with %s\\n\u0026#34;, err) } } 第二种：执行命令，并获取结果# 有时候我们执行一个命令就是想要获取输出结果，此时你可以调用 Cmd 的 CombinedOutput 函数。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os/exec\u0026#34; ) func main() { cmd := exec.Command(\u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, \u0026#34;/var/log/\u0026#34;) out, err := cmd.CombinedOutput() if err != nil { fmt.Printf(\u0026#34;combined out:\\n%s\\n\u0026#34;, string(out)) log.Fatalf(\u0026#34;cmd.Run() failed with %s\\n\u0026#34;, err) } fmt.Printf(\u0026#34;combined out:\\n%s\\n\u0026#34;, string(out)) } CombinedOutput 函数，只返回 out，并不区分 stdout 和 stderr。如果你想区分他们，可以直接看第三种方法。\n$ go run demo.go combined out: total 11540876 -rw-r--r-- 2 root root 4096 Oct 29 2018 yum.log drwx------ 2 root root 94 Nov 6 05:56 audit -rw-r--r-- 1 root root 185249234 Nov 28 2019 message -rw-r--r-- 2 root root 16374 Aug 28 10:13 boot.log 不过在那之前，我却发现一个小问题：有时候，shell 命令能执行，并不代表代码 exec 也能执行。\n比如我只想查看 /var/log/ 目录下的 log 后缀名的文件呢？shell命令如下\n$ ls -l /var/log/*.log total 11540 -rw-r--r-- 2 root root 4096 Oct 29 2018 /var/log/yum.log -rw-r--r-- 2 root root 16374 Aug 28 10:13 /var/log/boot.log 按照这个写法将它放入到 exec.Command\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os/exec\u0026#34; ) func main() { cmd := exec.Command(\u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, \u0026#34;/var/log/*.log\u0026#34;) out, err := cmd.CombinedOutput() if err != nil { fmt.Printf(\u0026#34;combined out:\\n%s\\n\u0026#34;, string(out)) log.Fatalf(\u0026#34;cmd.Run() failed with %s\\n\u0026#34;, err) } fmt.Printf(\u0026#34;combined out:\\n%s\\n\u0026#34;, string(out)) } 什么情况？居然不行，报错了。\n$ go run demo.go combined out: ls: cannot access /var/log/*.log: No such file or directory 2020/11/11 19:46:00 cmd.Run() failed with exit status 2 exit status 1 为什么会报错呢？\n其实很简单，原来 ls -l /var/log/*.log 并不等价于下面这段代码。\nexec.Command(\u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, \u0026#34;/var/log/*.log\u0026#34;) 上面这段代码对应的 Shell 命令应该是下面这样，如果你这样子写，ls 就会把参数里的内容当成具体的文件名，而忽略通配符 *\n$ ls -l \u0026#34;/var/log/*.log\u0026#34; ls: cannot access /var/log/*.log: No such file or directory 第三种：执行命令，并区分stdout 和 stderr# 上面的写法，无法实现区分标准输出和标准错误，只要换成下面种写法，就可以实现。\npackage main import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os/exec\u0026#34; ) func main() { cmd := exec.Command(\u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, \u0026#34;/var/log/*.log\u0026#34;) var stdout, stderr bytes.Buffer cmd.Stdout = \u0026amp;stdout // 标准输出 cmd.Stderr = \u0026amp;stderr // 标准错误 err := cmd.Run() outStr, errStr := string(stdout.Bytes()), string(stderr.Bytes()) fmt.Printf(\u0026#34;out:\\n%s\\nerr:\\n%s\\n\u0026#34;, outStr, errStr) if err != nil { log.Fatalf(\u0026#34;cmd.Run() failed with %s\\n\u0026#34;, err) } } 输出如下，可以看到前面的报错内容被归入到标准错误里\n$ go run demo.go out: err: ls: cannot access /var/log/*.log: No such file or directory 2020/11/11 19:59:31 cmd.Run() failed with exit status 2 exit status 1 第四种：多条命令组合，请使用管道# 将上一条命令的执行输出结果，做为下一条命令的参数。在 Shell 中可以使用管道符 | 来实现。\n比如下面这条命令，统计了 message 日志中 ERROR 日志的数量。\n$ grep ERROR /var/log/messages | wc -l 19 类似的，在 Golang 中也有类似的实现。\nCopyCopypackage main import ( \u0026#34;os\u0026#34; \u0026#34;os/exec\u0026#34; ) func main() { c1 := exec.Command(\u0026#34;grep\u0026#34;, \u0026#34;ERROR\u0026#34;, \u0026#34;/var/log/messages\u0026#34;) c2 := exec.Command(\u0026#34;wc\u0026#34;, \u0026#34;-l\u0026#34;) c2.Stdin, _ = c1.StdoutPipe() c2.Stdout = os.Stdout _ = c2.Start() _ = c1.Run() _ = c2.Wait() } 输出如下\n$ go run demo.go 19 第五种：设置命令级别的环境变量# 使用 os 库的 Setenv 函数来设置的环境变量，是作用于整个进程的生命周期的。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/exec\u0026#34; ) func main() { os.Setenv(\u0026#34;NAME\u0026#34;, \u0026#34;myname\u0026#34;) cmd := exec.Command(\u0026#34;echo\u0026#34;, os.ExpandEnv(\u0026#34;$NAME\u0026#34;)) out, err := cmd.CombinedOutput() if err != nil { log.Fatalf(\u0026#34;cmd.Run() failed with %s\\n\u0026#34;, err) } fmt.Printf(\u0026#34;%s\u0026#34;, out) } 只要在这个进程里，NAME 这个变量的值都会是 myname，无论你执行多少次命令\n$ go run demo.go myname 如果想把环境变量的作用范围再缩小到命令级别，也是有办法的。\n为了方便验证，我新建个 sh 脚本，内容如下\n$ cat /home/myname/demo.sh echo $NAME $ bash /home/myname/demo.sh # 由于全局环境变量中没有 NAME，所以无输出 另外，demo.go 里的代码如下\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/exec\u0026#34; ) func ChangeYourCmdEnvironment(cmd * exec.Cmd) error { env := os.Environ() cmdEnv := []string{} for _, e := range env { cmdEnv = append(cmdEnv, e) } cmdEnv = append(cmdEnv, \u0026#34;NAME=myname\u0026#34;) cmd.Env = cmdEnv return nil } func main() { cmd1 := exec.Command(\u0026#34;bash\u0026#34;, \u0026#34;/home/myname/demo.sh\u0026#34;) ChangeYourCmdEnvironment(cmd1) // 添加环境变量到 cmd1 命令: NAME=myname out1, _ := cmd1.CombinedOutput() fmt.Printf(\u0026#34;output: %s\u0026#34;, out1) cmd2 := exec.Command(\u0026#34;bash\u0026#34;, \u0026#34;/home/myname/demo.sh\u0026#34;) out2, _ := cmd2.CombinedOutput() fmt.Printf(\u0026#34;output: %s\u0026#34;, out2) } 执行后，可以看到第二次执行的命令，是没有输出 NAME 的变量值。\n$ go run demo.go output: myname output: ","date":"2022-12-04T21:16:01+08:00","permalink":"https://lxb.wiki/a9bb05dc/","title":"Go语言中用exec执行命令的五种姿势"},{"content":" 大家好！今年早些时候，我在写《[DNS 是如何工作的][1]》 时，有人问我——为什么人们有时在域名的末尾加一个点？例如，如果你通过运行 dig example.com 查询 example.com 的 IP，你会看到一下内容：\n$ dig example.com example.com. 5678 IN A 93.184.216.34 执行完 dig 命令后，example.com 有一个 . ——变成了 example.com.！发生了什么？\n有些 DNS 工具也要求传给它的域名后加一个 .：如果你在使用 [miekg/dns][2] 时传给它 example.com，它会报错：\n// trying to send this message will return an error m := new(dns.Msg) m.SetQuestion(\u0026#34;example.com\u0026#34;, dns.TypeA) 最初我以为我知道这个问题的答案（“呃，末尾的点意味着域名是完全限定的？”）。这是对的 —— 一个完全限定域名fully qualified domain name（FQDN）是一个末尾有 . 的域名！\n但是为什么末尾的点是有用且重要的呢？\n在 DNS 的请求/响应中，域名的末尾并没有 “.” 我曾经（错误地）认为 “为什么末尾有一个点？”的答案可能是 “在 DNS 请求/响应中，域名末尾有一个 .，所以我们把它放进去，以匹配你的计算机实际发送/接收的内容”。但事实并不是这样！\n当计算机发送 DNS 请求/响应时，域名的末尾并没有点。实际上，域名中没有点。\n域名会被编码成一系列的长度/字符串对。例如，域名 example.com 被编码为这 13 个字节。\n7example3com0 编码后的内容一个点也没有。一个 ASCII 域名（如 example.com）被转成了各种 DNS 软件的 DNS 请求/响应中使用的格式。\n今天我们来讨论域名被转成 DNS 响应的一个地方：区域文件。\n区域文件中域名末尾的 “.” 一些人管理域名的 DNS 记录的方法是创建一个被称为 “区域文件” 的文本文件，然后配置一些 DNS 服务器软件（如 nsd 或 bind）来为该区域文件中指定的 DNS 记录提供服务。\n下面是一个对应 example.com 的示例区域文件：\norange 300 IN A 1.2.3.4 fruit 300 IN CNAME orange grape 3000 IN CNAME example.com. 在这个文件中，任何不以 . 结尾的域名（比如 orange）后都会自动加上 .example.com。所以 orange 成了 orange.example.com 的简称。DNS 服务器从它的配置中得知这是一个 example.com 的区域文件，所以它知道在所有不以点结尾的名字后面自动添加 example.com。\n我想这里的想法只是为了少打几个字符——如果要打出全称，区域文件会是这样：\norange.example.com. 300 IN A 1.2.3.4 fruit.example.com. 300 IN CNAME orange.example.com. grape.example.com. 3000 IN CNAME example.com. 确实多了很多字符。\n你也可以不通过区域文件来使用 DNS 尽管官方的 DNS RFC（[RFC 1035][3]）中定义了区域文件格式，但你也可以不通过区域文件来使用 DNS。例如，AWS Route 53 就不用区域文件来存储 DNS 记录！你可以通过 Web 界面或 API 来创建记录，我猜他们是用某种数据库而不是一堆文本文件来存储记录。\n不过，Route 53（像许多其他 DNS 工具一样）确实支持导入和导出区域文件，这个功能或许在你更换 DNS 提供商时很有用。\ndig 命令输出中末尾的 “.” 现在我们来讨论下 dig 命令的输出：\n$ dig example.com ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.18.1-1ubuntu1.1-Ubuntu \u0026lt;\u0026lt;\u0026gt;\u0026gt; +all example.com ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 10712 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 65494 ;; QUESTION SECTION: ;example.com. IN A ;; ANSWER SECTION: example.com. 81239 IN A 93.184.216.34 有一件奇怪的事是，几乎每一行都以 ;; 开头，这是怎么回事？; 是区域文件中的注释字符！\n我想 dig 以这种奇怪的方式输出的原因可能是为了方便你粘贴这些内容到区域文件时，不用修改就可以直接用。\n这也是 example.com 末尾有个 . 的原因 —— 区域文件要求域名末尾必须有点（否则它们会被解释为是相对于该区域的）。因此 dig 也这么处理了。\n我真的希望 dig 有一个 +human 选项，以更人性化的方式打印出这些信息，但现在我太懒了，懒得花工夫去实际贡献代码来做这件事（而且我并不擅长 C），所以我只能在我的博客上抱怨一下 :)\ncurl 命令输出中末尾的 “.” 我们来看下另一个末尾有 . 的例子：curl！\n我家里有台计算机名为 grapefruit，其上运行着 Web 服务器。当我执行 curl grapefruit 时，会输出：\n$ curl grapefruit \u0026lt;!DOCTYPE HTML PUBLIC \u0026#34;-//W3C//DTD HTML 4.01//EN\u0026#34; \u0026#34;http://www.w3.org/TR/html4/strict.dtd\u0026#34;\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; ...... 这样运行没问题！但是如果我在域名后加一个 . 会怎样呢？它报错了：\n$ curl grapefruit. curl: (6) Could not resolve host: grapefruit. 发生了什么？为了搞清楚，我们需要先来学习下搜索域：\n初识搜索域 当我执行 curl grapefrult 时，它是怎么被转成一个 DNS 请求的？你可能会认为我的计算机会向域名 grapefruit 发送一个请求，对吗？但事实并不是这样。\n让我们用 tcpdump 来看看到底是什么域名在被查询。\n$ sudo tcpdump -i any port 53 [...] A? grapefruit.lan. (32) 实际上是向 grapefruit.lan. 发送的请求。为什么呢？\n解释一下：\ncurl 调用函数 getaddrinfo 来查询 grapefruit getaddrinfo 查询了我计算机上的文件 /etc/resolv.conf /etc/resolv.conf 包含两行内容： nameserver 127.0.0.53 search lan 因为有 search lan 这行内容，所以 getaddrinfo 在 grapefruit 的末尾添加了一个 lan，去查询 grapefruit.lan 什么时候搜索域被使用? 现在我们知道了一些奇怪的事情：当我们查询一个域名时，有时会有一个额外的东西（如 lan）被加到最后。但是什么时候会发生这种情况呢？\n如果我们在域名末尾添加一个 .，那么这时不会用到搜索域 如果域名中间包含一个 .（如 example.com），那么默认也不会用到搜索域。但是可以通过修改配置来改变处理逻辑（在 [ndots][4] 里有更详细的说明） 我们现在知道了 curl grapefruit. 与 curl grapefruit 结果不一样的原因——因为一个查询的是 grapefruit.，而另一个查询的是 grapefruit.lan.。\n我的计算机怎么知道使用哪个搜索域呢？ 当我连接路由时，它会通过 DHCP 告诉我它的搜索域是 lan —— 它也是通过这个方式给我的计算机分配 IP。\n所以为什么要在域名末尾加一个点呢？ 现在我们已经了解了区域文件和搜索域，下面是我认为的人们要在域名末尾加点的原因：\n有两种情况下，域名会被修改，并在末尾添加其他东西。\n在 example.com 的区域文件中，grapefruit 会被转为 grapefruit.example.com 在我的本地网络（我的计算机已经配置了使用搜索域 lan），grapefruit 被转为 grapefruit.lan 因此，由于域名在某些情况下实际上可能被转成其他名字，人们就在结尾处加一个 .，以此来表示 “这是域名，末尾不需要添加任何东西，这就是全部内容”。否则会引起混乱。\n“这就是全部内容”的技术术语是**“完全限定域名”，简称为“FQDN”**。所以 google.com. 是一个完全限定域名，而 google.com 不是。\n我总是要提醒自己这样做的原因，因为我很少使用区域文件和搜索域，所以我经常觉得——“我当然是指 google.com 而不是 google.com.something.else! 我为什么要指其他东西？那太傻了！”\n但是有些人确实在使用区域文件和搜索域（例如 Kubernetes 中使用了搜索域！），所以结尾的 . 很有用，可以让人确切的知道，不应该再添加其他东西。\n什么时候在末尾添加 “.”？ 以下是关于何时在域名末尾加 \u0026ldquo;. \u0026quot; 的几个简单说明：\n需要添加：配置 DNS 时\n在配置 DNS 时，使用完全限定域名从来都不是坏事。你不一定要这样做：非完全限定域名通常也能正常工作，但我从来没有遇到过不接受完全限定域名的 DNS 软件。\n有些 DNS 软件需要这样做：现在我为 jvns.ca 使用的 DNS 服务器让我在域名的末尾加上 .（例如在 CNAME 记录中），并提示如果我不添加，它将在我输入的内容末尾加上 .jvns.ca。我不同意这个设计决定，但这不是什么大问题，我只是在最后加一个 .。\n不需要加：在浏览器中\n令人困惑的是，在浏览器中，在域名结尾处加一个 . 不能正常运行。例如，如果我在浏览器中输入 https://twitter.com.，它就会报错。它会返回 404。\n我认为这里发生的事情是，它将 HTTP Host 标头设置为 Host：twitter.com.，而对端的 Web 服务器则期望 Host：twitter.com。\n同样地，https://jvns.ca. 由于某种原因，返回了一个 SSL 错误。\n我认为相对域名在过去是比较常见的 最后一件事：我认为“相对”域名（比如我用 grapefruit 来指代我家的另一台计算机 grapefruit.lan）在过去更常用，因为 DNS 是在大学或其他有大型内部网络的大机构中开发的。\n在今天的互联网上，使用“绝对”域名（如 example.com）似乎更为普遍。\nvia: https://jvns.ca/blog/2022/09/12/why-do-domain-names-end-with-a-dot-/\n作者：Julia Evans 选题：lujun9972 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2022-11-16T22:20:00Z","permalink":"https://lxb.wiki/a258db2c/","title":"【译】域名末尾带个点"},{"content":"\n每个进程都有一个打开的文件表（fdtable)。表中的每一项是struct file类型，包含了打开文件的一些属性比如偏移量，读写访问模式等，这是真正意义上的文件句柄。\n文件描述符是一个整数。代表fdtable中的索引位置（下标），指向具体的struct file（文件句柄）。\n哪些地方会分配文件句柄？\n知道文件句柄最终是通过get_empty_filp函数从filp cache中分配的之后，我们顺着函数调用链路简单梳理下，就能知道有哪些地方会分配文件句柄了：\nopen系统调用打开文件（path_openat内核函数) 打开一个目录（dentry_open函数) 共享内存attach （do_shmat函数） socket套接字（sock_alloc_file函数） 管道（create_pipe_files函数） epoll/inotify/signalfd等功能用到的匿名inode文件系统（anon_inode_getfile函数) file-nr文件里面的第一个字段代表的是内核分配的struct file的个数，也就是文件句柄个数，而不是文件描述符\n机器上的常常会出现文件句柄使用量与常用的lsof命令的数量相去甚远的情况\n因为文件描述符和文件句柄是两个不同的东西：lsof在用户空间，主要还是从文件描述符的角度来看文件句柄。\n我们来做一个实验：只打开一次文件，然后复制1000次文件描述符。\n我们启动dupfd进程打开了一次/dev/zero文件，复制了1000次文件描述符。file-nr中的文件句柄数只是个位数的变化，而lsof看到的结果涨了1000多。\n如果我们把前面的代码换成open 1000次， 就可以看到file-nr和lsof的输出几乎都涨了1000。\n我们循环1000次打开/dev/zero文件，之后mmap映射到进程地址空间，然后把这些打开的文件描述符都关掉。很显然，打开的描述符都被close掉了，不会有什么变化。 那为什么文件句柄数还是增加了1000个左右呢？\n原来，linux内核中很多对象都是有引用计数的。 虽然文件句柄是由open先打开的，但mmap之后，引用计数被加1，尽管我们接着把文件描述符close掉了，但是底层指向的struct file由于引用数大于0，不会被回收。\n","date":"2022-11-02T21:52:46+08:00","permalink":"https://lxb.wiki/200486d9/","title":"Linux 文件句柄与文件描述符"},{"content":"前置依赖 1 创建 Google Cloud 项目 https://console.cloud.google.com/projectcreate\n在项目页面上，确保启用了 Google Sheets API。你可以在“API 和服务”\u0026gt;“库”中搜索并启用该 API。\n2 创建服务账号密钥： 在 Google Cloud Console 的项目页面上，导航到“API 和服务”\u0026gt;“凭据”。 点击“创建凭据”按钮，选择“服务账号密钥”。 在“服务账号”部分，选择“新建服务账号”，并为其指定一个名称。 在“角色”部分，选择“项目”\u0026gt;“编辑者”角色。 选择“JSON”作为密钥类型，并点击“创建”按钮。这将下载一个 JSON 文件，其中包含你的服务账号密钥。 Google Sheet 分享给服务账号，邀请其成为“编辑者”，被邀请人填入服务账号的邮箱 Go 代码 安装 Go 的 Google Sheets API 客户端库：\ngo get -u google.golang.org/api/sheets/v4 import ( \u0026#34;golang.org/x/oauth2/google\u0026#34; \u0026#34;google.golang.org/api/sheets/v4\u0026#34; ) func main() { // 加载密钥文件 b, err := ioutil.ReadFile(credential.json) if err != nil { log.Fatalf(\u0026#34;无法读取密钥文件：%v\u0026#34;, err) } // 从密钥文件创建一个配置 config, err := google.JWTConfigFromJSON(b, sheets.SpreadsheetsScope) if err != nil { log.Fatalf(\u0026#34;无法创建配置：%v\u0026#34;, err) } // 使用配置创建一个客户端 client := config.Client(context.Background()) // 创建 Sheets 服务 sheetsService, err := sheets.New(client) if err != nil { log.Fatalf(\u0026#34;无法创建 Sheets 服务：%v\u0026#34;, err) } // 指定要写入的 Spreadsheet ID 和 Sheet 名称 spreadsheetID := \u0026#34;MY_GG_SHEET_ID\u0026#34; // sheetName := \u0026#34;test\u0026#34; sheetName := time.Now().Format(\u0026#34;010215\u0026#34;) // 创建一个 SheetProperties 对象，指定新 Sheet 的名称 sheetProperties := \u0026amp;sheets.SheetProperties{ Title: sheetName, } // 创建一个 AddSheetRequest 对象，将 SheetProperties 放入其中 addSheetRequest := \u0026amp;sheets.AddSheetRequest{ Properties: sheetProperties, } // 创建一个 BatchUpdateSpreadsheetRequest 对象，将 AddSheetRequest 放入其中 batchUpdateRequest := \u0026amp;sheets.BatchUpdateSpreadsheetRequest{ Requests: []*sheets.Request{ { AddSheet: addSheetRequest, }, }, } // 执行批量更新操作，创建新的 Sheet batUpdResp, err := sheetsService.Spreadsheets.BatchUpdate(spreadsheetID, batchUpdateRequest).Do() if err != nil { log.Fatalf(\u0026#34;Unable to create new sheet: %v\u0026#34;, err) panic(\u0026#34;执行批量更新操作，创建新的 Sheet失败\u0026#34;) } // 打印新 Sheet 的 ID newSheetID := batUpdResp.Replies[0].AddSheet.Properties.SheetId fmt.Printf(\u0026#34;Created new sheet with ID: %d\\n\u0026#34;, newSheetID) // 构建要写入的数据 values := [][]interface{}{ {\u0026#34;Value 1\u0026#34;, \u0026#34;Value 2\u0026#34;, \u0026#34;Value 3\u0026#34;}, {\u0026#34;Value 4\u0026#34;, \u0026#34;Value 5\u0026#34;, \u0026#34;Value 6\u0026#34;}, } // 构建写入请求 writeRequest := \u0026amp;sheets.ValueRange{ Values: values, } //// 执行写入请求 //_, err = sheetsService.Spreadsheets.Values.Update(spreadsheetID, sheetName, writeRequest).ValueInputOption(\u0026#34;RAW\u0026#34;).Do() //if err != nil { //\tlog.Fatalf(\u0026#34;无法写入数据：%v\u0026#34;, err) //} //fmt.Println(\u0026#34;数据已成功写入 Google Sheets！\u0026#34;) // 执行追加操作 appendResp, err := sheetsService.Spreadsheets.Values.Append(spreadsheetID, sheetName, writeRequest).ValueInputOption(\u0026#34;USER_ENTERED\u0026#34;).Do() if err != nil { log.Fatalf(\u0026#34;Unable to append data: %v\u0026#34;, err) } // 打印追加操作的结果 fmt.Printf(\u0026#34;Appended %d rows\\n\u0026#34;, appendResp.Updates.UpdatedRows) } 参考资料 https://developers.google.com/docs/api/reference/rest https://github.com/googleworkspace/go-samples/tree/main/sheets/quickstart\n","date":"2022-11-02T21:11:17+08:00","permalink":"https://lxb.wiki/ee1035bf/","title":"Go 调用 GoogleSheets API 写入数据"},{"content":" Access to XMLHttpRequest at ‘http://127.0.0.1:8000/api/test/‘ from origin ‘http://127.0.0.1:3000’ has been blocked by CORS policy: No ‘Access-Control-Allow-Origin’ header is present on the requested resource.\n什么是跨域 由于开发模式为前后端分离式开发，故而通常情况下，前端和后端可能运行不同的ip或者port下，导致出现跨域问题，故而单独说明\n跨域是指一个域下的文档或脚本试图去请求另一个域下的资源，这里跨域是广义的。 其实我们通常所说的跨域是狭义的，是由浏览器同源策略限制的一类请求场景。\n什么是同源策略？\n同源策略/SOP(Same origin policy)是一种约定，由Netscape公司1995年引入浏览器，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，浏览器很容易受到XSS、CSFR等攻击。所谓同源是指”协议+域名+端口”三者相同，即便两个不同的域名指向同一个ip地址，也非同源。\n同源策略限制以下几种行为：\nCookie、LocalStorage 和 IndexDB 无法读取 DOM 和 Js对象无法获得 AJAX 请求不能发送\n解决方案： 1.1 后端允许 pip install django-cors-headers 1.2 注册应用 settings.py\nINSTALLED_APPS = ( ... \u0026#39;corsheaders\u0026#39;,\t# 加入这个应用描述 ... ) 1.3 添加中间件 MIDDLEWARE_CLASSES = ( ... \u0026#39;corsheaders.middleware.CorsMiddleware\u0026#39;,# 注意顺序！！！(可以放第一个) \u0026#39;django.middleware.common.CommonMiddleware\u0026#39;, ... ) 1.4 添加允许跨域ip #直接允许所有主机跨域 CORS_ORIGIN_ALLOW_ALL = True 默认为False 1.5 允许携带cookie CORS_ALLOW_CREDENTIALS = True 1.6 添加允许的请求头和方法 CORS_ALLOW_METHODS = ( \u0026#39;DELETE\u0026#39;, \u0026#39;GET\u0026#39;, \u0026#39;OPTIONS\u0026#39;, \u0026#39;PATCH\u0026#39;, \u0026#39;POST\u0026#39;, \u0026#39;PUT\u0026#39;, \u0026#39;VIEW\u0026#39;, ) CORS_ALLOW_HEADERS = ( \u0026#39;XMLHttpRequest\u0026#39;, \u0026#39;X_FILENAME\u0026#39;, \u0026#39;accept-encoding\u0026#39;, \u0026#39;authorization\u0026#39;, \u0026#39;content-type\u0026#39;, \u0026#39;dnt\u0026#39;, \u0026#39;origin\u0026#39;, \u0026#39;user-agent\u0026#39;, \u0026#39;x-csrftoken\u0026#39;, \u0026#39;x-requested-with\u0026#39;, \u0026#39;Pragma\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;, ) 1.7 前端请求添加Header const config = { withCredentials: false, headers: { \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, } } axios.get(myUrl, config).then(res =\u0026gt; console.log(res)) 2.1 前端配置代理 vite.config.js\nimport { defineConfig } from \u0026#39;vite\u0026#39; import vue from \u0026#39;@vitejs/plugin-vue\u0026#39; // https://vitejs.dev/config/ export default defineConfig({ plugins: [vue()], base: \u0026#39;./\u0026#39;, server: { //同plugins同级 cors: true, open: true, port: 3000, //本地端口号 proxy: { //配置代理服务器 \u0026#34;/api\u0026#34;: { target: \u0026#34;https://mydomain.com\u0026#34;, //目标url changeOrigin: true, //允许跨域 rewrite: (path) =\u0026gt; path.replace(/^\\/api/, \u0026#34;\u0026#34;), //重写路径,替换/api } } } }) 当本地开发请求 http://localhost:3000/api/xxx 时，会被代理到\nhttps://mydomain.com/xxx\n","date":"2022-10-23T22:20:35+08:00","permalink":"https://lxb.wiki/97232292/","title":"解决跨域问题"},{"content":" 在寻找部署静态网页的方法吗？这几个开源的静态网站生成工具可以帮你迅速部署界面优美、功能强大的静态网站，无需掌握复杂的 HTML 和 CSS 技能。\n静态网站是什么？ 技术上来讲，静态网站是指网页不是由服务器动态生成的。HTML、CSS 和 JavaScript 文件就静静地躺在服务器的某个路径下，它们的内容与终端用户接收到的版本是一样的。原始的源码文件已经提前编译好了，源码在每次请求后都不会变化。\nLinux.CN 是一个依赖多个数据库的动态网站，当有浏览器的请求时，网页就会生成并提供服务。大部分网站是动态的，你与这些网站互动时，大量的内容会经常改变。\n静态网站有一些好处，比如加载时间更短，请求的服务器资源更少、更安全（值得商榷）。\n传统上，静态网站更适合于创建只有少量网页、内容变化不频繁的小网站。\n然而，随着静态网站生成工具出现后，静态网站的适用范围越来越大。你还可以使用这些工具搭建博客网站。\n我整理了几个开源的静态网站生成工具，这些工具可以帮你搭建界面优美的网站。\n最好的开源静态网站生成工具 请注意，静态网站不会提供很复杂的功能。如果你需要复杂的功能，那么你可以参考适用于动态网站的最佳开源 CMS列表。\n1、Jekyll Jekyll 是用 Ruby 写的最受欢迎的开源静态生成工具之一。实际上，Jekyll 是 GitHub 页面 的引擎，它可以让你免费用 GitHub 托管网站。\n你可以很轻松地跨平台配置 Jekyll，包括 Ubuntu。它利用 Markdown、Liquid（模板语言）、HTML 和 CSS 来生成静态的网页文件。如果你要搭建一个没有广告或推广自己工具或服务的产品页的博客网站，它是个不错的选择。\n它还支持从常见的 CMS（内容管理系统Content management system）如 Ghost、WordPress、Drupal 7 迁移你的博客。你可以管理永久链接、类别、页面、文章，还可以自定义布局，这些功能都很强大。因此，即使你已经有了一个网站，如果你想转成静态网站，Jekyll 会是一个完美的解决方案。你可以参考官方文档或 GitHub 页面了解更多内容。\nJekyll 2、Hugo Hugo 是另一个很受欢迎的用于搭建静态网站的开源框架。它是用 Go 语言写的。\n它运行速度快、使用简单、可靠性高。如果你需要，它也可以提供更高级的主题。它还提供了一些有用的快捷方式来帮助你轻松完成任务。无论是组合展示网站还是博客网站，Hogo 都有能力管理大量的内容类型。\n如果你想使用 Hugo，你可以参照它的官方文档或它的 GitHub 页面来安装以及了解更多相关的使用方法。如果需要的话，你还可以将 Hugo 部署在 GitHub 页面或任何 CDN 上。\nHugo 3、Hexo Hexo 是一个有趣的开源框架，基于 Node.js。像其他的工具一样，你可以用它搭建相当快速的网站，不仅如此，它还提供了丰富的主题和插件。\n它还根据用户的每个需求提供了强大的 API 来扩展功能。如果你已经有一个网站，你可以用它的迁移扩展轻松完成迁移工作。\n你可以参照官方文档或 GitHub 页面 来使用 Hexo。\nHexo 4、Gatsby Gatsby 是一个越来越流行的开源网站生成框架。它使用 React.js 来生成快速、界面优美的网站。\n几年前在一个实验性的项目中，我曾经非常想尝试一下这个工具，它提供的成千上万的新插件和主题的能力让我印象深刻。与其他静态网站生成工具不同的是，你可以使用 Gatsby 生成一个网站，并在不损失任何功能的情况下获得静态网站的好处。\n它提供了与很多流行的服务的整合功能。当然，你可以不使用它的复杂的功能，或将其与你选择的流行 CMS 配合使用，这也会很有趣。你可以查看他们的官方文档或它的 GitHub 页面了解更多内容。\nGatsby 5、VuePress VuePress 是由 Vue.js 支持的静态网站生成工具，而 Vue.js 是一个开源的渐进式 JavaScript 框架。\n如果你了解 HTML、CSS 和 JavaScript，那么你可以无压力地使用 VuePress。你应该可以找到几个有用的插件和主题来为你的网站建设开个头。此外，看起来 Vue.js 的更新一直很活跃，很多开发者都在关注 Vue.js，这是一件好事。\n你可以参照他们的官方文档和 GitHub 页面了解更多。\nVuePress 6、Nuxt.js Nuxt.js 使用了 Vue.js 和 Node.js，但它致力于模块化，并且有能力依赖服务端而非客户端。不仅如此，它的目标是为开发者提供直观的体验，并提供描述性错误，以及详细的文档等。\n正如它声称的那样，在你用来搭建静态网站的所有工具中，Nuxt.js 可以做到功能和灵活性两全其美。他们还提供了一个 Nuxt 线上沙盒，让你不费吹灰之力就能直接测试它。\n你可以查看它的 GitHub 页面和官方网站了解更多。\nNuxt.js 7、Docusaurus Docusaurus 是一个有趣的开源静态网站生成工具，为搭建文档类网站量身定制。它还是 Facebook 开源计划的一个项目。\nDocusaurus 是用 React 构建的。你可以使用所有的基本功能，像文档版本管理、文档搜索和翻译大多是预先配置的。如果你想为你的产品或服务搭建一个文档网站，那么可以试试 Docusaurus。\n你可以从它的 GitHub 页面和它的官网获取更多信息。\nDocusaurus 8、Eleventy Eleventy 自称是 Jekyll 的替代品，旨在以更简单的方法来制作更快的静态网站。\n它似乎很容易上手，而且它还提供了适当的文档来帮助你。如果你想找一个简单的静态网站生成工具，Eleventy 似乎会是一个有趣的选择。\n你可以参照它的 GitHub 页面和官网来了解更多的细节。\nEleventy 9、Publii Publii 是一个令人印象深刻的开源 CMS，它能使生成一个静态网站变得很容易。它是用 Electron 和 Vue.js 构建的。如果有需要，你也可以把你的文章从 WorkPress 网站迁移过来。此外，它还提供了与 GitHub 页面、Netlify 及其它类似服务的一键同步功能。\n如果你利用 Publii 生成一个静态网站，你还可以得到一个所见即所得的编辑器。你可以从官网下载它，或者从它的 GitHub 页面了解更多信息。\nPublii 10、Primo 一个有趣的开源静态网站生成工具，目前开发工作仍很活跃。虽然与其他的静态生成工具相比，它还不是一个成熟的解决方案，有些功能还不完善，但它是一个独特的项目。\nPrimo 旨在使用可视化的构建器帮你构建和搭建网站，这样你就可以轻松编辑和部署到任意主机上。\n你可以参照官网或查看它的 GitHub 页面了解更多信息。\nPrimo 结语 还有很多文章中没有列出的网站生成工具。然而，我试图提到最好的静态生成器，为您提供最快的加载时间，最好的安全性和令人印象深刻的灵活性。\n列表中没有你最喜欢的工具？在下面的评论中告诉我。\nvia: https://itsfoss.com/open-source-static-site-generators/\n作者：Ankush Das 选题：lujun9972 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2022-10-02T18:26:55Z","permalink":"https://lxb.wiki/690c8418/","title":"【译】10大静态网站生成工具"},{"content":" 移动光标到行首：Ctrl + a\n移动光标到行尾：Ctrl + e\n移动光标到上一个单词的开头：Ctrl + ←\n移动光标到下一个单词的开头：Ctrl + →\n删除光标之前的单词：Ctrl + w\n恢复刚刚删除的字符：Ctrl + y\n清除光标到行尾的内容：Ctrl + k\n清除光标到行首的内容：Ctrl + u\n删除光标所在位置的字符：Backspace 或 Ctrl + h\n删除光标所在位置的字符：Delete 或 Ctrl + d\n光标向上滚动一页：Shift + Page Up\n光标向下滚动一页：Shift + Page Down\n移动光标到文本的开头：Shift + Home\n移动光标到文本的末尾：Shift + End\n交换光标所在位置的字符：Ctrl + t\n复制光标所在位置的字符：Ctrl + Shift + c\n粘贴复制的内容：Ctrl + Shift + v\n撤消最后的操作：Ctrl + z\n重做被撤消的操作：Ctrl + Shift + z 或 Ctrl + y\n在命令行历史记录中向上滚动：Ctrl + p\n在命令行历史记录中向下滚动：Ctrl + n\n在命令行历史记录中搜索命令：Ctrl + r，然后输入关键字进行搜索\n在命令行历史记录中重复上一个命令：Ctrl + o\n在命令行历史记录中编辑上一个命令：Ctrl + x + e\n清除当前行的命令：Ctrl + c\n将光标置于当前行并清除：Ctrl + l\n切换到下一个终端会话：Ctrl + Alt + →\n切换到上一个终端会话：Ctrl + Alt + ←\n切换到下一个单词的开头：Alt + f\n切换到上一个单词的开头：Alt + b\n将光标移动到下一行的开头：Ctrl + n\n将光标移动到上一行的开头：Ctrl + p\n移动光标到下一屏的开头：Ctrl + v\n移动光标到上一屏的开头：Ctrl + Shift + v\n搜索命令历史记录中的下一个匹配项：Ctrl + s\n搜索命令历史记录中的上一个匹配项：Ctrl + r\n将当前行的命令追加到命令历史记录中：Ctrl + Shift + ↑\n将当前行的命令追加到命令历史记录中：Ctrl + Shift + ↓\n将当前命令行复制到剪贴板：Ctrl + Shift + c\n将剪贴板中的内容粘贴到命令行：Ctrl + Shift + v\n","date":"2022-09-25T22:05:44+08:00","permalink":"https://lxb.wiki/9eb2da78/","title":"Linux命令行光标操作快捷键"},{"content":"问题： 在终端按下 ctrl + 左/右 方向键时，出现以下字符\n# ctrl+ 方向键的结果 ;5D ;5C 解决： 新建 ~/.inputrc 文件，新增以下内容\n# mappings for Ctrl-left-arrow and Ctrl-right-arrow for word moving \u0026#34;\\e[1;5C\u0026#34;: forward-word \u0026#34;\\e[1;5D\u0026#34;: backward-word \u0026#34;\\e[5C\u0026#34;: forward-word \u0026#34;\\e[5D\u0026#34;: backward-word \u0026#34;\\e\\e[C\u0026#34;: forward-word \u0026#34;\\e\\e[D\u0026#34;: backward-word 参考资料 https://www.linuxfromscratch.org/lfs/view/11.3/chapter09/inputrc.html\n","date":"2022-09-25T21:57:50+08:00","permalink":"https://lxb.wiki/1188538d/","title":"解决ctrl+左右方向键失效"},{"content":"通过API清理排队的任务 删除已经开始构建的任务（已有build_number）\ncurl -X POST \u0026lt;jenkins-server\u0026gt;/job/\u0026lt;job-name\u0026gt;/\u0026lt;build-number\u0026gt;/doDelete 对于排队中的任务\n注意下面的id 不是build_number\ncurl -X POST \u0026#39;http://jenkins/queue/cancelItem?id=85\u0026#39; To find x, you can parse the result of:\nhttp://jenkins/queue/api/json?tree=items[id,task[name]] To cancel a build that is in progress:\nhttp://jenkins/job/\u0026lt;jobName\u0026gt;/y/stop To find y, you can parse the result of:\nhttp://jenkins/job/\u0026lt;jobName\u0026gt;/lastBuild/api/json?tree=building,number 脚本处理排队中的任务 获取jenkins所有排队中任务，然后通过jobname过滤，然后想精确到某个任务可以在任务里通过判断任务的参数来确定：比如唯一的ID。\nfun JenkinsServer.cancelTaskInQueue(jobName: String, p1: String, p2: String, p3: String){ runScript(runScriptHtml(jobName, URLEncoder.encode(\u0026#34;import hudson.model.*\\n\u0026#34; + \u0026#34; \\n\u0026#34; + \u0026#34;def q = Jenkins.instance.queue\\n\u0026#34; + \u0026#34;q.items.findAll { \\n\u0026#34; + \u0026#34; \\n\u0026#34; + \u0026#34; it.task.name.startsWith(\\\u0026#34;${jobName}\\\u0026#34;)\\n\u0026#34; + \u0026#34; \\n\u0026#34; + \u0026#34;}.each { \\n\u0026#34; + \u0026#34; p1=\\\u0026#34;\\\u0026#34;\\n\u0026#34; + \u0026#34; p2=\\\u0026#34;\\\u0026#34;\\n\u0026#34; + \u0026#34; p3=\\\u0026#34;\\\u0026#34;\\n\u0026#34; + \u0026#34; it.params.eachLine{\\n\u0026#34; + \u0026#34; aa = it.split(\\\u0026#34;=\\\u0026#34;)\\n\u0026#34; + \u0026#34; \\n\u0026#34; + \u0026#34; if(aa[0].equals(\\\u0026#34;p1\\\u0026#34;)){\\n\u0026#34; + \u0026#34; if(aa.length == 2){\\n\u0026#34; + \u0026#34; \\tp1 = aa[1]\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34; if(aa[0].equals(\\\u0026#34;p2\\\u0026#34;)){\\n\u0026#34; + \u0026#34; if(aa.length == 2){\\n\u0026#34; + \u0026#34; \\tp2 = aa[1]\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34; if(aa[0].equals(\\\u0026#34;p3\\\u0026#34;)){\\n\u0026#34; + \u0026#34; if(aa.length == 2){\\n\u0026#34; + \u0026#34; \\tp3 = aa[1]\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34; if(\\\u0026#34;${p1}\\\u0026#34;.equals(p1) \u0026amp;\u0026amp; \\\u0026#34;${p2}\\\u0026#34;.equals(p2) \u0026amp;\u0026amp; \\\u0026#34;${p3}\\\u0026#34;.equals(p3)){\\n\u0026#34; + \u0026#34; println(\\\u0026#34;cancel auto build ${p1}:${p2} is ${p3}\\\u0026#34;)\\n\u0026#34; + \u0026#34; q.cancel(it);\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34;}\\n\u0026#34; + \u0026#34;\\n\u0026#34;, \u0026#34;UTF-8\u0026#34;))) } 清除段时间内大量堆积的任务 进入 Manage Jenkins -\u0026gt; Script Console , 然后执行后面的脚本\n单条结束任务 查看进程的名字\nThread.getAllStackTraces().keySet().each() { t -\u0026gt; println(\u0026#34;name:\u0026#34;+t.getName()) } 进程名字结果示例:\nname:Thread-90 name:Scheduler-174573182-1 name:Thread-116 name:Thread-110 name:Thread-83 name:org.jenkinsci.plugins.workflow.steps.SynchronousNonBlockingStepExecution [#52] name:SCMTrigger [#10] 停止特定进程\nThread.getAllStackTraces().keySet().each() { t -\u0026gt; if (t.getName()==\u0026#34;刚才查出来的某条进程名字\u0026#34; ) { t.interrupt(); } } 删掉所有进程\nThread.getAllStackTraces().keySet().each() { t -\u0026gt; t.interrupt(); } 清掉所有Build Queue Jenkins.instance.queue.clear() ","date":"2022-09-06T20:52:29+08:00","permalink":"https://lxb.wiki/c71b015c/","title":"Jenkins 僵尸任务\u0026排队任务清理"},{"content":"[toc]\n[toc]\n在很多场景中，比如我们需要搭建一个集群，这时候容器要识别集群内的节点，就需要添加相应的host解析。\n背景 hosts文件其实并不是存储在Docker镜像中的，/etc/hosts, /etc/resolv.conf和/etc/hostname，是存在主机上的/var/lib/docker/containers/(docker_id) 目录下，容器启动时是通过mount将这些文件挂载到容器内部的。因此如果在容器中修改这些文件，修改部分不会存在于容器的top layer，而是直接写入这3个文件中。容器重启后修改内容不存在的原因是Docker每次创建新容器时，会根据当前docker0下的所有节点的IP信息重新建立hosts文件。也就是说，你的修改会被Docker给自动覆盖掉。\n解决办法 OPT 1 开启时加参数 开启容器时候添加参数 --add-host machine:ip 可以实现hosts修改，在容器中可以识别machine主机。\ndocker run --name nginx nginx:latest --add-host=\u0026#39;server:127.0.0.1\u0026#39; --add-host=\u0026#39;server2:127.0.0.2\u0026#39; OPT 2 修改容器hosts查找目录 让容器开启时候，不去找/etc/hosts文件，而是去找自定义的hosts文件，下面是一个Dockerfile实例\nFROM ubuntu:14.04 RUN cp /etc/hosts /tmp/hosts #路径长度最好保持一致 RUN mkdir -p -- /lib-override \u0026amp;\u0026amp; cp /lib/x86_64-linux-gnu/libnss_files.so.2 /lib-override RUN sed -i \u0026#39;s:/etc/hosts:/tmp/hosts:g\u0026#39; /lib-override/libnss_files.so.2 ENV LD_LIBRARY_PATH /lib-override RUN echo \u0026#34;192.168.0.1 node1\u0026#34; \u0026gt;\u0026gt; /tmp/hosts OPT 3 在 一个 RUN 中 设置 /etc/hosts 的同时，运行需要dns服务的安装 由于在不同的 RUN 层中，/etc/hosts 会被docker重写覆盖掉，所以必须在同一个 RUN 层中同时设置并使用对应的域名映射\nRUN echo \u0026#34;111.8.8.111 mirror.npm.com\u0026#34; \u0026gt;\u0026gt; /etc/hosts \u0026amp;\u0026amp; npm install ","date":"2022-08-22T21:07:36+08:00","permalink":"https://lxb.wiki/265eeb54/","title":"Dockerfile修改hosts"},{"content":"什么是Shell ​ 在计算机科学中，Shell俗称壳（用来区别于核），是指“为使用者提供操作界面”的软件（command interpreter，命令解析器）。它类似于DOS下的COMMAND.COM和后来的cmd.exe。它接收用户命令，然后调用相应的应用程序。\n​ 同时它又是一种程序设计语言。作为命令语言，它交互式解释和执行用户输入的命令或者自动地解释和执行预先设定好的一连串的命令；作为程序设计语言，它定义了各种变量和参数，并提供了许多在高级语言中才具有的控制结构，包括循环和分支。\nsh介绍 ​ sh（Bourne Shell）是一个早期的重要shell，1978年由史蒂夫·伯恩编写，并同Version 7 Unix一起发布。\n​ 在一般的linux系统当中（如redhat，centos），使用sh调用执行脚本相当于打开了bash的POSIX标准模式（等效于bash的 \u0026ndash;posix 参数）一般的，sh是bash的“子集”\nbash介绍 ​ bash（Bourne-Again Shell）是一个为GNU计划编写的Unix shell。1987年由布莱恩·福克斯创造。主要目标是与POSIX标准保持一致，同时兼顾对sh的兼容，是各种Linux发行版标准配置的Shell，在Linux系统上/bin/sh往往是指向/bin/bash的符号链接。\nsh与bash的区别： ​ sh 遵循POSIX规范：“当某行代码出错时，不继续往下解释”。bash 就算出错，也会继续向下执行。\nsh测试脚本\n#!/bin/sh source 233 echo \u0026#34;error\u0026#34; bash测试脚本\n#!/bin/bash source 233 echo \u0026#34;error\u0026#34; 查看结果：\n[root@localhost function]# sh test2.sh test2.sh: 第 2 行:source: 233: 没有找到文件 [root@localhost function]# bash test2.sh test2.sh:行2: 233: 没有那个文件或目录 error 小结：\nsh 跟bash的区别是bash是否开启POSIX模式。 sh是bash的一种特殊的模式，sh就是开启了POSIX标准的bash， /bin/sh 相当于 /bin/bash --posix。 在Linux系统上/bin/sh往往是指向/bin/bash的符号链接\n","date":"2022-08-13T21:39:42+08:00","permalink":"https://lxb.wiki/9cfe95d9/","title":"Linux中sh与bash的区别"},{"content":" Cobra 是一个 Golang 包，它提供了简单的接口来创建命令行程序。同时，Cobra 也是一个应用程序，用来生成应用框架，从而开发以 Cobra 为基础的应用。\n主要功能 简易的子命令行模式，如 app server， app fetch 等等 完全兼容 posix 命令行模式 嵌套子命令 subcommand 支持全局，局部，串联 flags 使用 cobra 很容易的生成应用程序和命令，使用 cobra create appname 和 cobra add cmdname 如果命令输入错误，将提供智能建议，如 app srver，将提示 srver 没有，是不是 app server 自动生成 commands 和 flags 的帮助信息 自动生成详细的 help 信息，如 app help 自动识别帮助 flag -h，\u0026ndash;help 自动生成应用程序在 bash 下命令自动完成功能 自动生成应用程序的 man 手册 命令行别名 自定义 help 和 usage 信息 可选的与 viper apps 的紧密集成 cobra 中的主要概念 commands 行为 args 命令行参数(或称为位置参数) flags 对行为的改变(即命令行选项) 执行命令行程序时的一般格式为： APPNAME COMMAND ARG --FLAG\n创建 cobra 应用 获取最新版本\n$ go get -u github.com/spf13/cobra@latest 安装 cobra-cli\n$ go install github.com/spf13/cobra-cli@latest 创建\n$ cd /pathto/mysrc $ go mod init $ cobra-cli init 执行后，该目录下生成的结构如下：\n▾ demo ▾ cmd/ root.go main.go 使用 cobra 程序生成命令代码 除了生成应用程序框架，还可以生成子命令的代码文件。添加自命令 mysub1\n$ cd /pathto/mysrc $ cobra-cli add mysub1 为命令添加具体的功能 打开文件 cmd/root.go ，找到变量 rootCmd 的初始化过程并为之设置 Run 方法：\nRun: func(cmd *cobra.Command, args []string) { fmt.Println(\u0026#34;cobra demo program\u0026#34;) }, 创建一个 version Command 用来输出当前的软件版本。先在 cmd 目录下添加 version.go 文件，编辑文件的内容如下：\npackage cmd import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/spf13/cobra\u0026#34; ) func init() { rootCmd.AddCommand(versionCmd) } var versionCmd = \u0026amp;cobra.Command{ Use: \u0026#34;version\u0026#34;, Short: \u0026#34;Print the version number of cobrademo\u0026#34;, Long: `All software has versions. This is cobrademo\u0026#39;s`, Run: func(cmd *cobra.Command, args []string) { fmt.Println(\u0026#34;cobrademo version is v1.0\u0026#34;) }, } 为 Command 添加选项(flags) 选项(flags)用来控制 Command 的具体行为。根据选项的作用范围，可以把选项分为两类：\npersistent local 对于 persistent 类型的选项，既可以设置给该 Command，又可以设置给该 Command 的子 Command。对于一些全局性的选项，比较适合设置为 persistent 类型，比如控制输出的 verbose 选项：\nvar Verbose bool rootCmd.PersistentFlags().BoolVarP(\u0026amp;Verbose, \u0026#34;verbose\u0026#34;, \u0026#34;v\u0026#34;, false, \u0026#34;verbose output\u0026#34;) local 类型的选项只能设置给指定的 Command，比如下面定义的 source 选项：\nvar Source string rootCmd.Flags().StringVarP(\u0026amp;Source, \u0026#34;source\u0026#34;, \u0026#34;s\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Source directory to read from\u0026#34;) 该选项不能指定给 rootCmd 之外的其它 Command。 默认情况下的选项都是可选的，但一些用例要求用户必须设置某些选项，这种情况 cobra 也是支持的，通过 Command 的 MarkFlagRequired 方法标记该选项即可：\nvar Name string rootCmd.Flags().StringVarP(\u0026amp;Name, \u0026#34;name\u0026#34;, \u0026#34;n\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;user name (required)\u0026#34;) rootCmd.MarkFlagRequired(\u0026#34;name\u0026#34;) 命令行参数(arguments) 命令行参数(arguments)与命令行选项的区别(flags/options)。以常见的 ls 命令来说，其命令行的格式为： ls [OPTION]... [FILE]… 其中的 OPTION 对应本文中介绍的 flags，以 - 或 -- 开头；而 FILE 则被称为参数(arguments)或位置参数。一般的规则是参数在所有选项的后面，上面的 … 表示可以指定多个选项和多个参数。\ncobra 默认提供了一些验证方法：\nNoArgs - 如果存在任何位置参数，该命令将报错 ArbitraryArgs - 该命令会接受任何位置参数 OnlyValidArgs - 如果有任何位置参数不在命令的 ValidArgs 字段中，该命令将报错 MinimumNArgs(int) - 至少要有 N 个位置参数，否则报错 MaximumNArgs(int) - 如果位置参数超过 N 个将报错 ExactArgs(int) - 必须有 N 个位置参数，否则报错 ExactValidArgs(int) 必须有 N 个位置参数，且都在命令的 ValidArgs 字段中，否则报错 RangeArgs(min, max) - 如果位置参数的个数不在区间 min 和 max 之中，报错 帮助信息(help command) cobra 会自动添加 --help(-h) 选项，同时还自动添加了 help 子命，默认效果和使用 \u0026ndash;help 选项相同。如果为 help 命令传递其它命令作为参数，则会显示对应命令的帮助信息。也可以自定义 help 的处理\ncmd.SetHelpCommand(cmd *Command) cmd.SetHelpFunc(f func(*Command, []string)) cmd.SetHelpTemplate(s string) 提示信息(usage message) 提示信息和帮助信息很相似，只不过它是在你输入了非法的参数、选项或命令时才出现的。也可以自定义提示信息：\ncmd.SetUsageFunc(f func(*Command) error) cmd.SetUsageTemplate(s string) 在 Commnad 执行前后执行额外的操作 Command 执行的操作是通过 Command.Run 方法实现的，为了支持我们在 Run 方法执行的前后执行一些其它的操作，Command 还提供了额外的几个方法，它们的执行顺序如下：\nPersistentPreRun PreRun Run PostRun PersistentPostRun var rootCmd = \u0026amp;cobra.Command{ Use: \u0026#34;cobrademo\u0026#34;, Short: \u0026#34;sparkdev\u0026#39;s cobra demo\u0026#34;, Long: \u0026#34;the demo show how to use cobra package\u0026#34;, PersistentPreRun: func(cmd *cobra.Command, args []string) { fmt.Printf(\u0026#34;Inside rootCmd PersistentPreRun with args: %v\\n\u0026#34;, args) }, PreRun: func(cmd *cobra.Command, args []string) { fmt.Printf(\u0026#34;Inside rootCmd PreRun with args: %v\\n\u0026#34;, args) }, Run: func(cmd *cobra.Command, args []string) { fmt.Printf(\u0026#34;cobra demo program, with args: %v\\n\u0026#34;, args) }, PostRun: func(cmd *cobra.Command, args []string) { fmt.Printf(\u0026#34;Inside rootCmd PostRun with args: %v\\n\u0026#34;, args) }, PersistentPostRun: func(cmd *cobra.Command, args []string) { fmt.Printf(\u0026#34;Inside rootCmd PersistentPostRun with args: %v\\n\u0026#34;, args) }, } 代码解析 Command 结构体 Command 结构体是 cobra 抽象出来的核心概念，它的实例表示一个命令或者是一个命令的子命令。下面的代码仅展示 Command 结构体中一些比较重要的字段：\ntype Command struct { // 用户通过指定 Run 函数来完成命令 // PreRun 和 PostRun 则允许用户在 Run 运行的前后时机执行自定义代码 PersistentPreRun func(cmd *Command, args []string) PreRun func(cmd *Command, args []string) Run func(cmd *Command, args []string) PostRun func(cmd *Command, args []string) PersistentPostRun func(cmd *Command, args []string) // commands 字段包含了该命令的所有子命令 commands []*Command // parent 字段记录了该命令的父命令 parent *Command // 该命令的 help 子命令 helpCommand *Command ... } 执行命令的逻辑 cobra 包启动程序执行的代码一般为：\ncmd.Execute() Execute() 函数会调用我们定义的 rootCmd(Command 的一个实例)的 Execute() 方法。 在 Command 的 Execute() 方法中又调用了 Command 的 ExecuteC() 方法，我们可以通过下面的调用堆栈看到执行命令逻辑的调用过程：\ncmd.Execute() -\u0026gt; // main.go rootCmd.Execute() -\u0026gt; // root.go c.ExecuteC() -\u0026gt; // command.go cmd.execute(flags) -\u0026gt; // command.go c.Run() // command.go c.Run() 方法即用户为命令(Command) 设置的执行逻辑。\n解析命令行子命令 ExecuteC() 方法中，在执行 execute() 方法前，需要先通过 Find() 方法解析命令行上的子命令：\ncmd, flags, err = c.Find(args) 比如我们执行下面的命令：\n$ ./myApp mycmd1 解析出的 cmd 就是 imamycmd1ge 子命令，接下来就是执行 mycmd1 子命令的执行逻辑。\nFind() 方法的逻辑如下：\n$ ./myApp help mycmd1 这里的 myApp 对应代码中的 rootCmd，Find() 方法中定义了一个名称为 innerfind 的函数，innerfind 从参数中解析出下一个名称，这里是 help，然后从 rootCmd 开始查找解析出的名称 help 是不是当前命令的子命令，如果 help 是 rootCmd 的子命令，继续查找。接下来查找名称 mycmd1，发现 mycmd1 不是 help 的子命令，innerfind 函数就返回 help 命令。execute() 方法中就执行这个找到的 help 子命令。\n为根命令添加 help 子命令 在执行 ExecuteC() 方法时，cobra 会为根命令添加一个 help 子命令，这个子命令主要用来提供子命令的帮助信息。因为任何一个程序都需要提供输出帮助信息的方式，所以 cobra 就为它实现了一套默认的逻辑。help 子命令是通过 InitDefaultHelpCmd() 方法添加的，其实现代码如下：\n// InitDefaultHelpCmd adds default help command to c. // It is called automatically by executing the c or by calling help and usage. // If c already has help command or c has no subcommands, it will do nothing. func (c *Command) InitDefaultHelpCmd() { if !c.HasSubCommands() { return } if c.helpCommand == nil { c.helpCommand = \u0026amp;Command{ Use: \u0026#34;help [command]\u0026#34;, Short: \u0026#34;Help about any command\u0026#34;, Long: `Help provides help for any command in the application. Simply type ` + c.Name() + ` help [path to command] for full details.`, Run: func(c *Command, args []string) { cmd, _, e := c.Root().Find(args) if cmd == nil || e != nil { c.Printf(\u0026#34;Unknown help topic %#q\\n\u0026#34;, args) c.Root().Usage() } else { cmd.InitDefaultHelpFlag() // make possible \u0026#39;help\u0026#39; flag to be shown cmd.Help() } }, } } c.RemoveCommand(c.helpCommand) c.AddCommand(c.helpCommand) } 如果没有找到用户指定的子命令,就输出错误信息，并调用根命令的 Usage() 方法：\nc.Printf(\u0026#34;Unknown help topic %#q\\n\u0026#34;, args) c.Root().Usage() cobra 默认提供的 usage 模板如下：\n`Usage:{{if .Runnable}} {{.UseLine}}{{end}}{{if .HasAvailableSubCommands}} {{.CommandPath}} [command]{{end}}{{if gt (len .Aliases) 0}} Aliases: {{.NameAndAliases}}{{end}}{{if .HasExample}} Examples: {{.Example}}{{end}}{{if .HasAvailableSubCommands}} Available Commands:{{range .Commands}}{{if (or .IsAvailableCommand (eq .Name \u0026#34;help\u0026#34;))}} {{rpad .Name .NamePadding }} {{.Short}}{{end}}{{end}}{{end}}{{if .HasAvailableLocalFlags}} Flags: {{.LocalFlags.FlagUsages | trimTrailingWhitespaces}}{{end}}{{if .HasAvailableInheritedFlags}} Global Flags: {{.InheritedFlags.FlagUsages | trimTrailingWhitespaces}}{{end}}{{if .HasHelpSubCommands}} Additional help topics:{{range .Commands}}{{if .IsAdditionalHelpTopicCommand}} {{rpad .CommandPath .CommandPathPadding}} {{.Short}}{{end}}{{end}}{{end}}{{if .HasAvailableSubCommands}} Use \u0026#34;{{.CommandPath}} [command] --help\u0026#34; for more information about a command.{{end}} ` 如果找到用户指定的子命令，就为子命令添加默认的 help flag，并执行其 Help() 方法：\ncmd.InitDefaultHelpFlag() // make possible \u0026#39;help\u0026#39; flag to be shown cmd.Help() 示例：\n通过 cobra 实现了一个命令行程序 myApp，它有一个子命令 image，image 也有一个子命令 times。执行下面的命令：\n$ ./myApp help mycmd1 在 help 命令的 Run 方法中，c 为 help 命令， args 为 mycmd1。结果就是通过 help 查看 mycmd1 命令的帮助文档。如果 mycmd1 后面还有其他的子命令，比如：\n$ ./myApp help mycmd1 mysub1 则 c.Root().Find(args) 逻辑会找出子命令 mysub1(此时 args 为 mycmd1 mysub1)，最终由 help 查看 mysub1 命令的帮助文档。 注意：help 信息中包含 usage 信息。\n为命令添加 help flag 除了在 InitDefaultHelpCmd() 方法中会调用 InitDefaultHelpFlag() 方法，在 execute() 方法中执行命令逻辑前也会调用 InitDefaultHelpFlag() 方法为命令添加默认的 help flag，\nc.InitDefaultHelpFlag() 下面是 InitDefaultHelpFlag() 方法的实现：\n// InitDefaultHelpFlag adds default help flag to c. // It is called automatically by executing the c or by calling help and usage. // If c already has help flag, it will do nothing. func (c *Command) InitDefaultHelpFlag() { c.mergePersistentFlags() if c.Flags().Lookup(\u0026#34;help\u0026#34;) == nil { usage := \u0026#34;help for \u0026#34; if c.Name() == \u0026#34;\u0026#34; { usage += \u0026#34;this command\u0026#34; } else { usage += c.Name() } c.Flags().BoolP(\u0026#34;help\u0026#34;, \u0026#34;h\u0026#34;, false, usage) } } 这让我们不必为命令添加 help flag 就可以直接使用\n输出 help 信息 不管是 help 命令还是 help falg，最后都是通过 HelpFunc() 方法来获得输出 help 信息的逻辑：\n// HelpFunc returns either the function set by SetHelpFunc for this command // or a parent, or it returns a function with default help behavior. func (c *Command) HelpFunc() func(*Command, []string) { if c.helpFunc != nil { return c.helpFunc } if c.HasParent() { return c.Parent().HelpFunc() } return func(c *Command, a []string) { c.mergePersistentFlags() err := tmpl(c.OutOrStdout(), c.HelpTemplate(), c) if err != nil { c.Println(err) } } } 如果我们没有指定自定义的逻辑，就找父命令的，再没有就用 cobra 的默认逻辑。cobra 默认设置的帮助模板如下(包含 usage)：\n`{{with (or .Long .Short)}}{{. | trimTrailingWhitespaces}} {{end}}{{if or .Runnable .HasSubCommands}}{{.UsageString}}{{end}}` 参考资料：\nCobra. Dev https://github.com/spf13/cobra ","date":"2022-07-16T22:23:51+08:00","permalink":"https://lxb.wiki/e80bf483/","title":"Go命令行库cobra"},{"content":"术语定义 名词 说明 job 任务 payload 在POST请求中提交的数据 {optionalFolderPath} 可选参数：任务所在目录的路径 {job_name} 必须参数：任务名称 在 GET/POST 时需要附加 HTTP 认证才能访问 API 本文使用的数据结构可以在 jenkins-rest/domain 中查看详细定义 API类型 API类型 说明 JobsAP 任务管理（任务信息、创建、修改） OBPluginManagerAPI 插件管理（插件信息、安装插件） QueueAPI 任务队列相关（队列状态） StatisticsAPI Jenkins统计信息 CrumbIssuerAPI 系统哈希值信息（用于防御CSRF攻击） SystemAPI Jenkins系统状态（版本、路径） API汇总 名称 API 创建 Job POST http://localhost:8080/createItem/api/json 更新 Job POST http://localhost:8080/job/{job_name}/config.xml/api/json 获取 Job GET http://localhost:8080/job/{job_name}/api/json 获取 JobXml GET http://localhost:8080/job/{job_name}/config.xml/api/json 删除 Job POST http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/doDelete enable Job POST http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/enable disable Job POST http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/disable 获取任务描述 GET http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/description 设置任务描述 POST http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/description 创建 Build POST http://localhost:8080/job/{job_name}/build/api/json 获取 QueueItem GET http://localhost:8080/queue/item/17/api/json 取消任务队列 POST http://127.0.0.1:8080/cancelItem?id={id} 所有任务队列信息 GET http://127.0.0.1:8080/queue/api/json 获取 Build信息 GET http://localhost:8080/job/test/6/api/json 获取上次构建序号 GET http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/lastBuild/buildNumber 获取上次构建时间戳 GET http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/lastBuild/buildTimestamp 获取TXT日志 GET http://localhost:8080/job/test/{build_number}/logText/progressiveText/api/json 获取 Html 日志 GET http://localhost:8080/job/test/{build_number}/logText/progressiveHtml/api/json 系统哈希值信息 GET http://127.0.0.1:8080/crumbIssuer/api/xml?{key}={value} load统计信息 GET http://127.0.0.1:8080/overallLoad/api/json 插件管理 GET http://127.0.0.1:8080/pluginManager/api/json 安装插件 POST http://127.0.0.1:8080/pluginManager/installNecessaryPlugins API详述 创建 Job jenkins 的配置都是靠 xml 的格式落地的,所以配置其实都是 xml 的形式.\nPOST http://127.0.0.1:8080/createItem 参数\nkey value name 任务名称 payload XML配置文件 返回类型：RequestStatus\n字段 类型 说明 value Boolean errors List 如何知道 config.xml应该如何编写呢?\n可以在 jenkins 收工创建一个需要的项目,然后编辑完成后,到 jenkins 工作目录下 找到 jobs/{job_name}/config.xml 用他作为模板来书写你需要的模板. 通过获取 xml 的 api 来获取 GET http://localhost:8080/job/{job_name}/config.xml/api/json\nJava Client\njenkinsServer.createJob(\u0026#34;auto_test_job\u0026#34;, replacedText, true); String xml = jenkinsServer.getJobXml(\u0026#34;auto_test_job\u0026#34;); 更新Job POST http://localhost:8080/job/{job_name}/config.xml/api/json 参数\n字段 说明 payload XML配置文件 config.xml的内容传入到 body 中,contentType 设置为text/xml\n返回类型：Boolean\nJava Client\njenkinsServer.updateJob(\u0026#34;auto_test_job\u0026#34;, replacedText, true); job-info 获取任务信息 GET http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/api/json\n返回类型：JobInfo\n字段 类型 说明 description String 描述 name String 项目名称 url boolean 路径 buildable String 是否可构建 builds List 构建记录 lastBuild BuildInfo 上次构建记录 …… delete 删除任务 POST http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/doDelete 返回类型：RequestStatus\n补充：\n也可以使用\nDELETE https://\u0026lt;Jenkins_url\u0026gt;/job/\u0026lt;job_name\u0026gt;/ 注意最后有个 /，不加 / 不能正常删除\nenable允许任务 POST http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/enable 返回类型：Boolean\ndisable 禁止任务 POST http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/disable 返回类型：Boolean\nget-description 获取任务描述 GET http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/description 返回类型：String\nset-description 设置任务描述 POST http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/description 参数\nkey value description 描述 返回类型：Boolean\n创建 Build POST http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/build POST http://localhost:8080/job/{job_name}/build/api/json 返回类型： IntegerResponse\n字段 类型 说明 value Integer errors List build-with-params 使用参数创建任务 POST http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/buildWithParameters 参数\nkey value payload Map\u0026lt;String, List\u0026gt; properties 返回类型： IntegerResponse\n新的构建请求提交到服务器成功后返回一个类似于队列ID的东西,因为是异步构建,那么要获取构建的状态,就需要,用这个队列 id去进一步的获取. 例如:\n$ curl -v -XPOST http://localhost:8080/job/test/build/api/json * Trying ::1... * TCP_NODELAY set * Connected to localhost (::1) port 8080 (#0) \u0026gt; POST /job/test/build/api/json HTTP/1.1 \u0026gt; Host: localhost:8080 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 201 Created \u0026lt; Date: Sat, 05 Jan 2019 08:33:45 GMT \u0026lt; X-Content-Type-Options: nosniff \u0026lt; Location: http://localhost:8080/queue/item/17/ \u0026lt; Content-Length: 0 \u0026lt; Server: Jetty(9.4.z-SNAPSHOT) \u0026lt; * Connection #0 to host localhost left intact 上面的Location: http://localhost:8080/queue/item/17/就是返回的队列信息,下面的 queueItem 获取就是依赖这个.\n根据 QueueId 获取 QueueItem GET http://localhost:8080/queue/item/17/api/json 参数\n字段 说明 {queueId} 任务队列ID 返回类型：QueueItem\n$ curl http://localhost:8080/queue/item/17/api/json\\?pretty\\=true { \u0026#34;_class\u0026#34; : \u0026#34;hudson.model.Queue$LeftItem\u0026#34;, \u0026#34;actions\u0026#34; : [ { \u0026#34;_class\u0026#34; : \u0026#34;hudson.model.CauseAction\u0026#34;, \u0026#34;causes\u0026#34; : [ { \u0026#34;_class\u0026#34; : \u0026#34;hudson.model.Cause$UserIdCause\u0026#34;, \u0026#34;shortDescription\u0026#34; : \u0026#34;由用户 anonymous 启动\u0026#34;, \u0026#34;userId\u0026#34; : null, \u0026#34;userName\u0026#34; : \u0026#34;anonymous\u0026#34; } ] } ], \u0026#34;blocked\u0026#34; : false, \u0026#34;buildable\u0026#34; : false, \u0026#34;id\u0026#34; : 17, \u0026#34;inQueueSince\u0026#34; : 1546677225670, \u0026#34;params\u0026#34; : \u0026#34;\u0026#34;, \u0026#34;stuck\u0026#34; : false, \u0026#34;task\u0026#34; : { \u0026#34;_class\u0026#34; : \u0026#34;hudson.maven.MavenModuleSet\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;url\u0026#34; : \u0026#34;http://localhost:8080/job/test/\u0026#34;, \u0026#34;color\u0026#34; : \u0026#34;blue\u0026#34; }, \u0026#34;url\u0026#34; : \u0026#34;queue/item/17/\u0026#34;, \u0026#34;why\u0026#34; : null, \u0026#34;cancelled\u0026#34; : false, \u0026#34;executable\u0026#34; : { \u0026#34;_class\u0026#34; : \u0026#34;hudson.maven.MavenModuleSetBuild\u0026#34;, \u0026#34;number\u0026#34; : 6, \u0026#34;url\u0026#34; : \u0026#34;http://localhost:8080/job/test/6/\u0026#34; } } cancel 取消任务队列 POST http://127.0.0.1:8080/cancelItem?id={id} 参数\n字段 说明 {id} 任务队列ID 返回类型：RequestStatus\nqueue 所有任务队列信息 GET http://127.0.0.1:8080/queue/api/json 返回类型：List\n字段 类型 说明 blocked Boolean 是否阻塞 buildable Boolean 是否可构建 id Integer inQueueSince Long params Map\u0026lt;String, String\u0026gt; 任务参数 task Task Task中包含任务名称和URL …… 获取 Build 详情 GET http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/{number}/api/json 返回类型：BuildInfo\n字段 类型 说明 artifacts List artifacts actions Lis actions building boolean 路径 description String 描述 …… curl http://localhost:8080/job/test/6/api/json\\?pretty\\=true { ... \u0026#34;building\u0026#34; : false, \u0026#34;description\u0026#34; : null, \u0026#34;displayName\u0026#34; : \u0026#34;#6\u0026#34;, \u0026#34;duration\u0026#34; : 13631, \u0026#34;estimatedDuration\u0026#34; : 17999, \u0026#34;executor\u0026#34; : null, \u0026#34;fullDisplayName\u0026#34; : \u0026#34;test #6\u0026#34;, \u0026#34;id\u0026#34; : \u0026#34;6\u0026#34;, \u0026#34;keepLog\u0026#34; : false, \u0026#34;number\u0026#34; : 6, \u0026#34;queueId\u0026#34; : 17, \u0026#34;result\u0026#34; : \u0026#34;SUCCESS\u0026#34;, \u0026#34;timestamp\u0026#34; : 1546677234794, \u0026#34;url\u0026#34; : \u0026#34;http://localhost:8080/job/test/6/\u0026#34;, \u0026#34;builtOn\u0026#34; : \u0026#34;\u0026#34;, ... } 从返回结果可以看到 是否还在 build:\u0026quot;building\u0026quot; : false,如果 build 结束状态就在:\u0026quot;result\u0026quot; : \u0026quot;SUCCESS\u0026quot;\n获取上次Build详情 curl http://172.12.12.234:8080/job/pytest_7.0/lastBuild/api/xml --user jenkins:1 last-build-number 获取上次构建序号 GET http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/lastBuild/buildNumber 返回类型：Integer\nlast-build-timestamp 获取上次构建时间戳 GET http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/lastBuild/buildTimestamp 返回类型：String\nprogressive-text 获取构建控制台输出 获取上次构建的日志\nGET http://127.0.0.1:8080/{optionalFolderPath}job/{job_name}/lastBuild/logText/progressiveText 返回类型：ProgressiveText\n字段 类型 说明 text String 控制台输出 size Integer 字数 hasMoreData Boolean 是否有更多数据 获取某次构建的日志\n// text GET http://localhost:8080/job/test/{build_number}/logText/progressiveText/api/json // html GET http://localhost:8080/job/test/{build_number}/logText/progressiveHtml/api/json JobWithDetails job = jenkinsServer.getJob(jenkinsJob); ... QueueReference reference = job.build( true); ... QueueItem queueItem = jenkinsServer.getQueueItem(new QueueReference(queuePart)); ... Build build = jenkinsServer.getBuild(queueItem); ... BuildWithDetails details = build.details(); BuildResult result = details.getResult(); ... String logs = details.getConsoleOutputText(); CrumbIssuer 系统哈希值信息（用于防御CSRF攻击） CrumbIssuerApi path: /crumbIssuer/api/xml crumb GET http://127.0.0.1:8080/crumbIssuer/api/xml?{key}={value} 参数\nkey value xpath concat(//crumbRequestField,”:”,//crumb) 返回类型：Crumb\n字段 类型 value String errors List Statistics 统计信息 StatisticsApi path: / overall-load GET http://127.0.0.1:8080/overallLoad/api/json 返回类型：OverallLoad\n字段 类型 说明 availableExecutors Map\u0026lt;String, String\u0026gt; busyExecutors Map\u0026lt;String, String\u0026gt; connectingExecutors Map\u0026lt;String, String\u0026gt; definedExecutors Map\u0026lt;String, String\u0026gt; idleExecutors Map\u0026lt;String, String\u0026gt; onlineExecutors Map\u0026lt;String, String\u0026gt; queueLength Map\u0026lt;String, String\u0026gt; totalExecutors Map\u0026lt;String, String\u0026gt; totalQueueLength Map\u0026lt;String, String\u0026gt; System 系统信息 path: / 返回类型：SystemInfo\n字段 类型 说明 hudsonVersion String jenkinsVersion String jenkinsSession String instanceIdentity String sshEndpoint String server String PluginManager 插件管理（插件信息、安装插件） PluginManagerApi path: /pluginManager plugins 插件列表 GET http://127.0.0.1:8080/pluginManager/api/json 返回类型：List\n字段 类型 说明 active Boolean backupVersion String bundled Boolean deleted Boolean downgradable Boolean enabled Boolean longName String …… installNecessaryPlugins 安装插件 POST http://127.0.0.1:8080/pluginManager/installNecessaryPlugins 参数\npayload: \u0026lt;jenkins\u0026gt;\u0026lt;install plugin=\u0026#34;{pluginID}\u0026#34;/\u0026gt;\u0026lt;/jenkins\u0026gt; 字段 说明 {pluginID} 要安装的插件ID 返回类型：RequestStatus\n代码示例 配置 导入依赖\n\u0026lt;!--jenkins-java-client--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.offbytwo.jenkins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jenkins-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.3.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 创建连接配置，配置对应的信息\nimport com.offbytwo.jenkins.JenkinsServer; import com.offbytwo.jenkins.client.JenkinsHttpClient; import java.net.URI; import java.net.URISyntaxException; public class JenkinsConnect { private JenkinsConnect(){} // 连接 Jenkins 需要设置的信息 static final String JENKINS_URL = \u0026#34;http://jenkins:8080/\u0026#34;; static final String JENKINS_USERNAME = \u0026#34;jenkins\u0026#34;; static final String JENKINS_PASSWORD = \u0026#34;jenkins\u0026#34;; /** * Http 客户端工具 * * 如果有些 API 该Jar工具包未提供，可以用此Http客户端操作远程接口，执行命令 * @return */ public static JenkinsHttpClient getClient(){ JenkinsHttpClient jenkinsHttpClient = null; try { jenkinsHttpClient = new JenkinsHttpClient(new URI(JENKINS_URL), JENKINS_USERNAME, JENKINS_PASSWORD); } catch (URISyntaxException e) { e.printStackTrace(); } return jenkinsHttpClient; } /** * 连接 Jenkins */ public static JenkinsServer connection() { JenkinsServer jenkinsServer = null; try { jenkinsServer = new JenkinsServer(new URI(JENKINS_URL), JENKINS_USERNAME, JENKINS_PASSWORD); } catch (URISyntaxException e) { e.printStackTrace(); } return jenkinsServer; } } JENKINS_URL是Jenkins的反向代理地址， Configure System -\u0026gt; Jenkins location url， 一般和Jenkins首页访问地址一致\nJENKINS_USERNAME Jenkins登录账号\nJENKINS_PASSWORD Jenkins账号密码\n使用示例 import com.offbytwo.jenkins.JenkinsServer; import com.offbytwo.jenkins.client.JenkinsHttpClient; import com.offbytwo.jenkins.model.Build; import com.offbytwo.jenkins.model.Job; import com.offbytwo.jenkins.model.JobWithDetails; import com.offbytwo.jenkins.model.MavenJobWithDetails; import java.io.IOException; import java.util.HashMap; import java.util.Map; public class JobApi { // Jenkins 对象 private JenkinsServer jenkinsServer; // http 客户端对象 private JenkinsHttpClient jenkinsHttpClient; /** * 构造方法中调用连接 Jenkins 方法 */ JobApi() { // 连接 Jenkins jenkinsServer = JenkinsConnect.connection(); // 设置客户端连接 Jenkins jenkinsHttpClient = JenkinsConnect.getClient(); } /** * 创建 Job */ public void ceateJob(){ try { /**创建一个流水线任务，且设置一个简单的脚本**/ // 创建 Pipeline 脚本 String script = \u0026#34;node(){ \\n\u0026#34; + \u0026#34;echo \u0026#39;hello world!\u0026#39; \\n\u0026#34; + \u0026#34;}\u0026#34;; // xml配置文件，且将脚本加入到配置中 String xml = \u0026#34;\u0026lt;flow-definition plugin=\\\u0026#34;workflow-job@2.32\\\u0026#34;\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;description\u0026gt;测试项目\u0026lt;/description\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;definition class=\\\u0026#34;org.jenkinsci.plugins.workflow.cps.CpsFlowDefinition\\\u0026#34; plugin=\\\u0026#34;workflow-cps@2.66\\\u0026#34;\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;script\u0026gt;\u0026#34; + script + \u0026#34;\u0026lt;/script\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;sandbox\u0026gt;true\u0026lt;/sandbox\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;/definition\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;/flow-definition\u0026gt;\u0026#34;; // 创建 Job jenkinsServer.createJob(\u0026#34;test-job\u0026#34;,xml, true); } catch (IOException e) { e.printStackTrace(); } } /** * 更新 Job * * 更改之前创建的无参数Job，更改其为参数Job */ public void updateJob(){ try { /** * 更改一个流水线任务，让一个无参数的任务变成带参数任务 */ // 创建 Pipeline 脚本，用一个key变量 String script = \u0026#34;node(){ \\n\u0026#34; + \u0026#34;echo \\\u0026#34;${key}\\\u0026#34; \\n\u0026#34; + \u0026#34;}\u0026#34;; // xml配置文件，且将脚本加入到配置中 String xml = \u0026#34;\u0026lt;flow-definition plugin=\\\u0026#34;workflow-job@2.32\\\u0026#34;\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;actions/\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;description\u0026gt;测试项目\u0026lt;/description\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;keepDependencies\u0026gt;false\u0026lt;/keepDependencies\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;properties\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;hudson.model.ParametersDefinitionProperty\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;parameterDefinitions\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;hudson.model.StringParameterDefinition\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;name\u0026gt;key\u0026lt;/name\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;description\u0026gt;用于测试的字符变量\u0026lt;/description\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;defaultValue\u0026gt;hello\u0026lt;/defaultValue\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;trim\u0026gt;false\u0026lt;/trim\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;/hudson.model.StringParameterDefinition\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;/parameterDefinitions\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;/hudson.model.ParametersDefinitionProperty\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;/properties\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;definition class=\\\u0026#34;org.jenkinsci.plugins.workflow.cps.CpsFlowDefinition\\\u0026#34; plugin=\\\u0026#34;workflow-cps@2.66\\\u0026#34;\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;script\u0026gt;\u0026#34; + script + \u0026#34;\u0026lt;/script\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;sandbox\u0026gt;true\u0026lt;/sandbox\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;/definition\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;disabled\u0026gt;false\u0026lt;/disabled\u0026gt;\\n\u0026#34; + \u0026#34;\u0026lt;/flow-definition\u0026gt;\u0026#34;; // 创建 Job jenkinsServer.updateJob(\u0026#34;test-job\u0026#34;,xml, true); } catch (IOException e) { e.printStackTrace(); } } /** * 获取 Job 基本信息 */ public void getJob(){ try { // 获取 Job 信息 JobWithDetails job = jenkinsServer.getJob(\u0026#34;das-app-android-pkg\u0026#34;); // 获取 Job 名称 System.out.println(job.getName()); // 获取 Job URL System.out.println(job.getUrl()); // 获取 Job 下一个 build 编号 System.out.println(job.getNextBuildNumber()); // 获取 Job 显示的名称 System.out.println(job.getDisplayName()); // 输出 Job 描述信息 System.out.println(job.getDescription()); // 获取 Job 下游任务列表 System.out.println(job.getDownstreamProjects()); // 获取 Job 上游任务列表 System.out.println(job.getUpstreamProjects()); } catch (IOException e) { e.printStackTrace(); } } /** * 获取 Maven Job 信息 */ public void getMavenJob(){ try { // 获取 Job 信息 MavenJobWithDetails job = jenkinsServer.getMavenJob(\u0026#34;test-job\u0026#34;); } catch (IOException e) { e.printStackTrace(); } } /** * 获取 Job 列表 */ public void getJobList(){ try { // 获取 Job 列表 Map\u0026lt;String, Job\u0026gt; jobs = jenkinsServer.getJobs(); for (Job job:jobs.values()){ System.out.println(job.getName()); } } catch (IOException e) { e.printStackTrace(); } } /** * 获取 View 名称获取 Job 列表 */ public void getJobListByView(){ try { // 获取 Job 列表 Map\u0026lt;String,Job\u0026gt; jobs = jenkinsServer.getJobs(\u0026#34;all\u0026#34;); for (Job job:jobs.values()){ System.out.println(job.getName()); } } catch (IOException e) { e.printStackTrace(); } } /** * 查看 Job XML 信息 */ public void getJobConfig(){ try { String xml = jenkinsServer.getJobXml(\u0026#34;test-job\u0026#34;); System.out.println(xml); } catch (IOException e) { e.printStackTrace(); } } /** * 执行无参数 Job build */ public void buildJob(){ try { jenkinsServer.getJob(\u0026#34;test-job\u0026#34;).build(true); } catch (IOException e) { e.printStackTrace(); } } /** * 执行带参数 Job build */ public void buildParamJob(){ try { /** * 例如，现有一个job，拥有一个字符参数\u0026#34;key\u0026#34; * 现在对这个值进行设置，然后执行一个输出这个值的脚本 */ // 设置参数值 Map\u0026lt;String,String\u0026gt; param = new HashMap\u0026lt;\u0026gt;(); param.put(\u0026#34;way\u0026#34;,\u0026#34;gm-R-b\u0026#34;); // 执行 build 任务 jenkinsServer.getJob(\u0026#34;das-app-android-pkg\u0026#34;).build(param, true); } catch (IOException e) { e.printStackTrace(); } } /** * 停止最后构建的 Job Build */ public void stopLastJobBuild(){ try { // 获取最后的 build 信息 Build build = jenkinsServer.getJob(\u0026#34;test-job\u0026#34;).getLastBuild(); // 停止最后的 build build.Stop(); } catch (IOException e) { e.printStackTrace(); } } /** * 删除 Job */ public void deleteJob(){ try { jenkinsServer.deleteJob(\u0026#34;test-job\u0026#34;, true); } catch (IOException e) { e.printStackTrace(); } } /** * 禁用 Job */ public void disableJob(){ try { jenkinsServer.disableJob(\u0026#34;test-job\u0026#34;, true); } catch (IOException e) { e.printStackTrace(); } } /** * 启用 Job */ public void enableJob(){ try { jenkinsServer.enableJob(\u0026#34;test-job\u0026#34;, true); } catch (IOException e) { e.printStackTrace(); } } public static void main(String[] args) { JobApi jobApi = new JobApi(); // jobApi.getJob(); // jobApi.getJobList(); jobApi.buildParamJob(); // // 创建 Job // jobApi.ceateJob(); // // 构建无参数的 Job // jobApi.buildJob(); // // 构建带参数的 Job // jobApi.buildParamJob(); // // 停止最后构建的 Job Build // jobApi.stopLastJobBuild(); // // 更新 Job // jobApi.updateJob(); // // 获取 Job 信息 // jobApi.getJob(); // // 获取 Maven 项目 Job // jobApi.getMavenJob(); // // 获取 Job 配置xml // jobApi.getJobConfig(); // 获取全部 Job 列表 // jobApi.getJobList(); // 根据 view 名称获取 Job 列表 // jobApi.getJobListByView(); // // 禁用 Job // jobApi.disableJob(); // // 启用 Job // jobApi.enableJob(); // // 删除 Job // jobApi.deleteJob(); } } ","date":"2022-07-05T20:56:19+08:00","permalink":"https://lxb.wiki/6316d574/","title":"Jenkins的Api"},{"content":" Mermaid 是一个基于 Javascript 的图表绘制工具，通过解析类 Markdown 的文本语法来实现图表的创建和动态修改。Mermaid 诞生的主要目的是让文档的更新能够及时跟上开发进度。\n流程图分类 有两种流程图\nflowchart graph flowchart 语法过于复杂，不赘述。下面内容只保留 graph 语法。\n示例 graph TD start(程序开始) --\u0026gt; 随机选取K个样本作为均值向量 --\u0026gt; id1([划分簇开始]) --\u0026gt; 计算样本与各均值向量之间的距离 --\u0026gt; 根据距离最近的均值向量确定每个样本的簇标记 --\u0026gt; 将样本划入相应的簇 --\u0026gt; id2{遍历完成?} id2 -- NO --\u0026gt; id1 id2 -- YES --\u0026gt; id3([更新簇均值向量开始]) --\u0026gt; id4[计算各簇新均值向量μ] --\u0026gt; id5{所有计算完成?} id5 -- YES --\u0026gt; 保留μ集合为簇新中心点 --\u0026gt; id6{所有μ是否更新?} id5 -- NO --\u0026gt; id3 id6 -- NO --\u0026gt; endd(结束, 输出均值向量) id6 == YES ==\u0026gt;id1 方向 在 graph 之后加上空格可以传入参数，可以定义流程图方向。\n参数值 TB TD BT RL LR 说明 从上到下 从上到下 从下到上 从右到左 从左到右 节点 每一行输入任意字符都会被识别为一个新节点。输入的字符将被作为节点的ID，同时默认作为节点名称显示。默认形状是矩形。\n形状 除了矩形还有多种形状可选，在节点后面增加符号对即可。\n名称 形状符号中输入字符作为展示的名称。\n默认可以不用引号，但如果需要使用转义符、或者括号，则需要用引号包裹。\n连接线 语法结构大致是：节点ID 连接线符号 节点ID（ 例如 NodeA \u0026lt;--\u0026gt; NodeB）。\n如果一行末尾没有节点ID，则会找到下一行第一个节点ID连接，也就意味着连接线的语法是可以换行的。\n如果节点ID是前文没有出现过的，会当做一个新的节点处理。所以节点的创建与连接是可以一次性书写的。\n线的定义 连接线由三个字符组成，末尾符号代表端点图形，第一二个符号代表线的样式。\n绘制双向箭头的话，需要在头部增加一个符号，一共是四个字符。\n中间符号可以重复，重复会渲染出更长的连接线。\n如NodeA \u0026lt;--\u0026gt; NodeB就是双箭头符号，中间代表线段形状，头尾代表箭头形状。\n线的形状 线条有三种： 箭头形状 箭头形状有三种： 双向箭头： 多个节点连接 \u0026amp; 符号可以让图形一次性连接多个节点：\n连接线上的文字注释 可以在连接线上增加连接线的注释。注释有两种写法：\n写在末尾：||符号，只需要在连接线符号末尾增加—\u0026gt;|文字|即可展示。\n写在中间：类似—文字—\u0026gt;、-. 文字 .-\u0026gt;，等于是重复连接符号，前半部分是定义上一个图形到文字的连接线样式，后半部分是定义文字到图形的连接线样式。\n通常来说写在末尾会比较方便点。 注释 %% 号为注释符，会将符号之后到此行结束都视为注释。\n子图（分组） 子图实际上就是给图形分组，增加一个背景色块，使用subgraph ID、end包裹，中间图语法与此前一样。\nsubgraph ID之后用方括号包裹可以定义显示名称。其中元素可以任意连接，用子图ID可以定义子图与子图的连接线。\ngraph TB subgraph one a --\u0026gt; b end subgraph tow c --\u0026gt; d end c --\u0026gt; b 另一种用法：\ngraph LR subgraph submo D[\u0026#34;DDD\u0026#34;] E[\u0026#34;EEE\u0026#34;] F[\u0026#34;FFF\u0026#34;] end Start --\u0026gt; D D --\u0026gt; E D --\u0026gt; F E \u0026amp; F --\u0026gt; End ","date":"2022-06-20T20:34:38Z","permalink":"https://lxb.wiki/62afdbe0/","title":"mermaid画流程图语法"},{"content":" 简介 sed 是一种流编辑器， 一次处理一行文件并把输出送往屏幕。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。\n命令、选项参数 命令 功能描述 a\\ 在当前行的后面加入一行或者文本。 c\\ 用新的文本改变或者替代本行的文本。 d 从pattern space位置删除行。 i\\ 在当前行的上面插入文本。 h 拷贝pattern space的内容到holding buffer(特殊缓冲区)。 H 追加pattern space的内容到holding buffer。 g 获得holding buffer中的内容，并替代当前pattern space中的文本。 G 获得holding buffer中的内容，并追加到当前pattern space的后面。 n 读取下一个输入行，用下一个命令处理新的行而不是用第一个命令。 p 打印pattern space中的行。 P 打印pattern space中的第一行。 q 退出sed。 w file 写并追加pattern space到file的末尾。 ! 表示后面的命令对所有没有被选定的行发生作用。 s/re/string 用string替换正则表达式re。 = 打印当前行号码。 替换标记 g 行内全面替换，如果没有g，只替换第一个匹配。 p 打印行。 x 互换pattern space和holding buffer中的文本。 y 把一个字符翻译为另一个字符(但是不能用于正则表达式)。 [root@www ~]# sed [-nefr] [动作] 选项与参数： -n ：取消默认输出。使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN 的数据一般都会被列出到终端上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。 -e ：直接在命令列模式上进行 sed 的动作编辑；允许多点编辑。 -f ：直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作； -r ：sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法) -i ：直接修改读取的文件内容，而不是输出到终端。 动作说明： [n1[,n2]]function n1, n2 ：不见得会存在，一般代表『选择进行动作的行数』，举例来说，如果我的动作是需要在 10 到 20 行之间进行的，则『 10,20[动作行为] 』 function： a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚； i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； p ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～ s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ 以行为单位的新增/删除 将 /etc/passwd 的内容列出并且列印行号，同时，将第 2~5 行删除！\n[root@www ~]# nl /etc/passwd | sed \u0026#39;2,5d\u0026#39; 1 root:x:0:0:root:/root:/bin/bash 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown .....(后面省略)..... sed 的动作为 '2,5d' ，那个 d 就是删除！因为 2-5 行给他删除了，所以显示的数据就没有 2-5 行罗～ 另外，注意一下，原本应该是要下达 sed -e 才对，没有 -e 也行啦！同时也要注意的是， sed 后面接的动作，请务必以 \u0026rsquo;\u0026rsquo; 两个单引号括住喔！\n只要删除第 2 行\nnl /etc/passwd | sed \u0026#39;2d\u0026#39; 要删除第 3 到最后一行\nnl /etc/passwd | sed \u0026#39;3,$d\u0026#39; 在第二行后(亦即是加在第三行)加上『drink tea』字样！\n[root@www ~]# nl /etc/passwd | sed \u0026#39;2a drink tea\u0026#39; 1 root:x:0:0:root:/root:/bin/bash 2 bin:x:1:1:bin:/bin:/sbin/nologin drink tea 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin .....(后面省略)..... 那如果是要在第二行前\nnl /etc/passwd | sed \u0026#39;2i drink tea\u0026#39; 如果是要增加两行以上，在第二行后面加入两行字，例如『Drink tea or \u0026hellip;..』与『drink beer』 这里是 \\ 还是 \\\u0026gt; ?\n[root@www ~]# nl /etc/passwd | sed \u0026#39;2a Drink tea or ......\\ \u0026gt; drink beer ?\u0026#39; 1 root:x:0:0:root:/root:/bin/bash 2 bin:x:1:1:bin:/bin:/sbin/nologin Drink tea or ...... drink beer ? 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin .....(后面省略)..... 每一行之间都必须要以反斜杠『 \\ 』来进行新行的添加喔！所以，上面的例子中，我们可以发现在第一行的最后面就有 \\ 存在。\n以行为单位的替换与显示 将第2-5行的内容取代成为『No 2-5 number』\n[root@www ~]# nl /etc/passwd | sed \u0026#39;2,5c No 2-5 number\u0026#39; 1 root:x:0:0:root:/root:/bin/bash No 2-5 number 6 sync:x:5:0:sync:/sbin:/bin/sync .....(后面省略)..... 仅列出 /etc/passwd 文件内的第 5-7 行\n[root@www ~]# nl /etc/passwd | sed -n \u0026#39;5,7p\u0026#39; 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 数据的搜寻并显示 搜索 /etc/passwd有root关键字的行\nnl /etc/passwd | sed \u0026#39;/root/p\u0026#39; 1 root:x:0:0:root:/root:/bin/bash 1 root:x:0:0:root:/root:/bin/bash 2 daemon:x:1:1:daemon:/usr/sbin:/bin/sh 3 bin:x:2:2:bin:/bin:/bin/sh 4 sys:x:3:3:sys:/dev:/bin/sh 5 sync:x:4:65534:sync:/bin:/bin/sync ....下面忽略 如果root找到，除了输出所有行，还会输出匹配行。\n使用-n的时候将只打印包含模板的行。\nnl /etc/passwd | sed -n \u0026#39;/root/p\u0026#39; 1 root:x:0:0:root:/root:/bin/bash 数据的搜寻并删除 删除/etc/passwd所有包含root的行，其他行输出\nnl /etc/passwd | sed \u0026#39;/root/d\u0026#39; 2 daemon:x:1:1:daemon:/usr/sbin:/bin/sh 3 bin:x:2:2:bin:/bin:/bin/sh ....下面忽略 #第一行的匹配root已经删除了 数据的搜寻并执行命令 找到匹配模式eastern的行后， 搜索/etc/passwd,找到root对应的行，执行后面花括号中的一组命令，每个命令之间用分号分隔，这里把bash替换为blueshell，再输出这行：\nnl /etc/passwd | sed -n \u0026#39;/root/{s/bash/blueshell/;p}\u0026#39; 1 root:x:0:0:root:/root:/bin/blueshell 如果只替换/etc/passwd的第一个bash关键字为blueshell，就退出\nnl /etc/passwd | sed -n \u0026#39;/bash/{s/bash/blueshell/;p;q}\u0026#39; 1 root:x:0:0:root:/root:/bin/blueshell 最后的q是退出。\n数据的搜寻并替换 除了整行的处理模式之外， sed 还可以用行为单位进行部分数据的搜寻并取代。基本上 sed 的搜寻与替代的与 vi 相当的类似！他有点像这样：\nsed \u0026#39;s/要被取代的字串/新的字串/g\u0026#39; 先观察原始信息，利用 /sbin/ifconfig 查询 IP\n[root@www ~]# /sbin/ifconfig eth0 eth0 Link encap:Ethernet HWaddr 00:90:CC:A6:34:84 inet addr:192.168.1.100 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fe80::290:ccff:fea6:3484/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 .....(以下省略)..... 本机的ip是192.168.1.100。\n将 IP 前面的部分予以删除\n[root@www ~]# /sbin/ifconfig eth0 | grep \u0026#39;inet addr\u0026#39; | sed \u0026#39;s/^.*addr://g\u0026#39; 192.168.1.100 Bcast:192.168.1.255 Mask:255.255.255.0 接下来则是删除后续的部分，亦即： 192.168.1.100 Bcast:192.168.1.255 Mask:255.255.255.0 将 IP 后面的部分予以删除\n[root@www ~]# /sbin/ifconfig eth0 | grep \u0026#39;inet addr\u0026#39; | sed \u0026#39;s/^.*addr://g\u0026#39; | sed \u0026#39;s/Bcast.*$//g\u0026#39; 192.168.1.100 多点编辑 一条sed命令，删除/etc/passwd第三行到末尾的数据，并把bash替换为blueshell\nnl /etc/passwd | sed -e \u0026#39;3,$d\u0026#39; -e \u0026#39;s/bash/blueshell/\u0026#39; 1 root:x:0:0:root:/root:/bin/blueshell 2 daemon:x:1:1:daemon:/usr/sbin:/bin/sh -e表示多点编辑，第一个编辑命令删除/etc/passwd第三行到末尾的数据，第二条命令搜索bash替换为blueshell。\n直接修改文件内容(危险动作) sed 可以直接修改文件的内容，不必使用管道命令或数据流重导向！ 不过，由於这个动作会直接修改到原始的文件，所以请你千万不要随便拿系统配置来测试！ 我们还是使用下载的 regular_express.txt 文件来测试看看吧！\n利用 sed 将 regular_express.txt 内每一行结尾若为 . 则换成 !\n[root@www ~]# sed -i \u0026#39;s/\\.$/\\!/g\u0026#39; regular_express.txt 利用 sed 直接在 regular_express.txt 最后一行加入『# This is a test』\n[root@www ~]# sed -i \u0026#39;$a # This is a test\u0026#39; regular_express.txt 由於 $ 代表的是最后一行，而 a 的动作是新增，因此该文件最后新增『# This is a test』！\nsed 的『 -i 』选项可以直接修改文件内容，这功能非常有帮助！举例来说，如果你有一个 100 万行的文件，你要在第 100 行加某些文字，此时使用 vim 可能会疯掉！因为文件太大了！那怎办？就利用 sed 啊！透过 sed 直接修改/取代的功能，你甚至不需要使用 vim 去修订！\n","date":"2022-06-10T22:28:34Z","permalink":"https://lxb.wiki/f54357bf/","title":"流编辑器sed"},{"content":" utteranc 官网 https://utteranc.es/\n1 安装应用 https://github.com/apps/utterances 设置指定仓库\n2 基本参数 官方的脚本如下：\n\u0026lt;script src=\u0026#34;https://utteranc.es/client.js\u0026#34; repo=\u0026#34;yansheng836/yansheng836.github.io\u0026#34; issue-term=\u0026#34;title\u0026#34; theme=\u0026#34;github-light\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; async\u0026gt; \u0026lt;/script\u0026gt; 主要参数：\nrepo：存放评论的issues的仓库名（即步骤1指定访问的仓库），可以和博客相同，也可以不同。 issue-term：指定issues的标题，title表示使用文章的标题作为issues的标题。可选参数（只介绍部分）： URL：博客网址：网址全路径 pathname：URL 去掉域名 title：博客标题（推荐使用这个，因为上面两个涉及到网址，如果网址包含中文，会被转义，不方便看。） theme：评论系统的主题，在Theme里面，选择主题，页面会变色：https://utteranc.es/#heading-theme 3 pure 主题配置 修改 themes/pure/_config.yml\ncomment type 改为 utterance 添加 utterance 相关配置 修改 ejs 在 themes/pure/layout/_partial/post/comment.ejs 文件中插入以下代码\n\u0026lt;% } else if (theme.comment.type === \u0026#39;utterance\u0026#39;) { %\u0026gt; \u0026lt;% if (theme.comment.utterance.enable){ %\u0026gt; \u0026lt;section id=\u0026#34;comments\u0026#34; class=\u0026#34;comments\u0026#34;\u0026gt; \u0026lt;style\u0026gt; .utterances{max-width: 100%;} \u0026lt;/style\u0026gt; \u0026lt;script src=\u0026#34;https://utteranc.es/client.js\u0026#34; repo=\u0026#34;\u0026lt;%= theme.comment.utterance.repo %\u0026gt;\u0026#34; issue-term=\u0026#34;\u0026lt;%= theme.comment.utterance.issue_term %\u0026gt;\u0026#34; theme=\u0026#34;\u0026lt;%= theme.comment.utterance.theme %\u0026gt;\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; async\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;% } %\u0026gt; ","date":"2022-05-11T22:15:38Z","permalink":"https://lxb.wiki/852e4155/","title":"Hexo pure主题配置utteranc评论"},{"content":" EasyConnect 会在后台强行添加名为 EasyMonitor 的开机自启守护进程，执行以下命令关闭\nsudo launchctl unload /Library/LaunchDaemons/com.sangfor.EasyMonitor.plist 可实际上 EasyConnect 还启动了另一个“杀不掉”的后台进程 ECAgent，活动频率很低，似乎不会造成内存泄漏，略显不起眼。但这无法作为它肆意常驻的理由。\n禁用 首先找到 plist 文件，在 /Library/LaunchAgents/com.sangfor.ECAgentProxy.plist。它无法被 launchctl unload，不过没关系，你可以直接把它挪走或删除，并且今后都不再需要它。\nsudo mv /Library/LaunchAgents/com.sangfor.ECAgentProxy.plist ~ 当然这时候它还是不能被 kill 掉，要想从 launchctl 中删除而不重启电脑，可以采用 launchctl remove。\nlaunchctl remove com.sangfor.ECAgentProxy 启用 关闭后台进程之后，启动 EasyConnect 会弹出警告：\nAlert Initialization failed. Please try reinstalling! 所以 需要使用时，必须重新加载 EasyMonitor。\n# EasyConnect v7.6.7 开始 EasyMonitor 必须在 root 权限下运行，此前版本可以不加 sudo sudo launchctl load /Library/LaunchDaemons/com.sangfor.EasyMonitor.plist 而 ECAgent 就没这么麻烦了，它根本不必后台常驻 —— EasyConnect 启动时会自己创建一个，并且会随着 EasyConnect 进程一起退出。最终我删掉了 com.sangfor.ECAgentProxy.plist 文件的备份。\nMac 下禁用开机自启软件 有部分软件的开机启动项放在 /Library/LaunchDaemons\n使用 sudo launchctl unload xxx.plist 可以去掉某个软件的开机自启\n深信服的 EasyConnect 有一个进程叫做 EasyMonitor 可以说是非常流氓了，开机自启 + 常驻内存 + 内存泄露，时间长了以后会占用 1g 以上的内存。 它的 plist 位于 /Library/LaunchDaemons/com.sangfor.EasyMonitor.plist 使用上述命令可以干掉它。\n干掉他这个进程非常开心，但是会遇到一个问题，再次启动 EasyConnect 的时候，它不乐意了，会提示初始化失败，请重新安装，这时候就得重新 load 这个 plist 了，执行 sudo launchctl load /Library/LaunchDaemons/com.sangfor.EasyMonitor.plist\n","date":"2022-05-01T20:04:28Z","permalink":"https://lxb.wiki/446d3604/","title":"Mac上移除EasyConnect常驻后台进程"},{"content":" 使用这个简单的方法来迁移一个网站以及管理防火墙配置。\n你有过把一个 WordPress 网站迁移到一台新主机上的需求吗？我曾经迁移过好多次，迁移过程相当简单。当然，的的市场时候我都不会用通用的推荐方法，这次也不例外 —— 我用更简单的方法，这才是我推荐的方法。\n这个迁移方法没有破坏性，因此如果出于某些原因你需要还原到原来的服务器上，很容易可以实现。\n一个 WordPress 网站的组成部分 运行一个基于 WordPress 的网站有三个重要组成部分：WordPress 本身，一个 web 服务器，如 Apache（我正在用），以及 MariaDB。MariaDB 是 MySQL 的一个分支，功能相似。\n业界有大量的 Web 服务器，由于我使用了 Apache 很长时间，因此我推荐用 Apache。你可能需要把 Apache 的配置方法改成你用的 Web 服务器的方法。\n初始配置 我使用一台 Linux 主机作为防火墙和网络路由。在我的网络中 Web 服务器是另一台主机。我的内部网络使用的是 C 类私有网络地址范围，按 [无类别域间路由][5]Classless Internet Domain Routing（CIDR）方式简单地记作 192.168.0.0/24。\n对于防火墙，相比于更复杂的 firewalld，我更喜欢用非常简单的 IPTables。这份防火墙配置中的一行会把 80 端口（HTTP）接收到的包发送给 Web 服务器。在 /etc/sysconfig/iptables 文件中，你可以在注释中看到，我添加了规则，把其他入站服务器连接转发到同一台服务器上合适的端口。\n我使用命名虚拟主机named virtual host来配置原来的 Apache Web 服务器，因为我在这个 HTTPD 实例上运行着多个网站。使用命名虚拟主机配置是个不错的方法，因为（像我一样）未来你可能会在运行其他的网站，这个方法可以使其变得容易。\n/etc/httpd/conf/httpd.conf 中需要迁移的虚拟主机的网站相关部分请参考下面代码。这个片段中不涉及到 IP 地址的修改，因此在新服务器上使用时不需要修改。\n在迁移之前，你需要在 httpd.conf 的最顶端附近找到 Listen 声明并修改成类似下面这样。这个地址是服务器的真实私有 IP 地址，不是公开 IP 地址。\n你需要修改新主机上 Listen 的 IP 地址。\n前期工作 准备工作分为以下三步：\n安装服务 配置防火墙 配置 web 服务器 安装 Apache 和 MariaDB 如果你的新服务器上还没有 Apache 和 MariaDB，那么就安装它们。WordPress 的安装不是必要的。\n新服务器防火墙配置 确认下新服务器上的防火墙允许访问 80 端口。你每台电脑上都有一个防火墙，对吗？大部分现代发行版使用的初始化配置包含的防火墙会阻止所有进来的网络流量，以此来提高安全等级。\n下面片段的第一行内容可能已经在你的 IPTables 或其他基于防火墙的网络过滤器中存在了。它标识已经被识别为来自可接受来源的入站包，并绕过后面的其它 INPUT 过滤规则，这样可以节省时间和 CPU 周期。片段中最后一行标识并放行 80 端口新进来的请求到 HTTPD 的连接。\n下面的示例 /etc/sysconfig/iptables 文件是 IPTables 最少规则的例子，可以允许 SSH（端口 22）和 HTTPD（端口 80）连接。\n在新服务器主机上我需要做的就是在 /etc/sysconfig/iptables 文件的防火墙规则里添加上面片段的最后一行，然后重新加载修改后的规则集。\n大部分基于红帽的发行版本，如 Fedora，使用的是 firewalld。我发现对于它的适用场景（如家用、小到中型企业）而言，它过于复杂，因此我不用它。我建议你参照 firewalld 网页 来向 firewalld 添加入站端口 80。\n你的防火墙及其配置可能跟这个有些差异，但最终的目的是允许新 Web 服务器 80 端口接收 HTTPD 连接。\nHTTPD 配置 在 /etc/httpd/conf/httpd.conf 文件中配置 HTTPD。像下面一样在 Listen 片段中设置 IP 地址。我的新 Web 服务器 IP 地址是 192.168.0.125。\n复制（对应要迁移的网站的） VirtualHost 片段，粘贴到新服务器上 httpd.conf 文件的末尾。\n迁移过程 只有两组数据需要迁移到新服务器 —— 数据库本身和网站目录结构。把两个目录打包成 tar 文档。\n把两个 tar 文件复制到新服务器。我通常会把这类文件放到 /tmp 下，这个目录就是用来做这种事的。在新服务器上运行下面的命令，把 tar 文档解压到正确的目录。\nWordPress 的所有文件都在 /var/website1 下，因此不需要在新服务器上安装它。新服务器上不需要执行 WordPress 安装过程。\n这个目录就是需要迁移到新服务器上的全部内容。\n最后一步是启动（或重启）mysqld 和 httpd 服务守护进程。WrodPress 不是一个服务，因此不使用守护进程的方式来启动。\n启动之后，你应该检查下这些服务的状态。\n最终的修改 现在所需的服务都已经运行了，你可以把 /etc/sysconfig/iptables 文件中 HTTDP 的防火墙规则改成下面的样子：\n然后重新加载设置的 IPTables 规则。\n由于防火墙规则是在防火墙主机上，因此不需要把外部 DNS 入口改成指向新服务器。如果你使用的是内部 DNS 服务器，那么你需要把 IP 地址改成内部 DNS 数据库里的 A 记录。如果你没有用内部 DNS 服务器，那么请确保主机 /etc/hosts 文件里新服务器地址设置得没有问题。\n测试和清理 请确保对新配置进行测试。首先，停止旧服务器上的 mysqld 和 httpd 服务。然后通过浏览器访问网站。如果一切符合预期，那么你可以关掉旧服务器上的 mysqld 和 httpd。如果有失败，你可以把 IPTables 的路由规则改回去到旧服务器上，直到问题解决。\n之后我把 MySQL 和 HTTPD 从旧服务器上删除了，这样来确保它们不会意外地被启动。\n总结 就是这么简单。不需要执行数据库导出和导入的过程，因为 mysql 目录下所有需要的东西都已经复制过去了。需要执行导出/导入过程的场景是：有网站自己的数据库之外的数据库；MariaDB 实例上还有其他网站，而你不想把这些网站复制到新服务器上。\n迁移旧服务器上的其他网站也很容易。其他网站依赖的所有数据库都已经随着 MariaDB 的迁移被转移到了新服务器上。你只需要把 /var/website 目录迁移到新服务器，添加合适的虚拟主机片段，然后重启 HTTPD。\n我遵循这个过程把很多个网站从一个服务器迁移到另一个服务器，每次都没有问题。\nvia: https://opensource.com/article/21/9/migrate-wordpress\n作者：David Both 选题：lujun9972 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n[a] https://opensource.com/users/dboth\n[b] https://github.com/lujun9972\n[1] https://opensource.com/sites/default/files/styles/image-full-size/public/lead-images/browser_blue_text_editor_web.png?itok=lcf-m6N7 Text editor on a browser, in blue\n[2] https://wordpress.org/\n[3] https://opensource.com/article/18/2/how-configure-apache-web-server\n[4] https://mariadb.org/\n[5] https://opensource.com/article/16/12/cidr-network-notation-configuration-linux\n[6] https://en.wikipedia.org/wiki/Iptables\n[7] http://www.website1.org\n[8] mailto:me@website1.org\n[9] https://firewalld.org/documentation/howto/open-a-port-or-service.html\n","date":"2022-04-24T21:36:34Z","permalink":"https://lxb.wiki/ea5f4ef1/","title":"【译】如何把WordPress网站迁移到新主机"},{"content":" Go 团队接受了新增对模糊测试的支持的提议。\nGo 的应用越来越广泛。现在它是云原生软件、容器软件、命令行工具和数据库等等的首选语言。Go 很早之前就已经有了内建的 对测试的支持。这使得写测试代码和运行都相当简单。\n什么是模糊测试？ 模糊测试fuzz testing（fuzzing）是指向你的软件输入非预期的数据。理想情况下，这种测试会让你的应用程序崩溃或有非预期的表现。抛开最终的结果，从程序对非预期的输入数据的处理结果中你可以得到很多信息，这样你就可以增加一些合适的错误处理。\n任何一个软件都有对不同来源的输入或数据的接收说明，软件会对这些数据进行处理并返回适当的结果。软件开发后，测试工程师团队对其进行测试，找出软件中的错误，给出测试报告，并（由开发者）修复。通常测试的目的是验证软件的行为是否符合预期。测试又可以细分为不同的类型，如功能测试、集成测试、性能测试等等。每种测试方法关注软件功能的某一个方面，以便发现错误或者提升可靠性或性能。\n模糊测试在这一测试过程上更进一步，尝试向软件程序输入一些“无效”或“随机”的数据。这种输入是故意的，期望得到的结果就是程序崩溃或输出异常，这样就可以暴露程序中的错误以便由开发者来修复它们。与其他测试类似，很少需要手动进行模糊测试，业界有大量的模糊测试工具可以将这个过程自动化。\nGo 中的软件测试 举个例子，假如你想测试 add.go 中的 Add() 函数，你可以在 add_test.go 中导入 testing 包并把测试体写在以 TestXXX() 开头的函数内。\n考虑如下代码：\nfunc Add(num1, num2 int) int { } 在 add_test.go 文件中，你可能有如下测试代码：\nimport \u0026#34;testing\u0026#34; func TestAdd(t *testing.T) { } 运行测试：\n$ go test 新增对模糊测试的支持 Go 团队已经接受了 新增对模糊测试的支持的提议，以进一步推动这项工作。这涉及到新增一个 testing.F 类型，在 _test.go 文件中新增 FuzzXXX() 函数，在 Go 工具中会新增一个 -fuzz 选项来执行这些测试。\n在 add_test.go 文件中：\nfunc FuzzAdd(f *testing.F) { } 执行以下代码：\n$ go test -fuzz 在本文编写时，这个 功能还是试验性的，但是应该会在 1.18 发布版本中包含。（LCTT 译注：Go 1.18 刚刚发布，已经包含了对模糊测试的支持）目前很多功能如 -keepfuzzing、-race 等也还没有支持。Go 团队最近发布了一篇 模糊测试教程，值得读一下。\n安装 gotip 来获取最新的功能 如果你极度渴望在正式发布之前尝试这些功能，你可以使用 gotip 来测试即将正式发布的 Go 功能并反馈给他们。你可以使用下面的命令来安装 gotip。安装之后，你可以用 gotip 程序代替以前的 go 程序来编译和运行程序。\n$ go install golang.org/dl/gotip@latest $ gotip download $ gotip version go version devel go1.18-f009910 Thu Jan 6 16:22:21 2022 +0000 linux/amd64 社区对于模糊测试的观点 软件社区中经常会讨论模糊测试，不同的人对模糊测试有不同的看法。有些人认为这是一种有用的技术，可以找到错误，尤其是在安全方面。然而考虑到模糊测试所需要的资源（CPU、内存），有人就认为这是一种浪费，而他们更愿意用其他的测试方法。即使在 Go 团队内部，意见也不统一。我们可以看到 Go 的联合创始人 Rob Pike 对模糊测试的使用和在 Go 中的实现是持轻微的怀疑态度的。\n\u0026hellip;虽然模糊测试有助于发现某类错误，但是它会占用大量的 CPU 和存储资源，并且效益成本比率也不明确。我担心为了写模糊测试浪费精力，或者 git 仓库中充斥大量无用的测试数据\n~Rob Pike\n然而，Go 安全团队的另一个成员，Filo Sottile，似乎对 Go 新增支持模糊测试很乐观，举了很多例子来支持，也希望模糊测试能成为开发过程中的一部分。\n我想说模糊测试可以发现极端情况下的错误。这是我们作为安全团队对其感兴趣的原因：在极端情况下发现的错误可以避免在生产环境中成为弱点。\n我们希望模糊测试能成为开发的一部分 —— 不只是构建或安全方面 —— 而是整个开发过程：它能提升相关代码的质量\u0026hellip;\n~Filo Sottile\n现实中的模糊测试 对我而言，模糊测试在发现错误以及让系统变得更安全和更有弹性方面似乎非常有效。举个例子，Linux 内核也会使用名为 syzkaller 的工具进行模糊测试，这个工具已经发现了 大量 错误。\nAFL 也是比较流行的模糊测试工具，用来测试 C/C++ 写的程序。\n之前也有对 Go 程序进行模糊测试的观点，其中之一就是 Filo 在 GitHub 评论中提到的 go-fuzz。\ngo-fuzz 的记录提供了相当惊人的证据，证明模糊处理能很好地找到人类没有发现的错误。根据我的经验，我们只需要消耗一点点 CPU 的时间就可以得到极端情况下非常高效的测试结果。\n为什么在 Go 中新增对模糊测试的原生支持 如果我们的需求是对 Go 程序进行模糊测试，之前的工具像 go-fuzz 就可以完成，那么为什么要在这种语言中增加原生支持呢？Go 模糊测试设计草案 中说明了这样做的一些根本原因。设计的思路是让开发过程更简单，因为前面说的工具增加了开发者的工作量，还有功能缺失。如果你没有接触过模糊测试，那么我建议你读一下设计草案文档。\n开发者可以使用诸如 go-fuzz 或 fzgo（基于 go-fuzz）来解决某些需求。然而，已有的每种解决方案都需要在典型的 Go 测试上做更多的事，而且还缺少关键的功能。相比于其他的 Go 测试（如基准测试和单元测试），模糊测试不应该比它们复杂，功能也不应该比它们少。已有的解决方案增加了额外的开销，比如自定义命令行工具。\n模糊测试工具 在大家期望 Go 语言新增功能的列表中，模糊测试是其中很受欢迎的一项。虽然现在还是试验性的，但在将要到来的发布版本中会变得更强大。这给了我们足够的时间去尝试它以及探索它的使用场景。我们不应该把它视为一种开销，如果使用得当它会是一种发现错误非常高效的测试工具。使用 Go 的团队应该推动它的使用，开发者可以写简单的模糊测试，测试团队去慢慢扩展以此来使用它全部的能力。\nvia: https://opensource.com/article/22/1/native-go-fuzz-testing\n作者：Gaurav Kamathe 选题：lujun9972 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2022-04-19T21:30:29Z","permalink":"https://lxb.wiki/dfd7f257/","title":"【译】Go中的模糊测试"},{"content":" 前言 某电商项目中，抢购订单采用的是分布式锁来解决的。某次茅台抢购活动，库存共 100 瓶，分布式锁设计不当，最终超卖。\n事故现场 核心代码\npublic SeckillActivityRequestVO seckillHandle(SeckillActivityRequestVO request) { SeckillActivityRequestVO response; String key = \u0026#34;key:\u0026#34; + request.getSeckillId; try { Boolean lockFlag = redisTemplate.opsForValue().setIfAbsent(key, \u0026#34;val\u0026#34;, 10, TimeUnit.SECONDS); if (lockFlag) { // HTTP请求用户服务进行用户相关的校验 // 用户活动校验 // 库存校验 Object stock = redisTemplate.opsForHash().get(key+\u0026#34;:info\u0026#34;, \u0026#34;stock\u0026#34;); assert stock != null; if (Integer.parseInt(stock.toString()) \u0026lt;= 0) { // 业务异常 } else { redisTemplate.opsForHash().increment(key+\u0026#34;:info\u0026#34;, \u0026#34;stock\u0026#34;, -1); // 生成订单 // 发布订单创建成功事件 // 构建响应VO } } } finally { // 释放锁 stringRedisTemplate.delete(\u0026#34;key\u0026#34;); // 构建响应VO } return response; } 以上代码，通过分布式锁过期时间有效期 10s 来保障业务逻辑有足够的执行时间；采用 try-finally 语句块保证锁一定会及时释放。\n事故原因 飞天茅台抢购活动吸引了大量新用户下载注册我们的 APP，其中，不乏很多羊毛党，采用专业的手段来注册新用户来薅羊毛和刷单。正因如此，让用户服务一直处于较高的运行负载中。\n抢购活动开始的一瞬间，大量的用户校验请求打到了用户服务。\n导致用户服务网关出现了短暂的响应延迟，有些请求的响应时长超过了 10s，但由于 HTTP 请求的响应超时我们设置的是 30s。\n这就导致接口一直阻塞在用户校验那里，10s 后，分布式锁已经失效了，此时有新的请求进来是可以拿到锁的，也就是说锁被覆盖了。\n这些阻塞的接口执行完之后，又会执行释放锁的逻辑，这就把其他线程的锁释放了，导致新的请求也可以竞争到锁~这真是一个极其恶劣的循环。\n这个时候只能依赖库存校验，但是偏偏库存校验不是非原子性的，采用的是 get and compare 的方式，超卖的悲剧就这样发生了~~~\n事故分析 仔细分析下来，可以发现，这个抢购接口在高并发场景下，是有严重的安全隐患的，主要集中在三个地方：\n①没有其他系统风险容错处理\n由于用户服务吃紧，网关响应延迟，但没有任何应对方式，这是超卖的导火索。\n②看似安全的分布式锁其实一点都不安全\n虽然采用了 set key value [EX seconds] [PX milliseconds] [NX|XX]的方式，但是如果线程 A 执行的时间较长没有来得及释放，锁就过期了，此时线程 B 是可以获取到锁的。\n当线程 A 执行完成之后，释放锁，实际上就把线程 B 的锁释放掉了。这个时候，线程 C 又是可以获取到锁的，而此时如果线程 B 执行完释放锁实际上就是释放的线程 C 设置的锁。这是超卖的直接原因。\n③非原子性的库存校验\n非原子性的库存校验导致在并发场景下，库存校验的结果不准确。这是超卖的根本原因。\n通过以上分析，问题的根本原因在于库存校验严重依赖了分布式锁。因为在分布式锁正常 set、del 的情况下，库存校验是没有问题的。\n但是，当分布式锁不安全可靠的时候，库存校验就没有用了。\n解决方案 实现相对安全的分布式锁\n相对安全的定义：set、del 是一一映射的，不会出现把其他现成的锁 del 的情况。\n从实际情况的角度来看，即使能做到 set、del一一映射，也无法保障业务的绝对安全。\n因为锁的过期时间始终是有界的，除非不设置过期时间或者把过期时间设置的很长，但这样做也会带来其他问题。故没有意义。\n要想实现相对安全的分布式锁，必须依赖 key 的 value 值。在释放锁的时候，通过 value 值的唯一性来保证不会勿删。\n我们基于 LUA 脚本实现原子性的 get and compare，如下：\npublic void safedUnLock(String key, String val) { String luaScript = \u0026#34;local in = ARGV[1] local curr=redis.call(\u0026#39;get\u0026#39;, KEYS[1]) if in==curr then redis.call(\u0026#39;del\u0026#39;, KEYS[1]) end return \u0026#39;OK\u0026#39;\u0026#34;\u0026#34;; RedisScript\u0026lt;String\u0026gt; redisScript = RedisScript.of(luaScript); redisTemplate.execute(redisScript, Collections.singletonList(key), Collections.singleton(val)); } 我们通过 LUA 脚本来实现安全地解锁。\n实现安全的库存校验\n如果我们对于并发有比较深入的了解的话，会发现想 get and compare/ read and save 等操作，都是非原子性的。如果要实现原子性，我们也可以借助 LUA 脚本来实现。\n在公众号互联网架构师回复“2T”，获取惊喜礼包。\n但就我们这个例子中，由于抢购活动一单只能下 1 瓶，因此可以不用基于 LUA 脚本实现而是基于 Redis 本身的原子性。\n原因在于：\n// redis会返回操作之后的结果，这个过程是原子性的 Long currStock = redisTemplate.opsForHash().increment(\u0026#34;key\u0026#34;, \u0026#34;stock\u0026#34;, -1); 发现没有，代码中的库存校验完全是“画蛇添足”。\n改进之后的代码\n经过以上的分析之后，我们决定新建一个 DistributedLocker 类专门用于处理分布式锁：\npublic SeckillActivityRequestVO seckillHandle(SeckillActivityRequestVO request) { SeckillActivityRequestVO response; String key = \u0026#34;key:\u0026#34; + request.getSeckillId(); String val = UUID.randomUUID().toString(); try { Boolean lockFlag = distributedLocker.lock(key, val, 10, TimeUnit.SECONDS); if (!lockFlag) { // 业务异常 } // 用户活动校验 // 库存校验，基于redis本身的原子性来保证 Long currStock = stringRedisTemplate.opsForHash().increment(key + \u0026#34;:info\u0026#34;, \u0026#34;stock\u0026#34;, -1); if (currStock \u0026lt; 0) { // 说明库存已经扣减完了。 // 业务异常。 log.error(\u0026#34;[抢购下单] 无库存\u0026#34;); } else { // 生成订单 // 发布订单创建成功事件 // 构建响应 } } finally { distributedLocker.safedUnLock(key, val); // 构建响应 } return response; } 深度思考 ①分布式锁有必要么\n改进之后，其实可以发现，我们借助于 Redis 本身的原子性扣减库存，也是可以保证不会超卖的。\n对的。但是如果没有这一层锁的话，那么所有请求进来都会走一遍业务逻辑，由于依赖了其他系统，此时就会造成对其他系统的压力增大。\n这会增加的性能损耗和服务不稳定性，得不偿失。基于分布式锁可以在一定程度上拦截一些流量。\n②分布式锁的选型\n有人提出用 RedLock 来实现分布式锁。RedLock 的可靠性更高，但其代价是牺牲一定的性能。\n在本场景，这点可靠性的提升远不如性能的提升带来的性价比高。如果对于可靠性极高要求的场景，则可以采用 RedLock 来实现。\n③再次思考分布式锁有必要么\n由于 Bug 需要紧急修复上线，因此我们将其优化并在测试环境进行了压测之后，就立马热部署上线了。\n实际证明，这个优化是成功的，性能方面略微提升了一些，并在分布式锁失效的情况下，没有出现超卖的情况。\n然而，还有没有优化空间呢？有的！由于服务是集群部署，我们可以将库存均摊到集群中的每个服务器上，通过广播通知到集群的各个服务器。\n网关层基于用户 ID 做 hash 算法来决定请求到哪一台服务器。这样就可以基于应用缓存来实现库存的扣减和判断。\n性能又进一步提升了：\n// 通过消息提前初始化好，借助ConcurrentHashMap实现高效线程安全 private static ConcurrentHashMap\u0026lt;Long, Boolean\u0026gt; SECKILL_FLAG_MAP = new ConcurrentHashMap\u0026lt;\u0026gt;(); // 通过消息提前设置好。由于AtomicInteger本身具备原子性，因此这里可以直接使用HashMap private static Map\u0026lt;Long, AtomicInteger\u0026gt; SECKILL_STOCK_MAP = new HashMap\u0026lt;\u0026gt;(); ... public SeckillActivityRequestVO seckillHandle(SeckillActivityRequestVO request) { SeckillActivityRequestVO response; Long seckillId = request.getSeckillId(); if(!SECKILL_FLAG_MAP.get(requestseckillId)) { // 业务异常 } // 用户活动校验 // 库存校验 if(SECKILL_STOCK_MAP.get(seckillId).decrementAndGet() \u0026lt; 0) { SECKILL_FLAG_MAP.put(seckillId, false); // 业务异常 } // 生成订单 // 发布订单创建成功事件 // 构建响应 return response; } 通过以上的改造，我们就完全不需要依赖 Redis 了。性能和安全性两方面都能进一步得到提升！\n当然，此方案没有考虑到机器的动态扩容、缩容等复杂场景，如果还要考虑这些话，则不如直接考虑分布式锁的解决方案。\n","date":"2022-04-01T21:42:21Z","permalink":"https://lxb.wiki/f17b426c/","title":"【转】Redis 分布式锁使用不当事故记录"},{"content":" 对齐部署镜像和描述符是很困难的，但是某些策略可以使整个过程更高效。 在软件架构中，当两个组件之间有某些概念性或技术上的差异时会出现 阻抗失配impedance mismatch。这个术语其实是从电子工程中借用的，表示电路中输入和输出的电子阻抗必须要匹配。\n在软件开发中，存储在镜像仓库中的镜像与存储在源码控制管理系统（LCTT 译注：SCM，Source Code Management）中它的部署描述符deployment descriptor之间存在阻抗失配。你如何确定存储在 SCM 中的部署描述符表示的是正确的镜像？两个仓库追踪数据的方式并不一致，因此将一个镜像（在镜像仓库中独立存储的不可修改的二进制）和它的部署描述符（Git 中以文本文件形式存储的一系列修改记录）相匹配并不那么直观。\n注意：本文假定读者已经熟悉以下概念：\n源码控制管理Source Control Management（SCM）系统和分支 Docker 或符合 OCI 标准的镜像和容器 容器编排系统Container Orchestration Platforms（COP），如 Kubernetes 持续集成/持续交付Continuous Integration/Continuous Delivery（CI/CD） 软件开发生命周期Software development lifecycle（SDLC）环境 阻抗失配：SCM 与镜像仓库 为了更好地理解阻抗失配在什么场景下会成为问题，请考虑任意项目中的软件开发生命周期环境（SDLC），如开发、测试或发布环境。\n测试环境不会有阻抗失配。现在使用 CI/CD 的最佳实践中开发分支的最新提交都会对应开发环境中的最新部署。因此，一个典型的、成功的 CI/CD 开发流程如下：\n向 SCM 的开发分支提交新的修改 新提交触发一次镜像构建 新生成的镜像被推送到镜像仓库，标记为开发中 镜像被部署到容器编排系统（COP）中的开发环境，该镜像的部署描述符也更新为从 SCM 拉取的最新描述符。 换句话说，开发环境中最新的镜像永远与最新的部署描述符匹配。回滚到前一个构建的版本也不是问题，因为 SCM 也会跟着回滚。\n最终，随着开发流程继续推进，需要进行更多正式的测试，因此某个镜像 —— 镜像对应着 SCM 中的某次提交 —— 被推到测试环境。如果是一次成功的构建，那么不会有大问题，因为从开发环境推过来的镜像应该会与开发分支的最新提交相对应。\n开发环境的最新部署被允许入库，触发入库过程 最新部署的镜像被标记为测试中 镜像在测试环境中被拉取和部署，（该镜像）对应从 SCM 拉取的最新部署描述符 到目前为止,一切都没有问题，对吗？如果出现下面的场景，会有什么问题？\n场景 A：镜像被推到下游环境，如用户验收测试user acceptance testing （UAT），或者是生产环境。\n场景 B：测试环境中发现了一个破坏性的 bug，镜像需要回滚到某个确定正常的版本。\n在任一场景中，开发过程并没有停止，即开发分支上游有了一次或多次新的提交，而这意味着最新的部署描述符已经发生了变化，最新的镜像与之前部署在测试环境中的镜像不一致。对部署描述符的修改可能会也可能不会对之前版本的镜像起作用，但是它们一定是不可信任的。如果它们有了变化，那么它们就一定与目前为止你测试过的想要部署的镜像的部署描述符不一致。\n问题的关键是：如果部署的镜像不是镜像库中的最新版本，你怎么确定与部署的镜像相对应的是 SCM 中的哪个部署描述符？ 一言以蔽之，无法确定。两个库直接有阻抗失配。如果要详细阐述下，那么是有方法可以解决的，但是你需要做很多工作，这部分内容就是文章接下来的主题了。请注意，下面的方案并不是解决问题的唯一办法，但是已经投入到生产环境并已经对很多项目起了作用，而且已经被构建并部署到生产环境中运行了超过一年。\n二进制与部署描述符 源码通常被构建成一个 Docker 镜像或符合 OCI 标准的镜像，该镜像通常被部署到一个容器编排平台（COP）上，如 Kubernetes。部署到 COP 需要部署描述符来定义镜像被如何部署以及作为容器运行，如 Kubernetes 部署 或 CronJobs。这是因为在镜像和它的部署描述符之间有本质差异，在这里可以看到阻抗失配。在这次讨论中，我们认为镜像是存储在镜像仓库中不可修改的二进制。对源码的任何修改都不会修改镜像，而是用另一个新的镜像去替换它。\n相比之下，部署描述符是文本文件，因而可以被认为是源码且可修改。如果遵循最佳实践，那么部署描述符是被存储在 SCM，所有修改都会提交，而这很容易回溯。\n解决阻抗失配 建议的解决方案的第一部分，就是提供一个能匹配镜像仓库中的镜像与对保存部署描述符的 SCM 做的代码提交的方法。最直接的解决方案是用源提交的哈希值标记镜像。这个方法可以区分不同版本的镜像、容易分辨，并且提供足够的信息来查找正确的部署描述符，以便镜像更好地部署到 COP。\n再回顾下上面的场景：\n场景 A 镜像被推到下游环境： 当镜像被从测试环境推到 UAT 环境时，我们可以从镜像的标签中知道应该从 SCM 的哪一次源码提交拉取部署描述符。\n场景 B 当一个镜像需要在某一环节中回滚：无论我们选择回滚到那个镜像版本，我们都可以知道从 SCM 的哪一次源码提交拉取正确的部署描述符。\n在每一种情景中，无论在某个镜像被部署到测试环境后开发分支有多少次提交和构建，对于每一次升级的镜像，我们都可以找到它当初部署时对应的部署描述符。\n然而，这并不是阻抗失配的完整解决方案。再考虑两个场景：\n场景 C 在负载测试环境中，会尝试对不同的部署描述符进行多次部署，以此来验证某一次构建的表现。\n场景 D 一个镜像被推送到下游环境，在该环境中部署描述符有一个错误。\n在上面的所有场景中，我们都需要修改部署描述符，但是目前为止我们只有一个源码提交哈希。请记住，最佳实践要求我们所有对源码的修改都要先提交到 SCM。某次提交的哈希本身是无法修改的，因此我们需要一个比仅仅追踪原来的源码提交哈希更好地解决方案。\n解决方案是基于原来的源码提交哈希新建一个分支。我们把这个分支称为部署分支。每当一个镜像被推到下游测试或发布环境时，你应该基于前一个 SDLC 环境的部署分支的最新提交创建一个新的部署分支。\n这样同一个镜像可以重复多次部署到不同的 SDLC 环境，并在后面每个环境中可以感知前面发现的改动或对镜像做的修改。\n注意： 在某个环境中做的修改是如何影响下一个环境的，是用可以共享数据的工具（如 Helm Charts）还是手动剪切、粘贴到其他目录，都不在本文讨论的范围内。\n因此，当一个镜像被从一个 SDLC 环境中推到下一环境时：\n创建一个部署分支 如果镜像是从开发环境中推过来的，那么部署分支就基于构建这个镜像的源码提交哈希创建 否则，部署分支基于当前部署分支的最新提交创建 镜像被部署到下一个 SDLC 环境，使用的部署描述符是该环境中新创建的部署分支的部署描述符 图 1：部署分支树\n部署分支 下游环境的第一个部署分支，只有一次提交 下游环境的第二个部署分支，只有一次提交 有了部署分支这个解决方案，再回顾下上面的场景 C 和场景 D：\n场景 C 修改已经部署到下游 SDLC 环境中的镜像的部署描述符\n场景 D 修复某个 SDLC 环境中部署描述符的错误\n两个场景中，工作流如下：\n把对部署描述符做的修改提交到 SLDC 环境和镜像对应的部署分支 通过部署分支最新提交对应的部署描述符把镜像重新部署到 SLDC 环境 这样，部署分支彻底解决了（存储着代表一次独一无二的构建的单一的、不可修改的镜像的）镜像仓库与（存储着对应一个或多个 SDLC 环境的可修改的部署描述符的）SCM 仓库之间的阻抗失配。\n实践中的思考 这看起来像是行得通的解决方案，但同时它也为开发者和运维人员带来了新的实践中的问题，比如：\nA. 为了更好地管理部署分支，部署描述符作为资源应该保存在哪里，是否要与构建镜像的源码保存在同一个 SCM 仓库？\n到目前为止，我们都在避免谈论应该把部署描述符放在哪个仓库里。在还没有太多细节需要处理时，我们推荐把所有 SDLC 环境的部署描述符与镜像源码放在同一个 SCM 仓库。当部署分支创建后，镜像的源码可以作为方便找到部署的容器中运行的镜像的引用来使用。\n上面提到过，可以通过镜像的标签来关联镜像与原始的源码提交。在一个单独的仓库中查找某次提交的源码的引用，会给开发者带来更大的困难（即便借助工具），这就是没有必要把所有资源都分开存储的原因。\nB. 应该在部署分支上修改构建镜像的源码吗？\n简答：不应该。\n详细阐述：不应该，因为永远不要在部署分支上构建镜像，它们是在开发分支上构建的。修改部署分支上定义一个镜像的源码会破坏被部署的镜像的构建记录，而且这些修改并不会对镜像的功能生效。在对比两个部署分支的版本时这也会成为问题。这可能会导致两个版本的功能差异有错误的测试结果（这是使用部署分支的一个很小的额外好处）。\nC. 为什么使用镜像 标签tag？标记label 不可以吗？\n通过 标签tag 可以在仓库中很容易地查找镜像，可读性也很好。在一组镜像中读取和查找 标记label 的值需要拉取所有镜像的清单文件manifest，而这会增加复杂度、降低性能。而且，考虑到历史记录的追踪和不同版本的查找，对不同版本的镜像添加 标签tag 也很有必要，因此使用源码提交哈希是保证唯一性，以及保存能即时生效的有用信息的最简单的解决方案。\nD. 创建部署分支的最佳实践是怎样的？\nDevOps 最重要的三个原则：自动化、自动化、自动化。\n依赖资源来持续地强迫遵循最佳实践，充其量只是碰运气，因此在实现镜像的升级、回滚等 CI/CD 流水线时，把自动化部署分支写到脚本里。\nE. 对部署分支的命名规范有建议吗？\n\u0026lt;部署分支标识\u0026gt;-\u0026lt;环境\u0026gt;-\u0026lt;源码提交哈希\u0026gt;\n部署分支标识： 所有部署分支范围内唯一的字符串；如 “deployment” 或 “deploy” 环境： 部署分支适用的 SDLC 环境；如 “qa”（测试环境）、 “stg”（预生产环境）、 或 “prod”（生产环境） 源码提交哈希： 源码提交哈希中包含原来构建被部署的镜像的源码，开发者可以通过它很容易地查找到创建镜像的原始提交，同时也能保证分支名唯一。 例如， deployment-qa-asdf78s 表示推到 QA 环境的部署分支， deployment-stg-asdf78s 表示推到 STG 环境的部署分支。\nF. 你怎么识别环境中运行的哪个镜像版本？\n我们的建议是把最新的部署分支提交哈希和源码提交哈希添加到 标记 中。开发者和运维人员可以通过这两个独一无二的标识符查找到部署的所有东西及其来源。在诸如执行回滚或前滚操作时，使用那些不同版本的部署的选择器也能清理资源碎片。\nG. 什么时候应该把部署分支的修改合并回开发分支？\n这完全取决于开发团队。\n如果你修改的目的是为了做负载测试，只是想验证什么情况会让程序崩溃，那么这些修改不应该被合并回开发分支。另一方面，如果你发现和修复了一个错误，或者对下游环境的部署做了调整，那么就应该把部署分支的修改合并回开发分支。\nH. 有现成的部署分支示例让我们试水吗？\nel-CICD 已经在生产上使用这个策略持续一年半应用到超过一百个项目了，覆盖所有的 SDLC 环境，包括管理生产环境的部署。如果你可以访问 OKD、Red Hat OpenShift lab cluster 或 Red Hat CodeReady Containers，你可以下载el-CICD 的最新版本，参照 教程 来学习部署分支是何时以怎样的方式创建和使用的。\n结语 通过实践上面的例子可以帮助你更好的理解开发过程中阻抗失配相关的问题。对齐镜像和部署描述符是成功管理部署的关键部分。\nvia: https://opensource.com/article/21/8/impedance-mismatch-cicd\n作者：Evan \u0026ldquo;Hippy\u0026rdquo; Slatis 选题：lujun9972 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2022-03-26T14:32:25Z","permalink":"https://lxb.wiki/f5fbcabb/","title":"【译】解决 CI/CD 中的仓库阻抗失配"},{"content":" 基本流程 sequenceDiagram participant c as Client participant s as Server c -\u0026gt;\u0026gt; s: request Head为空 s -\u0026gt;\u0026gt; c: token在response中 c -\u0026gt;\u0026gt; s: 取出token；设置Head Postman实现 新增一个环境 设置环境变量 VARIABLE 名为为 token, VALUE 为空\n设置 Tests 然后点击发送。如果请求正常，那值就会填充到你的环境中。\n设置自定义固定头部 ","date":"2022-03-10T22:51:15Z","permalink":"https://lxb.wiki/3632d5ff/","title":"Postman 自动填充 Header"},{"content":" 为什么不再使用坚果云 使用坚果云同步笔记，出现了无法解决的灾难性问题\n第三方应用访问的限制 文件上传大小限制： 当前 WebDAV 客户端和网页端上传大小的限制是一致的，默认为 500M（私有云可以通过相关设置调整）。\n访问频率限制： 由于WebDAV协议比较占用系统资源，免费版用户限制访问频率为每30分钟不超过600次请求。付费用户限制访问频率为每30分钟不超过1500次请求。\n同步目录数限制： 目前坚果云的WebDAV协议单次请求文件数（包含文件和文件夹）为750个，支持分多页多次加载。如果您使用WebDAV的三方工具未实现按分页多次加载，可能会出现文件同步不完整的情况，建议您使用坚果云客户端进行直接同步。\n用坚果云同步joplin是个糟糕的选择，目前有两个问题： 一个是短时间大量同步文件，会触发坚果云的限制，导致同步失败，当触发该限制后，我们能做的只有耐心等待6个小时，该限制与免费版/专业版没有关系。 另一个才是灾难，坚果云对同一文件夹内的文件采取分页传输的机制，导致Joplin一次不能获取全部文件列表，导致Joplin认为有些文件在服务器端不存在，即认为该文件要被删除，Joplin就会删除本地对应的内容，直接的表现就是当笔记达到一定数量后用坚果云同步就会出现频繁的丢笔记现象。\n目前Joplin官方也不建议使用坚果云。\nFAQ | Joplin (joplinapp.org)\n在 2021 年 1 月已经有用户提过 issue\nData lost when using the webdav to sync data · Issue #4294 · laurent22/joplin (github.com)\nJoplin 配置teracloud 的WebDav TeraCLOUD注册 官网地址：https://teracloud.jp/en/。\n进入上述官网地址之后，点击 Create Account\n登录\u0026amp;填写推荐码 注册账号之后，在官网地址点击 Login 登录。 登录之后，点击 My Page ，进入我的页面。\n免费用户默认只给10G空间，如果使用推荐码，可以再增加5G空间。\n在 My Page 页面，Referral Bonus-\u0026gt;Enter Friends Referral Code，填写推荐码即可，如下所示。\n我的推荐码：BQMZ7。\n设置TeraCLOUD 开启WebDAV\n进入 My Page 页面，找到Apps Connection，勾选Turn on Apps Connection，如下图所示：\n创建Joplin同步文件夹\n从首页进入 File Browser 页面，创建用于Joplin同步的文件夹，如创建一个名为 terajoplin 的文件件\n配置Joplin\n打开 Joplin 客户端的 同步 选项\n同步目标选 Nextcloud\nNextcloud WebDAV URL 为 My Page|TeraCLOUD 中 Apps Connection 里的 WebDAV Connection URL后加刚刚在 File Browser 创建的目录名\nNextcloud username 为 My Page|TeraCLOUD 中 Apps Connection 里的 Connection ID\nNextcloud password 为 My Page|TeraCLOUD 中 Apps Connection 里的 Apps Password\n","date":"2022-01-15T20:01:15Z","permalink":"https://lxb.wiki/f3376d3f/","title":"Joplin配置TeraCloud的WebDav进行同步"},{"content":" 前言 SLO和SLA是大家常见的两个名词：服务等级目标和服务等级协议。\n云计算时代，各大云服务提供商都发布有自己服务的SLA条款，比如Amazon的EC2和S3服务都有相应的SLA条款。这些大公司的SLA看上去如此的高达上，一般是怎么定义出来的呢？本文就尝试从技术角度解剖一下SLA的制定过程。\n说SLA不能不提SLO，这个是众所周知的，但是还有一个概念知道的人就不多了，那就是SLI（Service Level Indicator），定义一个可执行的SLA，好的SLO和SLI是必不可少的。\n再有就是SLI/SLO/SLA都是和服务联系在一起的，脱离了服务这三个概念就没有什么意义了。\nService 什么是服务？\n简单说就是一切提供给客户的有用功能都可以称为服务。\n服务一般会由服务提供者提供，提供这个有用功能的组织被称为服务提供者，通常是人加上软件，软件的运行需要计算资源，为了能对外提供有用的功能软件可能会有对其他软件系统的依赖。\n客户是使用服务提供者提供的服务的人或公司。\nSLI SLI是经过仔细定义的测量指标，它根据不同系统特点确定要测量什么，SLI的确定是一个非常复杂的过程。\nSLI的确定需要回答以下几个问题：\n要测量的指标是什么？ 测量时的系统状态？ 如何汇总处理测量的指标？ 测量指标能否准确描述服务质量？ 测量指标的可靠度(trustworthy)？ 1. 常见的测量指标有以下几个方面： 性能\n响应时间(latency) 吞吐量(throughput) 请求量(qps) 实效性(freshness) 可用性\n运行时间(uptime) 故障时间/频率 可靠性 质量\n准确性(accuracy) 正确性(correctness) 完整性(completeness) 覆盖率(coverage) 相关性(relevance) 内部指标\n队列长度(queue length) 内存占用(RAM usage) 因素人\n响应时间(time to response) 修复时间(time to fix) 修复率(fraction fixed) **下面通过一个例子来说明一下：**hotmail的downtime SLI\n错误率(error rate)计算的是服务返回给用户的error总数 如果错误率大于X%，就算是服务down了，开始计算downtime 如果错误率持续超过Y分钟，这个downtime就会被计算在内 间断性的小于Y分钟的downtime是不被计算在内的。 2. 测量时的系统状态，在什么情况下测量会严重影响测量的结果 测量异常(badly-formed)请求，还是失败(fail)请求还是超时请求(timeout) 测量时的系统负载（是否最大负载） 测量的发起位置，服务器端还是客户端 测量的时间窗口（仅工作日、还是一周7天、是否包括计划内的维护时间段） 3. 如何汇总处理测量的指标？ 计算的时间区间是什么：是一个滚动时间窗口，还是简单的按照月份计算 使用平均值还是百分位值，比如：某服务X的ticket处理响应时间SLI的 测量指标：统计所有成功解决请求，从用户创建ticket到问题被解决的时间 怎么测量：用ticket自带的时间戳，统计所有用户创建的ticket 什么情况下的测量：只包括工作时间，不包含法定假日 用于SLI的数据指标：以一周为滑动窗口，95%分位的解决时间 4. 测量指标能否准确描述服务质量？ 性能：时效性、是否有偏差 准确性：精度、覆盖率、数据稳定性 完整性：数据丢失、无效数据、异常(outlier)数据 5. 测量指标的可靠度 是否服务提供者和客户都认可 是否可被独立验证，比如三方机构 客户端还是服务器端测量，取样间隔 错误请求是如何计算的 SLO **SLO(服务等级目标)**指定了服务所提供功能的一种期望状态。SLO里面应该包含什么呢？所有能够描述服务应该提供什么样功能的信息。\n服务提供者用它来指定系统的预期状态；开发人员编写代码来实现；客户依赖于SLO进行商业判断。SLO里没有提到，如果目标达不到会怎么样。\nSLO是用SLI来描述的，一般描述为： 比如以下SLO：\n每分钟平均qps \u0026gt; 100k/s 99% 访问延迟 \u0026lt; 500ms 99% 每分钟带宽 \u0026gt; 200MB/s 设置SLO时的几个最佳实践：\n指定计算的时间窗口 使用一致的时间窗口(XX小时滚动窗口、季度滚动窗口) 要有一个免责条款，比如：95%的时间要能够达到SLO 如果Service是第一次设置SLO，可以遵循以下原则\n测量系统当前状态\n设置预期(expectations)，而不是保证(guarantees) 初期的SLO不适合作为服务质量的强化工具 改进SLO\n设置更低的响应时间、更改的吞吐量等 保持一定的安全缓冲\n内部用的SLO要高于对外宣称的SLO 不要超额完成\n定期的downtime来使SLO不超额完成 设置SLO时的目标依赖于系统的不同状态(conditions)，根据不同状态设置不同的SLO：总SLO = service1.SLO1 *weight1 service2.SLO2* weight2 …\n为什么要有SLO，设置SLO的好处是什么呢？\n对于客户而言，是可预期的服务质量，可以简化客户端的系统设计\n对于服务提供者而言\n可预期的服务质量 更好的取舍成本/收益 更好的风险控制(当资源受限的时候) 故障时更快的反应，采取正确措施 SLO设好了，怎么保证能够达到目标呢？ 需要一个控制系统来：\n监控/测量SLIs 对比检测到的SLIs值是否达到目标 如果需要，修证目标或者修正系统以满足目标需要 实施目标的修改或者系统的修改 该控制系统需要重复的执行以上动作，以形成一个标准的反馈环路，不断的衡量和改进SLO/服务本身。\n我们讨论了目标以及目标是怎么测量的，还讨论了控制机制来达到设置的目标，但是如果因为某些原因，设置的目标达不到该怎么办呢？\n也许是因为大量的新增负载；也许是因为底层依赖不能达到标称的SLO而影响上次服务的SLO。这就需要SLA出场了。\nSLA SLA是一个涉及2方的合约，双方必须都要同意并遵守这个合约。当需要对外提供服务时，SLA是非常重要的一个服务质量信号，需要产品和法务部门的同时介入。\nSLA用一个简单的公式来描述就是： SLA = SLO 后果\nSLO不能满足的一系列动作，可以是部分不能达到\n比如：达到响应时间SLO 未达到可用性SLO 对动作的具体实施\n需要一个通用的货币来奖励/惩罚，比如：钱 SLA是一个很好的工具，可以用来帮助合理配置资源。一个有明确SLA的服务最理想的运行状态是：增加额外资源来改进系统所带来的收益小于把该资源投给其他服务所带来的收益。\n一个简单的例子就是某服务可用性从99.9%提高到99.99%所需要的资源和带来的收益之比，是决定该服务是否应该提供4个9的重要依据。\n","date":"2021-12-15T21:08:32Z","permalink":"https://lxb.wiki/ee700d45/","title":"SLO 和 SLA 的区别"},{"content":" 基于阿里的零售通业务，总结出的方法论。\n一个复杂业务的处理过程 业务背景 零售通是给线下小店供货的B2B模式，我们希望通过数字化重构传统供应链渠道，提升供应链效率，为新零售助力。阿里在中间是一个平台角色，提供的是Bsbc中的service的功能。\n在商品域，运营会操作一个“上架”动作，上架之后，商品就能在零售通上面对小店进行销售了。是零售通业务非常关键的业务操作之一，因此涉及很多的数据校验和关联操作。\n针对上架，一个简化的业务流程如下所示：\n过程分解 像这么复杂的业务，我想应该没有人会写在一个service方法中吧。一个类解决不了，那就分治吧。\n说实话，能想到分而治之的工程师，已经做的不错了，至少比没有分治思维要好很多。我也见过复杂程度相当的业务，连分解都没有，就是一堆方法和类的堆砌。\n不过，这里存在一个问题：即很多同学过度的依赖工具或是辅助手段来实现分解。比如在我们的商品域中，类似的分解手段至少有3套以上，有自制的流程引擎，有依赖于数据库配置的流程处理：\n本质上来讲，这些辅助手段做的都是一个pipeline的处理流程，没有其它。因此，我建议此处最好保持KISS（Keep It Simple and Stupid），即最好是什么工具都不要用，次之是用一个极简的Pipeline模式，最差是使用像流程引擎这样的重方法。\n除非你的应用有极强的流程可视化和编排的诉求，否则我非常不推荐使用流程引擎等工具。第一，它会引入额外的复杂度，特别是那些需要持久化状态的流程引擎；第二，它会割裂代码，导致阅读代码的不顺畅。大胆断言一下，全天下估计80%对流程引擎的使用都是得不偿失的。\n回到商品上架的问题，这里问题核心是工具吗？是设计模式带来的代码灵活性吗？显然不是，问题的核心应该是如何分解问题和抽象问题，知道金字塔原理的应该知道，此处，我们可以使用结构化分解将问题解构成一个有层级的金字塔结构：\n按照这种分解写的代码，就像一本书，目录和内容清晰明了。\n以商品上架为例，程序的入口是一个上架命令（OnSaleCommand）, 它由三个阶段（Phase）组成。\n@Command public class OnSaleNormalItemCmdExe { @Resource private OnSaleContextInitPhase onSaleContextInitPhase; @Resource private OnSaleDataCheckPhase onSaleDataCheckPhase; @Resource private OnSaleProcessPhase onSaleProcessPhase; @Override public Response execute(OnSaleNormalItemCmd cmd) { OnSaleContext onSaleContext = init(cmd); checkData(onSaleContext); process(onSaleContext); return Response.buildSuccess(); } private OnSaleContext init(OnSaleNormalItemCmd cmd) { return onSaleContextInitPhase.init(cmd); } private void checkData(OnSaleContext onSaleContext) { onSaleDataCheckPhase.check(onSaleContext); } private void process(OnSaleContext onSaleContext) { onSaleProcessPhase.process(onSaleContext); } } 每个Phase又可以拆解成多个步骤（Step），以OnSaleProcessPhase为例，它是由一系列Step组成的\n@Phase public class OnSaleProcessPhase { @Resource private PublishOfferStep publishOfferStep; @Resource private BackOfferBindStep backOfferBindStep; //省略其它step public void process(OnSaleContext onSaleContext){ SupplierItem supplierItem = onSaleContext.getSupplierItem(); // 生成OfferGroupNo generateOfferGroupNo(supplierItem); // 发布商品 publishOffer(supplierItem); // 前后端库存绑定 backoffer域 bindBackOfferStock(supplierItem); // 同步库存路由 backoffer域 syncStockRoute(supplierItem); // 设置虚拟商品拓展字段 setVirtualProductExtension(supplierItem); // 发货保障打标 offer域 markSendProtection(supplierItem); // 记录变更内容ChangeDetail recordChangeDetail(supplierItem); // 同步供货价到BackOffer syncSupplyPriceToBackOffer(supplierItem); // 如果是组合商品打标，写扩展信息 setCombineProductExtension(supplierItem); // 去售罄标 removeSellOutTag(offerId); // 发送领域事件 fireDomainEvent(supplierItem); // 关闭关联的待办事项 closeIssues(supplierItem); } } 看到了吗，这就是商品上架这个复杂业务的业务流程。需要流程引擎吗？不需要，需要设计模式支撑吗？也不需要。对于这种业务流程的表达，简单朴素的组合方法模式（Composed Method）是再合适不过的了。\n因此，在做过程分解的时候，我建议工程师不要把太多精力放在工具上，放在设计模式带来的灵活性上。而是应该多花时间在对问题分析，结构化分解，最后通过合理的抽象，形成合适的阶段（Phase）和步骤（Step）上。\n过程分解后的两个问题 1、领域知识被割裂肢解 什么叫被肢解？因为我们到目前为止做的都是过程化拆解，导致没有一个聚合领域知识的地方。每个Use Case的代码只关心自己的处理流程，知识没有沉淀。\n相同的业务逻辑会在多个Use Case中被重复实现，导致代码重复度高，即使有复用，最多也就是抽取一个util，代码对业务语义的表达能力很弱，从而影响代码的可读性和可理解性。\n2、代码的业务表达能力缺失 试想下，在过程式的代码中，所做的事情无外乎就是取数据\u0026ndash;做计算\u0026ndash;存数据，在这种情况下，要如何通过代码显性化的表达我们的业务呢？ 说实话，很难做到，因为我们缺失了模型，以及模型之间的关系。脱离模型的业务表达，是缺少韵律和灵魂的。\n举个例子，在上架过程中，有一个校验是检查库存的，其中对于组合品（CombineBackOffer）其库存的处理会和普通品不一样。原来的代码是这么写的：\nboolean isCombineProduct = supplierItem.getSign().isCombProductQuote(); // supplier.usc warehouse needn\u0026#39;t check if (WarehouseTypeEnum.isAliWarehouse(supplierItem.getWarehouseType())) { // quote warehosue check if (CollectionUtil.isEmpty(supplierItem.getWarehouseIdList()) \u0026amp;\u0026amp; !isCombineProduct) { throw ExceptionFactory.makeFault(ServiceExceptionCode.SYSTEM_ERROR, \u0026#34;亲，不能发布Offer，请联系仓配运营人员，建立品仓关系！\u0026#34;); } // inventory amount check Long sellableAmount = 0L; if (!isCombineProduct) { sellableAmount = normalBiz.acquireSellableAmount(supplierItem.getBackOfferId(), supplierItem.getWarehouseIdList()); } else { //组套商品 OfferModel backOffer = backOfferQueryService.getBackOffer(supplierItem.getBackOfferId()); if (backOffer != null) { sellableAmount = backOffer.getOffer().getTradeModel().getTradeCondition().getAmountOnSale(); } } if (sellableAmount \u0026lt; 1) { throw ExceptionFactory.makeFault(ServiceExceptionCode.SYSTEM_ERROR, \u0026#34;亲，实仓库存必须大于0才能发布，请确认已补货.\\r[id:\u0026#34; + supplierItem.getId() + \u0026#34;]\u0026#34;); } } 然而，如果我们在系统中引入领域模型之后，其代码会简化为如下：\nif(backOffer.isCloudWarehouse()){ return; } if (backOffer.isNonInWarehouse()){ throw new BizException(\u0026#34;亲，不能发布Offer，请联系仓配运营人员，建立品仓关系！\u0026#34;); } if (backOffer.getStockAmount() \u0026lt; 1){ throw new BizException(\u0026#34;亲，实仓库存必须大于0才能发布，请确认已补货.\\r[id:\u0026#34; + backOffer.getSupplierItem().getCspuCode() + \u0026#34;]\u0026#34;); } 有没有发现，使用模型的表达要清晰易懂很多，而且也不需要做关于组合品的判断了，因为我们在系统中引入了更加贴近现实的对象模型（CombineBackOffer继承BackOffer），通过对象的多态可以消除我们代码中的大部分的 if-else。\n过程分解+对象模型 通过上面的案例，我们可以看到有过程分解要好于没有分解，过程分解+对象模型要好于仅仅是过程分解。对于商品上架这个case，如果采用过程分解+对象模型的方式，最终我们会得到一个如下的系统结构：\n写复杂业务的方法论 通过上面案例的讲解，我想说，我已经交代了复杂业务代码要怎么写：即自上而下的结构化分解+自下而上的面向对象分析。\n接下来，让我们把上面的案例进行进一步的提炼，形成一个可落地的方法论，从而可以泛化到更多的复杂业务场景。\n上下结合 所谓上下结合，是指我们要结合自上而下的过程分解和自下而上的对象建模，螺旋式的构建我们的应用系统。这是一个动态的过程，两个步骤可以交替进行、也可以同时进行。\n这两个步骤是相辅相成的，上面的分析可以帮助我们更好的理清模型之间的关系，而下面的模型表达可以提升我们代码的复用度和业务语义表达能力。\n其过程如下图所示：\n使用这种上下结合的方式，我们就有可能在面对任何复杂的业务场景，都能写出干净整洁、易维护的代码。\n能力下沉 一般来说实践DDD有两个过程：\n套概念阶段 了解了一些DDD的概念，然后在代码中“使用”Aggregation Root，Bonded Context，Repository等等这些概念。更进一步，也会使用一定的分层策略。然而这种做法一般对复杂度的治理并没有多大作用。\n融会贯通阶段 术语已经不再重要，理解DDD的本质是统一语言、边界划分和面向对象分析的方法。\n大体上而言，我大概是在1.7的阶段，因为有一个问题一直在困扰我，就是哪些能力应该放在Domain层，是不是按照传统的做法，将所有的业务都收拢到Domain上，这样做合理吗？说实话，这个问题我一直没有想清楚。\n因为在现实业务中，很多的功能都是用例特有的（Use case specific）的，如果“盲目”的使用Domain收拢业务并不见得能带来多大的益处。相反，这种收拢会导致Domain层的膨胀过厚，不够纯粹，反而会影响复用性和表达能力。\n鉴于此，我最近的思考是我们应该采用能力下沉的策略。\n所谓的能力下沉，是指我们不强求一次就能设计出Domain的能力，也不需要强制要求把所有的业务功能都放到Domain层，而是采用实用主义的态度，即只对那些需要在多个场景中需要被复用的能力进行抽象下沉，而不需要复用的，就暂时放在App层的Use Case里就好了。\n注：Use Case是《架构整洁之道》里面的术语，简单理解就是响应一个Request的处理过程\n通过实践，我发现这种循序渐进的能力下沉策略，应该是一种更符合实际、更敏捷的方法。因为我们承认模型不是一次性设计出来的，而是迭代演化出来的。\n下沉的过程如下图所示，假设两个use case中，我们发现uc1的step3和uc2的step1有类似的功能，我们就可以考虑让其下沉到Domain层，从而增加代码的复用性。\n指导下沉有两个关键指标：代码的复用性和内聚性。\n复用性是告诉我们When（什么时候该下沉了），即有重复代码的时候。内聚性是告诉我们How（要下沉到哪里），功能有没有内聚到恰当的实体上，有没有放到合适的层次上（因为Domain层的能力也是有两个层次的，一个是Domain Service这是相对比较粗的粒度，另一个是Domain的Model这个是最细粒度的复用）。\n比如，在我们的商品域，经常需要判断一个商品是不是最小单位，是不是中包商品。像这种能力就非常有必要直接挂载在Model上。\npublic class CSPU { private String code; private String baseCode; //省略其它属性 /** * 单品是否为最小单位。 * */ public boolean isMinimumUnit(){ return StringUtils.equals(code, baseCode); } /** * 针对中包的特殊处理 * */ public boolean isMidPackage(){ return StringUtils.equals(code, midPackageCode); } } 之前，因为老系统中没有领域模型，没有CSPU这个实体。你会发现像判断单品是否为最小单位的逻辑是以StringUtils.equals(code, baseCode)的形式散落在代码的各个角落。这种代码的可理解性是可想而知的，至少我在第一眼看到这个代码的时候，是完全不知道什么意思。\n业务技术要怎么做 业务技术到底是在做业务，还是做技术？业务技术的技术性体现在哪里？\n通过上面的案例，我们可以看到业务所面临的复杂性并不亚于底层技术，要想写好业务代码也不是一件容易的事情。业务技术和底层技术人员唯一的区别是他们所面临的问题域不一样。\n业务技术面对的问题域变化更多、面对的人更加庞杂。而底层技术面对的问题域更加稳定、但对技术的要求更加深。比如，如果你需要去开发Pandora，你就要对Classloader有更加深入的了解才行。\n但是，不管是业务技术还是底层技术人员，有一些思维和能力都是共通的。比如，分解问题的能力，抽象思维，结构化思维等等。\n","date":"2021-12-08T21:51:01Z","permalink":"https://lxb.wiki/4c5cb7f3/","title":"如何写好业务代码"},{"content":" Go语言内置运行时（就是runtime），抛弃了传统的内存分配方式，改为自主管理。这样可以自主地实现更好的内存使用模式，比如内存池、预分配等等。这样，不会每次内存分配都需要进行系统调用。\nGolang运行时的内存分配算法主要源自 Google 为 C 语言开发的 TCMalloc算法，全称 Thread-CachingMalloc。核心思想就是把内存分为多级管理，从而降低锁的粒度。它将可用的堆内存采用二级分配的方式进行管理：每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向全局内存池申请，以避免不同线程对全局内存池的频繁竞争。\n基础概念 Go在程序启动的时候，会先向操作系统申请一块内存（注意这时还只是一段虚拟的地址空间，并不会真正地分配内存），切成小块后自己进行管理。\n申请到的内存块被分配了三个区域，在X64上分别是512MB，16GB，512GB大小。\narena区域就是我们所谓的堆区，Go动态分配的内存都是在这个区域，它把内存分割成8KB大小的页，一些页组合起来称为mspan。\nbitmap区域标识arena区域哪些地址保存了对象，并且用4bit标志位表示对象是否包含指针、GC标记信息。bitmap中一个byte大小的内存对应arena区域中4个指针大小（指针大小为 8B ）的内存，所以bitmap区域的大小是512GB/(4*8B)=16GB。\n从上图其实还可以看到bitmap的高地址部分指向arena区域的低地址部分，也就是说bitmap的地址是由高地址向低地址增长的。\nspans区域存放mspan（也就是一些arena分割的页组合起来的内存管理基本单元，后文会再讲）的指针，每个指针对应一页，所以spans区域的大小就是512GB/8KB*8B=512MB。除以8KB是计算arena区域的页数，而最后乘以8是计算spans区域所有指针的大小。创建mspan的时候，按页填充对应的spans区域，在回收object时，根据地址很容易就能找到它所属的mspan。\n内存管理单元 mspan：Go中内存管理的基本单元，是由一片连续的8KB的页组成的大块内存。注意，这里的页和操作系统本身的页并不是一回事，它一般是操作系统页大小的几倍。一句话概括：mspan是一个包含起始地址、mspan规格、页的数量等内容的双端链表。\n每个mspan按照它自身的属性Size Class的大小分割成若干个object，每个object可存储一个对象。并且会使用一个位图来标记其尚未使用的object。属性Size Class决定object大小，而mspan只会分配给和object尺寸大小接近的对象，当然，对象的大小要小于object大小。还有一个概念：Span Class，它和Size Class的含义差不多，\nSize_Class = Span_Class / 2 这是因为其实每个 Size Class有两个mspan，也就是有两个Span Class。其中一个分配给含有指针的对象，另一个分配给不含有指针的对象。这会给垃圾回收机制带来利好，之后的文章再谈。\n如下图，mspan由一组连续的页组成，按照一定大小划分成object。\nGo1.9.2里mspan的Size Class共有67种，每种mspan分割的object大小是8*2n的倍数，这个是写死在代码里的：\n// path: /usr/local/go/src/runtime/sizeclasses.go const _NumSizeClasses = 67 var class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536,1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} 根据mspan的Size Class可以得到它划分的object大小。 比如Size Class等于3，object大小就是32B。 32B大小的object可以存储对象大小范围在17B~32B的对象。而对于微小对象（小于16B），分配器会将其进行合并，将几个对象分配到同一个object中。\n数组里最大的数是32768，也就是32KB，超过此大小就是大对象了，它会被特别对待，这个稍后会再介绍。顺便提一句，类型Size Class为0表示大对象，它实际上直接由堆内存分配，而小对象都要通过mspan来分配。\n对于mspan来说，它的Size Class会决定它所能分到的页数，这也是写死在代码里的：\n// path: /usr/local/go/src/runtime/sizeclasses.go const _NumSizeClasses = 67 var class_to_allocnpages = [_NumSizeClasses]uint8{0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 3, 2, 3, 1, 3, 2, 3, 4, 5, 6, 1, 7, 6, 5, 4, 3, 5, 7, 2, 9, 7, 5, 8, 3, 10, 7, 4} 比如当我们要申请一个object大小为32B的mspan的时候，在class_to_size里对应的索引是3，而索引3在class_to_allocnpages数组里对应的页数就是1。\nmspan结构体定义：\n// path: /usr/local/go/src/runtime/mheap.go type mspan struct { //链表前向指针，用于将span链接起来 next *mspan //链表前向指针，用于将span链接起来 prev *mspan // 起始地址，也即所管理页的地址 startAddr uintptr // 管理的页数 npages uintptr // 块个数，表示有多少个块可供分配 nelems uintptr //分配位图，每一位代表一个块是否已分配 allocBits *gcBits // 已分配块的个数 allocCount uint16 // class表中的class ID，和Size Classs相关 spanclass spanClass // class表中的对象大小，也即块大小 elemsize uintptr } 我们将mspan放到更大的视角来看：\n上图可以看到有两个S指向了同一个mspan，因为这两个S指向的P是同属一个mspan的。所以，通过arena上的地址可以快速找到指向它的S，通过S就能找到mspan，回忆一下前面我们说的mspan区域的每个指针对应一页。\n假设最左边第一个mspan的Size Class等于10，根据前面的class_to_size数组，得出这个msapn分割的object大小是144B，算出可分配的对象个数是8KB/144B=56.89个，取整56个，所以会有一些内存浪费掉了，Go的源码里有所有Size Class的mspan浪费的内存的大小；再根据class_to_allocnpages数组，得到这个mspan只由1个page组成；假设这个mspan是分配给无指针对象的，那么spanClass等于20。\nstartAddr直接指向arena区域的某个位置，表示这个mspan的起始地址，allocBits指向一个位图，每位代表一个块是否被分配了对象；allocCount则表示总共已分配的对象个数。\n这样，左起第一个mspan的各个字段参数就如下图所示：\n内存管理组件 内存分配由内存分配器完成。分配器由3种组件构成：mcache, mcentral, mheap。\nmcache mcache：每个工作线程都会绑定一个mcache，本地缓存可用的mspan资源，这样就可以直接给Goroutine分配，因为不存在多个Goroutine竞争的情况，所以不会消耗锁资源。\nmcache的结构体定义：\n//path: /usr/local/go/src/runtime/mcache.go type mcache struct { alloc [numSpanClasses]*mspan } numSpanClasses = _NumSizeClasses \u0026lt;\u0026lt; 1 mcache用Span Classes作为索引管理多个用于分配的mspan，它包含所有规格的mspan。它是_NumSizeClasses的2倍，也就是67*2=134，为什么有一个两倍的关系，前面我们提到过：为了加速之后内存回收的速度，数组里一半的mspan中分配的对象不包含指针，另一半则包含指针。\n对于无指针对象的mspan在进行垃圾回收的时候无需进一步扫描它是否引用了其他活跃的对象。 后面的垃圾回收文章会再讲到，这次先到这里。\nmcache在初始化的时候是没有任何mspan资源的，在使用过程中会动态地从mcentral申请，之后会缓存下来。当对象小于等于32KB大小时，使用mcache的相应规格的mspan进行分配。\nmcentral mcentral：为所有mcache提供切分好的mspan资源。每个central保存一种特定大小的全局mspan列表，包括已分配出去的和未分配出去的。 每个mcentral对应一种mspan，而mspan的种类导致它分割的object大小不同。当工作线程的mcache中没有合适（也就是特定大小的）的mspan时就会从mcentral获取。\nmcentral被所有的工作线程共同享有，存在多个Goroutine竞争的情况，因此会消耗锁资源。结构体定义：\n//path: /usr/local/go/src/runtime/mcentral.go type mcentral struct { // 互斥锁 lock mutex // 规格 sizeclass int32 // 尚有空闲object的mspan链表 nonempty mSpanList // 没有空闲object的mspan链表，或者是已被mcache取走的msapn链表 empty mSpanList // 已累计分配的对象个数 nmalloc uint64 } empty表示这条链表里的mspan都被分配了object，或者是已经被cache取走了的mspan，这个mspan就被那个工作线程独占了。而nonempty则表示有空闲对象的mspan列表。每个central结构体都在mheap中维护。\n简单说下mcache从mcentral获取和归还mspan的流程：\n获取 加锁；从nonempty链表找到一个可用的mspan；并将其从nonempty链表删除；将取出的mspan加入到empty链表；将mspan返回给工作线程；解锁。 归还 加锁；将mspan从empty链表删除；将mspan加入到nonempty链表；解锁。 mheap mheap：代表Go程序持有的所有堆空间，Go程序使用一个mheap的全局对象_mheap来管理堆内存。\n当mcentral没有空闲的mspan时，会向mheap申请。而mheap没有资源时，会向操作系统申请新内存。mheap主要用于大对象的内存分配，以及管理未切割的mspan，用于给mcentral切割成小对象。\n同时我们也看到，mheap中含有所有规格的mcentral，所以，当一个mcache从mcentral申请mspan时，只需要在独立的mcentral中使用锁，并不会影响申请其他规格的mspan。\nmheap结构体定义：\n//path: /usr/local/go/src/runtime/mheap.go type mheap struct { lock mutex // spans: 指向mspans区域，用于映射mspan和page的关系 spans []*mspan // 指向bitmap首地址，bitmap是从高地址向低地址增长的 bitmap uintptr // 指示arena区首地址 arena_start uintptr // 指示arena区已使用地址位置 arena_used uintptr // 指示arena区末地址 arena_end uintptr central [67*2]struct { mcentral mcentral pad [sys.CacheLineSize - unsafe.Sizeof(mcentral{})%sys.CacheLineSize]byte } } 上图我们看到，bitmap和arena_start指向了同一个地址，这是因为bitmap的地址是从高到低增长的，所以他们指向的内存位置相同。\n分配流程 变量是在栈上分配还是在堆上分配，是由逃逸分析的结果决定的。通常情况下，编译器是倾向于将变量分配到栈上的，因为它的开销小，最极端的就是\u0026quot;zero garbage\u0026quot;，所有的变量都会在栈上分配，这样就不会存在内存碎片，垃圾回收之类的东西。\nGo的内存分配器在分配对象时，根据对象的大小，分成三类：小对象（小于等于16B）、一般对象（大于16B，小于等于32KB）、大对象（大于32KB）。\n大体上的分配流程：\n32KB 的对象，直接从mheap上分配； \u0026lt;=16B 的对象使用mcache的tiny分配器分配； (16B,32KB] 的对象，首先计算对象的规格大小，然后使用mcache中相应规格大小的mspan分配； 如果mcache没有相应规格大小的mspan，则向mcentral申请 如果mcentral没有相应规格大小的mspan，则向mheap申请 如果mheap中也没有合适大小的mspan，则向操作系统申请 总结 Go在程序启动时，会向操作系统申请一大块内存，之后自行管理。 Go内存管理的基本单元是mspan，它由若干个页组成，每种mspan可以分配特定大小的object。 mcache, mcentral, mheap是Go内存管理的三大组件，层层递进。mcache管理线程在本地缓存的mspan；mcentral管理全局的mspan供所有线程使用；mheap管理Go的所有动态分配内存。 极小对象会分配在一个object中，以节省资源，使用tiny分配器分配内存；一般小对象通过mspan分配内存；大对象则直接由mheap分配内存。 ","date":"2021-11-20T22:39:07Z","permalink":"https://lxb.wiki/57be14fe/","title":"Go 语言内存分配"},{"content":" Section1 channel 使用 1.1 make channel 一种是带缓冲的channel一种是不带缓冲的channel。创建方式分别如下：\n// buffered ch := make(chan Task, 3) // unbuffered ch := make(chan int) buffered channel\n如果我们创建一个带buffer的channel，底层的数据模型如下图：\n当我们向channel里面写入数据时候，会直接把数据存入circular queue(send)。当Queue存满了之后就会是如下的状态：\n当dequeue一个元素时候，如下所示：\n从上图可知，recvx自增加一，表示出队了一个元素，其实也就是循环数组实现FIFO语义。\n那么还有一个问题，当我们新建channel的时候，底层创建的hchan数据结构是在哪里分配内存的呢？其实Section2里面源码分析时候已经做了分析，hchan是在heap里面分配的。\n如下图所示：\n当我们使用make去创建一个channel的时候，实际上返回的是一个指向channel的pointer，所以我们能够在不同的function之间直接传递channel对象，而不用通过指向channel的指针。\n1.2 sends and receives 不同goroutine在channel上面进行读写时，涉及到的过程比较复杂，比如下图：\n上图中G1会往channel里面写入数据，G2会从channel里面读取数据。\nG1作用于底层hchan的流程如下图：\n先获取全局锁； 然后enqueue元素(通过移动拷贝的方式)； 释放锁； G2读取时候作用于底层数据结构流程如下图所示：\n先获取全局锁； 然后dequeue元素(通过移动拷贝的方式)； 释放锁； 上面的读写思路其实很简单，除了hchan数据结构外，不要通过共享内存去通信；而是通过通信(复制)实现共享内存。\n写入满channel的场景\n如下图所示：channel写入3个task之后队列已经满了，这时候G1再写入第四个task的时候会发生什么呢？\nG1这时候会暂停直到出现一个receiver。\n这个地方需要介绍一下Golang的scheduler的。我们知道goroutine是用户空间的线程，创建和管理协程都是通过Go的runtime，而不是通过OS的thread。\n但是Go的runtime调度执行goroutine却是基于OS thread的。如下图： 当向已经满的channel里面写入数据时候，会发生什么呢？如下图：\n上图流程大概如下：\n当前goroutine（G1）会调用gopark函数，将当前协程置为waiting状态； 将M和G1绑定关系断开； scheduler会调度另外一个就绪态的goroutine与M建立绑定关系，然后M 会运行另外一个G。 所以整个过程中，OS thread会一直处于运行状态，不会因为协程G1的阻塞而阻塞。最后当前的G1的引用会存入channel的sender队列(队列元素是持有G1的sudog)。\n那么blocked的G1怎么恢复呢？当有一个receiver接收channel数据的时候，会恢复 G1。\n实际上hchan数据结构也存储了channel的sender和receiver的等待队列。数据原型如下： 等待队列里面是sudog的单链表，sudog持有一个G代表goroutine对象引用，elem代表channel里面保存的元素。当G1执行ch\u0026lt;-task4的时候，G1会创建一个sudog然后保存进入sendq队列，实际上hchan结构如下图：\n这个时候，如果G2进行一个读取channel操作，读取前和读取后的变化图如下图：\n整个过程如下：\nG2调用 t:=\u0026lt;-ch 获取一个元素； 从channel的buffer里面取出一个元素task1； 从sender等待队列里面pop一个sudog； 将task4复制buffer中task1的位置，然后更新buffer的sendx和recvx索引值； 这时候需要将G1置为Runable状态，表示G1可以恢复运行； 这个时候将G1恢复到可运行状态需要scheduler的参与。G2会调用goready(G1)来唤醒G1。流程如下图所示：\n首先G2会调用goready(G1)，唤起scheduler的调度； 将G1设置成Runable状态； G1会加入到局部调度器P的local queue队列，等待运行。 读取空channel的场景\n当channel的buffer里面为空时，这时候如果G2首先发起了读取操作。如下图：\n会创建一个sudog，将代表G2的sudog存入recvq等待队列。然后G2会调用gopark函数进入等待状态，让出OS thread，然后G2进入阻塞态。\n这个时候，如果有一个G1执行写入操作，最直观的流程就是：\n将recvq中的task存入buffer；\ngoready(G2) 唤醒G2；\n但是我们有更加智能的方法：direct send; 其实也就是G1直接把数据写入到G2中的elem中，这样就不用走G2中的elem复制到buffer中，再从buffer复制给G1。如下图：\n具体过程就是G1直接把数据写入到G2的栈中。这样 G2 不需要去获取channel的全局锁和操作缓冲。\nSection2 channel源码 2.1 channel数据存储结构 在源码runtime/chan.go 里面定义了channel的数据模型，channel可以理解成一个缓冲队列，这个缓冲队列用来存储元素，并且提供FIFO的语义。源码如下：\ntype hchan struct { //channel队列里面总的数据量 qcount uint // total data in the queue // 循环队列的容量，如果是非缓冲的channel就是0 dataqsiz uint // size of the circular queue // 缓冲队列，数组类型。 buf unsafe.Pointer // points to an array of dataqsiz elements // 元素占用字节的size elemsize uint16 // 当前队列关闭标志位，非零表示关闭 closed uint32 // 队列里面元素类型 elemtype *_type // element type // 队列send索引 sendx uint // send index // 队列索引 recvx uint // receive index // 等待channel的G队列。 recvq waitq // list of recv waiters // 向channel发送数据的G队列。 sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G\u0026#39;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. // 全局锁 lock mutex } channel的数据结构相对比较简单，主要是两个结构： 1）一个数组实现的环形队列，数组有两个下标索引分别表示读写的索引，用于保存channel缓冲区数据。 2）channel的send和recv队列，队列里面都是持有goroutine的sudog元素，队列都是双链表实现的。 3）channel的全局锁。\n2.2 环形队列 chan内部实现了一个环形队列作为其缓冲区，队列的长度是创建chan时指定的。\n下图展示了一个可缓存6个元素的channel示意图：\ndataqsiz指示了队列长度为6，即可缓存6个元素； buf指向队列的内存，队列中还剩余两个元素； qcount表示队列中还有两个元素； sendx指示后续写入的数据存储的位置，取值[0, 6)； recvx指示从该位置读取数据, 取值[0, 6)； 2.3 等待队列 从channel读数据，如果channel缓冲区为空或者没有缓冲区，当前goroutine会被阻塞。 向channel写数据，如果channel缓冲区已满或者没有缓冲区，当前goroutine会被阻塞。\n被阻塞的goroutine将会挂在channel的等待队列中：\n因读阻塞的goroutine会被向channel写入数据的goroutine唤醒； 因写阻塞的goroutine会被从channel读数据的goroutine唤醒； 下图展示了一个没有缓冲区的channel，有几个goroutine阻塞等待读数据：\n注意，一般情况下recvq和sendq至少有一个为空。只有一个例外，那就是同一个goroutine使用select语句向channel一边写数据，一边读数据。\n2.4 类型信息 一个channel只能传递一种类型的值，类型信息存储在hchan数据结构中。\nelemtype代表类型，用于数据传递过程中的赋值； elemsize代表类型大小，用于在buf中定位元素位置。 2.5 锁 一个channel同时仅允许被一个goroutine读写，为简单起见，本章后续部分说明读写过程时不再涉及加锁和解锁。\nSection3 channel读写 3.1 创建channel 我们新建一个channel的时候一般使用 make(chan, n) 语句，这个语句的执行编译器会重写然后执行 chan.go里面的 makechan函数。函数源码如下：\nfunc makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size \u0026gt;= 1\u0026lt;\u0026lt;16 { throw(\u0026#34;makechan: invalid channel element type\u0026#34;) } if hchanSize%maxAlign != 0 || elem.align \u0026gt; maxAlign { throw(\u0026#34;makechan: bad alignment\u0026#34;) } if size \u0026lt; 0 || uintptr(size) \u0026gt; maxSliceCap(elem.size) || uintptr(size)*elem.size \u0026gt; maxAlloc-hchanSize { panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG\u0026#39;s are referenced from their owning thread so they can\u0026#39;t be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. var c *hchan switch { case size == 0 || elem.size == 0: // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = unsafe.Pointer(c) case elem.kind\u0026amp;kindNoPointers != 0: // Elements do not contain pointers. // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+uintptr(size)*elem.size, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // Elements contain pointers. c = new(hchan) c.buf = mallocgc(uintptr(size)*elem.size, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) if debugChan { print(\u0026#34;makechan: chan=\u0026#34;, c, \u0026#34;; elemsize=\u0026#34;, elem.size, \u0026#34;; elemalg=\u0026#34;, elem.alg, \u0026#34;; dataqsiz=\u0026#34;, size, \u0026#34;\\n\u0026#34;) } return c } 函数接收两个参数，一个是channel里面保存的元素的数据类型，一个是缓冲的容量(如果为0表示是非缓冲buffer)，创建流程如下：\n根据传递的缓冲大小size是否为零，分别创建不带buffer的channel或则带size大小的缓冲channel： 对于不带缓冲channel，申请一个hchan数据结构的内存大小； 对于带缓冲channel，new一个hchan对象，并初始化buffer内存 更新 chan中循环队列的关键属性：elemsize、elemtype、dataqsiz。 创建channel的过程实际上是初始化hchan结构。其中类型信息和缓冲区长度由make语句传入，buf的大小则与元素大小和缓冲区长度共同决定。\n创建channel的伪代码如下所示：\nfunc makechan(t *chantype, size int) *hchan { var c *hchan c = new(hchan) c.buf = malloc(元素类型大小*size) c.elemsize = 元素类型大小 c.elemtype = 元素类型 c.dataqsiz = size return c } 3.2 协程向channel写入数据(goroutine sender data) 所有执行 c \u0026lt; ep 将ep发送到channel的代码，最后都会调用到chan.go里面的 chansend函数。\n函数的定义如下：\nfunc chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { ...... } 函数有三个参数，第一个代表channel的数据结构，第二个是要指向写入的数据的指针，第三个block代表写入操作是否阻塞。\n向一个channel中写数据简单过程如下：\n如果等待接收队列recvq不为空，说明缓冲区中没有数据或者没有缓冲区，此时直接从recvq取出G,并把数据写入，最后把该G唤醒，结束发送过程； 如果缓冲区中有空余位置，将数据写入缓冲区，结束发送过程； 如果缓冲区中没有空余位置，将待发送数据写入G，将当前G加入sendq，进入睡眠，等待被读goroutine唤醒； 流程图如下：\n3.3 协程从channel接收数据(goroutine receive data) 所有执行 ep \u0026lt; c 使用ep接收channel数据的代码，最后都会调用到chan.go里面的 chanrecv函数。\n函数的定义如下：\nfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { ...... } 从源码注释就可以知道，该函数从channel里面接收数据，然后将接收到的数据写入到ep指针指向的对象里面。\n还有一个参数block，表示当channel无法返回数据时是否阻塞等待。当block=false并且channel里面没有数据时候，函数直接返回(false,false)。 从一个channel读数据简单过程如下：\n如果等待发送队列sendq不为空，且没有缓冲区，直接从sendq中取出G，把G中数据读出，最后把G唤醒，结束读取过程； 如果等待发送队列sendq不为空，此时说明缓冲区已满，从缓冲区中首部读出数据，把G中数据写入缓冲区尾部，把G唤醒，结束读取过程； 如果缓冲区中有数据，则从缓冲区取出数据，结束读取过程； 将当前goroutine加入recvq，进入睡眠，等待被写goroutine唤醒； 简单流程图如下：\n3.4 关闭channel 当我们执行channel的close操作的时候会关闭channel。\n关闭的主要流程如下所示：\n获取全局锁； 设置channel数据结构chan的关闭标志位； 获取当前channel上面的读goroutine并链接成链表； 获取当前channel上面的写goroutine然后拼接到前面的读链表后面； 释放全局锁； 唤醒所有的读写goroutine。 关闭channel时会把recvq中的G全部唤醒，本该写入G的数据位置为nil。把sendq中的G全部唤醒，但这些G会panic。\n除此之外，panic出现的常见场景还有：\n关闭值为nil的channel 关闭已经被关闭的channel 向已经关闭的channel写数据 Section4 常见用法 4.1 单向channel 单向channel指只能用于发送或接收数据，实际上并没有单向channel。\n我们知道channel可以通过参数传递，所谓单向channel只是对channel的一种使用限制，这跟C语言使用const修饰函数参数为只读是一个道理。\nfunc readChan(chanName \u0026lt;-chan int)： 通过形参限定函数内部只能从channel中读取数据 func writeChan(chanName chan\u0026lt;- int)： 通过形参限定函数内部只能向channel中写入数据 一个简单的示例程序如下：\nfunc readChan(chanName \u0026lt;-chan int) { \u0026lt;- chanName } func writeChan(chanName chan\u0026lt;- int) { chanName \u0026lt;- 1 } func main() { var mychan = make(chan int, 10) writeChan(mychan) readChan(mychan) } mychan是个正常的channel，而readChan()参数限制了传入的channel只能用来读，writeChan()参数限制了传入的channel只能用来写。\n4.2 select 使用select可以监控多channel，比如监控多个channel，当其中某一个channel有数据时，就从其读出数据。\n一个简单的示例程序如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func addNumberToChan(chanName chan int) { for { chanName \u0026lt;- 1 time.Sleep(1 * time.Second) } } func main() { var chan1 = make(chan int, 10) var chan2 = make(chan int, 10) go addNumberToChan(chan1) go addNumberToChan(chan2) for { select { case e := \u0026lt;- chan1 : fmt.Printf(\u0026#34;Get element from chan1: %d\\n\u0026#34;, e) case e := \u0026lt;- chan2 : fmt.Printf(\u0026#34;Get element from chan2: %d\\n\u0026#34;, e) default: fmt.Printf(\u0026#34;No element in chan1 and chan2.\\n\u0026#34;) time.Sleep(1 * time.Second) } } } 程序中创建两个channel： chan1和chan2。函数addNumberToChan()函数会向两个channel中周期性写入数据。通过select可以监控两个channel，任意一个可读时就从其中读出数据。\n程序输出如下：\nD:\\SourceCode\\GoExpert\\src\u0026gt;go run main.go Get element from chan1: 1 Get element from chan2: 1 No element in chan1 and chan2. Get element from chan2: 1 Get element from chan1: 1 No element in chan1 and chan2. Get element from chan2: 1 Get element from chan1: 1 No element in chan1 and chan2. 从输出可见，从channel中读出数据的顺序是随机的，事实上select语句的多个case执行顺序是随机的，关于select的实现原理会有专门章节分析。\n通过这个示例想说的是：select的case语句读channel不会阻塞，尽管channel中没有数据。这是由于case语句编译后调用读channel时会明确传入不阻塞的参数，此时读不到数据时不会将当前goroutine加入到等待队列，而是直接返回。\n4.3 range 通过range可以持续从channel中读出数据，好像在遍历一个数组一样，当channel中没有数据时会阻塞当前goroutine，与读channel时阻塞处理机制一样。\nfunc chanRange(chanName chan int) { for e := range chanName { fmt.Printf(\u0026#34;Get element from chan: %d\\n\u0026#34;, e) } } 注意：如果向此channel写数据的goroutine退出时，系统检测到这种情况后会panic，否则range将会永久阻塞。\n","date":"2021-11-10T21:56:56Z","permalink":"https://lxb.wiki/7b2461e3/","title":"Go channel 原理"},{"content":" 1、演示数据类型的实现 OBJECT ENCODING key\n该命令是用来显示五大数据类型的底层数据结构。\n比如对于 string 数据类型：\n可以看到实现string数据类型的数据结构有 embstr 以及 int。\n再比如 list 数据类型：\n2、简单动态字符串 Redis 是用 C 语言写的，但是对于Redis的字符串，却不是 C 语言中的字符串（即以空字符’\\0’结尾的字符数组），它是自己构建了一种名为 简单动态字符串（simple dynamic string,SDS）的抽象类型，并将 SDS 作为 Redis的默认字符串表示。\nSDS 定义：\nstruct sdshdr{ //记录buf数组中已使用字节的数量 //等于 SDS 保存字符串的长度 int len; //记录 buf 数组中未使用字节的数量 int free; //字节数组，用于保存字符串 char buf[]; } 用SDS保存字符串 “Redis”具体图示如下：\n我们看上面对于 SDS 数据类型的定义：\n1、len 保存了SDS保存字符串的长度\n2、buf[] 数组用来保存字符串的每个元素\n3、free j记录了 buf 数组中未使用的字节数量\n上面的定义相对于 C 语言对于字符串的定义，多出了 len 属性以及 free 属性。为什么不使用C语言字符串实现，而是使用 SDS呢？这样实现有什么好处？\n①、常数复杂度获取字符串长度\n由于 len 属性的存在，我们获取 SDS 字符串的长度只需要读取 len 属性，时间复杂度为 O(1)。而对于 C 语言，获取字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。通过 strlen key 命令可以获取 key 的字符串长度。\n②、杜绝缓冲区溢出\n我们知道在 C 语言中使用 strcat 函数来进行两个字符串的拼接，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。而对于 SDS 数据类型，在进行字符修改的时候，会首先根据记录的 len 属性检查内存空间是否满足需求，如果不满足，会进行相应的空间扩展，然后在进行修改操作，所以不会出现缓冲区溢出。\n③、减少修改字符串的内存重新分配次数\nC语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。\n而对于SDS，由于len属性和free属性的存在，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略：\n1、空间预分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。\n2、惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 free 属性将这些字节的数量记录下来，等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）\n④、二进制安全\n因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；而所有 SDS 的API 都是以处理二进制的方式来处理 buf 里面的元素，并且 SDS 不是以空字符串来判断是否结束，而是以 len 属性表示的长度来判断字符串是否结束。\n⑤、兼容部分 C 字符串函数\n虽然 SDS 是二进制安全的，但是一样遵从每个字符串都是以空字符串结尾的惯例，这样可以重用 C 语言库\u0026lt;string.h\u0026gt; 中的一部分函数。\n⑥、总结\n一般来说，SDS 除了保存数据库中的字符串值以外，SDS 还可以作为缓冲区（buffer）：包括 AOF 模块中的AOF缓冲区以及客户端状态中的输入缓冲区。后面在介绍Redis的持久化时会进行介绍。\n3、链表 链表是一种常用的数据结构，C 语言内部是没有内置这种数据结构的实现，所以Redis自己构建了链表的实现。\n链表定义：\ntypedef struct listNode{ //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点的值 void *value; }listNode 通过多个 listNode 结构就可以组成链表，这是一个双向链表，Redis还提供了操作链表的数据结构：\ntypedef struct list{ //表头节点 listNode *head; //表尾节点 listNode *tail; //链表所包含的节点数量 unsigned long len; //节点值复制函数 void (*free) (void *ptr); //节点值释放函数 void (*free) (void *ptr); //节点值对比函数 int (*match) (void *ptr,void *key); }list; Redis链表特性：\n①、双端：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。\n②、无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结束。　③、带链表长度计数器：通过 len 属性获取链表长度的时间复杂度为 O(1)。\n④、多态：链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。\n4、字典 字典又称为符号表或者关联数组、或映射（map），是一种用于保存键值对的抽象数据结构。字典中的每一个键 key 都是唯一的，通过 key 可以对值来进行查找或修改。C 语言中没有内置这种数据结构的实现，所以字典依然是 Redis自己构建的。\nRedis 的字典使用哈希表作为底层实现\n哈希表结构定义：\ntypedef struct dictht{ //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 //总是等于 size-1 unsigned long sizemask; //该哈希表已有节点的数量 unsigned long used; }dictht 哈希表是由数组 table 组成，table 中每个元素都是指向 dict.h/dictEntry 结构，dictEntry 结构定义如下：\ntypedef struct dictEntry{ //键 void *key; //值 union{ void *val; uint64_tu64; int64_ts64; }v; //指向下一个哈希表节点，形成链表 struct dictEntry *next; }dictEntry key 用来保存键，val 属性用来保存值，值可以是一个指针，也可以是uint64_t整数，也可以是int64_t整数。\n注意这里还有一个指向下一个哈希表节点的指针，我们知道哈希表最大的问题是存在哈希冲突，如何解决哈希冲突，有开放地址法和链地址法。这里采用的便是链地址法，通过next这个指针可以将多个哈希值相同的键值对连接在一起，用来解决哈希冲突。\n**①、哈希算法：**Redis计算哈希值和索引值方法如下：\n#1、使用字典设置的哈希函数，计算键 key 的哈希值 hash = dict-\u0026gt;type-\u0026gt;hashFunction(key); #2、使用哈希表的sizemask属性和第一步得到的哈希值，计算索引值 index = hash \u0026amp; dict-\u0026gt;ht[x].sizemask; **②、解决哈希冲突：**这个问题上面我们介绍了，方法是链地址法。通过字典里面的 *next 指针指向下一个具有相同索引值的哈希表节点。\n**③、扩容和收缩：**当哈希表保存的键值对太多或者太少时，就要通过 rerehash(重新散列）来对哈希表进行相应的扩展或者收缩。具体步骤：\n1、如果执行扩展操作，会基于原哈希表创建一个大小等于 ht[0].used*2n 的哈希表（也就是每次扩展都是根据原哈希表已使用的空间扩大一倍创建另一个哈希表）。相反如果执行的是收缩操作，每次收缩是根据已使用空间缩小一倍创建一个新的哈希表。\n2、重新利用上面的哈希算法，计算索引值，然后将键值对放到新的哈希表位置上。\n3、所有键值对都迁徙完毕后，释放原哈希表的内存空间。\n④、触发扩容的条件：\n1、服务器目前没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于1。\n2、服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于5。\nps：负载因子 = 哈希表已保存节点数量 / 哈希表大小。\n⑤、渐近式 rehash\n什么叫渐进式 rehash？也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行 增加操作，一定是在新的哈希表上进行的。\n5、跳跃表 跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。具有如下性质：\n1、由很多层结构组成；\n2、每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的head节点和后面的nil节点；\n3、最底层的链表包含了所有的元素；\n4、如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现（上一层的元素是当前层的元素的子集）；\n5、链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点；\nRedis中跳跃表节点定义如下：\ntypedef struct zskiplistNode { //层 struct zskiplistLevel{ //前进指针 struct zskiplistNode *forward; //跨度 unsigned int span; }level[]; //后退指针 struct zskiplistNode *backward; //分值 double score; //成员对象 robj *obj; } zskiplistNode 多个跳跃表节点构成一个跳跃表：\ntypedef struct zskiplist{ //表头节点和表尾节点 structz skiplistNode *header, *tail; //表中节点的数量 unsigned long length; //表中层数最大的节点的层数 int level; }zskiplist; ①、搜索：从最高层的链表节点开始，如果比当前节点要大和比当前层的下一个节点要小，那么则往下找，也就是和当前层的下一层的节点的下一个节点进行比较，以此类推，一直找到最底层的最后一个节点，如果找到则返回，反之则返回空。\n②、插入：首先确定插入的层数，有一种方法是假设抛一枚硬币，如果是正面就累加，直到遇见反面为止，最后记录正面的次数作为插入的层数。当确定插入的层数k后，则需要将新元素插入到从底层到k层。\n③、删除：在各个层中找到包含指定值的节点，然后将节点从链表中删除即可，如果删除以后只剩下头尾两个节点，则删除这一层。\n6、整数集合 整数集合（intset）是Redis用于保存整数值的集合抽象数据类型，它可以保存类型为int16_t、int32_t 或者int64_t 的整数值，并且保证集合中不会出现重复元素。\n定义如下：\ntypedef struct intset{ //编码方式 uint32_t encoding; //集合包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[]; }intset; 整数集合的每个元素都是 contents 数组的一个数据项，它们按照从小到大的顺序排列，并且不包含任何重复项。\nlength 属性记录了 contents 数组的大小。\n需要注意的是虽然 contents 数组声明为 int8_t 类型，但是实际上contents 数组并不保存任何 int8_t 类型的值，其真正类型有 encoding 来决定。\n①、升级\n当我们新增的元素类型比原集合元素类型的长度要大时，需要对整数集合进行升级，才能将新元素放入整数集合中。具体步骤：\n1、根据新元素类型，扩展整数集合底层数组的大小，并为新元素分配空间。\n2、将底层数组现有的所有元素都转成与新元素相同类型的元素，并将转换后的元素放到正确的位置，放置过程中，维持整个元素顺序都是有序的。\n3、将新元素添加到整数集合中（保证有序）。\n升级能极大地节省内存。\n②、降级\n整数集合不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态。\n7、压缩列表 压缩列表（ziplist）是Redis为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。\n压缩列表的原理：压缩列表并不是对数据利用某种算法进行压缩，而是将数据按照一定规则编码在一块连续的内存区域，目的是节省内存。\n压缩列表的每个节点构成如下：\n①、previous_entry_ength：记录压缩列表前一个字节的长度。previous_entry_ength的长度可能是1个字节或者是5个字节，如果上一个节点的长度小于254，则该节点只需要一个字节就可以表示前一个节点的长度了，如果前一个节点的长度大于等于254，则previous length的第一个字节为254，后面用四个字节表示当前节点前一个节点的长度。利用此原理即当前节点位置减去上一个节点的长度即得到上一个节点的起始位置，压缩列表可以从尾部向头部遍历。这么做很有效地减少了内存的浪费。\n②、encoding：节点的encoding保存的是节点的content的内容类型以及长度，encoding类型一共有两种，一种字节数组一种是整数，encoding区域长度为1字节、2字节或者5字节长。\n③、content：content区域用于保存节点的内容，节点内容类型和长度由encoding决定。\n8、总结 ​\t大多数情况下，Redis使用简单字符串SDS作为字符串的表示，相对于C语言字符串，SDS具有常数复杂度获取字符串长度，杜绝了缓存区的溢出，减少了修改字符串长度时所需的内存重分配次数，以及二进制安全能存储各种类型的文件，并且还兼容部分C函数。\n通过为链表设置不同类型的特定函数，Redis链表可以保存各种不同类型的值，除了用作列表键，还在发布与订阅、慢查询、监视器等方面发挥作用（后面会介绍）。\nRedis的字典底层使用哈希表实现，每个字典通常有两个哈希表，一个平时使用，另一个用于rehash时使用，使用链地址法解决哈希冲突。\n跳跃表通常是有序集合的底层实现之一，表中的节点按照分值大小进行排序。\n整数集合是集合键的底层实现之一，底层由数组构成，升级特性能尽可能的节省内存。\n压缩列表是Redis为节省内存而开发的顺序型数据结构，通常作为列表键和哈希键的底层实现之一。\n参考资料 Redis详解（三）\u0026mdash;\u0026mdash; redis的六大数据类型详细用法 - YSOcean - 博客园 (cnblogs.com)\n","date":"2021-11-02T21:21:18Z","permalink":"https://lxb.wiki/abddb7fd/","title":"Redis的底层数据结构 "},{"content":" 1. 准备 TCP是属于网络分层中的运输层(有的书也翻译为传输层)， 分层以及每层的协议，TCP是属于运输层(有的书也翻译为传输层)，如下两张图：\nTCP三次握手会涉及到状态转换所以这里贴出TCP的状态转换图如下：\n2.TCP三次握手简述 要想简单了解TCP三次握手，我们首先要了解TCP头部结构，如下：\nTCP传递给IP层的信息单位称为报文段或段，下面都用段做单位。\nTCP三次握手如图：\n2.1 第一次握手 客户端给服务器发送一个SYN段(在 TCP 标头中 SYN 位字段为 1 的 TCP/IP 数据包), 该段中也包含客户端的初始序列号(Sequence number = J)。\nSYN是同步的缩写，SYN 段是发送到另一台计算机的 TCP 数据包，请求在它们之间建立连接\n2.2 第二次握手 服务器返回客户端 SYN +ACK 段(在 TCP 标头中SYN和ACK位字段都为 1 的 TCP/IP 数据包)， 该段中包含服务器的初始序列号(Sequence number = K)；同时使 Acknowledgment number = J + 1来表示确认已收到客户端的 SYN段(Sequence number = J)。\nACK 是“确认”的缩写。 ACK 数据包是任何确认收到一条消息或一系列数据包的 TCP 数据包\n2.3 第三次握手 客户端给服务器响应一个ACK段(在 TCP 标头中 ACK 位字段为 1 的 TCP/IP 数据包), 该段中使 Acknowledgment number = K + 1来表示确认已收到服务器的 SYN段(Sequence number = K)。\n2.4 实例观察 2.4.1 tcpdump 使用tcpdump观察如下：因为都是在本机同时运行client和server所以命令为：tcpdump -i lo port 5555, 只能监听回路lo接口，结果如下\n如图用红色圈起来的就是3次握手，但是为什么最后一次握手，为什么ack = 1,而不是369535922 呢， 这是因为这里的第三次握手tcpdump显示的是相对的顺序号。但是为了便于观察我们需要把tcpdump的 顺序号变为绝对的顺序号。\n命令只需要加-S(大写)便可，即：tcpdump -i lo port 5555 -S\n加上之后结果就正常了如下图：\n从tcpdump的数据，可以明显的看到三次握手的过程是： 第一次握手：client SYN=1, Sequence number=2322326583 —\u0026gt; server 第二次握手：server SYN=1,Sequence number=3573692787; ACK=1, Acknowledgment number=2322326583 + 1 —\u0026gt; client 第三次握手：client ACK=1, Acknowledgment number=3573692787 + 1 \u0026ndash;\u0026gt;server\n想简单了解一下TCP三次握手的话, 看到这里就可以了.\n3.TCP三次握手详细解析过程： 3.1 第一次握手 客户在socket() connect()后主动(active open)连接上服务器, 发送SYN ，这时客户端的状态是SYN_SENT 服务器在进行socket(),bind(),listen()后等待客户的连接，收到客户端的 SYN 后，\n3.1.1 半连接队列(syn queue)未满 服务器将该连接的状态变为SYN_RCVD, 服务器把连接信息放到半连接队列(syn queue)里面。\n3.1.2 半连接队列(syn queue)已满 服务器不会将该连接的状态变为SYN_RCVD，且将该连接丢弃(SYN flood攻击就是利用这个原理， 对于SYN foold攻击，应对方法之一是使syncookies生效，将其值置1即可，路径/proc/sys/net/ipv4/tcp_syncookies， 即使是半连接队列syn queue已经满了，也可以接收正常的非恶意攻击的客户端的请求， 但是这种方法只在无计可施的情况下使用，man tcp里面的解析是这样说的， Centos6.9默认是置为1\n半连接队列(syn queue)最大值 /proc/sys/net/ipv4/tcp_max_syn_backlog\nSYN flood攻击\n攻击方的客户端只发送SYN分节给服务器，然后对服务器发回来的SYN+ACK什么也不做，直接忽略掉， 不发送ACK给服务器；这样就可以占据着服务器的半连接队列的资源，导致正常的客户端连接无法连接上服务器。维基百科\n(SYN flood攻击的方式其实也分两种，第一种，攻击方的客户端一直发送SYN，对于服务器回应的SYN+ACK什么也不做，不回应ACK, 第二种，攻击方的客户端发送SYN时，将源IP改为一个虚假的IP, 然后服务器将SYN+ACK发送到虚假的IP, 这样当然永远也得不到ACK的回应。)\n3.2 第二次握手 服务器返回SYN+ACK段给到客户端，客户端收到SYN+ACK段后，客户端的状态从SYN_SENT变为ESTABLISHED， 也即是connect()函数的返回。\n3.3 第三次握手 全连接队列(accept queue)的最大值 /proc/sys/net/core/somaxconn (默认128)\n全连接队列值 = min(backlog, somaxconn) 这里的backlog是listen(int sockfd, int backlog)函数里面的那个参数backlog\n3.3.1 全连接队列(accept queue)未满 服务器收到客户端发来的ACK, 服务端该连接的状态从SYN_RCVD变为ESTABLISHED, 然后服务器将该连接从半连接队列(syn queue)里面移除，且将该连接的信息放到全连接队列(accept queue)里面。\n3.3.2 全连接队列(accept queue)已满 服务器收到客户端发来的ACK, 不会将该连接的状态从SYN_RCVD变为ESTABLISHED。 当然全连接队列(accept queue)已满时，则根据 tcp_abort_on_overflow 的值来执行相应动作 /proc/sys/net/ipv4/tcp_abort_on_overflow 查看参数值 3.3.2.1 tcp_abort_on_overflow = 0 则服务器建立该连接的定时器，\n这个定时器是一个服务器的规则是从新发送syn+ack的时间间隔成倍的增加， 比如从新了第二次握手，进行了5次，这五次的时间分别是 1s, 2s,4s,8s,16s, 这种倍数规则叫“二进制指数退让”(binary exponential backoff)\n给客户端定时从新发回SYN+ACK即从新进行第二次握手，(如果客户端设定的超时时间比较短就很容易出现异常) 服务器从新进行第二次握手的次数/proc/sys/net/ipv4/tcp_synack_retries\n3.3.2.2 tcp_abort_on_overflow = 1 关于tcp_abort_on_overflow的解析如下：\n意思应该是，当 tcp_abort_on_overflow 等于1 时,重置连接(一般是发送RST给客户端)， 至于怎么重置连接是系统的事情了。 不过我在查资料的过程发现，阿里中间件团队博客说并不是发送RST， —[阿里中间件团队博客]\n这个博客跑的实例观察到的是服务器会忽略client传过来的包，然后client重传，一定次数后client认为异常，然后断开连接。 当然，我们写代码的都知道代码是第一手的注释，实践是检验真理的唯一标准， 最好还是自己以自己实践为准，因为可能你的环境跟别人的不一样。)\n查看全连接队列(accept queue)的使用情况\n如上图，第二列Recv-Q是，全连接队列接收到达的连接，第三列是Send-Q全连接队列的所能容纳最大值， 如果，Recv-Q 大于 Send-Q 那么大于的那部分，是要溢出的即要被丢弃overflow掉的。\n希望热心的网友帮忙提改进意见时可以直接指出哪一段第几句(比如 2.4.1 tcpdump 第一段第一句, 命令tcpdump -i lo port 5555 里参数 i 用错了，应该用 I)，这样比较快速找到好改正。\n4 四次挥手 【注意】中断连接端可以是Client端，也可以是Server端。\n假设Client端发起中断连接请求，也就是发送FIN报文。Server端接到FIN报文后，意思是说\u0026quot;我Client端没有数据要发给你了\u0026quot;，但是如果你还有数据没有发送完成，则不必急着关闭Socket，可以继续发送数据。所以你先发送ACK，\u0026ldquo;告诉Client端，你的请求我收到了，但是我还没准备好，请继续你等我的消息\u0026rdquo;。这个时候Client端就进入FIN_WAIT状态，继续等待Server端的FIN报文。当Server端确定数据已发送完成，则向Client端发送FIN报文，\u0026ldquo;告诉Client端，好了，我这边数据发完了，准备好关闭连接了\u0026rdquo;。Client端收到FIN报文后，\u0026ldquo;就知道可以关闭连接了，但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。“，Server端收到ACK后，\u0026ldquo;就知道可以断开连接了\u0026rdquo;。Client端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，我Client端也可以关闭连接了。Ok，TCP连接就这样关闭了！\n整个过程Client端所经历的状态如下： 而Server端所经历的过程如下：\n【注意】 在TIME_WAIT状态中，如果TCP client端最后一次发送的ACK丢失了，它将重新发送。TIME_WAIT状态中所需要的时间是依赖于实现方法的。典型的值为30秒、1分钟和2分钟。等待之后连接正式关闭，并且所有的资源(包括端口号)都被释放。\n【问题1】为什么连接的时候是三次握手，关闭的时候却是四次握手？ 答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，\u0026ldquo;你发的FIN报文我收到了\u0026rdquo;。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。\n【问题2】为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？\n答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。\n根据第三版《UNIX网络编程 卷1》2.7节，TIME_WAIT状态的主要目的有两个：\n优雅的关闭TCP连接，也就是尽量保证被动关闭的一端收到它自己发出去的FIN报文的ACK确认报文； 处理延迟的重复报文，这主要是为了避免前后两个使用相同四元组的连接中的前一个连接的报文干扰后一个连接。 很明显，要实现上述两个目标，TIME_WAIT状态需要持续一段时间，但这段时间应该是多长呢？\n如果只考虑上述第一个目标，则TIME_WAIT状态需要持续的时间应该参考对端的RTO（重传超时时间）以及MSL（报文在网络中的最大生存时间）来计算而不是仅仅按MSL来计算，因为只要对端没有收到针对FIN报文的ACK，就会一直持续重传FIN报文直到重传超时，所以最能实现完美关闭连接的时长计算方式应该是从对端发送第一个FIN报文开始计时到它最后一次重传FIN报文这段时长加上MSL，但这个计算方式过于保守，只有在所有的ACK报文都丢失的情况下才需要这么长的时间；另外，第一个目标虽然重要，但并不十分关键，因为既然已经到了关闭连接的最后一步，说明在这个TCP连接上的所有用户数据已经完成可靠传输，所以要不要完美的关闭这个连接其实已经不是那么关键了。因此，（我猜）RFC标准的制定者才决定以网络丢包不太严重为前提条件，然后根据第二个目标来计算TIME_WAIT状态应该持续的时长。\n对于刚才说的第二点，如何理解TIME_WAIT状态持续2MSL的时间就可以避免前后两个使用相同四元组的连接中的前一个连接的报文干扰后一个连接呢？\n首先我们需要了解如下要点：\nTCP连接中的一端发送了FIN报文之后如果收不到对端针对该FIN的ACK，则会反复多次重传FIN报文，大约持续几分钟； 被动关闭处于LAST_ACK状态的一端在收到最后一个ACK之后不会发送任何报文，立即进入CLOSED状态； 主动关闭的一端在收到被动关闭端发送过来的FIN报文并回复ACK之后进入TIME_WAIT状态； 之所以TIME_WAIT状态需要维持一段时间而不是进入CLOSED状态，是因为需要处理对端可能重传的FIN报文或其它一些因网络原因而延迟的数据报文，不处理这些报文可能导致前后两个使用相同四元组的连接中的后一个连接出现异常(详见UNIX网络编程卷1的2.7节 第三版)； 处于TIME_WAIT状态的一端在收到重传的FIN时会重新计时(rfc793 以及 linux kernel源代码tcp_timewait_state_process函数)。 下面我们开始分析为什么在发送了最后一个ACK报文之后需要等待2MSL时长来确保没有任何属于当前连接的报文还存活于网络之中（前提是在这2MSL时间内不再收到对方的FIN报文，但即使收到了对端的FIN报文也并不影响我们的讨论，因为如果收到FIN则会回复ACK并重新计时）。\n为了便于描述，我们设想有一个处于拆链过程中的TCP连接，这个连接的两端分别是A和B，其中A是主动关闭连接的一端，因为刚刚向对端发送了针对对端发送过来的FIN报文的ACK，此时正处于TIME_WAIT状态；而B是被动关闭的一端，此时正处于LAST_ACK状态，在收到最后一个ACK之前它会一直重传FIN报文直至超时。随着时间的流逝，A发送给B的ACK报文将会有两种结局：\nACK报文在网络中丢失；如前所述，这种情况我们不需要考虑，因为除非多次重传失败，否则AB两端的状态不会发生变化直至某一个ACK不再丢失。 ACK报文被B接收到。我们假设A发送了ACK报文后过了一段时间t之后B才收到该ACK，则有 0 \u0026lt; t \u0026lt;= MSL。因为A并不知道它发送出去的ACK要多久对方才能收到，所以A至少要维持MSL时长的TIME_WAIT状态才能保证它的ACK从网络中消失。同时处于LAST_ACK状态的B因为收到了ACK，所以它直接就进入了CLOSED状态，而不会向网络发送任何报文。所以晃眼一看，A只需要等待1个MSL就够了，但仔细想一下其实1个MSL是不行的，因为在B收到ACK前的一刹那，B可能因为没收到ACK而重传了一个FIN报文，这个FIN报文要从网络中消失最多还需要一个MSL时长，所以A还需要多等一个MSL。 综上所述，TIME_WAIT至少需要持续2MSL时长，这2个MSL中的第一个MSL是为了等自己发出去的最后一个ACK从网络中消失，而第二MSL是为了等在对端收到ACK之前的一刹那可能重传的FIN报文从网络中消失。另外，虽然说维持TIME_WAIT状态一段时间有2个目的，但这段时间具体应该多长主要是为了达成上述第二个目的而设计的。\n","date":"2021-10-21T22:54:29Z","permalink":"https://lxb.wiki/5fa4c221/","title":"TCP协议中的三次握手和四次挥手"},{"content":" 为什么要用统一配置？\n我们做项目时用到的配置比如数据库配置等\u0026hellip;我们都是写死在项目里面，如果需要更改，那么也是的修改配置文件然后再投产上去，那么问题来了，如果做集群的呢，有100台机器，这时候做修改那就太不切实际了；那么就需要用到统一配置管理啦。\n解决思路\n1.把公共配置抽取出来\n2.对公共配置进行维护\n3.修改公共配置后应用不需要重新部署\n采用方案\n1.公共配置抽取存放于zookeeper中并落地数据库\n2.对公共配置修改后发布到zookeeper中并落地数据库\n3.对应用开启配置实时监听，zookeeper配置文件一旦被修改，应用可实时监听到并获取\n下面基于zookeeper粗略实现了一个统一配置管理\n需要用到的jar是zkclient\n配置文件Config\npackage com.cwh.zk.util; import java.io.Serializable; public class Config implements Serializable{ /** * */ private static final long serialVersionUID = 1L; private String userNm; private String userPw; public Config() { } public Config(String userNm, String userPw) { this.userNm = userNm; this.userPw = userPw; } public String getUserNm() { return userNm; } public void setUserNm(String userNm) { this.userNm = userNm; } public String getUserPw() { return userPw; } public void setUserPw(String userPw) { this.userPw = userPw; } @Override public String toString() { return \u0026#34;Config [userNm=\u0026#34; + userNm + \u0026#34;, userPw=\u0026#34; + userPw + \u0026#34;]\u0026#34;; } }\t配置管理中心ZkConfigMag\npackage com.cwh.zk.util; import org.I0Itec.zkclient.ZkClient; public class ZkConfigMag { private Config config; /** * 从数据库加载配置 */ public Config downLoadConfigFromDB(){ //getDB config = new Config(\u0026#34;nm\u0026#34;, \u0026#34;pw\u0026#34;); return config; } /** * 配置文件上传到数据库 */ public void upLoadConfigToDB(String nm, String pw){ if(config==null)config = new Config(); config.setUserNm(nm); config.setUserPw(pw); //updateDB } /** * 配置文件同步到zookeeper */ public void syncConfigToZk(){ ZkClient zk = new ZkClient(\u0026#34;localhost:2181\u0026#34;); if(!zk.exists(\u0026#34;/zkConfig\u0026#34;)){ zk.createPersistent(\u0026#34;/zkConfig\u0026#34;,true); } zk.writeData(\u0026#34;/zkConfig\u0026#34;, config); zk.close(); } } 应用监听实现ZkGetConfigClient\npackage com.cwh.zk.util; import org.I0Itec.zkclient.IZkDataListener; import org.I0Itec.zkclient.ZkClient; public class ZkGetConfigClient { private Config config; public Config getConfig() { ZkClient zk = new ZkClient(\u0026#34;localhost:2181\u0026#34;); config = (Config)zk.readData(\u0026#34;/zkConfig\u0026#34;); System.out.println(\u0026#34;加载到配置：\u0026#34;+config.toString()); //监听配置文件修改 zk.subscribeDataChanges(\u0026#34;/zkConfig\u0026#34;, new IZkDataListener(){ @Override public void handleDataChange(String arg0, Object arg1) throws Exception { config = (Config) arg1; System.out.println(\u0026#34;监听到配置文件被修改：\u0026#34;+config.toString()); } @Override public void handleDataDeleted(String arg0) throws Exception { config = null; System.out.println(\u0026#34;监听到配置文件被删除\u0026#34;); } }); return config; } public static void main(String[] args) { ZkGetConfigClient client = new ZkGetConfigClient(); client.getConfig(); System.out.println(client.config.toString()); for(int i = 0;i\u0026lt;10;i++){ System.out.println(client.config.toString()); try { Thread.sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } } } } 测试，启动配置管理中心\npackage com.cwh.zkConfig.test; import com.cwh.zk.util.Config; import com.cwh.zk.util.ZkConfigMag; public class ZkConfigTest { public static void main(String[] args) { ZkConfigMag mag = new ZkConfigMag(); Config config = mag.downLoadConfigFromDB(); System.out.println(\u0026#34;....加载数据库配置....\u0026#34;+config.toString()); mag.syncConfigToZk(); System.out.println(\u0026#34;....同步配置文件到zookeeper....\u0026#34;); //歇会，这样看比较清晰 try { Thread.sleep(10000); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } mag.upLoadConfigToDB(\u0026#34;cwhcc\u0026#34;, \u0026#34;passwordcc\u0026#34;); System.out.println(\u0026#34;....修改配置文件....\u0026#34;+config.toString()); mag.syncConfigToZk(); System.out.println(\u0026#34;....同步配置文件到zookeeper....\u0026#34;); } } 测试结果：\n配置管理中心打印：\n应用监听：\n","date":"2021-10-15T22:17:32Z","permalink":"https://lxb.wiki/15475898/","title":"基于zookeeper实现统一配置管理"},{"content":" ZooKeeper 可以作为注册中心，也可以作为分布式锁的一种实现。Kafka 使用 ZooKeeper 管理自己的元数据配置。\n一、什么是ZooKeeper 官网介绍\n官网还有另一段话：\nZooKeeper: A Distributed Coordination Service for Distributed Applications\nWiki中对ZooKeeper的介绍：\n概括：\nZooKeeper主要服务于分布式系统，可以用ZooKeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理。 使用分布式系统就无法避免对节点管理的问题(需要实时感知节点的状态、对节点进行统一管理等等)，而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper作为一个能够通用解决这些问题的中间件就应运而生了。 二、为什么ZooKeeper能干这么多？ Wiki 中提到：\nZooKeeper nodes store their data in a hierarchical name space, much like a file system or a tree data structure\nZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗树，每个节点叫做ZNode。每一个节点可以通过路径来标识，结构图如下：\n那ZooKeeper这颗\u0026quot;树\u0026quot;有什么特点呢？？ZooKeeper的节点我们称之为Znode，Znode分为两种类型：\n短暂/临时(Ephemeral)：当客户端和服务端断开连接后，所创建的Znode(节点)会自动删除 持久(Persistent)：当客户端和服务端断开连接后，所创建的Znode(节点)不会删除 ZooKeeper和Redis一样，也是C/S结构(分成客户端和服务端)\n2.1 监听器 在上面我们已经简单知道了ZooKeeper的数据结构了，ZooKeeper还配合了监听器才能够做那么多事的。\n常见的监听场景有以下两项：\n监听Znode节点的数据变化 监听子节点的增减变化 没错，通过监听+Znode节点(持久/短暂[临时])，ZooKeeper就可以玩出这么多花样了。\n3.1 统一配置管理 比如我们现在有三个系统A、B、C，他们有三份配置，分别是ASystem.yml、BSystem.yml、CSystem.yml，然后，这三份配置又非常类似，很多的配置项几乎都一样。\n此时，如果我们要改变其中一份配置项的信息，很可能其他两份都要改。并且，改变了配置项的信息很可能就要重启系统 于是，我们希望把ASystem.yml、BSystem.yml、CSystem.yml相同的配置项抽取出来成一份公用的配置common.yml，并且即便common.yml改了，也不需要系统A、B、C重启。\n做法：我们可以将common.yml这份配置放在ZooKeeper的Znode节点中，系统A、B、C监听着这个Znode节点有无变更，如果变更了，及时响应。\n参考资料：基于zookeeper实现统一配置管理\n3.2 统一命名服务 统一命名服务的理解其实跟域名一样，是我们为这某一部分的资源给它取一个名字，别人通过这个名字就可以拿到对应的资源。\n比如说，现在我有一个域名www.java3y.com，但我这个域名下有多台机器：\n192.168.1.1 192.168.1.2 192.168.1.3 192.168.1.4 别人访问www.java3y.com即可访问到我的机器，而不是通过IP去访问。\n3.3 分布式锁 我们可以使用ZooKeeper来实现分布式锁，那是怎么做的呢？？下面来看看：\n系统A、B、C都去访问/locks节点\n访问的时候会创建带顺序号的临时/短暂(EPHEMERAL_SEQUENTIAL)节点，比如，系统A创建了id_000000节点，系统B创建了id_000002节点，系统C创建了id_000001节点。\n接着，拿到/locks节点下的所有子节点(id_000000,id_000001,id_000002)，判断自己创建的是不是最小的那个节点\n如果是，则拿到锁。\n释放锁：执行完操作后，把创建的节点给删掉 如果不是，则监听比自己要小1的节点变化\n举个例子：\n系统A拿到/locks节点下的所有子节点，经过比较，发现自己(id_000000)，是所有子节点最小的。所以得到锁 系统B拿到/locks节点下的所有子节点，经过比较，发现自己(id_000002)，不是所有子节点最小的。所以监听比自己小1的节点id_000001的状态 系统C拿到/locks节点下的所有子节点，经过比较，发现自己(id_000001)，不是所有子节点最小的。所以监听比自己小1的节点id_000000的状态 …\u0026hellip; 等到系统A执行完操作以后，将自己创建的节点删除(id_000000)。通过监听，系统C发现id_000000节点已经删除了，发现自己已经是最小的节点了，于是顺利拿到锁 ….系统B如上 3.4集群状态 ZooKeeper是怎么\u0026quot;感知\u0026ldquo;节点的动态新增或者删除的\n还是以三个系统A、B、C为例，在ZooKeeper中创建临时节点即可：\n只要系统A挂了，那/groupMember/A这个节点就会删除，通过监听groupMember下的子节点，系统B和C就能够感知到系统A已经挂了。(新增也是同理)\n除了能够感知节点的上下线变化，ZooKeeper还可以实现动态选举Master的功能。(如果集群是主从架构模式下)\n原理也很简单，如果想要实现动态选举Master的功能，Znode节点的类型是带顺序号的临时节点(EPHEMERAL_SEQUENTIAL)就好了。\nZookeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的Znode节点就会删除。然后让新的最小编号作为Master，这样就可以实现动态选举的功能了。 ","date":"2021-10-15T21:51:29Z","permalink":"https://lxb.wiki/f07e16f1/","title":"ZooKeeper总结"},{"content":" 1. 相比较于其他语言, Go 有什么优势或者特点？ Go 允许跨平台编译，编译出来的是二进制的可执行文件，直接部署在对应系统上即可运行。 Go 在语言层次上天生支持高并发，通过 goroutine 和 channel 实现。channel 的理论依据是 CSP 并发模型， 即所谓的通过通信来共享内存；Go 在 runtime 运行时里实现了属于自己的调度机制：GMP，降低了内核态和用户态的切换成本。 Go 的代码风格是强制性的统一，如果没有按照规定来，会编译不通过。 2. Golang 里的 GMP 模型？ GMP 模型是 golang 自己的一个调度模型，它抽象出了下面三个结构：\nG： 也就是协程 goroutine，由 Go runtime 管理。我们可以认为它是用户级别的线程。 P： processor 处理器。每当有 goroutine 要创建时，会被添加到 P 上的 goroutine 本地队列上，如果 P 的本地队列已满，则会维护到全局队列里。 M： 系统线程。在 M 上有调度函数，它是真正的调度执行者，M 需要跟 P 绑定，并且会让 P 按下面的原则挑出个 goroutine 来执行： 优先从 P 的本地队列获取 goroutine 来执行；如果本地队列没有，从全局队列获取，如果全局队列也没有，会从其他的 P 上偷取 goroutine。\n3. goroutine 的协程有什么特点，和线程相比？ goroutine 非常的轻量，初始分配只有 2KB，当栈空间不够用时，会自动扩容。同时，自身存储了执行 stack 信息，用于在调度时能恢复上下文信息。\n而线程比较重，一般初始大小有几 MB(不同系统分配不同)，线程是由操作系统调度，是操作系统的调度基本单位。而 golang 实现了自己的调度机制，goroutine 是它的调度基本单位。\n4. Go 的垃圾回收机制？ Go 采用的是三色标记法，将内存里的对象分为了三种：\n白色对象：未被使用的对象； 灰色对象：当前对象有引用对象，但是还没有对引用对象继续扫描过； 黑色对象，对上面提到的灰色对象的引用对象已经全部扫描过了，下次不用再扫描它了。 当垃圾回收开始时，Go 会把根对象标记为灰色，其他对象标记为白色，然后从根对象遍历搜索，按照上面的定义去不断的对灰色对象进行扫描标记。当没有灰色对象时，表示所有对象已扫描过，然后就可以开始清除白色对象了。\n5. go 的内存分配是怎么样的？ Go 的内存分配借鉴了 Google 的 TCMalloc 分配算法，其核心思想是内存池 + 多级对象管理。内存池主要是预先分配内存，减少向系统申请的频率；多级对象有：mheap、mspan、arenas、mcentral、mcache。它们以 mspan 作为基本分配单位。具体的分配逻辑如下：\n当要分配大于 32K 的对象时，从 mheap 分配。 当要分配的对象小于等于 32K 大于 16B 时，从 P 上的 mcache 分配，如果 mcache 没有内存，则从 mcentral 获取，如果 mcentral 也没有，则向 mheap 申请，如果 mheap 也没有，则从操作系统申请内存。 当要分配的对象小于等于 16B 时，从 mcache 上的微型分配器上分配。 6. channel 的内部实现是怎么样的？ channel 内部维护了两个 goroutine 队列，一个是待发送数据的 goroutine 队列，另一个是待读取数据的 goroutine 队列。\n每当对 channel 的读写操作超过了可缓冲的 goroutine 数量，那么当前的 goroutine 就会被挂到对应的队列上，直到有其他 goroutine 执行了与之相反的读写操作，将它重新唤起。\n7. 对已经关闭的 channel 进行读写，会怎么样？ 当 channel 被关闭后，如果继续往里面写数据，程序会直接 panic 退出。如果是读取关闭后的 channel，不会产生 pannic，还可以读到数据。但关闭后的 channel 没有数据可读取时，将得到零值，即对应类型的默认值。\n为了能知道当前 channel 是否被关闭，可以使用下面的写法来判断。\nif v, ok := \u0026lt;-ch; !ok { fmt.Println(\u0026#34;channel 已关闭，读取不到数据\u0026#34;) } 还可以使用下面的写法不断的获取 channel 里的数据：\nfor data := range ch { // get data dosomething } 这种用法会在读取完 channel 里的数据后就结束 for 循环，执行后面的代码。\n8. map 为什么不是线程安全的？ map 在扩缩容时，需要进行数据迁移，迁移的过程并没有采用锁机制防止并发操作，而是会对某个标识位标记为 1，表示此时正在迁移数据。如果有其他 goroutine 对 map 也进行写操作，当它检测到标识位为 1 时，将会直接 panic。\n如果我们想要并发安全的 map，则需要使用 sync.map。\n9. map 的 key 为什么得是可比较类型的？ map 的 key、value 是存在 buckets 数组里的，每个 bucket 又可以容纳 8 个 key 和 8 个 value。当要插入一个新的 key - value 时，会对 key 进行 hash 运算得到一个 hash 值，然后根据 hash 值 的低几位(取几位取决于桶的数量，比如一开始桶的数量是 5，则取低 5 位)来决定命中哪个 bucket。\n在命中某个 bucket 后，又会根据 hash 值的高 8 位来决定是 8 个 key 里的哪个位置。如果不巧，发生了 hash 冲突，即该位置上已经有其他 key 存在了，则会去其他空位置寻找插入。如果全都满了，则使用 overflow 指针指向一个新的 bucket，重复刚刚的寻找步骤。\n从上面的流程可以看出，在判断 hash 冲突，即该位置是否已有其他 key 时，肯定是要进行比较的，所以 key 必须得是可比较类型的。像 slice、map、function 就不能作为 key。\n","date":"2021-10-10T21:18:51Z","permalink":"https://lxb.wiki/30fc3293/","title":"Go 八股"},{"content":" Kafka允许topic的分区拥有若干副本，这个数量是可以配置的，你可以为每个topci配置副本的数量。Kafka会自动在每个个副本上备份数据，所以当一个节点down掉时数据依然是可用的。\nKafka的副本功能不是必须的，你可以配置只有一个副本，这样其实就相当于只有一份数据。\n创建副本的单位是topic的分区，每个分区都有一个leader和零或多个followers.所有的读写操作都由leader处理，一般分区的数量都比broker的数量多的多，各分区的leader均匀的分布在brokers中。所有的followers都复制leader的日志，日志中的消息和顺序都和leader中的一致。flowers向普通的consumer那样从leader那里拉取消息并保存在自己的日志文件中。 许多分布式的消息系统自动的处理失败的请求，它们对一个节点是否 着（alive）”有着清晰的定义。Kafka判断一个节点是否活着有两个条件：\n节点必须可以维护和ZooKeeper的连接，Zookeeper通过心跳机制检查每个节点的连接。 如果节点是个follower,他必须能及时的同步leader的写操作，延时不能太久。 符合以上条件的节点准确的说应该是“同步中的（in sync）”，而不是模糊的说是“活着的”或是“失败的”。Leader会追踪所有“同步中”的节点，一旦一个down掉了，或是卡住了，或是延时太久，leader就会把它移除。至于延时多久算是“太久”，是由参数replica.lag.max.messages决定的，怎样算是卡住了，怎是由参数replica.lag.time.max.ms决定的。 只有当消息被所有的副本加入到日志中时，才算是“committed”，只有committed的消息才会发送给consumer，这样就不用担心一旦leader down掉了消息会丢失。Producer也可以选择是否等待消息被提交的通知，这个是由参数request.required.acks决定的。\nKafka保证只要有一个“同步中”的节点，“committed”的消息就不会丢失。\nLeader的选择\nKafka的核心是日志文件，日志文件在集群中的同步是分布式数据系统最基础的要素。\n如果leaders永远不会down的话我们就不需要followers了！一旦leader down掉了，需要在followers中选择一个新的leader.但是followers本身有可能延时太久或者crash，所以必须选择高质量的follower作为leader.必须保证，一旦一个消息被提交了，但是leader down掉了，新选出的leader必须可以提供这条消息。大部分的分布式系统采用了多数投票法则选择新的leader,对于多数投票法则，就是根据所有副本节点的状况动态的选择最适合的作为leader.Kafka并不是使用这种方法。\nKafaka动态维护了一个同步状态的副本的集合（a set of in-sync replicas），简称ISR，在这个集合中的节点都是和leader保持高度一致的，任何一条消息必须被这个集合中的每个节点读取并追加到日志中了，才回通知外部这个消息已经被提交了。因此这个集合中的任何一个节点随时都可以被选为leader.ISR在ZooKeeper中维护。ISR中有f+1个节点，就可以允许在f个节点down掉的情况下不会丢失消息并正常提供服。ISR的成员是动态的，如果一个节点被淘汰了，当它重新达到“同步中”的状态时，他可以重新加入ISR.这种leader的选择方式是非常快速的，适合kafka的应用场景。\n一个邪恶的想法：如果所有节点都down掉了怎么办？Kafka对于数据不会丢失的保证，是基于至少一个节点是存活的，一旦所有节点都down了，这个就不能保证了。 实际应用中，当所有的副本都down掉时，必须及时作出反应。可以有以下两种选择:\n等待ISR中的任何一个节点恢复并担任leader。 选择所有节点中（不只是ISR）第一个恢复的节点作为leader. 这是一个在可用性和连续性之间的权衡。如果等待ISR中的节点恢复，一旦ISR中的节点起不起来或者数据都是了，那集群就永远恢复不了了。如果等待ISR意外的节点恢复，这个节点的数据就会被作为线上数据，有可能和真实的数据有所出入，因为有些数据它可能还没同步到。Kafka目前选择了第二种策略，在未来的版本中将使这个策略的选择可配置，可以根据场景灵活的选择。\n这种窘境不只Kafka会遇到，几乎所有的分布式数据系统都会遇到。\n副本管理\n以上仅仅以一个topic一个分区为例子进行了讨论，但实际上一个Kafka将会管理成千上万的topic分区.Kafka尽量的使所有分区均匀的分布到集群所有的节点上而不是集中在某些节点上，另外主从关系也尽量均衡这样每个几点都会担任一定比例的分区的leader.\n优化leader的选择过程也是很重要的，它决定了系统发生故障时的空窗期有多久。Kafka选择一个节点作为“controller”,当发现有节点down掉的时候它负责在游泳分区的所有节点中选择新的leader,这使得Kafka可以批量的高效的管理所有分区节点的主从关系。如果controller down掉了，活着的节点中的一个会备切换为新的controller.\n","date":"2021-09-26T22:01:43Z","permalink":"https://lxb.wiki/4c6cb38f/","title":"Kafka 主从同步"},{"content":" 一、简介 1.1 概述 Kafka主要设计目标如下：\n以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。 同时支持离线数据处理和实时数据处理。 支持在线水平扩展 1.2 消息系统介绍 一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个或多个应用间是如何传递的。分布式消息传递基于可靠的消息队列，在客户端应用和消息系统之间异步传递消息。有两种主要的消息传递模式：点对点传递模式、发布-订阅模式。大部分的消息系统选用发布-订阅模式。Kafka就是一种发布-订阅模式。\n1.3 点对点消息传递 在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费者消费队列中的数据。但是一条消息只能被消费一次。当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。这种架构描述示意图如下：\n生产者发送一条消息到queue，只有一个消费者能收到。\n1.4 发布-订阅消息传递 在发布-订阅消息系统中，消息被持久化到一个topic中。与点对点消息系统不同的是，消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个消费者消费，数据被消费后不会立马删除。在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。该模式的示例图如下：\n发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息。\n1.5 Kafka的优点 1）解耦：\n在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。\n2）冗余：（副本）\n有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的\u0026quot;插入-获取-删除\u0026quot;范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。\n3）扩展性\n因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。\n4）灵活性\u0026amp;峰值处理能力\n在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。\n5）可恢复性\n系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。\n6）顺序保证\n在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。\n7）缓冲\n在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。\n8）异步通信\n很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。\n1.6 常用MQ对比 1）RabbitMQ\nRabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。\n2）Redis\nRedis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。\n3）ZeroMQ\nZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZeroMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演这个服务器角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。\n4）ActiveMQ\nActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。\n5）Kafka/Jafka\nKafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。\n1.7 Kafka中的术语解释 概述 在深入理解Kafka之前，先介绍一下Kafka中的术语。下图展示了Kafka的相关术语以及之间的关系：\n上图中一个topic配置了3个partition。Partition1有两个offset：0和1。Partition2有4个offset。Partition3有1个offset。副本的id和副本所在的机器的id恰好相同。\n如果一个topic的副本数为3，那么Kafka将在集群中为每个partition创建3个相同的副本。集群中的每个broker存储一个或多个partition。多个producer和consumer可同时生产和消费数据。\n1 broker Kafka 集群包含一个或多个服务器，服务器节点称为broker。\nbroker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。\n如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。\n如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。\n2 Topic 每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\n类似于数据库的表名\n3 Partition topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。\n4 Producer 生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息追加到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。\n5 Consumer 消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。\n6 Consumer Group 每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。topic的消息会复制-给consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。\n7 Leader 每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。\n8 Follower Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。\n9 Offset kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka\n一、Kafka的架构 如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。\n2.1 分布式模型 Kafka每个主题的多个分区日志分布式地存储在Kafka集群上，同时为了故障容错，每个分区都会以副本的方式复制到多个消息代理节点上。其中一个节点会作为主副本（Leader），其他节点作为备份副本（Follower，也叫作从副本）。主副本会负责所有的客户端读写操作，备份副本仅仅从主副本同步数据。当主副本出现故障时，备份副本中的一个副本会被选择为新的主副本。因为每个分区的副本中只有主副本接受读写，所以每个服务器端都会作为某些分区的主副本，以及另外一些分区的备份副本，这样Kafka集群的所有服务端整体上对客户端是负载均衡的。\nKafka的生产者和消费者相对于服务器端而言都是客户端。\nKafka生产者客户端发布消息到服务端的指定主题，会指定消息所属的分区。生产者发布消息时根据消息是否有键，采用不同的分区策略。消息没有键时，通过轮询方式进行客户端负载均衡；消息有键时，根据分区语义（例如hash）确保相同键的消息总是发送到同一分区。\nKafka的消费者通过订阅主题来消费消息，并且每个消费者都会设置一个消费组名称。因为生产者发布到主题的每一条消息都只会发送给消费者组的一个消费者。所以，如果要实现传统消息系统的“队列”模型，可以让每个消费者都拥有相同的消费组名称，这样消息就会负责均衡到所有的消费者；如果要实现“发布-订阅”模型，则每个消费者的消费者组名称都不相同，这样每条消息就会广播给所有的消费者。\n分区是消费者现场模型的最小并行单位。如下图（图1）所示，生产者发布消息到一台服务器的3个分区时，只有一个消费者消费所有的3个分区。在下图（图2）中，3个分区分布在3台服务器上，同时有3个消费者分别消费不同的分区。假设每个服务器的吞吐量时300MB，在下图（图1）中分摊到每个分区只有100MB，而在下图（图2）中，集群整体的吞吐量有900MB。可以看到，增加服务器节点会提升集群的性能，增加消费者数量会提升处理性能。\n同一个消费组下多个消费者互相协调消费工作，Kafka会将所有的分区平均地分配给所有的消费者实例，这样每个消费者都可以分配到数量均等的分区。Kafka的消费组管理协议会动态地维护消费组的成员列表，当一个新消费者加入消费者组，或者有消费者离开消费组，都会触发再平衡操作。\nKafka的消费者消费消息时，只保证在一个分区内的消息的完全有序性，并不保证同一个主题汇中多个分区的消息顺序。而且，消费者读取一个分区消息的顺序和生产者写入到这个分区的顺序是一致的。比如，生产者写入“hello”和“Kafka”两条消息到分区P1，则消费者读取到的顺序也一定是“hello”和“Kafka”。如果业务上需要保证所有消息完全一致，只能通过设置一个分区完成，但这种做法的缺点是最多只能有一个消费者进行消费。一般来说，只需要保证每个分区的有序性，再对消息假设键来保证相同键的所有消息落入同一分区，就可以满足绝大多数的应用。\n二、Topics和Partition Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。创建一个topic时，同时可以指定分区数目，分区数越多，其吞吐量也越大，但是需要的资源也越多，同时也会导致更高的不可用性，kafka在接收到生产者发送的消息之后，会根据均衡策略将消息存储到不同的分区中。因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。\n对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略删除旧数据。一是基于时间，二是基于Partition文件大小。例如可以通过配置$KAFKA_HOME/config/server.properties，让Kafka删除一周前的数据，也可在Partition文件超过1GB时删除旧数据，配置如下所示：\n# The minimum age of a log file to be eligible for deletion log.retention.hours=168 # The maximum size of a log segment file. When this size is reached a new log segment will be created. log.segment.bytes=1073741824 # The interval at which log segments are checked to see if they can be deleted according to the retention policies log.retention.check.interval.ms=300000 # If log.cleaner.enable=true is set the cleaner will be enabled and individual logs can then be marked for log compaction. log.cleaner.enable=false 因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高Kafka性能无关。选择怎样的删除策略只与磁盘以及具体的需求有关。另外，Kafka会为每一个Consumer Group保留一些metadata信息——当前消费的消息的position，也即offset。这个offset由Consumer控制。正常情况下Consumer会在消费完一条消息后递增该offset。当然，Consumer也可将offset设成一个较小的值，重新消费一些消息。因为offet由Consumer控制，所以Kafka broker是无状态的，它不需要标记哪些消息被哪些消费过，也不需要通过broker去保证同一个Consumer Group只有一个Consumer能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。\n三、Producer消息路由 Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就实现了负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O将会成为这个Topic的性能瓶颈，而有了Partition后，不同的消息可以并行写入不同broker的不同Partition里，极大的提高了吞吐率。可以在$KAFKA_HOME/config/server.properties中通过配置项num.partitions来指定新建Topic的默认Partition数量，也可在创建Topic时通过参数指定，同时也可以在Topic创建之后通过Kafka提供的工具修改。\n在发送一条消息时，可以指定这条消息的key，Producer根据这个key和Partition机制来判断应该将这条消息发送到哪个Parition。Paritition机制可以通过指定Producer的paritition. class这一参数来指定，该class必须实现kafka.producer.Partitioner接口。\n四、Consumer Group 使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。\n这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要实现广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Consumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不需要多次发送消息到不同的Topic。\n实际上，Kafka的设计理念之一就是同时提供离线处理和实时处理。根据这一特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一个数据中心，只需要保证这三个操作所使用的Consumer属于不同的Consumer Group即可。\n五、Push vs. Pull 作为一个消息系统，Kafka遵循了传统的方式，选择由Producer向broker push消息并由Consumer从broker pull消息。一些logging-centric system，比如Facebook的Scribe和Cloudera的Flume，采用push模式。事实上，push模式和pull模式各有优劣。\npush模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息。\n对于Kafka而言，pull模式更合适。pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。\n六、Kafka delivery guarantee 有这么几种可能的delivery guarantee：\nAt most once 消息可能会丢，但绝不会重复传输\nAt least one 消息绝不会丢，但可能会重复传输\nExactly once 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。\n当Producer向broker发送消息时，一旦这条消息被commit，因数replication的存在，它就不会丢。但是如果Producer发送数据给broker后，遇到网络问题而造成通信中断，那Producer就无法判断该条消息是否已经commit。虽然Kafka无法确定网络故障期间发生了什么，但是Producer可以生成一种类似于主键的东西，发生故障时幂等性的重试多次，这样就做到了Exactly once。\n接下来讨论的是消息从broker到Consumer的delivery guarantee语义。（仅针对Kafka consumer high level API）。Consumer在从broker读取消息后，可以选择commit，该操作会在Zookeeper中保存该Consumer在该Partition中读取的消息的offset。该Consumer下一次再读该Partition时会从下一条开始读取。如未commit，下一次读取的开始位置会跟上一次commit之后的开始位置相同。当然可以将Consumer设置为autocommit，即Consumer一旦读到数据立即自动commit。如果只讨论这一读取消息的过程，那Kafka是确保了Exactly once。但实际使用中应用程序并非在Consumer读取完数据就结束了，而是要进行进一步处理，而数据处理与commit的顺序在很大程度上决定了消息从broker和consumer的delivery guarantee semantic。\nKafka默认保证At least once，并且允许通过设置Producer异步提交来实现At most once。而Exactly once要求与外部存储系统协作，幸运的是Kafka提供的offset可以非常直接非常容易得使用这种方式。\n","date":"2021-09-25T21:55:19Z","permalink":"https://lxb.wiki/44075289/","title":"Kafka 架构"},{"content":" 前言 一定要参考[官网](mermaid - Markdownish syntax for generating flowcharts, sequence diagrams, class diagrams, gantt charts and git graphs. (mermaid-js.github.io))\n不要相信垃圾 CSDN\n安装插件 npm 安装\nnpm install hexo-filter-mermaid-diagrams 项目 [GitHub 主页]webappdevelp/hexo-filter-mermaid-diagrams: mermaid diagrams for hexo (github.com)\n编辑配置文件 修改文件 themes/pure/_config.yml\n文件最好添加以下内容：\n# mermaid chart mermaid: ## mermaid url https://github.com/knsv/mermaid enable: true # default true version: \u0026#34;7.1.2\u0026#34; # default v7.1.2 options: # find more api options from https://github.com/knsv/mermaid/blob/master/src/mermaidAPI.js #startOnload: true // default true 在 ejs 中引入 mermaid.js 修改 themes/pure/layout/_common/footer.ejs\n添加以下内容\n\u0026lt;% if (theme.mermaid.enable) { %\u0026gt; \u0026lt;script src=\u0026#39;https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; if (window.mermaid) { mermaid.initialize({theme: \u0026#39;forest\u0026#39;}); } \u0026lt;/script\u0026gt; \u0026lt;% } %\u0026gt; Q\u0026amp;A 如果加载完后，显示的图不正确，那么很有可能是因为引入 mermaid.min.js 的链接不正确\n","date":"2021-09-15T21:34:12Z","permalink":"https://lxb.wiki/6541b31d/","title":"hexo支持mermaid"},{"content":" CAP理论概述 CAP理论：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。\nCAP理论中的CA和数据库事务中ACID的CA并不是同一回事儿。两者之中的C都是都是一致性(Consistency)。CAP中的A指的是可用性（Availability），而ACID中的A指的是原子性（Atomicity)，切勿混为一谈。\nCAP的定义 Consistency 一致性 一致性指“all nodes see the same data at the same time”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，所以，一致性，说的就是数据一致性。分布式的一致性\n对于一致性，可以分为从客户端和服务端两个不同的视角。从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。\n一致性是因为有并发读写才有的问题，因此在理解一致性的问题时，一定要注意结合考虑并发读写的场景。\n从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。\n三种一致性策略\n对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。\n如果能容忍后续的部分或者全部访问不到，则是弱一致性。\n如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。\nCAP中说，不可能同时满足的这个一致性指的是强一致性。\nAvailability 可用性 可用性指“Reads and writes always succeed”，即服务一直可用，而且是正常响应时间。\n对于一个可用性的分布式系统，每一个非故障的节点必须对每一个请求作出响应。所以，一般我们在衡量一个系统的可用性的时候，都是通过停机时间来计算的。\n可用性分类 可用水平（%） 年可容忍停机时间 容错可用性 99.9999 \u0026lt;1 min 极高可用性 99.999 \u0026lt;5 min 具有故障自动恢复能力的可用性 99.99 \u0026lt;53 min 高可用性 99.9 \u0026lt;8.8h 商品可用性 99 \u0026lt;43.8 min 通常我们描述一个系统的可用性时，我们说淘宝的系统可用性可以达到5个9，意思就是说他的可用水平是99.999%，即全年停机时间不超过 (1-0.99999)*365*24*60 = 5.256 min，这是一个极高的要求。\n好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。一个分布式系统，上下游设计很多系统如负载均衡、WEB服务器、应用代码、数据库服务器等，任何一个节点的不稳定都可以影响可用性。\nPartition Tolerance分区容错性 分区容错性指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。\n分区容错性和扩展性紧密相关。在分布式应用中，可能因为一些分布式的原因导致系统无法正常运转。好的分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，或者是机器之间有网络异常，将分布式系统分隔未独立的几个部分，各个部分还能维持分布式系统的运作，这样就具有好的分区容错性。\n简单点说，就是在网络中断，消息丢失的情况下，系统如果还能正常工作，就是有比较好的分区容错性。\nCAP的证明 如上图，是我们证明CAP的基本场景，网络中有两个节点N1和N2，可以简单的理解N1和N2分别是两台计算机，他们之间网络可以连通，N1中有一个应用程序A，和一个数据库V，N2也有一个应用程序B2和一个数据库V。现在，A和B是分布式系统的两个部分，V是分布式系统的数据存储的两个子数据库。\n在满足一致性的时候，N1和N2中的数据是一样的，V0=V0。在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。\n如上图，是分布式系统正常运转的流程，用户向N1机器请求数据更新，程序A更新数据库Vo为V1，分布式系统将数据进行同步操作M，将V1同步的N2中V0，使得N2中的数据V0也更新为V1，N2中的数据再响应N2的请求。\n这里，可以定义N1和N2的数据库V之间的数据是否一样为一致性；外部对N1和N2的请求响应为可用行；N1和N2之间的网络环境为分区容错性。这是正常运作的场景，也是理想的场景，然而现实是残酷的，当错误发生的时候，一致性和可用性还有分区容错性，是否能同时满足，还是说要进行取舍呢？\n作为一个分布式系统，它和单机系统的最大区别，就在于网络，现在假设一种极端情况，N1和N2之间的网络断开了，我们要支持这种网络异常，相当于要满足分区容错性，能不能同时满足一致性和响应性呢？还是说要对他们进行取舍。\n假设在N1和N2之间网络断开的时候，有用户向N1发送数据更新请求，那N1中的数据V0将被更新为V1，由于网络是断开的，所以分布式系统同步操作M，所以N2中的数据依旧是V0；这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据V1，怎么办呢？\n有二种选择，第一，牺牲数据一致性，保证可用性。响应旧的数据V0给用户；\n第二，牺牲可用性，保证数据一致性。阻塞等待，直到网络连接恢复，数据更新操作M完成之后，再给用户响应最新的数据V1。\n这个过程，证明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。\nCAP权衡 通过CAP理论及前面的证明，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？\n我们分三种情况来阐述一下。\nCA without P 这种情况在分布式系统中几乎是不存在的。首先在分布式环境下，网络分区是一个自然的事实。因为分区是必然的，所以如果舍弃P，意味着要舍弃分布式系统。那也就没有必要再讨论CAP理论了。这也是为什么在前面的CAP证明中，我们以系统满足P为前提论述了无法同时满足C和A。\n比如我们熟知的关系型数据库，如My Sql和Oracle就是保证了可用性和数据一致性，但是他并不是个分布式系统。一旦关系型数据库要考虑主备同步、集群部署等就必须要把P也考虑进来。\n其实，在CAP理论中。C，A，P三者并不是平等的，CAP之父在《Spanner，真时，CAP理论》一文中写到：\n如果说Spanner真有什么特别之处，那就是谷歌的广域网。Google通过建立私有网络以及强大的网络工程能力来保证P，在多年运营改进的基础上，在生产环境中可以最大程度的减少分区发生，从而实现高可用性。\n从Google的经验中可以得到的结论是，无法通过降低CA来提升P。要想提升系统的分区容错性，需要通过提升基础设施的稳定性来保障。\n所以，对于一个分布式系统来说。P是一个基本要求，CAP三者中，只能在CA两者之间做权衡，并且要想尽办法提升P。\nCP without A 如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在CAP三者中保障CP而舍弃A。\n一个保证了CP而一个舍弃了A的分布式系统，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。\n设计成CP的系统其实也不少，其中最典型的就是很多分布式数据库，他们都是设计成CP的。在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的。\n无论是像Redis、HBase这种分布式存储系统，还是像Zookeeper这种分布式协调组件。数据的一致性是他们最最基本的要求。一个连数据一致性都保证不了的分布式存储要他有何用？\nZooKeeper是个CP（一致性+分区容错性）的，即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性。但是它不能保证每次服务请求的可用性，也就是在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。ZooKeeper是分布式协调服务，它的职责是保证数据在其管辖下的所有服务之间保持同步、一致。所以就不难理解为什么ZooKeeper被设计成CP而不是AP特性的了。\nAP wihtout C 要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。\n这种舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性可以达到N个9，所以，对于很多业务系统来说，比如淘宝的购物，12306的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性。\n你在12306买票的时候肯定遇到过这种场景，当你购买的时候提示你是有票的（但是可能实际已经没票了），你也正常的去输入验证码，下单了。但是过了一会系统提示你下单失败，余票不足。这其实就是先在可用性方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，会影响一些用户体验，但是也不至于造成用户流程的严重阻塞。\n但是，我们说很多网站牺牲了一致性，选择了可用性，这其实也不准确的。就比如上面的买票的例子，其实舍弃的只是强一致性。退而求其次保证了最终一致性。也就是说，虽然下单的瞬间，关于车票的库存可能存在数据不一致的情况，但是过了一段时间，还是要保证最终一致性的。\n对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。\n","date":"2021-09-10T21:54:27Z","permalink":"https://lxb.wiki/3bdd21ca/","title":"分布式系统的CAP理论"},{"content":" 1. 前言 go的map底层实现方式是hash表（C++的map是红黑树实现，而C++ 11新增的unordered_map则与go的map类似，都是hash实现）。go map的数据被置入一个由桶组成的有序数组中，每个桶最多可以存放8个key/value对。key的hash值(32位)的低阶位用于在该数组中定位到桶，而高8位则用于在桶中区分key/value对。 go map的hash表中的基本单位是桶，每个桶最多存8个键值对，超了，则会链接到额外的溢出桶。所以go map是基本数据结构是hash数组+桶内的key-value数组+溢出的桶链表 当hash表超过阈值需要扩容增长时，会分配一个新的数组，新数组的大小一般是旧数组的2倍。这里从旧数组将数据迁移到新数组，不会一次全量拷贝，go会在每次读写Map时以桶为单位做动态搬迁疏散。\n2. go map的数据结构 2.1 核心结体体 map主要由两个核心的结构，即基础结构和桶实现：\nhmap：map的基础结构 bmap：严格来说hmap.buckets指向桶组成的数组，每个桶的头部是bmap，之后是8个key，再是8个value，最后是1个溢出指针。溢出指针指向额外的桶链表，用于存储溢出的数据 const ( // 关键的变量 bucketCntBits = 3 bucketCnt = 1 \u0026lt;\u0026lt; bucketCntBits // 一个桶最多存储8个key-value对 loadFactorNum = 13 // 扩散因子：loadFactorNum / loadFactorDen = 6.5。 loadFactorDen = 2 // 即元素数量 \u0026gt;= (hash桶数量(2^hmp.B) * 6.5 / 8) 时，触发扩容 ) // map的基础数据结构 type hmap struct { count int\t// map存储的元素对计数，len()函数返回此值，所以map的len()时间复杂度是O(1) flags uint8 // 记录几个特殊的位标记，如当前是否有别的线程正在写map、当前是否为相同大小的增长（扩容/缩容？） B uint8 // hash桶buckets的数量为2^B个 noverflow uint16 // 溢出的桶的数量的近似值 hash0 uint32 // hash种子 buckets unsafe.Pointer // 指向2^B个桶组成的数组的指针，数据存在这里 oldbuckets unsafe.Pointer // 指向扩容前的旧buckets数组，只在map增长时有效 nevacuate uintptr // 计数器，标示扩容后搬迁的进度 extra *mapextra // 保存溢出桶的链表和未使用的溢出桶数组的首地址 } // 桶的实现结构 type bmap struct { // tophash存储桶内每个key的hash值的高字节 // tophash[0] \u0026lt; minTopHash表示桶的疏散状态 // 当前版本bucketCnt的值是8，一个桶最多存储8个key-value对 tophash [bucketCnt]uint8 // 特别注意： // 实际分配内存时会申请一个更大的内存空间A，A的前8字节为bmap // 后面依次跟8个key、8个value、1个溢出指针 // map的桶结构实际指的是内存空间A } // map.go里很多函数的第1个入参是这个结构，从成员来看很明显，此结构标示了键值对和桶的大小等必要信息 // 有了这个结构的信息，map.go的代码就可以与键值对的具体数据类型解耦 // 所以map.go用内存偏移量和unsafe.Pointer指针来直接对内存进行存取，而无需关心key或value的具体类型 type maptype struct { typ _type key *_type elem *_type bucket *_type // internal type representing a hash bucket keysize uint8 // size of key slot valuesize uint8 // size of value slot bucketsize uint16 // size of bucket flags uint32 } C++使用模板可以根据不同的类型生成map的代码。 golang则通过上述maptype结构体传递键值对的类型大小等信息，从而map.go直接用指针操作对应大小的内存来实现全局一份map代码同时适用于不同类型的键值对。这点上可以认为相比C++用模板实现map的方式，go map的目标文件的代码量会更小。\n2.2 数据结构图 map底层创建时，会初始化一个hmap结构体，同时分配一个足够大的内存空间A。其中A的前段用于hash数组，A的后段预留给溢出的桶。于是hmap.buckets指向hash数组，即A的首地址；hmap.extra.nextOverflow初始时指向内存A中的后段，即hash数组结尾的下一个桶，也即第1个预留的溢出桶。所以当hash冲突需要使用到新的溢出桶时，会优先使用上述预留的溢出桶，hmap.extra.nextOverflow依次往后偏移直到用完所有的溢出桶，才有可能会申请新的溢出桶空间。\n上图中，当需要分配一个溢出桶时，会优先从预留的溢出桶数组里取一个出来链接到链表后面，这时不需要再次申请内存。但当预留的桶被用完了，则需要申请新的内存给溢出桶。\n3. go map的常用操作 3.1 创建 使用make(map[k]v, hint)创建map时会调用makemap()函数，代码逻辑比较简单。 值得注意的是，makemap()创建的hash数组，数组的前面是hash表的空间，当hint \u0026gt;= 4时后面会追加2^(hint-4)个桶，之后再内存页帧对齐又追加了若干个桶（参见2.2章节结构图的hash数组部分） 所以创建map时一次内存分配既分配了用户预期大小的hash数组，又追加了一定量的预留的溢出桶，还做了内存对齐，一举多得。\n// make(map[k]v, hint), hint即预分配大小 // 不传hint时，如用new创建个预设容量为0的map时，makemap只初始化hmap结构，不分配hash数组 func makemap(t *maptype, hint int, h *hmap) *hmap { // 省略部分代码 // 随机hash种子 h.hash0 = fastrand() // 2^h.B 为大于hint*6.5(扩容因子)的最小的2的幂 B := uint8(0) // overLoadFactor(hint, B)只有一行代码：return hint \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(hint) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen) // 即B的大小应满足 hint \u0026lt;= (2^B) * 6.5 // 一个桶能存8对key-value，所以这就表示B的初始值是保证这个map不需要扩容即可存下hint个元素对的最小的B值 for overLoadFactor(hint, B) { B++ } h.B = B // 这里分配hash数组 if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) // makeBucketArray()会在hash数组后面预分配一些溢出桶， // h.extra.nextOverflow用来保存上述溢出桶的首地址 if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } // 分配hash数组 func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap) { base := bucketShift(b) // base代表用户预期的桶的数量，即hash数组的真实大小 nbuckets := base // nbuckets表示实际分配的桶的数量，\u0026gt;= base，这就可能会追加一些溢出桶作为溢出的预留 if b \u0026gt;= 4 { // 这里追加一定数量的桶，并做内存对齐 nbuckets += bucketShift(b - 4) sz := t.bucket.size * nbuckets up := roundupsize(sz) if up != sz { nbuckets = up / t.bucket.size } } // 后面的代码就是申请内存空间了，此处省略 // 这里大家可以思考下这个数组空间要怎么分配，其实就是n*sizeof(桶)，所以： // 每个桶前面是8字节的tophash数组，然后是8个key，再是8个value，最后放一个溢出指针 // sizeof(桶) = 8 + 8*sizeof(key) + 8*sizeof(value) + 8 return buckets, nextOverflow } 3.2 插入或更新 go map的插入操作，调用mapassign()函数。 同学们或许在某些资料上了解过：\ngo map需要初始化才能使用，对空map插入会panic。hmap指针传递的方式，决定了map在使用前必须初始化 go map不支持并发读写，会panic。如果一定要并发，请用sync.Map或自己解决冲突 上述两个限制，在mapassign()函数开头能找到答案：\n1 参数合法性检测，计算hash值\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // 不熟悉指针操作的同学，用指针传参往往会踩空指针的坑 // 这里大家可以思考下，为什么h要非空判断？ // 如果一定要在这里支持空map并检测到map为空时自动初始化，应该怎么写？ // 提示：指针的指针 if h == nil { panic(plainError(\u0026#34;assignment to entry in nil map\u0026#34;)) } // 在这里做并发判断，检测到并发写时，抛异常 // 注意：go map的并发检测是伪检测，并不保证所有的并发都会被检测出来。而且这玩意是在运行期检测。 // 所以对map有并发要求时，应使用sync.map来代替普通map，通过加锁来阻断并发冲突 if h.flags\u0026amp;hashWriting != 0 { throw(\u0026#34;concurrent map writes\u0026#34;) } hash := alg.hash(key, uintptr(h.hash0)) // 这里得到uint32的hash值 h.flags ^= hashWriting // 置Writing标志，key写入buckets后才会清除标志 if h.buckets == nil { // map不能为空，但hash数组可以初始是空的，这里会初始化 h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) } ... } 2 定位key在hash表中的位置\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... again: bucket := hash \u0026amp; bucketMask(h.B) // 这里用hash值的低阶位定位hash数组的下标偏移量 if h.growing() { growWork(t, h, bucket) // 这里是map的扩容缩容操作，我们在第4章单独讲 } // 通过下标bucket，偏移定位到具体的桶 b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) top := tophash(hash) // 这里取高8位用于在桶内定位键值对 ... } 3 进一步定位key可以插入的桶及桶中的位置\n两轮循环，外层循环遍历hash桶及其指向的溢出链表，内层循环则在桶内遍历（一个桶最多8个key-value对） 有可能正好链表上的桶都满了，这时inserti为nil，第4步会链接一个新的溢出桶进来 func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... var inserti *uint8 // tophash插入位置 var insertk unsafe.Pointer // key插入位置 var val unsafe.Pointer // value插入位置 bucketloop: for { for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { if isEmpty(b.tophash[i]) \u0026amp;\u0026amp; inserti == nil { // 找到个空位，先记录下tophash、key、value的插入位置 // 但要遍历完才能确定要不要插入到这个位置，因为后面有可能有重复的元素 inserti = \u0026amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) } if b.tophash[i] == emptyRest { break bucketloop // 遍历完整个溢出链表，退出循环 } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if !alg.equal(key, k) { continue } // 走到这里说明map里找到一个重复的key，更新key-value，跳到第5步 if t.needkeyupdate() { typedmemmove(t.key, k, key) } val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) goto done // 更新Key后跳到第5步 } ovf := b.overflow(t) if ovf == nil { break // 遍历完整个溢出链表，没找到能插入的空位，结束循环，下一步再追加一个溢出桶进来 } b = ovf // 继续遍历下一个溢出桶 } ... } 4 插入 key\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... // 这里判断要不要扩容，我们第4章再讲 if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } if inserti == nil { // inserti == nil说明上1步没找到空位，整个链表是满的，这里添加一个新的溢出桶上去 newb := h.newoverflow(t, b) // 分配新溢出桶，优先用3.1章节预留的溢出桶，用完了则分配一个新桶内存 inserti = \u0026amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) val = add(insertk, bucketCnt*uintptr(t.keysize)) } // 当key或value的类型大小超过一定值时，桶只存储key或value的指针。这里分配空间并取指针 if t.indirectkey() { kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectvalue() { vmem := newobject(t.elem) *(*unsafe.Pointer)(val) = vmem } typedmemmove(t.key, insertk, key) // 在桶中对应位置插入key *inserti = top // 插入tophash，hash值高8位 h.count++ // 插入了新的键值对，h.count数量+1 ... } 5 结束插入\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... done: if h.flags\u0026amp;hashWriting == 0 { throw(\u0026#34;concurrent map writes\u0026#34;) } h.flags \u0026amp;^= hashWriting // 释放hashWriting标志位 if t.indirectvalue() { val = *((*unsafe.Pointer)(val)) } return val // 返回value可插入位置的指针，注意，value还没插入 } 只插入了tophash和key，就结束了吗？value还没插入呢 是的，mapassign()只插入tophash和key，并返回val指针，编译器会在调用mapassign()后用汇编往val插入value google大佬这么骚气的操作，是为了减少value值传递的次数吗？ 3.3 删除 删除与插入类似，前面的步骤都是参数和状态判断、定位key-value位置，然后clear对应的内存。不展开说。以下是几个关键点： 删除过程中也会置hashWriting标志 当key/value过大时，hash表里存储的是指针，这时候用软删除，置指针为nil，数据交给gc去删。当然，这是map的内部处理，外层是无感知的，拿到的都是值拷贝 无论Key/value是值类型还是指针类型，删除操作都只影响hash表，外层已经拿到的数据不受影响。尤其是指针类型，外层的指针还能继续使用 由于定位key位置的方式是查找tophash，所以删除操作对tophash的处理是关键： map首先将对应位置的tophash[i]置为emptyOne，表示该位置已被删除 如果tophash[i]不是整个链表的最后一个，则只置emptyOne标志，该位置被删除但未释放，后续插入操作不能使用此位置 如果tophash[i]是链表最后一个有效节点了，则把链表最后面的所有标志为emptyOne的位置，都置为emptyRest。置为emptyRest的位置可以在后续的插入操作中被使用。 这种删除方式，以少量空间来避免桶链表和桶内的数据移动。事实上，go 数据一旦被插入到桶的确切位置，map是不会再移动该数据在桶中的位置了。 func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { ... b.tophash[i] = emptyOne // 先标记删除 // 如果b.tophash[i]不是最后一个元素，则暂时先占着坑。emptyOne标记的位置暂时不能被插入新元素(见3.2章节插入函数) if i == bucketCnt-1 { if b.overflow(t) != nil \u0026amp;\u0026amp; b.overflow(t).tophash[0] != emptyRest { goto notLast } } else { if b.tophash[i+1] != emptyRest { goto notLast } } for { // 如果b.tophash[i]是最后一个元素，则把末尾的emptyOne全部清除置为emptyRest b.tophash[i] = emptyRest if i == 0 { if b == bOrig { break // beginning of initial bucket, we\u0026#39;re done. } // Find previous bucket, continue at its last entry. c := b for b = bOrig; b.overflow(t) != c; b = b.overflow(t) { } i = bucketCnt - 1 } else { i-- } if b.tophash[i] != emptyOne { break } } ... } 3.4 查找 查找操作由mapaccess开头的一组函数实现。前面的章节在插入和删除之前都得先定位查找到元素，逻辑是类似的，也比较简单，就不细说了：\nmapaccess1()：通过Key查找，返回value指针，用于val := map[key]。未找到时返回value类型的0值。 mapaccess2()：通过key查找，返回value指针，以及bool类型的是否查找成功的标志，用于val, ok := map[key]。未找到时返回value类型的0值。 mapaccessK()：通过key查找，返回key和value指针，用于迭代器(range)。未找到时返回空指针 mapaccess1_fat()，对mapaccess1()的封装，区别是mapaccess1_fat()多了个zero参数，未找到时返回zero mapaccess2_fat()，也是对mapaccess1()的封装。相比mapaccess1_fat()，本函数增加一个是否查找成功的标志 3.5 range迭代 map的迭代是通过hiter结构和对应的两个辅助函数实现的。hiter结构由编译器在调用辅助函数之前创建并传入，每次迭代结果也由hiter结构传回。下方的it即是hiter结构体的指针变量。\n3.5.1 初始化迭代器mapiterinit() mapiterinit()函数主要是决定我们从哪个位置开始迭代，为什么是从哪个位置，而不是直接从hash数组头部开始呢？《go程序设计语言》好像提到过，hash表中数据每次插入的位置是变化的（其实是因为实现的原因，一方面hash种子是随机的，这导致相同的数据在不同的map变量内的hash值不同；另一方面即使同一个map变量内，数据删除再添加的位置也有可能变化，因为在同一个桶及溢出链表中数据的位置不分先后），所以为了防止用户错误的依赖于每次迭代的顺序，map作者干脆让相同的map每次迭代的顺序也是随机的。 迭代顺序随机的实现方式也简单，直接从随机的一个位置开始就行了：\nit.startBucket：这个是hash数组的偏移量，表示遍历从这个桶开始 it.offset：这个是桶内的偏移量，表示每个桶的遍历都从这个偏移量开始 于是，map的遍历过程如下：\n从hash数组中第it.startBucket个桶开始，先遍历hash桶，然后是这个桶的溢出链表。 之后hash数组偏移量+1，继续前一步动作。 遍历每一个桶，无论是hash桶还是溢出桶，都从it.offset偏移量开始。（如果只是随机一个开始的桶，range结果还是有序的；但每个桶都加it.offset偏移，这个输出结果就有点扑朔迷离，大家可以亲手试下，对同一个map多次range） 当迭代器经过一轮循环回到it.startBucket的位置，结束遍历。 func mapiterinit(t *maptype, h *hmap, it *hiter) { ... // 随机一个偏移量来开始 r := uintptr(fastrand()) if h.B \u0026gt; 31-bucketCntBits { r += uintptr(fastrand()) \u0026lt;\u0026lt; 31 } it.startBucket = r \u0026amp; bucketMask(h.B) it.offset = uint8(r \u0026gt;\u0026gt; h.B \u0026amp; (bucketCnt - 1)) ... mapiternext(it) // 初始化迭代器的同时也返回第1对key/value } 3.5.2 迭代过程mapiternext() 上一节迭代循环的过程很清晰了，这里我们说明几个重要的参数：\nit.startBucket：开始的桶 it.offset：每个桶开始的偏移量 it.bptr：当前遍历的桶 it.i：it.bptr已经遍历的键值对数量，i初始为0，当i=8时表示这个桶遍历完了，将it.bptr移向下一个桶 it.key：每次迭代的结果 it.value：每次迭代的结果 此外，迭代还需要关注扩容缩容的情况：\n如果是在迭代开始后才growing，这种情况当前的逻辑没处理，迭代有可能异常。呃，go map不支持并发。 如果是先growing，再开始迭代，这是有可能的。这种情况下，会先到旧hash表中检查key对应的桶有没有被疏散，未疏散则遍历旧桶，已疏散则遍历新hash表里对应的桶。 4. go map的扩容缩容 4.1 扩容缩容的基本原理 go map的扩容缩容都是grow相关的函数，这里扩容是真的，缩容是伪缩容，后面我会解释。我们先看下触发条件：\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } ... } // overLoadFactor()返回true则触发扩容，即map的count大于hash桶数量(2^B)*6.5 func overLoadFactor(count int, B uint8) bool { return count \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(count) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen) } // tooManyOverflowBuckets()，顾名思义，溢出桶太多了触发缩容 func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { if B \u0026gt; 15 { B = 15 } return noverflow \u0026gt;= uint16(1)\u0026lt;\u0026lt;(B\u0026amp;15) } map只在插入元素即mapassign()函数中对是否扩容缩容进行触发，条件即是上面这段代码：\n条件1：当前不处在growing状态 条件2-1：触发扩容：map的数据量count大于hash桶数量(2B)*6.5。注意这里的(2B)只是hash数组大小，不包括溢出的桶 条件2-2：触发缩容：溢出的桶数量noverflow\u0026gt;=32768(1\u0026laquo;15)或者\u0026gt;=hash数组大小。 仔细观察触发的代码，扩容和缩容是同一个函数，这是怎么做到的呢？在hashGrow()开始，会先判断是否满足扩容条件，如果满足就表明这次是扩容，不满足就一定是缩容条件触发了。扩容和缩容剩下的逻辑，主要区别就在于容量变化，就是hmap.B参数，扩容时B+1则hash表容量扩大1倍，缩容时hash表容量不变。\nh.oldbuckets：指向旧的hash数组，即当前的h.buckets h.buckets：指向新创建的hash数组 到这里触发的主要工作已经完成，接下来就是怎么把元素搬迁到新hash表里了。如果现在就一次全量搬迁过去，显然接下来会有比较长的一段时间map被占用（不支持并发）。所以搬迁的工作是异步增量搬迁的。 在插入和删除的函数内都有下面一段代码用于在每次插入和删除操作时，执行一次搬迁工作：\nif h.growing() { // 当前处于搬迁状态 growWork(t, h, bucket) // 调用搬迁函数 } func growWork(t *maptype, h *hmap, bucket uintptr) { // 将当前需要处理的桶搬迁 evacuate(t, h, bucket\u0026amp;h.oldbucketmask()) if h.growing() { // 再多搬迁一个桶 evacuate(t, h, h.nevacuate) } } 每执行一次插入或删除，都会调用growWork搬迁0~2个hash桶（有可能这次需要搬迁的2个桶在此之前都被搬过了） 搬迁是以hash桶为单位的，包含对应的hash桶和这个桶的溢出链表 被delete掉的元素(emptyone标志)会被舍弃（这是缩容的关键） 4.2 为什么叫“伪缩容”？如何实现“真缩容”？ 现在可以解释为什么我把map的缩容叫做伪缩容了：因为缩容仅仅针对溢出桶太多的情况，触发缩容时hash数组的大小不变，即hash数组所占用的空间只增不减。也就是说，如果我们把一个已经增长到很大的map的元素挨个全部删除掉，hash表所占用的内存空间也不会被释放。\n所以如果要实现“真缩容”，需自己实现缩容搬迁，即创建一个较小的map，将需要缩容的map的元素挨个搬迁过来：\n// go map缩容代码示例 myMap := make(map[int]int, 1000000) // 假设这里我们对bigMap做了很多次插入，之后又做了很多次删除，此时bigMap的元素数量远小于hash表大小 // 接下来我们开始缩容 smallMap := make(map[int]int, len(myMap)) for k, v := range myMap { smallMap[k] = v } myMap = smallMap // 缩容完成，原来的map被我们丢弃，交给gc去清理 5 Q\u0026amp;A关键知识点 5.1 基本原理 底层是hash实现，数据结构为hash数组 + 桶 + 溢出的桶链表，每个桶存储最多8个key-value对 查找和插入的原理：key的hash值（低阶位）与桶数量相与，得到key所在的hash桶，再用key的高8位与桶中的tophash[i]对比，相同则进一步对比key值，key值相等则找到 go map不支持并发。插入、删除、搬迁等操作会置writing标志，检测到并发直接panic 每次扩容hash表增大1倍，hash表只增不减 支持有限缩容，delete操作只置删除标志位，释放溢出桶的空间依靠触发缩容来实现。 map在使用前必须初始化，否则panic：已初始化的map是make(map[key]value)或make(map[key]value, hint)这两种形式。而new或var xxx map[key]value这两种形式是未初始化的，直接使用会panic。 5.2 时间复杂度和空间复杂度分析 时间复杂度，go map是hash实现，我们先不管具体原理，江湖套路hash实现的就叫它O(1)的时间复杂度：\n正常情况，且不考虑扩容状态，复杂度O(1)：通过hash值定位桶是O(1)，一个桶最多8个元素，合理的hash算法应该能把元素相对均匀散列，所以溢出链表（如果有）也不会太长，所以虽然在桶和溢出链表上定位key是遍历，考虑到数量小也可以认为是O(1) 正常情况，处于扩容状态时，复杂度也是O(1)：相比于上一种状态，扩容会增加搬迁最多2个桶和溢出链表的时间消耗，当溢出链表不太长时，复杂度也可以认为是O(1) 极端情况，散列极不均匀，大部分数据被集中在一条散列链表上，复杂度退化为O(n)。 go采用的hash算法应是很成熟的算法，极端情况暂不考虑。所以综合情况下go map的时间复杂度应为O(1)\n空间复杂度分析： 首先我们不考虑因删除大量元素导致的空间浪费情况（这种情况现在go是留给程序员自己解决），只考虑一个持续增长状态的map的一个空间使用率： 由于溢出桶数量超过hash桶数量时会触发缩容，所以最坏的情况是数据被集中在一条链上，hash表基本是空的，这时空间浪费O(n)。 最好的情况下，数据均匀散列在hash表上，没有元素溢出，这时最好的空间复杂度就是扩散因子决定了，当前go的扩散因子由全局变量决定，即loadFactorNum/loadFactorDen = 6.5。即平均每个hash桶被分配到6.5个元素以上时，开始扩容。所以最小的空间浪费是(8-6.5)/8 = 0.1875，即O(0.1875n)\n结论：go map的空间复杂度（指除去正常存储元素所需空间之外的空间浪费）是O(0.1875n) ~ O(n)之间。\n","date":"2021-08-28T22:30:18Z","permalink":"https://lxb.wiki/aaf3975f/","title":"go map数据结构"},{"content":" 互联网服务端处理网络请求的原理 一个典型互联网服务端处理网络请求的典型过程：\n由上图可以看到，主要处理步骤包括：\n1）获取请求数据，客户端与服务器建立连接发出请求，服务器接受请求（1-3）；\n2）构建响应，当服务器接收完请求，并在用户空间处理客户端的请求，直到构建响应完成（4）；\n3）返回数据，服务器将已构建好的响应再通过内核空间的网络 I/O 发还给客户端（5-7）。\n设计服务端并发模型时，主要有如下两个关键点：\n1）服务器如何管理连接，获取输入数据；\n2）服务器如何处理请求。\n以上两个关键点最终都与操作系统的 I/O 模型以及线程(进程)模型相关，这也是本文和下篇《高性能网络编程(六)：一文读懂高性能网络编程中的线程模型》将要介绍的内容。下面先详细介绍这I/O模型。\n“I/O 模型”的基本认识 介绍操作系统的 I/O 模型之前，先了解一下几个概念：\n1）阻塞调用与非阻塞调用；\n2）阻塞调用是指调用结果返回之前，当前线程会被挂起，调用线程只有在得到结果之后才会返回；\n3）非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。\n两者的最大区别在于被调用方在收到请求到返回结果之前的这段时间内，调用方是否一直在等待。\n阻塞是指调用方一直在等待而且别的事情什么都不做；非阻塞是指调用方先去忙别的事情。\n**同步处理与异步处理：**同步处理是指被调用方得到最终结果之后才返回给调用方；异步处理是指被调用方先返回应答，然后再计算调用结果，计算完最终结果后再通知并返回给调用方。\n阻塞、非阻塞和同步、异步的区别（阻塞、非阻塞和同步、异步其实针对的对象是不一样的）：\n1）阻塞、非阻塞的讨论对象是调用者；\n2）同步、异步的讨论对象是被调用者。\nrecvfrom 函数：\nrecvfrom 函数(经 Socket 接收数据)，这里把它视为系统调用。\n一个输入操作通常包括两个不同的阶段：\n1）等待数据准备好；\n2）从内核向进程复制数据。\n对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待分组到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。\n实际应用程序在系统调用完成上面的 2 步操作时，调用方式的阻塞、非阻塞，操作系统在处理应用程序请求时，处理方式的同步、异步处理的不同，可以分为 5 种 I/O 模型\n网络IO模型 网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作\nIO其实我们并不陌生，站在操作系统的角度上说，io一般指访问磁盘数据，可以分为两步，以read操作举例的话：\n第一阶段：等待数据准备 (Waiting for the data to be ready)。 第二阶段：将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)。 而网络IO也是如此，只不过它是读取的不是磁盘，而是socket：\n第一步：通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区。 第二步：把数据从内核缓冲区复制到应用进程缓冲区。 在理解网络IO模型之前，我们得先准备些IO模型的基础知识\nIO模型 Unix 有五种 I/O 模型：\n阻塞IO（bloking IO） 非阻塞IO（non-blocking IO） 多路复用IO（multiplexing IO） 信号驱动式IO（signal-driven IO） 异步IO（asynchronous IO） 每个 IO 模型都有自己的使用模式，它们对于特定的应用程序都有自己的优点。下面提供一个简单的图片以供了解。\n阻塞式 IO 应用进程被阻塞，直到数据复制到应用进程缓冲区中才返回。\n应该注意到，在阻塞的过程中，其它程序还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其他程序还可以执行，因此不消耗 CPU 时间，这种模型的 CPU 利用率效率会比较高。\n下图中，recvfrom 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。\n非阻塞式 IO 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。\n由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率是比较低的。\n多路复用IO 由于阻塞式IO通过轮询得到的只是一个IO任务是否完成，而可能有多个任务在同时进行，因此就想到了能否轮询多个IO任务的状态，只要有任何一个任务完成，就去处理它。这就是所谓的IO多路复用。LINUX下具体的实现方式就是select、poll、epoll。\n这种机制可以让单个进程具有处理多个 IO 事件的能力。又被称为 Event Driven IO，即事件驱动 IO。\n最实际的应用场景就是web服务器响应连接的方式，IO 复用可支持更多的连接，同时不需要进程线程创建和切换的开销，系统开销更小。\n多路复用的特点是通过一种机制一个进程能同时等待多个IO文件描述符，内核监视这些文件描述符（套接字描述符），其中的任意一个进入读就绪状态，select， poll，epoll函数就可以返回。对于监视的方式，又可以分为 select， poll， epoll三种方式。\n在IO多路复用中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的进程其实是一直被block的。只不过进程是被select这个函数block，而不是被socket IO给block。所以IO多路复用是阻塞在select，epoll这样的系统调用之上，而没有阻塞在真正的I/O系统调用如recvfrom之上。\n信号驱动 IO 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。\n相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。\n异步 IO 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。\n异步 IO 与信号驱动 IO 的区别在于，异步 IO 的信号是通知应用进程 IO 完成，而信号驱动 IO 的信号是通知应用进程可以开始 IO。\n五大 IO 模型比较 前四种 I/O 模型的主要区别在于第一个阶段，而第二个阶段是一样的：将数据从内核复制到应用进程过程中，应用进程会被阻塞。\n从上图中我们可以看出，越往后，阻塞越少，理论上效率也是最优。\n这五种 I/O 模型中，前四种属于同步 I/O，因为其中真正的 I/O 操作(recvfrom)将阻塞进程/线程，只有异步 I/O 模型才与 POSIX 定义的异步 I/O 相匹配。\nblocking和non-blocking区别 调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。\nsynchronous IO和asynchronous IO区别 在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的：\nA synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;\nAn asynchronous I/O operation does not cause the requesting process to be blocked;\n同步 I/O：应用进程在调用 recvfrom 操作时会阻塞。 异步 I/O：不会阻塞。 阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O 都是同步 I/O，虽然非阻塞式 I/O 和信号驱动 I/O 在等待数据阶段不会阻塞，但是在之后的将数据从内核复制到应用进程这个操作会阻塞。\nselect，poll，epoll比较 select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。\nselect select的调用过程如下所示：\n（1）使用copy_from_user从用户空间拷贝fd_set到内核空间\n（2）注册回调函数__pollwait\n（3）遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll）\n（4）以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。\n（5）__pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk-\u0026gt;sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。\n（6）poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。\n（7）如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。\n（8）把fd_set从内核空间拷贝到用户空间。\n总结： select的几大缺点：\n（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大\n（2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大\n（3）select支持的文件描述符数量太小了，默认是1024\npoll poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构，其他的都差不多。\nepoll epoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。\n对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。\n对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。\n对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。\n总结 （1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。\n（2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。\n应用场景 很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。\n1. select 应用场景 select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时要求更高的场景，比如核反应堆的控制。\nselect 可移植性更好，几乎被所有主流平台所支持。\n2. poll 应用场景 poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。\n需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。\n需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且epoll 的描述符存储在内核，不容易调试。\n3. epoll 应用场景 只需要运行在 Linux 平台上，并且有非常大量的描述符需要同时轮询，而且这些连接最好是长连接。\nweb服务器设计模型 并发\u0026amp;并行 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。 并行需要硬件支持，如多流水线或者多处理器。 操作系统通过引入进程和线程，使得程序能够并发运行。\n对于web服务而言，并发是指同时进行的任务数（如同时服务的 HTTP 请求），而并行是可以同时工作的物理资源数量（如 CPU 核数）。\n而针对并发IO而言，Reactor模型是一种常见的处理方式\nReactor模型 Reactor的中心思想是将所有要处理的I/O事件注册到一个中心I/O多路复用器上，同时主线程/进程阻塞在多路复用器上；一旦有I/O事件到来或是准备就绪(文件描述符或socket可读、写)，多路复用器返回并将事先注册的相应I/O事件分发到对应的处理器中。\nReactor是一种事件驱动机制，用“好莱坞原则”来形容Reactor再合适不过了：不要打电话给我们，我们会打电话通知你。 Reactor模式与Observer模式在某些方面极为相似：当一个主体发生改变时，所有依属体都得到通知。不过，观察者模式与单个事件源关联，而反应器模式则与多个事件源关联 。\n在Reactor模式中，有5个关键的参与者：\n描述符（handle）：由操作系统提供的资源，用于识别每一个事件，如Socket描述符、文件描述符、信号的值等。在Linux中，它用一个整数来表示。事件可以来自外部，如来自客户端的连接请求、数据等。事件也可以来自内部，如信号、定时器事件。 同步事件多路分离器（event demultiplexer）：事件的到来是随机的、异步的，无法预知程序何时收到一个客户连接请求或收到一个信号。所以程序要循环等待并处理事件，这就是事件循环。在事件循环中，等待事件一般使用I/O复用技术实现。在linux系统上一般是select、poll、epol_waitl等系统调用，用来等待一个或多个事件的发生。I/O框架库一般将各种I/O复用系统调用封装成统一的接口，称为事件多路分离器。调用者会被阻塞，直到分离器分离的描述符集上有事件发生。 事件处理器（event handler）：I/O框架库提供的事件处理器通常是由一个或多个模板函数组成的接口。这些模板函数描述了和应用程序相关的对某个事件的操作，用户需要继承它来实现自己的事件处理器，即具体事件处理器。因此，事件处理器中的回调函数一般声明为虚函数，以支持用户拓展。 具体的事件处理器（concrete event handler）：是事件处理器接口的实现。它实现了应用程序提供的某个服务。每个具体的事件处理器总和一个描述符相关。它使用描述符来识别事件、识别应用程序提供的服务。 Reactor 管理器（reactor）：定义了一些接口，用于应用程序控制事件调度，以及应用程序注册、删除事件处理器和相关的描述符。它是事件处理器的调度核心。 Reactor管理器使用同步事件分离器来等待事件的发生。一旦事件发生，Reactor管理器先是分离每个事件，然后调度事件处理器，最后调用相关的模 板函数来处理这个事件。 可以看出，是Reactor管理器并不是应用程序负责等待事件、分离事件和调度事件。Reactor并没有被具体的事件处理器调度，而是管理器调度具体的事件处理器，由事件处理器对发生的事件作出处理，这就是Hollywood原则。应用程序要做的仅仅是实现一个具体的事件处理器，然后把它注册到Reactor管理器中。接下来的工作由管理器来完成：如果有相应的事件发生，Reactor会主动调用具体的事件处理器，由事件处理器对发生的事件作出处理。\n为什么使用Reactor 有了I/O复用，有了epoll已经可以使服务器并发几十万连接的同时，维持高TPS了，难道这还不够吗？\n答案是，技术层面足够了，但在软件工程层面却是不够的。\n程序使用IO复用的难点在哪里呢？\n1个请求可能由多次IO处理完成，但相比传统的单线程完整处理请求生命期的方法，IO复用在人的大脑思维中并不自然，因为，程序员编程中，处理请求A的时候，假定A请求必须经过多个IO操作A1-An（两次IO间可能间隔很长时间），每经过一次IO操作，再调用IO复用时，IO复用的调用返回里，非常可能不再有A，而是返回了请求B。即请求A会经常被请求B打断，处理请求B时，又被C打断。这种思维下，编程容易出错。\n在程序中： 某一瞬间，服务器共有10万个并发连接，此时，一次IO复用接口的调用返回了100个活跃的连接等待处理。先根据这100个连接找出其对应的对象，这并不难，epoll的返回连接数据结构里就有这样的指针可以用。接着，循环的处理每一个连接，找出这个对象此刻的上下文状态，再使用read、write这样的网络IO获取此次的操作内容，结合上下文状态查询此时应当选择哪个业务方法处理，调用相应方法完成操作后，若请求结束，则删除对象及其上下文。\n这样，我们就陷入了面向过程编程方法之中了，在面向应用、快速响应为王的移动互联网时代，这样做早晚得把自己玩死。我们的主程序需要关注各种不同类型的请求，在不同状态下，对于不同的请求命令选择不同的业务处理方法。这会导致随着请求类型的增加，请求状态的增加，请求命令的增加，主程序复杂度快速膨胀，导致维护越来越困难，苦逼的程序员再也不敢轻易接新需求、重构。\n反应堆是解决上述软件工程问题的一种途径，它也许并不优雅，开发效率上也不是最高的，但其执行效率与面向过程的使用IO复用却几乎是等价的，所以，无论是nginx、memcached、redis等等这些高性能组件的代名词，都义无反顾的一头扎进了反应堆的怀抱中。\n反应堆模式可以在软件工程层面，将事件驱动框架分离出具体业务，将不同类型请求之间用OO的思想分离。通常，反应堆不仅使用IO复用处理网络事件驱动，还会实现定时器来处理时间事件的驱动（请求的超时处理或者定时任务的处理）\nReactor的几种模式 1 单线程模式 这是最简单的单Reactor单线程模型。Reactor线程是个多面手，负责多路分离套接字，Accept新连接，并分派请求到处理器链中。该模型适用于处理器链中业务处理组件能快速完成的场景。不过这种单线程模型不能充分利用多核资源，所以实际使用的不多。\n2 多线程模式（单Reactor） 该模型在事件处理器（Handler）链部分采用了多线程（线程池），也是后端程序常用的模型。\n3 多线程模式（多个Reactor） 比起第二种模型，它是将Reactor分成两部分，mainReactor负责监听并accept新连接，然后将建立的socket通过多路复用器（Acceptor）分派给subReactor。subReactor负责多路分离已连接的socket，读写网络数据；业务处理功能，其交给worker线程池完成。通常，subReactor个数上可与CPU个数等同。\nProacotr模型 Proactor是和异步I/O相关的。\n比较 以读操作为例： 在Reactor（同步）中实现读：\n注册读就绪事件和相应的事件处理器 事件分离器等待事件 事件到来，激活分离器，分离器调用事件对应的处理器。 事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。 Proactor（异步）中的读：\n处理器发起异步读操作（注意：操作系统必须支持异步IO）。在这种情况下，处理器无视IO就绪事件，它关注的是完成事件。 事件分离器等待操作完成事件 在分离器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分离器读操作完成。 事件分离器呼唤处理器。 事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分离器。 参考资料 一文读懂高性能网络编程中的I/O模型 - 知乎 (zhihu.com)\n网络I/O模型\u0026ndash;5种常见的网络I/O模型 - QiangAnan - 博客园 (cnblogs.com)\n如何理解高性能网络模型\n","date":"2021-08-16T22:52:32Z","permalink":"https://lxb.wiki/3af5472b/","title":"网络 IO 模型"},{"content":" 一、事务的基本要素（ACID） 1、原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。\n2、一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。\n3、隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。\n4、持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。\n二、事务的并发问题 1、脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据\n2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。\n3、幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。\n小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表\n三、MySQL事务隔离级别 事务隔离级别 脏读 不可重复读 幻读 读未提交（read-uncommitted） 是 是 是 不可重复读（read-committed） 否 是 是 可重复读（repeatable-read） 否 否 是 串行化（serializable） 否 否 否 mysql默认的事务隔离级别为repeatable-read\n四、用例子说明各个隔离级别的情况 1、读未提交： （1）打开一个客户端A，并设置当前事务模式为read uncommitted（未提交读），查询表account的初始值：\n（2）在客户端A的事务提交之前，打开另一个客户端B，更新表account：\n（3）这时，虽然客户端B的事务还没提交，但是客户端A就可以查询到B已经更新的数据：\n（4）一旦客户端B的事务因为某种原因回滚，所有的操作都将会被撤销，那客户端A查询到的数据其实就是脏数据：\n（5）在客户端A执行更新语句update account set balance = balance - 50 where id =1，lilei的balance没有变成350，居然是400，是不是很奇怪，数据不一致啊，如果你这么想就太天真 了，在应用程序中，我们会用400-50=350，并不知道其他会话回滚了，要想解决这个问题可以采用读已提交的隔离级别\n2、读已提交 （1）打开一个客户端A，并设置当前事务模式为read committed（读已提交），查询表account的所有记录：\n（2）在客户端A的事务提交之前，打开另一个客户端B，更新表account：\n（3）这时，客户端B的事务还没提交，客户端A不能查询到B已经更新的数据，解决了脏读问题：\n（4）客户端B的事务提交\n（5）客户端A执行与上一步相同的查询，结果 与上一步不一致，即产生了不可重复读的问题\n3、可重复读 （1）打开一个客户端A，并设置当前事务模式为repeatable read，查询表account的所有记录\n（2）在客户端A的事务提交之前，打开另一个客户端B，更新表account并提交\n（3）在客户端A查询表account的所有记录，与步骤（1）查询结果一致，没有出现不可重复读的问题\n（4）在客户端A，接着执行update balance = balance - 50 where id = 1，balance没有变成400-50=350，lilei的balance值用的是步骤（2）中的350来算的，所以是300，数据的一致性倒是没有被破坏。可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）。\n（5）重新打开客户端B，插入一条新数据后提交\n（6）在客户端A查询表account的所有记录，没有 查出 新增数据，所以没有出现幻读\n4.串行化 （1）打开一个客户端A，并设置当前事务模式为serializable，查询表account的初始值：\n（2）打开一个客户端B，并设置当前事务模式为serializable，插入一条记录报错，表被锁了插入失败，mysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到。\n补充：\n1、事务隔离级别为读提交时，写数据只会锁住相应的行\n2、事务隔离级别为可重复读时，如果检索条件有索引（包括主键索引）的时候，默认加锁方式是next-key 锁；如果****检索条件****没有索引，更新数据时会锁住整张表。一个间隙被事务加了锁，其他事务是不能在这个间隙插入记录的，这样可以防止幻读。\n3、事务隔离级别为串行化时，读写数据都会锁住整张表\n4、隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。\n5、MYSQL MVCC实现机制参考链接：https://blog.csdn.net/whoamiyang/article/details/51901888\n6、关于next-key 锁可以参考链接：https://blog.csdn.net/bigtree_3721/article/details/73731377\n后注：\n关于 四、3、可重复的的第(6)步， 待验证\n","date":"2021-08-02T23:20:12Z","permalink":"https://lxb.wiki/689978a2/","title":"MySQL的四种事务隔离级别"},{"content":" 1. 丢消息 检测消息丢失的方法 一般而言，一个新的系统刚刚上线，各方面都不太稳定，需要一个磨合期，这个时候，特别需要监控到你的系统中是否有消息丢失的情况。\n如果是 IT 基础设施比较完善的公司，一般都有分布式链路追踪系统，使用类似的追踪系统可以很方便地追踪每一条消息。\n可以利用消息队列的有序性来验证是否有消息丢失。原理非常简单，在 Producer 端，我们给每个发出的消息附加一个连续递增的序号，然后在 Consumer 端来检查这个序号的连续性。\n如果没有消息丢失，Consumer 收到消息的序号必然是连续递增的，或者说收到的消息，其中的序号必然是上一条消息的序号 +1。如果检测到序号不连续，那就是丢消息了。还可以通过缺失的序号来确定丢失的是哪条消息，方便进一步排查原因。\n大多数消息队列的客户端都支持拦截器机制，你可以利用这个拦截器机制，在 Producer 发送消息之前的拦截器中将序号注入到消息中，在 Consumer 收到消息的拦截器中检测序号的连续性，这样实现的好处是消息检测的代码不会侵入到你的业务代码中，待你的系统稳定后，也方便将这部分检测的逻辑关闭或者删除。\n如果是在一个分布式系统中实现这个检测方法，有几个问题需要你注意。\n首先，像 Kafka 和 RocketMQ 这样的消息队列，它是不保证在 Topic 上的严格顺序的，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。\n如果你的系统中 Producer 是多实例的，由于并不好协调多个 Producer 之间的发送顺序，所以也需要每个 Producer 分别生成各自的消息序号，并且需要附加上 Producer 的标识，在 Consumer 端按照每个 Producer 分别来检测序号的连续性。\nConsumer 实例的数量最好和分区数量一致，做到 Consumer 和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性。\n确保消息可靠传递 整个消息从生产到消费的过程中，哪些地方可能会导致丢消息，以及应该如何避免消息丢失。一条消息从生产到消费完成这个过程，可以划分三个阶段\n生产阶段: 在这个阶段，从消息在 Producer 创建出来，经过网络传输发送到 Broker 端。 存储阶段: 在这个阶段，消息在 Broker 端存储，如果是集群，消息会在这个阶段被复制到其他的副本上。 消费阶段: 在这个阶段，Consumer 从 Broker 上拉取消息，经过网络传输发送到 Consumer 上。 1. 生产阶段 在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传递：当你的代码调用发消息方法时，消息队列的客户端会把消息发送到 Broker，Broker 收到消息后，会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送。\n只要 Producer 收到了 Broker 的确认响应，就可以保证消息在生产阶段不会丢失。有些消息队列在长时间没收到发送确认响应后，会自动重试，如果重试再失败，就会以返回值或者异常的方式告知用户。\n你在编写发送消息代码时，需要注意，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失。以 Kafka 为例，我们看一下如何可靠地发送消息：\n同步发送时，只要注意捕获异常即可。\ntry { RecordMetadata metadata = producer.send(record).get(); System.out.println(\u0026#34; 消息发送成功。\u0026#34;); } catch (Throwable e) { System.out.println(\u0026#34; 消息发送失败！\u0026#34;); System.out.println(e); } 异步发送时，则需要在回调方法里进行检查。这个地方是需要特别注意的，很多丢消息的原因就是，我们使用了异步发送，却没有在回调中检查发送结果。\nproducer.send(record, (metadata, exception) -\u0026gt; { if (metadata != null) { System.out.println(\u0026#34; 消息发送成功。\u0026#34;); } else { System.out.println(\u0026#34; 消息发送失败！\u0026#34;); System.out.println(exception); } }); 2. 存储阶段 在存储阶段正常情况下，只要 Broker 在正常运行，就不会出现丢失消息的问题，但是如果 Broker 出现了故障，比如进程死掉了或者服务器宕机了，还是可能会丢失消息的。\n如果对消息的可靠性要求非常高，可以通过配置 Broker 参数来避免因为宕机丢消息。\n对于单个节点的 Broker，需要配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费。例如，在 RocketMQ 中，需要将刷盘方式 flushDiskType 配置为 SYNC_FLUSH 同步刷盘。\n如果是 Broker 是由多个节点组成的集群，需要将 Broker 集群配置成：至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker，也不会发生消息丢失。消息队列通过消息复制来确保消息的可靠性的。\n3. 消费阶段 消费阶段采用和生产阶段类似的确认机制来保证消息的可靠传递，客户端从 Broker 拉取消息后，执行用户的消费业务逻辑，成功后，才会给 Broker 发送消费确认响应。如果 Broker 没有收到消费确认响应，下\n次拉消息的时候还会返回同一条消息，确保消息不会在网络传输过程中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失。\n你在编写消费代码时需要注意的是，不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。\n同样，我们以用 Python 语言消费 RabbitMQ 消息为例，来看一下如何实现一段可靠的消费代码：\ndef callback(ch, method, properties, body): print(\u0026#34; [x] 收到消息 %r\u0026#34; % body) # 在这儿处理收到的消息 database.save(body) print(\u0026#34; [x] 消费完成 \u0026#34;) # 完成消费业务逻辑后发送消费确认响应 ch.basic_ack(delivery_tag = method.delivery_tag) channel.basic_consume(queue=\u0026#39;hello\u0026#39;, on_message_callback=callback) 在消费的回调方法 callback 中，正确的顺序先是把消息保存到数据库，然后再发送消费确认响应。这样如果保存消息到数据库失败了，就不会执行消费确认的代码，下次拉到的还是这条消息，直到消费成功。\n两个消费者先后去拉消息是否能拉到同一条消息？\n首先，消息队列一般都会有协调机制，不会让这种情况出现，但是由于网络不确定性，这种情况还是在极小概率下会出现的。\n在同一个消费组内，A消费者拉走了index=10的这条消息，还没返回确认，这时候这个分区的消费位置还是10，B消费者来拉消息，可能有2种情况：\n\\1. 超时前，Broker认为这个分区还被A占用着，会拒绝B的请求。\n\\2. 超时后，Broker认为A已经超时没返回，这次消费失败，当前消费位置还是10，B再来拉消息，会给它返回10这条消息。\n在生产阶段，你需要捕获消息发送的错误，并重发消息。\n在存储阶段，你可以通过配置刷盘和复制相关的参数，让消息写入到多个副本的磁盘上，来确保消息不会因为某个 Broker 宕机或者磁盘损坏而丢失。\n在消费阶段，你需要在处理完全部消费业务逻辑之后，再发送消费确认。\n你在理解了这几个阶段的原理后，如果再出现丢消息的情况，应该可以通过在代码中加一些日志的方式，很快定位到是哪个阶段出了问题，然后再进一步深入分析，快速找到问题原因。\n2. 重复消息 在消息传递过程中，如果出现传递失败的情况，发送方会执行重试，重试的过程中就有可能会产生重复的消息。对使用消息队列的业务系统来说，如果没有对重复消息进行处理，就有可能会导致系统的数据出现错误。\n消息重复的情况必然存在 在 MQTT 协议中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是：\nAt most once: 至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。 At least once: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。 Exactly once：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。 这个服务质量标准不仅适用于 MQTT，对所有的消息队列都是适用的。我们现在常用的绝大部分消息队列提供的服务质量都是 At least once，包括 RocketMQ、RabbitMQ 和 Kafka 都是这样。也就是说，消息\n队****列很难保证消息不重复。\nKafka 支持的“Exactly once”和我们刚刚提到的消息传递的服务质量标准“Exactly once”是不一样的，它是 Kafka 提供的另外一个特性，Kafka 中支持的事务也和我们通常意义理解的事务有一定的差异。在 Kafka\n中，事务和 Excactly once 主要是为了配合流计算使用的特性。巧妙地用了两个所有人都非常熟悉的概念“事务”和“Exactly once”来包装它的新的特性，实际上它实现的这个事务和 Exactly once 并不是我们通常\n理解的那两个特性。\n为什么大部分消息队列都选择只提供 At least once 的服务质量，而不是级别更高的 Exactly once？\n解决一个问题，往往会引发别的问题。若消息队列实现了exactly once，会引发的问题有：\n①消费端在pull消息时，需要检测此消息是否被消费，这个检测机制无疑会拉低消息消费的速度。可以预想到，随着消息的剧增，消费性能势必会急剧下降，导致消息积压；\n②检查机制还需要业务端去配合实现，若一条消息长时间未返回ack，消息队列需要去回调看下消费结果（这个类似于事物消息的回查机制）。这样就会增加业务端的压力，与很多的未知因素。\n所以，消息队列不实现exactly once，而是at least once + 幂等性，这个幂等性让给我们去处理。\n最重要的原因是消息队列即使做到了Exactly once级别，consumer也还是要做幂等。因为在consumer从消息队列取消息这里，如果consumer消费成功，但是ack失败，consumer还是会取到重复的消息，所以消\n息队列花大力气做成Exactly once并不能解决业务侧消息重复的问题。\n1、At least once + 幂等消费 = Exactly once，所以对于消息队列来讲，要做到Exactly once，其实是需消费端的共同配合（幂等消费）才可完成，消息队列基本只提供At least once的实现；\n2、从给的几种幂等消费的方案看，需要引入数据库、条件更新、分布式事务或锁等额外辅助，消息队列如果需要保障Exactly once，会导致消费端代码侵入，例如需要消费端增加消息队列用来处理幂等的client\n端，而消费端的形态可是太多了，兼容适配工作量巨大。故这个Exactly once留给用户自己处理，并且具有选择权，毕竟不是所有业务场景都需要Exactly once，例如机房温度上报的案例。\n如果队列的实现是At least once，但是为了确保消息不丢失，Broker Service会进行一定的重试，但是不可能一直重试，如果一直重试失败怎么处理了？\n有的消息队列会有一个特殊的队列来保存这些总是消费失败的“坏消息”，然后继续消费之后的消息，避免坏消息卡死队列。这种坏消息一般不会是因为网络原因或者消费者死掉导致的，大多都是消息数据本身有\n问题，消费者的业务逻辑处理不了导致的。\n用幂等性解决重复消息问题 一般解决重复消息的办法是，在消费端，让我们消费消息的操作具备幂等性。\n幂等（Idempotence）是一个数学上的概念，它是这样定义的：\n如果一个函数 f(x) 满足：f(f(x)) = f(x)，则函数 f(x) 满足幂等性。\n这个概念被拓展到计算机领域，被用来描述一个操作、方法或者服务。一个幂等操作的特点是，其任意多次执行所产生的影响均与一次执行的影响相同。\n一个幂等的方法，使用同样的参数，对它进行多次调用和一次调用，对系统产生的影响是一样的。所以，对于幂等的方法，不用担心重复执行会对系统造成任何改变。\n比如在不考虑并发的情况下，“将账户 X 的余额设置为 100 元”，执行一次后对系统的影响是，账户 X 的余额变成了 100 元。只要提供的参数 100 元不变，那即使再执行多少次，账户 X 的余额始终都是 100 元，\n不会变化，这个操作就是一个幂等的操作。\n再比如“将账户 X 的余额加 100 元”，这个操作它就不是幂等的，每执行一次，账户余额就会增加 100 元，执行多次和执行一次对系统的影响（也就是账户的余额）是不一样的。\n如果我们系统消费消息的业务逻辑具备幂等性，那就不用担心消息重复的问题了，因为同一条消息，消费一次和消费多次对系统的影响是完全一样的。也就可以认为，消费多次等于消费一次。\n从对系统的影响结果来说：At least once + 幂等消费 = Exactly once。\n那么如何实现幂等操作呢？最好的方式就是，从业务逻辑设计上入手，将消费的业务逻辑设计成具备幂等性的操作。但是，不是所有的业务都能设计成天然幂等的，这里就需要一些方法和技巧来实现幂等。\n下面我给你介绍几种常用的设计幂等操作的方法：\n1. 利用数据库的唯一约束实现幂等 刚刚提到的那个不具备幂等特性转账的例子：将账户 X 的余额加 100 元。在这个例子中，我们可以通过改造业务逻辑，让它具备幂等性。\n首先，我们可以限定，对于每个转账单每个账户只可以执行一次变更操作，在分布式系统中，这个限制实现的方法非常多，最简单的是我们在数据库中建一张转账流水表，这个表有三个字段：转账单 ID、账户\nID 和变更金额，然后给转账单 ID 和账户 ID 这两个字段联合起来创建一个唯一约束，这样对于相同的转账单 ID 和账户 ID，表里至多只能存在一条记录。\n这样，我们消费消息的逻辑可以变为：“在转账流水表中增加一条转账记录，然后再根据转账记录，异步操作更新用户余额即可。”在转账流水表增加一条转账记录这个操作中，由于我们在这个表中预先定义了“账\n户 ID 转账单 ID”的唯一约束，对于同一个转账单同一个账户只能插入一条记录，后续重复的插入操作都会失败，这样就实现了一个幂等的操作。我们只要写一个 SQL，正确地实现它就可以了。\n基于这个思路，不光是可以使用关系型数据库，只要是支持类似“INSERT IF NOT EXIST”语义的存储类系统都可以用于实现幂等，\n比如， **Redis 的 SETNX 命令来替代数据库中的唯一约束，来实现幂****等消费。 （ redis中的hash：**hsetnx ； ）\n比如，Elasticsearch中的幂等操作： PUT /movie_index/movie/3，加上文档 ID\n2. 为更新的数据设置前置条件 另外一种实现幂等的思路是，给数据变更设置一个前置条件，如果满足条件就更新数据，否则拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。这样，重复执行这个操作时，由于第一次\n更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。\n比如，刚刚我们说过，“将账户 X 的余额增加 100 元”这个操作并不满足幂等性，我们可以把这个操作加上一个前置条件，变为：“如果账户 X 当前的余额为 500 元，将余额加 100 元”，这个操作就具备了幂等\n性。对应到消息队列中的使用时，可以在发消息时在消息体中带上当前的余额，在消费的时候进行判断数据库中，当前余额是否与消息中的余额相等，只有相等才执行变更操作。\n但是，如果我们要更新的数据不是数值，或者我们要做一个比较复杂的更新操作怎么办？用什么作为前置判断条件呢？更加通用的方法是，给你的数据增加一个版本号属性，每次更数据前，比较当前数据的版本\n号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时将版本号 +1，一样可以实现幂等更新。\n3. 记录并检查操作 如果上面提到的两种实现幂等方法都不能适用于你的场景，我们还有一种通用性最强，适用范围最广的实现幂等性方法：记录并检查操作，也称为“Token 机制或者 GUID（全局唯一 ID）机制”，实现的思路特别\n简单：在执行数据更新操作之前，先检查一下是否执行过这个更新操作。\n具体的实现方法是，在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。\n原理和实现是不是很简单？其实一点儿都不简单，在分布式系统中，这个方法其实是非常难实现的。首先，给每个消息指定一个全局唯一的 ID 就是一件不那么简单的事儿，方法有很多，但都不太好同时满足简\n单、高可用和高性能，或多或少都要有些牺牲。更加麻烦的是，在“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作保证原子性，才能真正实现幂等，否则就会出现 Bug。\n比如说，对于同一条消息：“全局 ID 为 8，操作为：给 ID 为 666 账户增加 100 元”，有可能出现这样的情况：\nt0 时刻：Consumer A 收到条消息，检查消息执行状态，发现消息未处理过，开始执行“账户增加 100 元”； t1 时刻：Consumer B 收到条消息，检查消息执行状态，发现消息未处理过，因为这个时刻，Consumer A 还未来得及更新消息执行状态。 这样就会导致账户被错误地增加了两次 100 元，这是一个在分布式系统中非常容易犯的错误，一定要引以为戒。\n对于这个问题，当然我们可以用事务来实现，也可以用锁来实现，但是在分布式系统中，无论是分布式事务还是分布式锁都是比较难解决问题。\n几种实现幂等操作的方法\n可以利用数据库的约束来防止重复更新数据， 可以为数据更新设置一次性的前置条件，来防止重复消息，如果这两种方法都不适用于你的场景， 还可以用“记录并检查操作”的方式来保证幂等，这种方法适用范围最广，但是实现难度和复杂度也比较高，一般不推荐使用。 这些实现幂等的方法，不仅可以用于解决重复消息的问题，也同样适用于，在其他场景中来解决重复请求或者重复调用的问题。比如，我们可以将 HTTP 服务设计成幂等的，解决前端或者 APP 重复提交表单数\n据的问题；也可以将一个微服务设计成幂等的，解决 RPC 框架自动重试导致的重复调用问题。这些方法都是通用的。\n3. 消息积压问题 在使用消息队列遇到的问题中，消息积压这个问题，应该是最常遇到的问题。\n消息积压的直接原因，一定是系统中的某个部分出现了性能问题，来不及处理上游发送的消息，才会导致消息积压。 所以在使用消息队列时，如何来优化代码的性能，避免出现消息积压。\n优化性能来避免消息积压 在使用消息队列的系统中，对于性能的优化，主要体现在生产者和消费者这一收一发两部分的业务逻辑中。对于消息队列本身的性能，不需要太关注。\n主要原因是，对于绝大多数使用消息队列的业务来说，消息队列本身的处理能力要远大于业务系统的处理能力。主流消息队列的单个节点，消息收发的性能可以达到每秒钟处理几万至几十万条消息的水平，还可\n以通过水平扩展 Broker 的实例数成倍地提升处理能力。而一般的业务系统需要处理的业务逻辑远比消息队列要复杂，单个节点每秒钟可以处理几百到几千次请求，已经可以算是性能非常好的了。所以，对于消\n息队列的性能优化，我们更关注的是，在消息的收发两端，我们的业务代码怎么和消息队列配合，达到一个最佳的性能。\n1. 发送端性能优化 如果说，代码发送消息的性能上不去，需要优先检查一下，是不是发消息之前的业务逻辑耗时太多导致的。\n对于发送消息的业务逻辑，只需要注意设置合适的并发和批量大小，就可以达到很好的发送性能。\nProducer 发送消息的过程，Producer 发消息给 Broker，Broker 收到消息后返回确认响应，这是一次完整的交互。假设这一次交互的平均时延是 1ms，把这 1ms 的时间分解开，它包括了下面这些步骤的耗时：\n发送端准备数据、序列化消息、构造请求等逻辑的时间，也就是发送端在发送网络请求之前的耗时； 发送消息和返回响应在网络传输中的耗时； Broker 处理消息的时延。 如果是单线程发送，每次只发送 1 条消息，那么每秒只能发送 1000ms / 1ms * 1 条 /ms = 1000 条 消息，这种情况下并不能发挥出消息队列的全部实力。\n无论是增加每次发送消息的批量大小，还是增加并发，都能成倍地提升发送性能。至于到底是选择批量发送还是增加并发，主要取决于发送端程序的业务性质。\n比如说，你的消息发送端是一个微服务，主要接受 RPC 请求处理在线业务。很自然的，微服务在处理每次请求的时候，就在当前线程直接发送消息就可以了，因为所有 RPC 框架都是多线程支持多并发的，自\n然也就实现了并行发送消息。并且在线业务比较在意的是请求响应时延，选择批量发送必然会影响 RPC 服务的时延。这种情况，比较明智的方式就是通过并发来提升发送性能。\n如果你的系统是一个离线分析系统，离线系统在性能上的需求是什么呢？它不关心时延，更注重整个系统的吞吐量。发送端的数据都是来自于数据库，这种情况就更适合批量发送，你可以批量从数据库读取数\n据，然后批量来发送消息，同样用少量的并发就可以获得非常高的吞吐量。\n2. 消费端性能优化 使用消息队列的时候，大部分的性能问题都出现在消费端，如果消费的速度跟不上发送端生产消息的速度，就会造成消息积压。如果这种性能倒挂的问题只是暂时的，那问题不大，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息是可以逐渐被消化掉的。\n要是消费速度一直比生产速度慢，时间长了，整个系统就会出现问题，要么，消息队列的存储被填满无法提供服务，要么消息丢失，这对于整个系统来说都是严重故障。\n所以，在设计系统的时候，一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。\n消费端的性能优化除了优化消费业务逻辑以外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。特别需要注意的一点是，在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区\n（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。因为对于消费者，在每个分区上实际只能支持单线程消费。\n一个解决消费慢的问题常见的错误：\n它收消息处理的业务逻辑可能比较慢，也很难再优化了，为了避免消息积压，在收到消息的 OnMessage 方法中，不处理任何业务逻辑，把这个消息放到一个内存队列里面就返回了。然后它可以启动很多的业务\n线程，这些业务线程里面是真正处理消息的业务逻辑，这些线程从内存队列里取消息处理，这样它就解决了单个 Consumer 不能并行消费的问题。\n这个方法是不是很完美地实现了并发消费？错误！ 因为会丢消息。如果收消息的节点发生宕机，在内存队列中还没来及处理的这些消息就会丢失。\n在onMessage方法结束后，如果没有抛异常，就自动ACK了。而这个时候，消息只是在内存队列中，并没有被真正处理完。\n如果onMessage方法中，收到消息后不确认，等真正处理完消息再确认，就可以了吧，这样就可以用内存队列了\n理论上是可以的，但要注意，像RocketMQ，采用默认配置的时候，onMessage方法结束后，如果没抛异常，默认就会自动确认了。\n在消费端是否可以通过批量消费的方式来提升消费性能？在什么样场景下，适合使用这种方法？或者说，这种方法有什么局限性？\n批量消费即一次取一批消息，等这一批消息都成功了，再提交最后一条消息的位置作为新的消费位置。如果其中任何一条失败，则认为整批都失败。\n批量消费应该是与消息处理是需要实时与否有关。如果需要实时处理，如订单相关的，就不能批量，但是发送提醒邮件之类的，就可以。\n批量消费有意义的场景要求：\n1.要么消费端对消息的处理支持批量处理，比如批量入库 \\2. 要么消费端支持多线程/协程并发处理，业务上也允许消息无序。 \\3. 或者网络带宽在考虑因素内，需要减少消息的overhead。 批量消费的局限性：\n\\1. 需要一个整体ack的机制，一旦一条靠前的消息消费失败，可能会引起很多消息重试。 \\2. 多线程下批量消费速度受限于最慢的那个线程。 但其实以上局限并没有影响主流MQ的实现了批量功能。\n1、要求消费端能够批量处理或者开启多线程进行单条处理 2、批量消费一旦某一条数据消费失败会导致整批数据重复消费 3、对实时性要求不能太高，批量消费需要Broker积累到一定消费数据才会发送到Consumer\n消费端进行批量操作，感觉和上面的先将消息放在内存队列中，然后在并发消费消息，如果机器宕机，这些批量消息都会丢失，如果在数据库层面，批量操作在大事务，会导致锁的竞争，并且也会导致主备的不\n一致。如果是一些不重要的消息如对日志进行备份，就可以使用批量操作之类的提高消费性能，因为一些日志消息丢失也是可以接受的。\n如果使用了批量消费的方式，那么就需要批量确认，如果一次消费十条消息，除了第七条消费失败了，其他的都处理成功了，但是这中情况下broker只能将消费的游标修改成消息7，而之后的消息虽然处理成功\n了，但是也只能使用类似于拉回重传的方式再次消费，浪费性能，而且这种批量消费对于消费者的并发我觉得不是很友好，可能消费者1来了取走了十条消息在处理，这时候消费者2过来了也想取十条消息，但是\n他需要等待消费者1进行ack才可以取走消息。\n如何判断增加多少consumer消费实例的个数？\n可以简单计算一下，消费并行度：单实例平均消费tps * 消费并行度 \u0026gt; 生产消息的总tps 消费并行度 = min（consumer实例数，分区数量）\n消息积压的紧急处理 还有一种消息积压的情况是，日常系统正常运转的时候，没有积压或者只有少量积压很快就消费掉了，但是某一个时刻，突然就开始积压消息并且积压持续上涨。这种情况下需要你在短时间内找到消息积压的原\n因，迅速解决问题才不至于影响业务。\n导致突然积压的原因肯定是多种多样的，不同的系统、不同的情况有不同的原因，不能一概而论。但是，排查消息积压原因，是有一些相对固定而且比较有效的方法的。\n能导致积压突然增加，最粗粒度的原因，只有两种：要么是发送变快了，要么是消费变慢了。\n大部分消息队列都内置了监控的功能，只要通过监控数据，很容易确定是哪种原因。如果是单位时间发送的消息增多，比如说是赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升消费性能，唯一的\n方法是通过扩容消费端的实例数来提升总体的消费能力。\n如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。\n还有一种不太常见的情况，你通过监控发现，无论是发送消息的速度还是消费消息的速度和原来都没什么变化，这时候你需要检查一下你的消费端，是不是消费失败导致的一条消息反复消费这种情况比较多，这\n种情况也会拖慢整个系统的消费速度。\n如果监控到消费变慢了，你需要检查你的消费实例，分析一下是什么原因导致消费变慢。优先检查一下日志是否有大量的消费错误，如果没有错误的话，可以通过打印堆栈信息，看一下你的消费线程是不是卡在\n什么地方不动了，比如触发了死锁或者卡在等待某些资源上了。\n**优化消息收发性能，**预防消息积压的方法有两种，增加批量或者是增加并发，在发送端这两种方法都可以使用，在消费端需要注意的是，增加并发需要同步扩容分区数量，否则是起不到效果的。\n对于系统发生消息积压的情况，需要先解决积压，再分析原因，毕竟保证系统的可用性是首先要解决的问题。快速解决积压的方法就是通过水平扩容增加 Consumer 的实例数量。\n消息积压处理： 1、发送端优化，增加批量和线程并发两种方式处理 2、消费端优化，优化业务逻辑代码、水平扩容增加并发并同步扩容分区数量 查看消息积压的方法： 1、消息队列内置监控，查看发送端发送消息与消费端消费消息的速度变化 2、查看日志是否有大量的消费错误 3、打印堆栈信息，查看消费线程卡点信息\n面试解决消息积压的方法： （1）临时扩容，增加消费端，用硬件提升消费速度。 （2）服务降级，关闭一些非核心业务，减少消息生产。 （3）通过日志分析，监控等找到挤压原因，消息队列三部分，上游生产者是否异常生产大量数据，中游消息队列存储层是否出现问题，下游消费速度是否变慢，就能确定哪个环节出了问题 （4）根据排查解决异常部分。 （5）等待积压的消息被消费，恢复到正常状态，撤掉扩容服务器。\n4. 如何保证消息的严格顺序？ 怎么来保证消息的严格顺序？主题层面是无法保证严格顺序的，只有在队列上才能保证消息的严格顺序。\n如果说，你的业务必须要求全局严格顺序，就只能把消息队列数配置成 1，生产者和消费者也只能是一个实例，这样才能保证全局严格顺序。\n大部分情况下，并不需要全局严格顺序，只要保证局部有序就可以满足要求了。比如，在传递账户流水记录的时候，只要保证每个账户的流水有序就可以了，不同账户之间的流水记录是不需要保证顺序的。\n如果需要保证局部严格顺序，可以这样来实现。在发送端，我们使用账户 ID 作为 Key，采用一致性哈希算法计算出队列编号，指定队列来发送消息。一致性哈希算法可以保证，相同 Key 的消息总是发送到同一\n个队列上，这样可以保证相同 Key 的消息是严格有序的。如果不考虑队列扩容，也可以用队列数量取模的简单方法来计算队列编号。\n","date":"2021-07-24T23:05:09Z","permalink":"https://lxb.wiki/ff873094/","title":"消息队列中的问题| 丢消息| 重复消费| 消息积压"},{"content":" 一 B树\n**1.B树的定义：**B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。\n2.B树的特征：\n根节点至少有两个子节点 每个中间节点都包含k-1个元素和k个孩子，其中 m/2 ≤ k ≤ m （m为树的阶） 每个叶子节点都包含k-1个元素，其中 m/2 ≤ k ≤ m （m为树的阶） 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域划分（一个结点有k个孩子时，必有k-1个元素才能将子树中所有元素划分为k个子集） 3.B树的操作\n**3.1 B树的查找：**如下图，查询元素8\n第一次磁盘IO：把15所在节点读到内存中，然后与8做比较，小于15，找到下一个节点（5和9对应的节点）\n第二次磁盘IO：把5和9所在的节点读到内存中，然后与8做比较，5\u0026lt;8\u0026lt;9，找到下一个节点（6和8对应的节点）\n第三次磁盘IO：把6和8所在节点读到内存中，然后与8做比较，找到了元素8\n3.1 B树的插入： 将元素7插入下图中的B树\n步骤一：自顶向下查找元素7应该在的位置，即在6和8之间\n步骤二：三阶B树中的节点最多有两个元素，把6 7 8里面的中间元素上移（中间元素上移是插入操作的关键）\n步骤三：上移之后，上一层节点元素也超载了，5 7 9中间元素上移，现在根节点变为了 7 15\n步骤四：要对B树进行调整，使其满足B树的特性，最终如下图：\n二 B+树\nB+树是B树的一种变形体，它与B树的差异在于：\n有K个子节点的节点必然有K个关键码 非叶节点仅具有索引作用，元素信息均存放在叶节点中 树的所有叶节点构成一个有序链表，可以按照关键码排序的次序遍历全部记录 B+树的优势：\n由于B+树在内部节点上不包含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子节点上关联的数据也具有更好的缓存命中率。\nB+树的叶子节点都是相连的，因此对整棵树的遍历只需要一次线性遍历叶子节点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。\n总结：我们知道二叉查找树的时间复杂度是Ｏ(logN)，效率已经足够高。为什么出现B树和B+树呢？当大量数据存储在磁盘上，进行查询操作时，需要先将数据加载到内存中（磁盘IO操作），而数据并不能一次性全部加载到内存中，只能逐一加载每个磁盘页（对应树的一个节点），并且磁盘IO操作很慢，平衡二叉树由于树深度过大而造成磁盘IO读写过于频繁，进而导致效率低下。为了减少磁盘IO的次数，就需要降低树的深度，那么就引出了B树和B+树：每个节点存储多个元素，采用多叉树结构。这样就提高了效率，比如数据库索引，就是存储在磁盘上，采用的就是B+树的数据结构。\n","date":"2021-07-11T21:07:59Z","permalink":"https://lxb.wiki/17ced2c4/","title":"B树和B+树"},{"content":" Sortedset底层存储结构 sortedset同时会由两种数据结构支持,ziplist和skiplist.\n只有同时满足如下条件是,使用的是ziplist,其他时候则是使用skiplist\n有序集合保存的元素数量小于128个 有序集合保存的所有元素的长度小于64字节 当ziplist作为存储结构时候,每个集合元素使用两个紧挨在一起的压缩列表结点来保存,第一个节点保存元素的成员,第二个元素保存元素的分值.\n当使用skiplist作为存储结构时,使用skiplist按序保存元素分值,使用dict来保存元素和分值的对应关系\n1 跳跃表 跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。跳跃表支持平均O（logN）、最坏O（N）复杂度的节点查找，还可以通过顺序性操作来批量处理节点。\n在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单。\nRedis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员（member）是比较长的字符串时，Redis就会使用跳跃表来作为有序集合键的底层实现。\nRedis只在两个地方用到了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构，除此之外，跳跃表在Redis里面没有其他用途。\nRedis的配置文件中关于有序集合底层实现的两个配置。 1）zset-max-ziplist-entries 128:zset采用压缩列表时，元素个数最大值。默认值为128。 2）zset-max-ziplist-value 64:zset采用压缩列表时，每个元素的字符串长度最大值。默认值为64。 zset插入第一个元素时，会判断下面两种条件：\nzset-max-ziplist-entries的值是否等于0； zset-max-ziplist-value小于要插入元素的字符串长度。满足任一条件Redis就会采用跳跃表作为底层实现，否则采用压缩列表作为底层实现方式。 一般情况下，不会将zset-max-ziplist-entries配置成0，元素的字符串长度也不会太长，所以在创建有序集合时，默认使用压缩列表的底层实现。zset新插入元素时，会判断以下两种条件：\nzset中元素个数大于zset_max_ziplist_entries； 插入元素的字符串长度大于zset_max_ziplist_value。当满足任一条件时，Redis便会将zset的底层实现由压缩列表转为跳跃表。 zset在转为跳跃表之后，即使元素被逐渐删除，也不会重新转为压缩列表。\n2 跳跃表的结构 其c语言代码如下：\ntypedef struct zskiplistNode { //成员对象 robj *obj; double score;//分值 struct zskiplistNode *backward;//回退指针 //层 struct zskiplistLevel { //前进指针 struct zskiplistNode *forward; //跨度 unsigned int span; } level[]; } zskiplistNode; 1）obj：用于存储字符串类型的数据。 2）score：用于存储排序的分值。 3）backward：后退指针，只能指向当前节点最底层的前一个节点，头节点和第一个节点——backward指向NULL，从后向前遍历跳跃表时使用。 4）level：为柔性数组。每个节点的数组长度不一样，在生成跳跃表节点时，随机生成一个1～64的值，值越大出现的概率越低。 level数组的每项包含以下两个元素。\nforward：指向本层下一个节点，尾节点的forward指向NULL。 span:forward指向的节点与本节点之间的元素个数。span值越大，跳过的节点个数越多。 除了跳跃表节点外，还需要一个跳跃表结构来管理节点，Redis使用zskiplist结构体，定义如下：\ntypedef struct zskiplist { struct zskiplistNode *header, *tail; unsigned long length; int level; } zskiplist; 1）header：指向跳跃表头节点。头节点是跳跃表的一个特殊节点，它的level数组元素个数为64。头节点在有序集合中不存储任何member和score值，ele值为NULL, score值为0；也不计入跳跃表的总长度。头节点在初始化时，64个元素的forward都指向NULL, span值都为0。 2）tail：指向跳跃表尾节点。 3）length：跳跃表长度，表示除头节点之外的节点总数。 4）level：跳跃表的高度。\n查找从最高层开始，如果本层的next节点大于要查找的值或next节点为NULL，则从本节点开始，降低一层继续向后查找，依次类推，如果找到则返回节点；否则返回NULL。采用该原理查找节点，在节点数量比较多时，可以跳过一些节点，查询效率大大提升，这就是跳跃表的基本思想。\n1）跳跃表由很多层构成。 2）跳跃表有一个头（header）节点，头节点中有一个64层的结构，每层的结构包含指向本层的下个节点的指针，指向本层下个节点中间所跨越的节点个数为本层的跨度（span）。 3）除头节点外，层数最多的节点的层高为跳跃表的高度（level） 4）每层都是一个有序链表，数据递增。 5）除header节点外，一个元素在上层有序链表中出现，则它一定会在下层有序链表中出现。 6）跳跃表每层最后一个节点指向NULL，表示本层有序链表的结束。 7）跳跃表拥有一个tail指针，指向跳跃表最后一个节点。 8）最底层的有序链表包含所有节点，最底层的节点个数为跳跃表的长度（length）（不包括头节点）。 9）每个节点包含一个后退指针，头节点和第一个节点指向NULL；其他节点指向最底层的前一个节点。\nRedis通过zslRandomLevel函数随机生成一个1～64的值作为新建节点的高度\n3 压缩列表 压缩列表ziplist本质上就是一个字节数组，是Redis为了节约内存而设计的一种线性数据结构，可以包含多个元素，每个元素可以是一个字节数组或一个整数。\nRedis的有序集合、散列和列表都直接或者间接使用了压缩列表。当有序集合或散列表的元素个数比较少，且元素都是短字符串时，Redis便使用压缩列表作为其底层数据存储结构。列表使用快速链表（quicklist）数据结构存储，而快速链表就是双向链表与压缩列表的组合。\n一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。\n1）zlbytes：压缩列表的字节长度，占4个字节，因此压缩列表最多有232-1个字节。 2）zltail：压缩列表尾元素相对于压缩列表起始地址的偏移量，占4个字节。3）zllen：压缩列表的元素个数，占2个字节。zllen无法存储元素个数超过65535（216-1）的压缩列表，必须遍历整个压缩列表才能获取到元素个数。4）entryX：压缩列表存储的元素，可以是字节数组或者整数，长度不限。entry的编码结构将在后面详细介绍。 5）zlend：压缩列表的结尾，占1个字节，恒为0xFF。\n而压缩列表元素(entry)的编码结构： previous_entry_length字段表示前一个元素的字节长度 占1个或者5个字节，当前一个元素的长度小于254字节时，用1个字节表示；当前一个元素的长度大于或等于254字节时，用5个字节来表示。 encoding字段表示当前元素的编码 数据内容存储在content字段 其中包含了很多复杂的解码运算，想详细了解的可以找对应的书来看。\n连锁更新 每个节点的previous_entry_length属性都记录了前一个节点的长度，添加新节点可能会引发连锁更新之外，删除节点也可能会引发连锁更新。 因为某个可能的结点previous_entry_length属性仅长1字节，它没办法保存新节点new的长度，所以程序将对压缩列表执行空间重分配操作，并将则个节点的previous_entry_length属性从原来的1字节长扩展为5字节长。进而引发后面的连锁更新。 其最坏复杂度是O（N 2）。\n尽管连锁更新的复杂度较高，但它真正造成性能问题的几率是很低的：\n压缩列表里要恰好有多个连续的、长度介于250字节至253字节之间的节点，连锁更新才有可能被引发，在实际中，这种情况并不多见； 即使出现连锁更新，但只要被更新的节点数量不多，就不会对性能造成任何影响：比如说，对三五个节点进行连锁更新是绝对不会影响性能的；\n4 quicklist quicklist是Redis底层最重要的数据结构之一，它是Redis对外提供的6种基本数据结构中List的底层实现，在Redis 3.2版本中引入。\n在引入quicklist之前，Redis采用压缩链表（ziplist）以及双向链表（adlist）作为List的底层实现。当元素个数比较少并且元素长度比较小时，Redis采用ziplist作为其底层存储；当任意一个条件不满足时，Redis采用adlist作为底层存储结构。\n这么做的主要原因是，当元素长度较小时，采用ziplist可以有效节省存储空间，但ziplist的存储空间是连续的，当元素个数比较多时，修改元素时，必须重新分配存储空间，这无疑会影响Redis的执行效率，故而采用一般的双向链表。\n结构如下： 代码如下\ntypedef struct quicklist{ quicklistNode *head; quicklistNode *tail; unsigned long count;//quicklist中元素总数 unsigned long len;//quicklist Node（节点）个数 int fill : 16;//每个quicklistNode中ziplist长度 }quicklist; typedef struct quicklistNode{ struct quicklistNode *prev; struct quicklistNode *next; unsigned char *zl;//zl指向该节点对应的ziplist结构； unsigned int sz;//整个ziplist结构的大小 unsigned int count:16;//ziplist的个数 unsigned int coding：2;//1代表是原生的，2代表使用LZF进行压缩； unsigned int containnr：2;//container为quicklistNode节点zl指向的容器类型：1代表none,2代表使用ziplist存储数据； unsigned int recompress:1;//recompress代表这个节点之前是否是压缩节点 unsigned int extra:10;//extra为预留 }quicklistNode; 数据压缩 quicklist每个节点的实际数据存储结构为ziplist，这种结构的主要优势在于节省存储空间。为了进一步降低ziplist所占用的空间，Redis允许对ziplist进一步压缩，Redis采用的压缩算法是LZF，压缩过后的数据可以分成多个片段，每个片段有2部分：一部分是解释字段，另一部分是存放具体的数据字段。 解释字段可以占用1～3个字节，数据字段可能不存在。\ntypedef struct quicklistLZF{ unsigned int sz;//sz表示compressed所占字节大小 char compress[]; }quicklistLZF; 解释字段有3种: 1）字面型，解释字段占用1个字节，数据字段长度由解释字段后5位决定。 2）简短重复型，解释字段占用2个字节，没有数据字段，数据内容与前面数据内容重复，重复长度小于8。 3）批量重复型，解释字段占3个字节，没有数据字段，数据内容与前面内容重复。\n压缩： 数据与前面重复的，记录重复位置以及重复长度，否则直接记录原始数据内容。压缩算法的流程如下：遍历输入字符串，对当前字符及其后面2个字符进行散列运算，如果在Hash表中找到曾经出现的记录，则计算重复字节的长度以及位置，反之直接输出数据。 解压： 可能存在重复数据与当前位置重叠的情况，例如在当前位置前的15个字节处，重复了20个字节，此时需要按位逐个复制。\n","date":"2021-06-22T22:56:12Z","permalink":"https://lxb.wiki/f1113725/","title":"Redis-Sorted-Set底层数据结构"},{"content":" 文件事件处理器 Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。\n消息处理流程 文件事件处理器使用I/O多路复用(multiplexing)程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。 当被监听的套接字准备好执行连接应答(accept)、读取(read)、写入(write)、关闭(close)等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。 尽管多个文件事件可能会并发地出现，但I/O多路复用程序总是会将所有产生事件的套接字都推到一个队列里面，然后通过这个队列，以有序（sequentially）、同步（synchronously）、每次一个套接字的方式向文件事件分派器传送套接字：当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕）， I/O多路复用程序才会继续向文件事件分派器传送下一个套接字。\nI/O 多路复用程序的实现 Redis的I/O多路复用程序的所有功能是通过包装select、epoll、evport和kqueue这些I/O多路复用函数库来实现的，每个I/O多路复用函数库在Redis源码中都对应一个单独的文件，比如ae_select.c、ae_epoll.c、ae_kqueue.c等。\n因为Redis为每个I/O多路复用函数库都实现了相同的API，所以I/O多路复用程序的底层实现是可以互换的，如下图所示 Redis在I/O多路复用程序的实现源码中用#include宏定义了相应的规则，程序会在编译时自动选择系统中性能最好的I/O多路复用函数库来作为Redis的I/O多路复用程序的底层实现：\n/* Include the best multiplexing layer supported by this system. * The following should be ordered by performances, descending. */ #ifdef HAVE_EVPORT #include \u0026#34;ae_evport.c\u0026#34; #else #ifdef HAVE_EPOLL #include \u0026#34;ae_epoll.c\u0026#34; #else #ifdef HAVE_KQUEUE #include \u0026#34;ae_kqueue.c\u0026#34; #else #include \u0026#34;ae_select.c\u0026#34; #endif #endif #endif 文件事件的类型 I/O 多路复用程序可以监听多个套接字的ae.h/AE_READABLE事件和ae.h/AE_WRITABLE事件，这两类事件和套接字操作之间的对应关系如下：\n当套接字变得可读时（客户端对套接字执行write操作，或者执行close操作），或者有新的可应答（acceptable）套接字出现时（客户端对服务器的监听套接字执行connect操作），套接字产生AE_READABLE 事件 当套接字变得可写时（客户端对套接字执行read操作），套接字产生AE_WRITABLE事件。I/O多路复用程序允许服务器同时监听套接字的AE_READABLE事件和AE_WRITABLE事件，如果一个套接字同时产生了这两种事件，那么文件事件分派器会优先处理AE_READABLE事件，等到AE_READABLE事件处理完之后，才处理AE_WRITABLE 事件。这也就是说，如果一个套接字又可读又可写的话，那么服务器将先读套接字，后写套接字。 文件事件的处理器 Redis为文件事件编写了多个处理器，这些事件处理器分别用于实现不同的网络通讯需求，常用的处理器如下：\n为了对连接服务器的各个客户端进行应答， 服务器要为监听套接字关联连接应答处理器。 为了接收客户端传来的命令请求， 服务器要为客户端套接字关联命令请求处理器。 为了向客户端返回命令的执行结果， 服务器要为客户端套接字关联命令回复处理器。\n连接应答处理器 networking.c中acceptTcpHandler函数是Redis的连接应答处理器，这个处理器用于对连接服务器监听套接字的客户端进行应答，具体实现为sys/socket.h/accept函数的包装。\n当Redis服务器进行初始化的时候，程序会将这个连接应答处理器和服务器监听套接字的AE_READABLE事件关联起来，当有客户端用sys/socket.h/connect函数连接服务器监听套接字的时候， 套接字就会产生AE_READABLE 事件， 引发连接应答处理器执行， 并执行相应的套接字应答操作，如图所示。 命令请求处理器 networking.c中readQueryFromClient函数是Redis的命令请求处理器，这个处理器负责从套接字中读入客户端发送的命令请求内容， 具体实现为unistd.h/read函数的包装。\n当一个客户端通过连接应答处理器成功连接到服务器之后， 服务器会将客户端套接字的AE_READABLE事件和命令请求处理器关联起来，当客户端向服务器发送命令请求的时候，套接字就会产生 AE_READABLE事件，引发命令请求处理器执行，并执行相应的套接字读入操作，如图所示。 在客户端连接服务器的整个过程中，服务器都会一直为客户端套接字的AE_READABLE事件关联命令请求处理器。\n命令回复处理器 networking.c中sendReplyToClient函数是Redis的命令回复处理器，这个处理器负责将服务器执行命令后得到的命令回复通过套接字返回给客户端，具体实现为unistd.h/write函数的包装。\n当服务器有命令回复需要传送给客户端的时候，服务器会将客户端套接字的AE_WRITABLE事件和命令回复处理器关联起来，当客户端准备好接收服务器传回的命令回复时，就会产生AE_WRITABLE事件，引发命令回复处理器执行，并执行相应的套接字写入操作， 如图所示。 当命令回复发送完毕之后， 服务器就会解除命令回复处理器与客户端套接字的 AE_WRITABLE 事件之间的关联\n一次完整的客户端与服务器连接事件示例 假设Redis服务器正在运作，那么这个服务器的监听套接字的AE_READABLE事件应该正处于监听状态之下，而该事件所对应的处理器为连接应答处理器。\n如果这时有一个Redis客户端向Redis服务器发起连接，那么监听套接字将产生AE_READABLE事件， 触发连接应答处理器执行：处理器会对客户端的连接请求进行应答， 然后创建客户端套接字，以及客户端状态，并将客户端套接字的 AE_READABLE 事件与命令请求处理器进行关联，使得客户端可以向主服务器发送命令请求。\n之后，客户端向Redis服务器发送一个命令请求，那么客户端套接字将产生 AE_READABLE事件，引发命令请求处理器执行，处理器读取客户端的命令内容， 然后传给相关程序去执行。\n执行命令将产生相应的命令回复，为了将这些命令回复传送回客户端，服务器会将客户端套接字的AE_WRITABLE事件与命令回复处理器进行关联：当客户端尝试读取命令回复的时候，客户端套接字将产生AE_WRITABLE事件， 触发命令回复处理器执行， 当命令回复处理器将命令回复全部写入到套接字之后， 服务器就会解除客户端套接字的AE_WRITABLE事件与命令回复处理器之间的关联。 思考问题 Q： Redis是单线程模型为什么效率还这么高？ A：\n纯内存访问：数据存放在内存中，内存的响应时间大约是100纳秒，这是Redis每秒万亿级别访问的重要基础。 非阻塞I/O：Redis采用epoll做为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接，读写，关闭都转换为了时间，不在I/O上浪费过多的时间。 单线程避免了线程切换和竞态产生的消耗。 Redis采用单线程模型，每条命令执行如果占用大量时间，会造成其他线程阻塞，对于Redis这种高性能服务是致命的，所以Redis是面向高速执行的数据库\n","date":"2021-06-11T22:33:18Z","permalink":"https://lxb.wiki/9106c914/","title":"Redis的线程模型"},{"content":" 概念 epoll是一种I/O事件通知机制，是linux 内核实现IO多路复用的一个实现。 IO多路复用是指，在一个操作里同时监听多个输入输出源，在其中一个或多个输入输出源可用的时候返回，然后对其的进行读写操作。\nI/O 输入输出(input/output)的对象可以是文件(file)， 网络(socket)，进程之间的管道(pipe)。在linux系统中，都用文件描述符(fd)来表示。\n事件 可读事件，当文件描述符关联的内核读缓冲区可读，则触发可读事件。(可读：内核缓冲区非空，有数据可以读取) 可写事件，当文件描述符关联的内核写缓冲区可写，则触发可写事件。(可写：内核缓冲区不满，有空闲空间可以写入） 通知机制 通知机制，就是当事件发生的时候，则主动通知。通知机制的反面，就是轮询机制。\nepoll 的通俗解释 结合以上三条，epoll的通俗解释是一种当文件描述符的内核缓冲区非空的时候，发出可读信号进行通知，当写缓冲区不满的时候，发出可写信号通知的机制\nepoll 的 API\nepoll的核心是3个API，核心数据结构是：1个红黑树和1个链表\n1. int epoll_create(int size) 功能：\n内核会产生一个epoll 实例数据结构并返回一个文件描述符，这个特殊的描述符就是epoll实例的句柄，后面的两个接口都以它为中心（即epfd形参）。 size参数表示所要监视文件描述符的最大值，不过在后来的Linux版本中已经被弃用（同时，size不要传0，会报invalid argument错误）\n2. int epoll_ctl(int epfd， int op， int fd， struct epoll_event *event) 功能：\n将被监听的描述符添加到红黑树或从红黑树中删除或者对监听事件进行修改 typedef union epoll_data { void *ptr; /* 指向用户自定义数据 */ int fd; /* 注册的文件描述符 */ uint32_t u32; /* 32-bit integer */ uint64_t u64; /* 64-bit integer */ } epoll_data_t; struct epoll_event { uint32_t events; /* 描述epoll事件 */ epoll_data_t data; /* 见上面的结构体 */ }; 对于需要监视的文件描述符集合，epoll_ctl对红黑树进行管理，红黑树中每个成员由描述符值和所要监控的文件描述符指向的文件表项的引用等组成。\nop参数说明操作类型：\nEPOLL_CTL_ADD：向interest list添加一个需要监视的描述符 EPOLL_CTL_DEL：从interest list中删除一个描述符 EPOLL_CTL_MOD：修改interest list中一个描述符 struct epoll_event结构描述一个文件描述符的epoll行为。在使用epoll_wait函数返回处于ready状态的描述符列表时，\ndata域是唯一能给出描述符信息的字段，所以在调用epoll_ctl加入一个需要监测的描述符时，一定要在此域写入描述符相关信息 events域是bit mask，描述一组epoll事件，在epoll_ctl调用中解释为：描述符所期望的epoll事件，可多选。 常用的epoll事件描述如下：\nEPOLLIN：描述符处于可读状态 EPOLLOUT：描述符处于可写状态 EPOLLET：将epoll event通知模式设置成edge triggered EPOLLONESHOT：第一次进行通知，之后不再监测 EPOLLHUP：本端描述符产生一个挂断事件，默认监测事件 EPOLLRDHUP：对端描述符产生一个挂断事件 EPOLLPRI：由带外数据触发 EPOLLERR：描述符产生错误时触发，默认检测事件 3. int epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeout) 功能：\n阻塞等待注册的事件发生，返回事件的数目，并将触发的事件写入events数组中。 events: 用来记录被触发的events，其大小应该和maxevents一致 maxevents: 返回的events的最大个数 处于ready状态的那些文件描述符会被复制进ready list中，epoll_wait用于向用户进程返回ready list。events和maxevents两个参数描述一个由用户分配的struct epoll event数组，调用返回时，内核将ready list复制到这个数组中，并将实际复制的个数作为返回值。注意，如果ready list比maxevents长，则只能复制前maxevents个成员；反之，则能够完全复制ready list。 另外，struct epoll event结构中的events域在这里的解释是：在被监测的文件描述符上实际发生的事件。 参数timeout描述在函数调用中阻塞时间上限，单位是ms：\ntimeout = -1表示调用将一直阻塞，直到有文件描述符进入ready状态或者捕获到信号才返回； timeout = 0用于非阻塞检测是否有描述符处于ready状态，不管结果怎么样，调用都立即返回； timeout \u0026gt; 0表示调用将最多持续timeout时间，如果期间有检测对象变为ready状态或者捕获到信号则返回，否则直到超时。 epoll的两种触发方式 epoll监控多个文件描述符的I/O事件。epoll支持边缘触发(edge trigger，ET)或水平触发（level trigger，LT)，通过epoll_wait等待I/O事件，如果当前没有可用的事件则阻塞调用线程。\nselect和poll只支持LT工作模式，epoll的默认的工作模式是LT模式。\n1.水平触发的时机 对于读操作，只要缓冲内容不为空，LT模式返回读就绪。 对于写操作，只要缓冲区还不满，LT模式会返回写就绪。 当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它还会通知你在上没读写完的文件描述符上继续读写，当然如果你一直不去读写，它会一直通知你。如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率。\n2.边缘触发的时机 对于读操作 当缓冲区由不可读变为可读的时候，即缓冲区由空变为不空的时候。 当有新数据到达时，即缓冲区中的待读数据变多的时候。 当缓冲区有数据可读，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLIN事件时。 对于写操作 当缓冲区由不可写变为可写时。 当有旧数据被发送走，即缓冲区中的内容变少的时候。 当缓冲区有空间可写，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLOUT事件时。 当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你。这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。\n在ET模式下， 缓冲区从不可读变成可读，会唤醒应用进程，缓冲区数据变少的情况，则不会再唤醒应用进程。\n举例1：\n读缓冲区刚开始是空的 读缓冲区写入2KB数据 水平触发和边缘触发模式此时都会发出可读信号 收到信号通知后，读取了1KB的数据，读缓冲区还剩余1KB数据 水平触发会再次进行通知，而边缘触发不会再进行通知 举例2：（以脉冲的高低电平为例）\n水平触发：0为无数据，1为有数据。缓冲区有数据则一直为1，则一直触发。 边缘触发发：0为无数据，1为有数据，只要在0变到1的上升沿才触发。 JDK并没有实现边缘触发，Netty重新实现了epoll机制，采用边缘触发方式；另外像Nginx也采用边缘触发。\nJDK在Linux已经默认使用epoll方式，但是JDK的epoll采用的是水平触发，而Netty重新实现了epoll机制，采用边缘触发方式，netty epoll transport 暴露了更多的nio没有的配置参数，如 TCP_CORK, SO_REUSEADDR等等；另外像Nginx也采用边缘触发。\nepoll与select、poll的对比 1. 用户态将文件描述符传入内核的方式 select：创建3个文件描述符集并拷贝到内核中，分别监听读、写、异常动作。这里受到单个进程可以打开的fd数量限制，默认是1024。 poll：将传入的struct pollfd结构体数组拷贝到内核中进行监听。 epoll：执行epoll_create会在内核的高速cache区中建立一颗红黑树以及就绪链表(该链表存储已经就绪的文件描述符)。接着用户执行的epoll_ctl函数添加文件描述符会在红黑树上增加相应的结点。 2. 内核态检测文件描述符读写状态的方式 select：采用轮询方式，遍历所有fd，最后返回一个描述符读写操作是否就绪的mask掩码，根据这个掩码给fd_set赋值。 poll：同样采用轮询方式，查询每个fd的状态，如果就绪则在等待队列中加入一项并继续遍历。 epoll：采用回调机制。在执行epoll_ctl的add操作时，不仅将文件描述符放到红黑树上，而且也注册了回调函数，内核在检测到某文件描述符可读/可写时会调用回调函数，该回调函数将文件描述符放在就绪链表中。 3. 找到就绪的文件描述符并传递给用户态的方式 select：将之前传入的fd_set拷贝传出到用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。 poll：将之前传入的fd数组拷贝传出用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。 epoll：epoll_wait只用观察就绪链表中有无数据即可，最后将链表的数据返回给数组并返回就绪的数量。内核将就绪的文件描述符放在传入的数组中，所以只用遍历依次处理即可。这里返回的文件描述符是通过mmap让内核和用户空间共享同一块内存实现传递的，减少了不必要的拷贝。 4. 重复监听的处理方式 select：将新的监听文件描述符集合拷贝传入内核中，继续以上步骤。 poll：将新的struct pollfd结构体数组拷贝传入内核中，继续以上步骤。 epoll：无需重新构建红黑树，直接沿用已存在的即可。 epoll更高效的原因 select和poll的动作基本一致，只是poll采用链表来进行文件描述符的存储，而select采用fd标注位来存放，所以select会受到最大连接数的限制，而poll不会。 select、poll、epoll虽然都会返回就绪的文件描述符数量。但是select和poll并不会明确指出是哪些文件描述符就绪，而epoll会。造成的区别就是，系统调用返回后，调用select和poll的程序需要遍历监听的整个文件描述符找到是谁处于就绪，而epoll则直接处理即可。 select、poll都需要将有关文件描述符的数据结构拷贝进内核，最后再拷贝出来。而epoll创建的有关文件描述符的数据结构本身就存于内核态中，系统调用返回时利用mmap()文件映射内存加速与内核空间的消息传递：即epoll使用mmap减少复制开销。 select、poll采用轮询的方式来检查文件描述符是否处于就绪态，而epoll采用回调机制。造成的结果就是，随着fd的增加，select和poll的效率会线性降低，而epoll不会受到太大影响，除非活跃的socket很多。 epoll的边缘触发模式效率高，系统不会充斥大量不关心的就绪文件描述符 虽然epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。\n","date":"2021-06-06T22:18:57Z","permalink":"https://lxb.wiki/3bdc8aea/","title":"epoll高效运行的原理"},{"content":" redis是一个内存数据库，数据保存在内存中，但是我们都知道内存的数据变化是很快的，也容易发生丢失。幸好Redis还为我们提供了持久化的机制，分别是RDB(Redis DataBase)和AOF(Append Only File)。\n一、持久化流程 既然redis的数据可以保存在磁盘上，那么这个流程是什么样的呢？\n要有下面五个过程：\n（1）客户端向服务端发送写操作(数据在客户端的内存中)。\n（2）数据库服务端接收到写请求的数据(数据在服务端的内存中)。\n（3）服务端调用write这个系统调用，将数据往磁盘上写(数据在系统内存的缓冲区中)。\n（4）操作系统将缓冲区中的数据转移到磁盘控制器上(数据在磁盘缓存中)。\n（5）磁盘控制器将数据写到磁盘的物理介质中(数据真正落到磁盘上)。\n这5个过程是在理想条件下一个正常的保存流程，但是在大多数情况下，我们的机器等等都会有各种各样的故障，这里划分了两种情况：\n（1）Redis数据库发生故障，只要在上面的第三步执行完毕，那么就可以持久化保存，剩下的两步由操作系统替我们完成。\n（2）操作系统发生故障，必须上面5步都完成才可以。\n在这里只考虑了保存的过程可能发生的故障，其实保存的数据也有可能发生损坏，需要一定的恢复机制，不过在这里就不再延伸了。现在主要考虑的是redis如何来实现上面5个保存磁盘的步骤。它提供了两种策略机制，也就是RDB和AOF。\n二、RDB机制 RDB其实就是把数据以快照的形式保存在磁盘上。什么是快照呢，你可以理解成把当前时刻的数据拍成一张照片保存下来。\nRDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是默认的持久化方式，这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。\n在我们安装了redis之后，所有的配置都是在redis.conf文件中，里面保存了RDB和AOF两种持久化机制的各种配置。\n既然RDB机制是通过把某个时刻的所有数据生成一个快照来保存，那么就应该有一种触发机制，是实现这个过程。对于RDB来说，提供了三种机制：save、bgsave、自动化。我们分别来看一下\n1、save触发方式\n该命令会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成为止。具体流程如下：\n执行完成时候如果存在老的RDB文件，就把新的替代掉旧的。我们的客户端可能都是几万或者是几十万，这种方式显然不可取。\n2、bgsave触发方式\n执行该命令时，Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。具体流程如下：\n具体操作是Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。基本上 Redis 内部所有的RDB操作都是采用 bgsave 命令。\n3、自动触发\n自动触发是由我们的配置文件来完成的。在redis.conf配置文件中，里面有如下配置，我们可以去设置：\n**①save：**这里是用来配置触发 Redis的 RDB 持久化条件，也就是什么时候将内存中的数据保存到硬盘。比如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。\n默认如下配置：\n#表示900 秒内如果至少有 1 个 key 的值变化，则保存save 900 1#表示300 秒内如果至少有 10 个 key 的值变化，则保存save 300 10#表示60 秒内如果至少有 10000 个 key 的值变化，则保存save 60 10000\n不需要持久化，那么你可以注释掉所有的 save 行来停用保存功能。\n**②stop-writes-on-bgsave-error ：**默认值为yes。当启用了RDB且最后一次后台保存数据失败，Redis是否停止接收数据。这会让用户意识到数据没有正确持久化到磁盘上，否则没有人会注意到灾难（disaster）发生了。如果Redis重启了，那么又可以重新开始接收数据了\n**③rdbcompression ；**默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。\n**④rdbchecksum ：**默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。\n**⑤dbfilename ：**设置快照的文件名，默认是 dump.rdb\n**⑥dir：**设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名。\n我们可以修改这些配置来实现我们想要的效果。因为第三种方式是配置的，所以我们对前两种进行一个对比：\n4、RDB 的优势和劣势\n①、优势\n（1）RDB文件紧凑，全量备份，非常适合用于进行备份和灾难恢复。\n（2）生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。\n（3）RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。\n②、劣势\nRDB快照是一次全量备份，存储的是内存数据的二进制序列化形式，存储上非常紧凑。当进行快照持久化时，会开启一个子进程专门负责快照持久化，子进程会拥有父进程的内存数据，父进程修改内存子进程不会反应出来，所以在快照持久化期间修改的数据不会被保存，可能丢失数据。\n三、AOF机制 全量备份总是耗时的，有时候我们提供一种更加高效的方式AOF，工作机制很简单，redis会将每一个收到的写命令都通过write函数追加到文件中。通俗的理解就是日志记录。\n1、持久化原理\n他的原理看下面这张图：\n每当有一个写命令过来时，就直接保存在我们的AOF文件中。\n2、文件重写原理\nAOF的方式也同时带来了另一个问题。持久化文件会变的越来越大。为了压缩aof的持久化文件。redis提供了bgrewriteaof命令。将内存中的数据以命令的方式保存到临时文件中，同时会fork出一条新进程来将文件重写。\n重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。\n3、AOF也有三种触发机制\n（1）每修改同步always：同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好\n（2）每秒同步everysec：异步操作，每秒记录 如果一秒内宕机，有数据丢失\n（3）不同no：从不同步\n4、优点\n（1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据。（2）AOF日志文件没有任何磁盘寻址的开销，写入性能非常高，文件不容易破损。\n（3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。\n（4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据\n5、缺点\n（1）对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大\n（2）AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的\n（3）以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。\n四、RDB和AOF到底该如何选择 选择的话，两者加一起才更好。因为两个持久化机制你明白了，剩下的就是看自己的需求了，需求不同选择的也不一定，但是通常都是结合使用。有一张图可供总结：\n其他资料 Redis持久化原理(RDB)\n","date":"2021-06-01T21:18:51Z","permalink":"https://lxb.wiki/f885fe0f/","title":"Redis持久化机制"},{"content":" 1 SLA 业内喜欢用SLA （服务等级协议，全称：service level agreement）来衡量系统的稳定性，对互联网公司来说就是网站服务可用性的一个保证。9越多代表全年服务可用时间越长服务越可靠，停机时间越短。就以一个标准99.99%为例，停机时间52.6分钟，平均到每周也就是只能有差不多1分钟的停机时间，也就是说网络抖动这个时间可能就没了。保证一个系统四个9或者更高的五个9，需要一套全体共识严格标准的规章制度，没有规矩不成方圆。创建的规范有如下几种：\n1、研发规范、自身稳定；\n2、事务中不能包含远程调用；\n3、超时时间和重试次数要合理；\n4、表数据操作必须double check，合理利用索引，避免出现慢查询、分库分表不走分表键；\n5、没有有效的资源隔离， 避免不同业务共用一个线程池或连接池；\n6、合理的系统拓扑，禁止不合理服务依赖，能依赖就依赖，否则同步尽量改成异步弱依赖；\n7、精简的代码逻辑；\n8、核心路径流程必须进行资源隔离，确保任何突发情况主流程不能受影响。\n2 单服务稳定性 关键字：开关可控、单一职责、服务隔离、异常兜底、监控发现！\n对于稳定性来说，抛开整体系统架构设计，单就每个业务域服务的稳定性也是非常的重要。只有每个业务环节都稳如泰山，才能保障整个稳定性。单服务稳定可以从以下几个方面来进行：\n1、禁用设计：应该提供控制具体功能是否开启可用的配置，在相应的功能服务出现故障时，快速下线局部功能，以保证整体服务的可用性；\n2、必要的缓存：缓存是解决并发的利器，可以有效的提高系统的吞吐量。按照业务以及技术的纬度必要时可以增加多级缓存来保证其命中率；\n3、接口无状态性：服务接口应是无状态的，当前接口访问不应该依赖上层接口的状态逻辑；\n4、接口单一职责性：对于核心功能的接口，不应该过多的耦合不属于它的功能。如果一个接口做的事情太多应做拆分，保证单接口的稳定性和快速响应；\n5、第三方服务隔离性：任何依赖于第三方的服务（不论接口还是中间件等），都应该做到熔断和降级，不能有强耦合的依赖；\n6、业务场景兜底方案：核心业务场景要做到完整兜底方法，从前端到后端都应有兜底措施；\n7、服务监控与及时响应：每个服务应做好对应监控工作，如有异常应及时响应，不应累积。\n3 集群稳定性 关键字：系统架构、部署发布、限流熔断、监控体系、压测机制！\n对于集群维度的稳定性来说，稳定性保障会更加复杂。单服务是局部，集群是全局。一个见微知著，一个高瞻远瞩。\n1、合理的系统架构：合理的系统架构是稳定的基石；\n2、小心的代码逻辑：代码时刻都要小心，多担心一点这里会不会有性能问题，那里会不会出现并发，代码就不会有多少问题；\n3、优秀的集群部署：一台机器永远会有性能瓶颈，优秀的集群部署，可以将一台机器的稳定放大无限倍，是高并发与大流量的保障；\n4、科学的限流熔断：高并发来临时，科学的限流和熔断是系统稳定的必要条件；\n5、精细的监控体系：没有监控体系，你永远不会知道你的系统到底有多少隐藏的问题和坑，也很难知道瓶颈在哪里；\n6、强悍的压测机制：压测是高并发稳定性的试金石，能提前预知高并发来临时，系统应该出现的模样；\n7、胆小的开发人员：永远需要一群胆小的程序员，他们讨厌bug，害怕error，不放过每一个波动，不信任所有的依赖。\n4 稳定性专项 专项指的是针对某些特定场景下的特定问题而梳理出对应的方案。下面是针对一些常见的稳定性专项的概述：\n1、预案：分为定时预案和紧急预案，定时预案是大促常规操作对于一系列开关的编排，紧急预案是应对突发情况的特殊处理，都依赖于事前梳理；\n2、预热：分为JIT代码预热和数据预热，阿里内部有专门的一个产品负责这块，通过存储线上的常态化流量或者热点流量进行回放来提前预热， 起源于某年双十一零点的毛刺问题，原因是访问了数据库的冷数据rt增高导致的一系列上层限流，现在预热已经成了大促之前的一个必要流程。\n3、强弱依赖:梳理强弱依赖是一个偏人肉的过程，但是非常重要，这是一个系统自查识别潜在风险点并为后续整理开关限流预案和根因分析的一个重要参考，阿里内部有一个强弱依赖检测的平台，通过对测试用例注入RPC调用的延迟或异常来观察链路的依赖变化，自动梳理出强弱依赖关系。\n4、限流降级熔断:应对突发流量防止请求超出自身处理能力系统被击垮的必要手段；\n5、监控告警\u0026amp;链路追踪:监控分为业务监控、系统监控和中间件监控和基础监控，作为线上问题发现和排查工具，重要性不言而喻。\n5 稳定性建设 稳定性建设，就和基础技术建设一样，是一个长期迭代和不断调整的过程，业内常见的稳定性建设类型，主要有如下几种：\n1、容量规划：个人感觉容量规划在大厂里也并没有做的很好，更多依赖的是业务方自己拍脑袋，然后全链路压测期间验证，不够就再加机器。\n2、混沌工程：混沌工程是近几年比较火的名词，通过不断给系统找麻烦来验证并完善系统能力，阿里在这块花了很大的精力建设红蓝军对抗攻防，进行定期和不定期的演练，最后以打分的形式来给各个部门系统做排名，除了系统层面的故障演练外还有资金演练，篡改线上sql语句制造资损来测试业务监控纠错的能力，通过制造小错来避免大错。\n跳转门：混沌工程-初识\n3、流量调度：通过metric秒级监控和聚类算法实时找出异常单机来降低RPC流量权重，提升集群整体吞吐能力减少异常请求。\n4、容灾\u0026amp;异地多活：起源于15年某施工队将光纤挖断带来的支付宝故障，由此出来的三地五中心和单元化架构，异地多活本身的成本比较高，然后又存在数据同步的延时问题和切流带来的脏数据问题，对于业务和技术都有比较高的要求。常见的容灾有如下几种：\n1）缓存挂掉，集群重启缓存预热如何处理？本地缓存，多级缓存是否可以替代？\n2）分布式锁，是否有开关一键切换？比如：ZK/ETCD编写的分布式锁；\n3）大促峰值流量，如何防止外部ddos攻击？如何识别流量类型？\n4）资源隔离：资源隔离，服务分组，流量隔离；\n5）高可用思想：避免单点设计！\n6）容错：容错上游，防御下游。容错主要需要注意如下几点：\n6-1：外部依赖的地方都要做熔断，避免雪崩；\n6-2：对于依赖我们的上游要限流，防止上游突发超过自己系统能够扛住的最大QPS；\n6-3：对于下游既要评估好接口超时时间，防止下游接口超时导致自己系统被拖累；\n6-4：下游接口要考虑各种异常情况，需要考虑中间状态，通过引入柔性事务，确保数\n据最终一致\n5、异地多活\n异地多活的本质，是数据中心架构的演进。\n1）演进：单机房——双机房——异地灾备——异地多活；\n2）定义：分多个地域、多个数据中心运行线上的业务，并且每个IDC均提供在线服务；\n3）优点：弹性扩展能力、流量就近接入、灵活调度、提升可用性与用户体验、容灾；\n4）步骤：\n4-1：基础设施：机房之间专线互联，保证网络质量稳定；\n4-2：持久存储：一主三从，主IDC同步复制，异地IDC异步复制；\n4-3：中间件：DB、MQ、分布式存储；\n4-4：应用部署：根据应用域划分，不同应用部署在不同地域，保持亲缘性；\n4-5：流量接入与调度：网络协议兼容，DNS，动态调度用户就近访问；\n4-6：监控与运维保障：专线实时监控，确保发生故障时可以触发Failover（失效备援）和\n流量调度。\n","date":"2021-05-25T21:57:43Z","permalink":"https://lxb.wiki/d0f092bd/","title":"如何保证服务稳定性"},{"content":" 1.安装lrzsz（要先安装brew） brew install lrzsz 2.配置 cd /usr/local/bin 在/usr/loal/bin 目录下创建两个文件\n命令：\nvi iterm2-recv-zmodem.sh vi iterm2-send-zmodem.sh 创建好两个文件后分别添加内容：\niterm2-recv-zmodem.sh #!/bin/bash # Author: Matt Mastracci (matthew@mastracci.com) # AppleScript from http://stackoverflow.com/questions/4309087/cancel-button-on-osascript-in-a-bash-script # licensed under cc-wiki with attribution required # Remainder of script public domain osascript -e \u0026#39;tell application \u0026#34;iTerm2\u0026#34; to version\u0026#39; \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; NAME=iTerm2 || NAME=iTerm if [[ $NAME = \u0026#34;iTerm\u0026#34; ]]; then FILE=`osascript -e \u0026#39;tell application \u0026#34;iTerm\u0026#34; to activate\u0026#39; -e \u0026#39;tell application \u0026#34;iTerm\u0026#34; to set thefile to choose folder with prompt \u0026#34;Choose a folder to place received files in\u0026#34;\u0026#39; -e \u0026#34;do shell script (\\\u0026#34;echo \\\u0026#34;\u0026amp;(quoted form of POSIX path of thefile as Unicode text)\u0026amp;\\\u0026#34;\\\u0026#34;)\u0026#34;` else FILE=`osascript -e \u0026#39;tell application \u0026#34;iTerm2\u0026#34; to activate\u0026#39; -e \u0026#39;tell application \u0026#34;iTerm2\u0026#34; to set thefile to choose folder with prompt \u0026#34;Choose a folder to place received files in\u0026#34;\u0026#39; -e \u0026#34;do shell script (\\\u0026#34;echo \\\u0026#34;\u0026amp;(quoted form of POSIX path of thefile as Unicode text)\u0026amp;\\\u0026#34;\\\u0026#34;)\u0026#34;` fi if [[ $FILE = \u0026#34;\u0026#34; ]]; then echo Cancelled. # Send ZModem cancel echo -e \\\\x18\\\\x18\\\\x18\\\\x18\\\\x18 sleep 1 echo echo \\# Cancelled transfer else cd \u0026#34;$FILE\u0026#34; /usr/local/bin/rz -E -e -b sleep 1 echo echo echo \\# Sent \\-\\\u0026gt; $FILE fi iterm2-send-zmodem.sh #!/bin/bash # Author: Matt Mastracci (matthew@mastracci.com) # AppleScript from http://stackoverflow.com/questions/4309087/cancel-button-on-osascript-in-a-bash-script # licensed under cc-wiki with attribution required # Remainder of script public domain osascript -e \u0026#39;tell application \u0026#34;iTerm2\u0026#34; to version\u0026#39; \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; NAME=iTerm2 || NAME=iTerm if [[ $NAME = \u0026#34;iTerm\u0026#34; ]]; then FILE=`osascript -e \u0026#39;tell application \u0026#34;iTerm\u0026#34; to activate\u0026#39; -e \u0026#39;tell application \u0026#34;iTerm\u0026#34; to set thefile to choose file with prompt \u0026#34;Choose a file to send\u0026#34;\u0026#39; -e \u0026#34;do shell script (\\\u0026#34;echo \\\u0026#34;\u0026amp;(quoted form of POSIX path of thefile as Unicode text)\u0026amp;\\\u0026#34;\\\u0026#34;)\u0026#34;` else FILE=`osascript -e \u0026#39;tell application \u0026#34;iTerm2\u0026#34; to activate\u0026#39; -e \u0026#39;tell application \u0026#34;iTerm2\u0026#34; to set thefile to choose file with prompt \u0026#34;Choose a file to send\u0026#34;\u0026#39; -e \u0026#34;do shell script (\\\u0026#34;echo \\\u0026#34;\u0026amp;(quoted form of POSIX path of thefile as Unicode text)\u0026amp;\\\u0026#34;\\\u0026#34;)\u0026#34;` fi if [[ $FILE = \u0026#34;\u0026#34; ]]; then echo Cancelled. # Send ZModem cancel echo -e \\\\x18\\\\x18\\\\x18\\\\x18\\\\x18 sleep 1 echo echo \\# Cancelled transfer else /usr/local/bin/sz \u0026#34;$FILE\u0026#34; -e -b sleep 1 echo echo \\# Received $FILE fi 将文件写好后保存好，使用如下命令添加权限\nchmod 777 iterm2-* 配置好配置文件之后，开始对iTerm2进行配置\n点击 iTerm2 的设置界面 Perference-\u0026gt; Profiles -\u0026gt; Default -\u0026gt; Advanced -\u0026gt; Triggers 的 Edit 按钮，加入以下配置\nRegular expression: rz waiting to receive.\\*\\*B0100 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-send-zmodem.sh Regular expression: \\*\\*B00000000000000 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-recv-zmodem.sh 备注：\nrz 上传功能：在bash中，也就是iTerm2终端输入rz 就会弹出文件选择框，选择文件 choose 就开始上传，会上传到当前目录 sz 下载功能 ：sz fileName(你要下载的文件的名字) 回车，会弹出窗体 我们选择要保存的地方即可。\n","date":"2021-05-13T23:25:13Z","permalink":"https://lxb.wiki/32451f0a/","title":"Mac iTerm2，使用rz和sz无效，解决方式"},{"content":" 书签误删该如何恢复\n1 打开访达，在菜单栏上点击【前往】—【前往文件夹】，或者使用快捷键【Command+Shift+G】即可打开【前往文件夹】\n输入以下路径【/Users/用户名/Library/Application Support/Google/Chrome】（注：路径中的用户名就是你电脑用户名称\n2 在chrome文件目录下找到 【Default】文件夹，将里面的 【Bookmarks.bak】 的文件复制到桌面，将.bak名的后缀去掉，如下图所示：\n注：如果你有多个用户的话，则需要找到对应的用户，一般在文件名为“Profile1、2、3”底下。\n3 在同样的文件夹底下，将修改好的 Bookmarks 复制进 去替换，重启chrome即可。\n","date":"2021-05-01T18:44:48Z","permalink":"https://lxb.wiki/ef3fb32/","title":"误删了Mac中Chrome书签后如何恢复"},{"content":" 对比Availability可用性、Reliability可靠性、Stability稳定性\n区分 从事故、稳定方面简单理解如下：\n描述 可靠性 不出事故 可用性 出事故后，快速止损 稳定性 解决故障问题基础上，服务持续稳定、性能稳定 总体对比 可用性 可用性指系统在给定时间内可以正常工作的概率，通常用SLA（服务等级协议，service level agreement）指标来表示。\n这是这段时间的总体的可用性指标。\n通俗叫法 可用性级别 年度宕机时间 周宕机时间 每天宕机时间 1个9 90% 36.5天 16.8小时 2.4小时 2个9 99% 87.6小时 1.68小时 14分钟 3个9 99.9% 8.76小时 10.1分钟 86秒 4个9 99.99% 52.6分钟 1.01分钟 8.6秒 5个9 99.999% 5.26分钟，315.36秒 6.05秒 0.86秒 可靠性 可靠性相关的几个指标如下：\nMTBF（Mean Time Between Failure） 即平均无故障时间，是指从新的产品在规定的工作环境条件下开始工作到出现第一个故障的时间的平均值。\nMTBF越长表示可靠性越高，正确工作能力越强 。\nMTTR（Mean Time To Repair） 即平均修复时间，是指可修复产品的平均修复时间，就是从出现故障到修复中间的这段时间。\nMTTR越短表示易恢复性越好。\nMTTF（Mean Time To Failure） 即平均失效时间。系统平均能够正常运行多长时间，才发生一次故障。\n系统的可靠性越高，平均无故障时间越长。\n这些指标跟可用性关系\nAvailability = UpTime/(UpTime+DownTime) = MTBF / (MTBF + MTTR) 稳定性 Stackoverflow 看到这样一段代码来表示稳定性和可靠性的区别，甚为有趣：\n# Reliable but unstable: add(a,b): if randomInt mod 5 == 0: throw exception else print a+b # Stable but unreliable: add(a,b): if randomInt mod 5 == 0: print a+a else print a+b ","date":"2021-03-29T23:01:42Z","permalink":"https://lxb.wiki/18166f99/","title":"可靠性、可用性、稳定性"},{"content":" 前言 之前的云笔记工具一直是有道云，免费版本已经足够使用了。\n让我下定决心放弃有道云的导火索是，突然有一天，我发现 MAC 和 Android 端都无法登录了。微博、知乎随便一搜“有道云不能登录”，发现这个问题从 2016 年就有很多用户遇到过（是很多用户，我遇到的问题并不是偶发），一直到 2021 年还没有解决（后来还发现，有道云把微博和知乎有关“有道云不能登录”的用户发帖全删了）。有道云连最基本的可用性和可靠性都无法保证，遂决定弃用有道云，转战其他工具平台。\n尝试过的笔记工具：\n印象笔记\nOneNote\nNotion\n语雀\n不看好语雀 纯在线服务，不能本地存储；当有一天服务端故障时，用户就完全不能使用 阿里内部的绩效项目，开发人员凭这个项目完成晋升后，一定会进入不再开发新功能的轮回 阿里系的其他产品也应谨慎使用 为知笔记\n功能不完善，搜索功能不能用 其他笔记都无法完全匹配我的使用习惯。最后决定，使用开源的 joplin。\njoplin 官网\nJoplin 介绍 Joplin 旨在取代印象笔记，成为全平台的免费开源笔记，其笔记的的书写格式是 markdown，界面支持中文。\n优点：\n开源 多种同步方式可选择: WebDav、OneDrive、DroupOut、Nextcloud 支持 WebDav 的网盘： 国外网盘：Box、Dropbox、TeraCLOUD、yandex、TransIP 国内网盘：坚果云、城通网盘 支持笔记加密，防止数据存储平台偷看笔记内容 全平台支持。我使用的平台有 MacOS、Android、Linux 支持从印象笔记和 markdown 文件导入 有浏览器剪藏插件 笔记格式为 markdown 支持各种插件 Joplin 安装 Joplin 官网 下载 + 安装\n界面说明 配置坚果云同步 我的同步服务器已从坚果云迁移到 TeraCLOUD\nJoplin配置TeraCloud的WebDav进行同步\n注册坚果云 创建文件夹，起名为 joplin 点击右上角 账户信息 -\u0026gt; 安全选项 -\u0026gt; 添加应用；应用名称为 joplin 打开 Joplin，点击菜单首选项-\u0026gt;同步 同步目标 WebDAV 工具-\u0026gt;选项-\u0026gt;同步 https://dav.jianguoyun.com/dav/joplin WebDAV 用户名 注册坚果云的用户名 WebDAV 密码 坚果云新添加的 joplin 的应用密码（不是坚果云登录密码） 点击检查同步配置，显示成功即可点击应用开始同步\n配置外部编辑器（可选）。首选项 -\u0026gt; 通用选项 -\u0026gt; Path，在应用程序中选择 Typora\n","date":"2021-03-09T21:07:57Z","permalink":"https://lxb.wiki/f5496f4b/","title":"Joplin+坚果云作为主力笔记工具"},{"content":" redis的zset和set都使用跳表实现。跳表简单地说，就是在链表上构造多级索引，以加速查找，是用空间换时间。它比红黑树实现更简单，不需要耗费大量的精力维护树的平衡。跳表的各个节点是有顺序的，可以进行范围查询。\n本文将分析跳表的构成、插入、删除等操作，并使用go实现。\n1. 跳表结构 上图就是一个包含5个节点的跳表结构。跳表的结构包含一个又一个的节点，和header节点。header节点是查询的起始点。跳表定义如下，包含头结点、尾节点、长度以及跳表的索引层数。\n// skiplist 持有一个跳表的完整数据 type skiplist struct { // header和tail表示跳表的头结点和尾节点 header, tail *skiplistNode // length 表示跳表的长度 length int // level 表示该跳表索引的层数 level int } 从上面跳表的定义看不出什么，跳表每个节点的定义就有很多东西了。\n// skiplistLevel 表示skiplist每一节点在每一层持有的数据结构 type skiplistLevel struct { // 该层节点的下一个节点，redis使用forward next *skiplistNode // 该层节点到下一节点中间间隔的跳数 span int } // skiplistNode 表示skiplist的每一个节点 type skiplistNode struct { // robj 代表该节点的数据 robj interface{} // score 表示该节点的分数，以便排序 score float64 // prev 表示该节点的上一节点，redis 中使用backward prev *skiplistNode // levels 表示该节点在每一层索引中到下一节点的信息 levels []skiplistLevel } 每一个节点中持有数据robj、该数据的分数score用来排序、上一节点的指针prev以便于反向遍历、各层索引信息levels。每一层的索引信息skiplistlevel包括该层索引中该节点指向的下一个节点的指针next、该节点到下一节点的间隔span。例如上图中，节点s2在第三层索引的下一节点是s4，而在第二层索引的下一节点是s3，而且间隔span分别是2和1。\n每个节点的索引层数通过随机数生成，redis设计的思路：使用第n级索引是使用第n-1级索引概率的1/4，最多使用32级索引，如果真用到了32级索引，这个跳表所持有的数据也是巨大的，因此不用担心索引不够用。\nfunc randomLevel() int { var level = 1 // SKIPLIST_P = 0.25 for rand.Float64() \u0026lt; SKIPLIST_P { level ++ } if level \u0026lt; SKIPLIST_MAXLEVEL { return level } return SKIPLIST_MAXLEVEL } 跳表按照score和robj从小到大进行排序，因此它的各个节点是有序的，可以进行范围查找。\n// compareObj 如果obj1\u0026gt;obj2，返回true func compareObj(obj1, obj2 interface{}) bool { var t1, t2 reflect.Type t1 = reflect.TypeOf(obj1) t2 = reflect.TypeOf(obj2) if t1.Kind() != t2.Kind() { compareObj(fmt.Sprint(obj1), fmt.Sprint(obj2)) } var v1, v2 reflect.Value v1 = reflect.ValueOf(obj1) v2 = reflect.ValueOf(obj2) switch t1.Kind() { case reflect.Int: return v1.Int() \u0026gt; v2.Int() case reflect.Float64, reflect.Float32: return v1.Float() \u0026gt; v2.Float() case reflect.String: return v1.String() \u0026gt; v2.String() } return compareObj(fmt.Sprint(obj1), fmt.Sprint(obj2)) } 2. 节点的插入 在链表中如果要插入一个节点S，需要找到在链表中比S小的最大节点F，把S挂在F节点后面。那么在跳表中也是这样的套路，只不过更复杂一些。下面分几步将上图中s2.5节点挂在s2后面，已知s2.5的score或者obj比s2的score或obj要大，但是小于s3。\n2.1. 查找比s2.5小的最大节点 在插入新节点之前，需要找到新节点可以插入的位置，就需要找出每一层索引中新节点的前一节点，这里就是比s2.5小的最大节点。跳表有五层索引，表示为0-4。跳表的起点是header，因此查找节点时需要从header的level 4开始进行，表示为header.levels[4]。代码中使用update[i]表示第i层索引中比s2.5小的最大节点指针。注意下面的代码还有一个rank数组，rank[i]就表示第i层索引中，update[i]节点到header的span，下面注意它是怎么增加的。\n从header.levels[4]开始向右遍历，此时rank[4]=0；header.levels[4]下一节点是s4比s2.5大，因此该层索引中s2.5的上一节点就是header，即update[4]=header，接下来向下进入第3层索引，即header.levels[3] 第3层索引中，初始rank[3] =rank[4]=0，向右遍历搜索到header的下一节点s2。s2就是这一层s2.5需要插入的位置的前一节点，因此update[3]=s2，rank[3]=rank[3]+header.levels[3].span=2，然后向下进入s2.levels[2] 依次遍历第2、1、0层索引，路径为s2.levels[2]-\u0026gt;s2.levels[1]-\u0026gt;s2.levels[0]，求得update[2]=update[1]=update[0]=s2，rank[2]=rank[1]=rank[0]=rank[3]=2。到这里，通过走楼梯的方式将s2.5需要插入的位置全找出来了 x = sl.header for i := sl.level-1; i \u0026gt;= 0; i -- { if i == sl.level-1 { rank[i] = 0 } else { rank[i] = rank[i+1] } // 寻找比score和robj小的最近节点 for x.levels[i].next != nil \u0026amp;\u0026amp; (x.levels[i].next.score \u0026lt; score || (x.levels[i].next.score == score \u0026amp;\u0026amp; compareObj(robj, x.levels[i].next.robj))) { rank[i] += x.levels[i].span x = x.levels[i].next } update[i] = x } 2.2. 插入节点s2.5 现在有了update数组表示各层索引中s2.5的上一节点位置，以及rank数组表示update各节点到header的距离，就可以进行s2.5的插入了。\nvar level = randomLevel() // 代码1 if level \u0026gt; sl.level { for i := sl.level; i \u0026lt; level; i ++ { rank[i] = 0 update[i] = sl.header update[i].levels[i].span = sl.length } sl.level = level } //----- x = createSkiplistNode(level, score, robj) // 代码2 for i := 0; i \u0026lt; level; i ++ { x.levels[i].next = update[i].levels[i].next update[i].levels[i].next = x x.levels[i].span = update[i].levels[i].span - (rank[0]-rank[i]) update[i].levels[i].span = rank[0] - rank[1] + 1 } // ----- // 代码3 for i := level-1; i \u0026lt; sl.level; i ++ { update[i].levels[i].span ++ } //----- // 如果当前节点是插入的第一个节点，它的prev是nil if update[0] == sl.header { x.prev = nil } else { x.prev = update[0] } if x.levels[0].next != nil { x.levels[0].next.prev = x } else { sl.tail = x } sl.length ++ 首先通过随机算法randomLevel()获取该节点的索引层数\n现在有两种情况：level比跳表原来的层数sl.level要大或者level小于等于sl.level\n首先处理level\u0026gt;sl.level的情况（代码1）。高于sl.level小于level的索引i中，s2.5的前一节点就直接是header，因此设置update[i]=header，同时rank[i]=0。header.levels[i].span设置为跳表的长度。设置sl.level=level。 现在只有level\u0026lt;=sl.level的情况了（代码2）。当索引i\u0026lt;level时，直接将s2.5挂在update[i].levels[i]的后面，并更新update[i].levels[i]和s2.5.levels[i]的span 而在level\u0026lt;=sl.level的情况（代码3），当level\u0026lt;=索引i\u0026lt;sl.level时，直接把update节点的span加一。因为此时新节点的索引层数level比跳表的层数少，那么新节点的插入对于比level高的索引节点来说就是将其与后面节点的距离增加了一个单位。 处理s2.5的prev指针，由上面的图也可以知道prev指针和第0层的索引是反向的，但是并不会指向header。这里我认为是为了方便反向遍历，如果s1.prev指向header，在反向遍历时需要加一层header的判断。\n处理跳表的tail指针，如果插入的节点在最后，则重新设置tail\n更新跳表长度\n3. 删除节点 上图中，如果想删除s3节点，需要两步：找到s3节点在各层索引处的上一节点；删除s3节点。\n3.2. 查找比s3小的最大节点 查找的算法依旧是从header的最高层索引开始下楼梯，并使用update数组保存每一层索引中s3的前一个节点。\n在上图中：\n从header.levels[4]开始向右遍历，找不到其他的节点小于s3，因此向下遍历header.levels[3]，第4层的最大节点是header，即update[4]=header 依次类推，update[3]=s2，update[2]=s2，update[1]=update[0]=s2，遍历路径见图中的蓝色箭头。 // 查找最近节点 x = sl.header for i := sl.level-1; i \u0026gt;= 0; i -- { for x.levels[i].next != nil \u0026amp;\u0026amp; (x.levels[i].next.score \u0026lt; score || (x.levels[i].next.score == score \u0026amp;\u0026amp; compareObj(robj, x.levels[i].next.robj))) { x = x.levels[i].next } update[i] = x } 2.3. 删除节点 删除节点就比较简单了，但是在这之前需要验证一下x指向的下一节点是不是需要删除的数据：\n// x之后的节点可能是需要删除的节点，也可能不是 x = x.levels[0].next if x != nil \u0026amp;\u0026amp; x.score == score \u0026amp;\u0026amp; equalObj(x.robj, robj) { sl.deleteNode(update, x) return true } 在deleteNode中，进行如下删除步骤：\n对每一层的update[i]进行：\n如果update[i].levels[i]的下一节点是x，则进行x的删除，包括节点指针和span的改变 如果update[i].levels[i]的下一节点不是x，例如：删除s3节点，它的update[4].levels[4]下一节点是s4，此时直接将update[4].levels[4]的span减一 将x的next节点（如果有的话）挂在x的prev节点后面\n更新跳表的level值。以删除s4节点为例，删除完该节点之后跳表实际层数应该调整为3。从第4层开始向下遍历，如果header.levels[i].next是nil，说明该层索引已经没必要存在了，就将跳表的level减一\n别忘了把跳表的length减一\n总结 跳表听起来挺难，如果仔细研究它的代码的话还是挺简单的。跳表主要难的地方就在于节点的插入和删除，只要理解了跳表的多级索引是怎么使用的，其他的操作：范围查询、查询排名等都比较简单了。这块的代码可以看redis的源码，在它的t_zset.c和redis.h中有zsl开头的代码就是跳表相关内容。不过我觉得更难的是写文档，写文档的时候需要阅读完代码之后理清思路，这块我发现通过画图还是可以加深理解的。\n","date":"2021-03-03T23:09:59Z","permalink":"https://lxb.wiki/e98e0a2b/","title":"redis 跳表分析并用 Go 实现"},{"content":" 关于 APNG APNG（Animated Portable Network Graphics）顾名思义是基于 PNG 格式扩展的一种动画格式，增加了对动画图像的支持，同时加入了 24 位图像和 8 位 Alpha 透明度的支持，这意味着动画将拥有更好的质量，其诞生的目的是为了替代老旧的 GIF 格式，但它目前并没有获得 PNG 组织官方的认可。\nAPNG 简史 MNG\n在 APNG 之前它还有一个老冤家叫 MNG（Multiple-image Network Graphics）即多图像网络图形，1996 年 6 月提出 PNF（Portable Network Frame）草案，同年8月更名为 MNG ，2001 年 1 月 31 日发布 MNG 规范 1.0 版本，MNG 是出自 PNG 开发组之手，但由于结构复杂的 MNG 程序库，使用过程会占用大量的资源，早期只有较少的浏览器支持，Chrome、IE、Opera、Safari 则从未支持过。\nAPNG\n2004 年，由 Mozilla 公司两位 Mozilla 程序员 Stuart Parmenter 和 Vladimir Vukićević 共同设计出 APNG，他们希望 Mozilla 社区能使用它，但提案未能通过。\nlibpng程序库\n2006 年，Google Summer of Code 活动中，加拿大圣力嘉学院的学生为 libpng 程序库加入了对 APNG 支持，此后开发者再次推荐给 Mozilla 社区，不过仍然遭到拒绝。\n首次支持\n2007 年 3 月 23 日，Mozilla 后知后觉，在 Mozilla Firefox 3.0 中 首次支持 APNG 格式。\n标准化申请\n2007 年 4 月 20 日，Mozilla 希望 APNG 能成为官方标准，因此 PNG 组织发起投票，最终以8：10的票数否决了 APNG 进了官方标准，因为 PNG 组织决心继续推广 MNG，但这不并影响 Mozilla 继续支持 APNG。\n为什么 GIF 能存活29年之久？ 开头讲 APNG 时提到，APNG 的出现就是为了替代 GIF，诞生于 1987 年的 GIF 为什么能存活 29 年之久？\n主要有四个原因：\n几乎所有的主流浏览器都支持 GIF 早期选择不多，GIF 几乎是唯一选择（GIF - 1987、JPEG - 1992、PNG - 1996、APNG - 2004、WebP - 2010） 实现起来简单，制作的工具多 采用 LZW 数据压缩算法，使得 GIF 体积小，在早期慢速的互联网易于传播 为什么要取代它？ 1、图片质量\n如果你使用的是非 Firefox、Safari 浏览器，那 APNG 格式的图片会向下兼容显示为静态图，你可以更换 Firefox、Safari 浏览器或者在 Chrome 浏览器安装 APNG Extension for Google Chrome 扩展来兼容，通过两者对比能总结出以下区别：\nGIF：\n最多支持 8 位 256 色，色阶过渡糟糕，图片具有颗粒感 不支持 Alpha 透明通道，边缘有杂边 APNG：\n支持 24 位真彩色图片 支持 8 位 Alpha 透明通道 向下兼容 PNG 2、图片体积\n如果你使用的浏览器不支持WebP，下面对比的 WebP 格式的图片将无法显示。\n从几组 GIF、APNG、WebP 的对比中可以发现，无论在纯色的图片或是多彩的图片，大部分情况下 APNG 依旧能比 GIF、WebP 以及有损的 WebP 的体积小。\nAPNG 的组成 APNG 是基于 PNG 格式扩展的，首先需要了解一个简单的 PNG 文件组成结构：\nPNG 由 4 部分组成，首先以 PNG Signature（PNG签名块）开头，紧接着一个 IHDR（图像头部块），然后是一个或多个的 IDAT（图像数据块），最终以 IEND（图像结束块）结尾。\nAPNG 规范引入了三个新大块，分别是：acTL（动画控制块）、fcTL（帧控制块）、fdAT（帧数据块），下图是三个独立的 PNG 文件组成 APNG 的示意图。\nacTL 块必须在第一个 IDAT 块之前，用于告诉解析器这是一个动画 PNG，包含动画帧总数和循环次数的信息 fcTL 块是每一帧都必须的，出现在 IDAT 或 fdAT 之前，包含顺序号、宽高、帧位置、延时等信息 fdAT 块与 IDAT 块有着相同的结构，除了 fcTL 中的顺序号 从图中可以发现第一帧与后面两帧不同，那是因为第一帧 APNG 文件存储的为一个正常的 PNG 数据块，对于不支持 APNG 的浏览器或软件，只会显示 APNG 文件的第一帧，忽略后面附加的动画块，这也是为什么 APNG 能向下兼容 PNG 的原因。\nAPNG 帧间优化 假设使用一个 4 帧图片合成 APNG\nAPNG 会通过算法计算帧之间的差异，只存储帧之前的差异，而不是存储全帧。\n通过 TweakPNG 软件观察 IDAT 图像数据块和 fdAT 帧数据块的大小，可以明显的看出来存储全帧与差异帧的区别，使得 APNG 文件大小有显著的减少。\n为什么没有普及？ 主要的原因是缺乏浏览器的支持，从 Can I use 查询可知 Firefox 从 3 到 49 版本自始自终支持着，Opera 早期只有三个版本支持过（10.1、11.5、12.1），后续版本则取消了对 APNG 的支持，而 Chrome、IE、Edge 则从未支持过 APNG，Chrome 和 Opera 都在推广自家的 WebP，而微软则一直是个不合群的家伙。\n但是，重要的一点是 2014 年 9 月 17 号 Apple 向用户推送了 iOS 8，这意味着 Safari 8 新增了对 APNG 的支持，这能有效的推动 APNG 的发展，至少在移动端。\n特性检测 既然存在兼容问题，那就需要通过判断应用场景。\n(function() { \u0026#34;use strict\u0026#34;; var apngTest = new Image(), ctx = document.createElement(\u0026#34;canvas\u0026#34;).getContext(\u0026#34;2d\u0026#34;); apngTest.onload = function () { ctx.drawImage(apngTest, 0, 0); self.apng_supported = ctx.getImageData(0, 0, 1, 1).data[3] === 0; }; apngTest.src = \u0026#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAACGFjVEwAAAABAAAAAcMq2TYAAAANSURBVAiZY2BgYPgPAAEEAQB9ssjfAAAAGmZjVEwAAAAAAAAAAQAAAAEAAAAAAAAAAAD6A+gBAbNU+2sAAAARZmRBVAAAAAEImWNgYGBgAAAABQAB6MzFdgAAAABJRU5ErkJggg==\u0026#34;; }()); 方法与 WebP 检测相似，同样是加载一张 1x1 像素大小的 Base64 编码图片，不同在于 WebP 加载完成后是判断图片宽高是否大于 1，而 APNG 则是将其绘制到画布中，通过 getImageData() 方法去获取该图片的像素数据，主要是获取 data[3] 的 Alpha 透明通道（值的范围：0 - 255），当返回 0（0代表透明的）时则表示支持 APNG，返回 255（255 代表完全可见的）则表示不支持 APNG。\nAPNG to Canvas 当然，目前也有用于兼容的库： apng-canvas\n使用该库需要以下条件支持：\nCanvas Typed Arrays Blob URLs requestAnimationFrame \u0026lt;img src=\u0026#34;example.png\u0026#34; class=\u0026#34;apng-image\u0026#34;\u0026gt; APNG.ifNeeded().then(function() { var images = document.querySelectorAll(\u0026#34;.apng-image\u0026#34;); for (var i = 0; i \u0026lt; images.length; i++) { APNG.animateImage(images[i]); } }); 制作工具 在了解 APNG 后，是不是心痒痒想制作 APNG 呢？在制作工具方面，APNG 已经不像早期那样工具匮乏了， APNG Software 网站上有大量的制作工具，有客户端版本（大部分只支持 Widnows）也有命令行版本，可以非常轻松的制作 APNG，比如下面这款软件。\nWindows客户端 - APNG Assembler\nMac客户端 - APNGb\n功能说明：\nPlayback Settings 可设置循环的次数，0 表示无限循环，可跳过第一帧 Delays - All Frames 可设置所有帧播放时所停留的时间 Compression Settings 可设置压缩参数，有三种压缩方式（zlib、7zip、Zopfli）以及颜色类型和调色板优化 Delays - Selected Frames 可设置选中帧播放时所停留的时间 这里演示图分别是 Windows 版本和 Mac 版本，功能基本一致，将序列帧图片拖拽到指定位置，设置一些基本的参数即可生成 APNG 图，Mac 版本比 Windows 版本多出一个将 APNG 图片 Disassembly（分解）功能，可分解为多个 PNG 图片。\n下载地址戳这里\n参考资料 Animated PNG demos GIF vs APNG vs WebP Inter-frame Optimization in APNG davidmz/apng-canvas - Github GIF - Wikipedia APNG - Wikipedia APNG Specification Can I use - APNG Portable Network Graphics - Wikipedia Multiple-image Network Graphics - Wikipedia APNG Software\nhttps://wiki.mozilla.org/APNG_Specification\nhttps://philip.html5.org/tests/apng/tests.html\n","date":"2021-02-24T23:00:47Z","permalink":"https://lxb.wiki/941edb97/","title":"APNG与 GIF"},{"content":" 大部分Linux发行版的默认账户是普通用户，而更改系统文件或者执行某些命令，需要root身份才能进行，这就需要从当前用户切换到root用户。Linux中切换用户的命令是su或su -。前天我在使用useradd这个命令时，才体会到这两者的本质区别。如图：\n我首先是用su命令切换到root身份的，但是运行useradd时，出现错误：bash: useradd: command not found。google了一下，原因是在这个用su命令切换过来的root用户上。\nsu命令和su -命令最大的本质区别就是：前者只是切换了root身份，但Shell环境仍然是普通用户的Shell；而后者连用户和Shell环境一起切换成root身份了。只有切换了Shell环境才不会出现PATH环境变量错误。su切换成root用户以后，pwd一下，发现工作目录仍然是普通用户的工作目录；而用su -命令切换以后，工作目录变成root的工作目录了。用echo $PATH命令看一下su和su -以后的环境变量有何不同。以此类推，要从当前用户切换到其它用户也一样，应该使用su -命令。 如图：\n","date":"2021-02-13T21:24:47Z","permalink":"https://lxb.wiki/686a477f/","title":"Linux 下 su 和 su - 的区别"},{"content":" 拜占庭将军问题 拜占庭将军问题是 Leslie Lamport 在 The Byzantine Generals Problem 论文中提出的分布式领域的容错问题，它是分布式领域中最复杂、最严格的容错模型。\n在该模型下，系统不会对集群中的节点做任何的限制，它们可以向其他节点发送随机数据、错误数据，也可以选择不响应其他节点的请求，这些无法预测的行为使得容错这一问题变得更加复杂。\n拜占庭将军问题描述了一个如下的场景，有一组将军分别指挥一部分军队，每一个将军都不知道其它将军是否是可靠的，也不知道其他将军传递的信息是否可靠，但是它们需要通过投票选择是否要进攻或者撤退：\n在这一节中，黄色代表状态未知，绿色代表进攻，蓝色代表撤退，最后红色代表当前将军的信息不可靠。\n在这时，无论将军是否可靠，只要所有的将军达成了统一的方案，选择进攻或者撤退其实就是没有任何问题的：\n上述的情况不会对当前的战局有太多的影响，也不会造成损失，但是如果其中的一个将军告诉其中一部分将军选择进攻、另一部分选择撤退，就会出现非常严重的问题了。\n由于将军的队伍中出了一个叛徒或者信息在传递的过程中被拦截，会导致一部分将军会选择进攻，剩下的一部分会选择撤退，它们都认为自己的选择是大多数人的选择，这时就出现了严重的不一致问题。\n拜占庭将军问题是对分布式系统容错的最高要求，然而这不是日常工作中使用的大多数分布式系统中会面对的问题，我们遇到更多的还是节点故障宕机或者不响应等情况，这就大大简化了系统对容错的要求；不过类似 Bitcoin、Ethereum 等分布式系统确实需要考虑拜占庭容错的问题。\n​\t拜占庭将军问题是分布式领域最复杂、最严格的容错模型。但在日常工作中使用的分布式系统面对的问题不会那么复杂，更多的是计算机故障挂掉了，或者网络通信问题而没法传递信息，这种情况不考虑计算机之间互相发送恶意信息，极大简化了系统对容错的要求，最主要的是达到一致性。\n所以将拜占庭将军问题根据常见的工作上的问题进行简化：假设将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成一致性决定？\n对于这个简化后的问题，有许多解决方案，第一个被证明的共识算法是 Paxos，由拜占庭将军问题的作者 Leslie Lamport 在1990年提出，最初以论文难懂而出名，后来这哥们在2001重新发了一篇简单版的论文 Paxos Made Simple，然而还是挺难懂的。\n因为 Paxos 难懂，难实现，所以斯坦福大学的教授在2014年发表了新的分布式协议 Raft。与 Paxos 相比，Raft 有着基本相同运行效率，但是更容易理解，也更容易被用在系统开发上。\n针对简化版拜占庭将军问题，Raft 解决方案类比 我们还是用拜占庭将军的例子来帮助理解 Raft。\n​\t假设将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成一致性决定？\nRaft 的解决方案大概可以理解成 先在所有将军中选出一个大将军，所有的决定由大将军来做。选举环节：比如说现在一共有3个将军 A, B, C，每个将军都有一个随机时间的倒计时器，倒计时一结束，这个将军就会把自己当成大将军候选人，然后派信使去问其他几个将军，能不能选我为总将军？假设现在将军A倒计时结束了，他派信使传递选举投票的信息给将军B和C，如果将军B和C还没把自己当成候选人（倒计时还没有结束），并且没有把选举票投给其他，他们把票投给将军A，信使在回到将军A时，将军A知道自己收到了足够的票数，成为了大将军。在这之后，是否要进攻就由大将军决定，然后派信使去通知另外两个将军，如果在一段时间后还没有收到回复（可能信使被暗杀），那就再重派一个信使，直到收到回复。\n故事先讲到这里，希望不做技术方面的朋友可以大概能理解 Raft 的原理，下面从比较技术的角度讲讲 Raft 的原理。\n1. Raft 节点状态 从拜占庭将军的故事映射到分布式系统上，每个将军相当于一个分布式网络节点，每个节点有三种状态：Follower，Candidate，Leader，状态之间是互相转换的，可以参考下图，具体的后面说。\n每个节点上都有一个倒计时器 (Election Timeout)，时间随机在 150ms 到 300ms 之间。有几种情况会重设 Timeout：\n收到选举的请求 收到 Leader 的 Heartbeat (后面会讲到) 在 Raft 运行过程中，最主要进行两个活动：\n选主 Leader Election 复制日志 Log Replication 2. 选主 Leader Election 2.1 正常情况下选主 假设现在有如图5个节点，5个节点一开始的状态都是 Follower。\n在一个节点倒计时结束 (Timeout) 后，这个节点的状态变成 Candidate 开始选举，它给其他几个节点发送选举请求 (RequestVote)\n其他四个节点都返回成功，这个节点的状态由 Candidate 变成了 Leader，并在每个一小段时间后，就给所有的 Follower 发送一个 Heartbeat 以保持所有节点的状态，Follower 收到 Leader 的 Heartbeat 后重设 Timeout。\n这是最简单的选主情况，只要有超过一半的节点投支持票了，Candidate 才会被选举为 Leader，5个节点的情况下，3个节点 (包括 Candidate 本身) 投了支持就行。\n2.2 Leader 出故障情况下的选主 一开始已经有一个 Leader，所有节点正常运行。\nLeader 出故障挂掉了，其他四个 Follower 将进行重新选主。\n4个节点的选主过程和5个节点的类似，在选出一个新的 Leader 后，原来的 Leader 恢复了又重新加入了，这个时候怎么处理？在 Raft 里，第几轮选举是有记录的，重新加入的 Leader 是第一轮选举 (Term 1) 选出来的，而现在的 Leader 则是 Term 2，所有原来的 Leader 会自觉降级为 Follower\n2.3 多个 Candidate 情况下的选主 假设一开始有4个节点，都还是 Follower。\n有两个 Follower 同时 Timeout，都变成了 Candidate 开始选举，分别给一个 Follower 发送了投票请求。\n两个 Follower 分别返回了ok，这时两个 Candidate 都只有2票，要3票才能被选成 Leader。\n两个 Candidate 会分别给另外一个还没有给自己投票的 Follower 发送投票请求。\n但是因为 Follower 在这一轮选举中，都已经投完票了，所以都拒绝了他们的请求。所以在 Term 2 没有 Leader 被选出来。\n这时，两个节点的状态是 Candidate，两个是 Follower，但是他们的倒计时器仍然在运行，最先 Timeout 的那个节点会进行发起新一轮 Term 3 的投票。\n两个 Follower 在 Term 3 还没投过票，所以返回 OK，这时 Candidate 一共有三票，被选为了 Leader。\n如果 Leader Heartbeat 的时间晚于另外一个 Candidate timeout 的时间，另外一个 Candidate 仍然会发送选举请求。\n两个 Follower 已经投完票了，拒绝了这个 Candidate 的投票请求。\nLeader 进行 Heartbeat， Candidate 收到后状态自动转为 Follower，完成选主。\n以上是 Raft 最重要活动之一选主的介绍，以及在不同情况下如何进行选主。\n3. 复制日志 Log Replication 3.1 正常情况下复制日志 Raft 在实际应用场景中的一致性更多的是体现在不同节点之间的数据一致性，客户端发送请求到任何一个节点都能收到一致的返回，当一个节点出故障后，其他节点仍然能以已有的数据正常进行。在选主之后的复制日志就是为了达到这个目的。\n一开始，Leader 和 两个 Follower 都没有任何数据。\n客户端发送请求给 Leader，储存数据 “sally”，Leader 先将数据写在本地日志，这时候数据还是 Uncommitted (还没最终确认，红色表示)\nLeader 给两个 Follower 发送 AppendEntries 请求，数据在 Follower 上没有冲突，则将数据暂时写在本地日志，Follower 的数据也还是 Uncommitted。\nFollower 将数据写到本地后，返回 OK。Leader 收到后成功返回，只要收到的成功的返回数量超过半数 (包含Leader)，Leader 将数据 “sally” 的状态改成 Committed。( 这个时候 Leader 就可以返回给客户端了)\nLeader 再次给 Follower 发送 AppendEntries 请求，收到请求后，Follower 将本地日志里 Uncommitted 数据改成 Committed。这样就完成了一整个复制日志的过程，三个节点的数据是一致的，\n3.2 Network Partition 情况下进行复制日志 在 Network Partition 的情况下，部分节点之间没办法互相通信，Raft 也能保证在这种情况下数据的一致性。\n一开始有 5 个节点处于同一网络状态下。\nNetwork Partition 将节点分成两边，一边有两个节点，一边三个节点。\n两个节点这边已经有 Leader 了，来自客户端的数据 “bob” 通过 Leader 同步到 Follower。\n因为只有两个节点，少于3个节点，所以 “bob” 的状态仍是 Uncommitted。所以在这里，服务器会返回错误给客户端\n另外一个 Partition 有三个节点，进行重新选主。客户端数据 “tom” 发到新的 Leader，通过和上节网络状态下相似的过程，同步到另外两个 Follower。\n因为这个 Partition 有3个节点，超过半数，所以数据 “tom” 都 Commit 了。\n网络状态恢复，5个节点再次处于同一个网络状态下。但是这里出现了数据冲突 “bob\u0026quot; 和 “tom\u0026quot;\n三个节点的 Leader 广播 AppendEntries\n两个节点 Partition 的 Leader 自动降级为 Follower，因为这个 Partition 的数据 “bob” 没有 Commit，返回给客户端的是错误，客户端知道请求没有成功，所以 Follower 在收到 AppendEntries 请求时，可以把 “bob“ 删除，然后同步 ”tom”，通过这么一个过程，就完成了在 Network Partition 情况下的复制日志，保证了数据的一致性。\n小总结 Raft 是能够实现分布式系统强一致性的算法，每个系统节点有三种状态 Follower，Candidate，Leader。实现 Raft 算法两个最重要的事是：选主和复制日志\n参考链接： Raft 官网：https://raft.github.io/\nRaft 原理动画 (推荐看看)：http://thesecretlivesofdata.com/raft/\nRaft 算法解析图片来源：http://www.infoq.com/cn/articles/coreos-analyse-etcd\n分布式一致性与共识算法 https://draveness.me/consensus/\n共识算法：Raft https://www.jianshu.com/p/8e4bbe7e276c\n","date":"2021-02-06T20:36:12Z","permalink":"https://lxb.wiki/3d118e3a/","title":"raft 算法"},{"content":" 使用子模块和子树来帮助你管理多个存储库中共有的子项目。\n如果你参与了开源项目的开发，那么你很可能已经用了 Git 来管理你的源码。你可能遇到过有很多依赖和/或子项目的项目。你是如何管理它们的？\n对于一个开源组织，要实现社区和产品的单一来源文档和依赖管理比较棘手。文档和项目往往会碎片化和变得冗余，这致使它们很难维护。\n必要性 假设你想把单个项目作为一个存储库内的子项目，传统的方法是把该项目复制到父存储库中，但是，如果你想要在多个父项目中使用同一个子项目呢？如果把子项目复制到所有父项目中，当有更新时，你都要在每个父项目中做修改，这是不太可行的。这会导致父项目中的冗余和数据不一致，使更新和维护子项目变得很困难。\nGit 子模块和子树 如果你可以用一条命令把一个项目放进另一个项目中，会怎样呢？如果你随时可以把一个项目作为子项目添加到任意数目的项目中，并可以同步更新修改呢？Git 提供了这类问题的解决方案：Git 子模块submodule子模块submodule和 Git 子树subtree子树subtree。创建这些工具的目的是以更加模块化的水平来支持共用代码的开发工作流，旨在 Git 存储库源码管理source-code management源码管理source-code management（SCM）与它下面的子树之间架起一座桥梁。\n生长在桑树上的樱桃树\n下面是本文要详细介绍的概念的一个真实应用场景。如果你已经很熟悉树形结构，这个模型看起来是下面这样：\nGit 子模块是什么？ Git 在它默认的包中提供了子模块，子模块可以把 Git 存储库嵌入到其他存储库中。确切地说，Git 子模块指向子树中的某次提交。下面是我 Docs-test GitHub 存储库中的 Git 子模块的样子：\n文件夹@提交 Id 格式表明这个存储库是一个子模块，你可以直接点击文件夹进入该子树。名为 .gitmodules 的配置文件包含所有子模块存储库的详细信息。我的存储库的 .gitmodules 文件如下：\n你可以用下面的命令在你的存储库中使用 Git 子模块：\n克隆一个存储库并加载子模块 克隆一个含有子模块的存储库：\n$ git clone --recursive \u0026lt;URL to Git repo\u0026gt; 如果你之前已经克隆了存储库，现在想加载它的子模块：\n$ git submodule update --init 如果有嵌套的子模块：\n$ git submodule update --init --recursive 下载子模块 串行地连续下载多个子模块是很枯燥的工作，所以 clone 和 submodule update 会支持 --jobs （或 -j）参数：\n例如，想一次下载 8 个子模块，使用：\n$ git submodule update --init --recursive -j 8 $ git clone --recursive --jobs 8 \u0026lt;URL to Git repo\u0026gt; 拉取子模块 在运行或构建父项目之前，你需要确保依赖的子项目都是最新的。\n拉取子模块的所有修改：\n$ git submodule update --remote 使用子模块创建存储库： 向一个父存储库添加子树：\n$ git submodule add \u0026lt;URL to Git repo\u0026gt; 初始化一个已存在的 Git 子模块：\n$ git submodule init 你也可以通过为 submodule update 命令添加 --update 参数在子模块中创建分支和追踪提交：\n$ git submodule update --remote 更新子模块的提交 上面提到过，一个子模块就是一个指向子树中某次提交的链接。如果你想更新子模块的提交，不要担心。你不需要显式地指定最新的提交。你只需要使用通用的 submodule update 命令：\n$ git submodule update 就像你平时创建父存储库和把父存储库推送到 GitHub 那样添加和提交就可以了。\n从一个父存储库中删除一个子模块 仅仅手动删除一个子项目文件夹不会从父项目中移除这个子项目。想要删除名为 childmodule 的子模块，使用：\n$ git rm -f childmodule 虽然 Git 子模块看起来很容易上手，但是对于初学者来说，有一定的使用门槛。\nGit 子树是什么？ Git 子树 subtree子树 subtree，是在 Git 1.7.11 引入的，让你可以把任何存储库的副本作为子目录嵌入另一个存储库中。它是 Git 项目可以注入和管理项目依赖的几种方法之一。它在常规的提交中保存了外部依赖信息。Git 子树提供了整洁的集成点，因此很容易复原它们。\n如果你参考 GitHub 提供的子树教程来使用子树，那么无论你什么时候添加子树，在本地都不会看到 .gittrees 配置文件。这让我们很难分辨哪个是子树，因为它们看起来很像普通的文件夹，但是它们却是子树的副本。默认的 Git 包中不提供带 .gittrees 配置文件的 Git 子树版本，因此如果你想要带 .gittrees 配置文件的 git-subtree 命令，必须从 Git 源码存储库的 /contrib/subtree 文件夹 下载 git-subtree。\n你可以像克隆其他常规的存储库那样克隆任何含有子树的存储库，但由于在父存储库中有整个子树的副本，因此克隆过程可能会持续很长时间。\n你可以用下面的命令在你的存储库中使用 Git 子树。\n向父存储库中添加一个子树 想要向父存储库中添加一个子树，首先你需要执行 remote add，之后执行 subtree add 命令：\n$ git remote add remote-name \u0026lt;URL to Git repo\u0026gt; $ git subtree add --prefix=folder/ remote-name \u0026lt;URL to Git repo\u0026gt; subtree-branchname 上面的命令会把整个子项目的提交历史合并到父存储库。\n向子树推送修改以及从子树拉取修改 $ git subtree push-all 或者\n$ git subtree pull-all 你应该使用哪个？ 任何工具都有优缺点。下面是一些可能会帮助你决定哪种最适合你的特性：\nGit 子模块的存储库占用空间更小，因为它们只是指向子项目的某次提交的链接，而 Git 子树保存了整个子项目及其提交历史。 Git 子模块需要在服务器中可访问，但子树是去中心化的。 Git 子模块大量用于基于组件的开发，而 Git 子树多用于基于系统的开发。 Git 子树并不是 Git 子模块的直接可替代项。有明确的说明来指导我们该使用哪种。如果有一个归属于你的外部存储库，使用场景是向它回推代码，那么就使用 Git 子模块，因为推送代码更容易。如果你有第三方代码，且不会向它推送代码，那么使用 Git 子树，因为拉取代码更容易。\n自己尝试使用 Git 子树和子模块，然后在评论中留下你的使用感想。\nvia: https://opensource.com/article/20/5/git-submodules-subtrees\n作者：Manaswini Das 选题：lujun9972 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2020-12-23T22:11:17Z","permalink":"https://lxb.wiki/331c3227/","title":"【译】使用子模块和子树来管理 Git 项目"},{"content":" 阅读本文并下载我们的免费备忘单，去使用开源的数据库吧。\n当你写一个程序或配置一个服务时，你最终都要持久化存储信息。有时候，你只需要一个 INI 或者 YAML 配置文件就够了。而有时候，一个自定义格式的 XML 或者 JSON 或其他类似的文件会更好。\n但也有时候你需要校验输入、快速查询信息、关联数据、通常还要熟练地处理你的用户的请求。这就是设计数据库的目的，而 MariaDB（由 MySQL 的原始开发人员开发的一个分支） 是一个极佳的选项。在本文中我使用的是 MariaDB，但这些信息同样适用于 MySQL。\n通过编程语言与数据库进行交互是很普遍的。正因如此，出现了大量 Java、Python、Lua、PHP、Ruby、C++ 和其他语言的 SQL 库。然而，在使用这些库之前，理解数据库引擎做了什么以及为什么选择数据库是重要的对我们会很有帮助。本文介绍 MariaDB 和 mysql 命令来帮助你熟悉数据库处理数据的基本原理。\n如果你还没有安装 MariaDB，请查阅我的文章 在 Linux 上安装 MariaDB。如果你没有使用 Linux，请参照 MariaDB 下载页面提供的指导方法。\n与 MariaDB 交互 你可以使用 mysql 命令与 MariaDB 进行交互。首先使用子命令 ping 确认你的服务是运行着的，在提示后输入密码：\n$ mysqladmin -u root -p ping Enter password: mysqld is alive 为了易于读者理解，打开一个交互式的 MariaDB 会话：\n$ mysql -u root -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. [...] Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. MariaDB [(none)]\u0026gt; 你现在是在一个 MariaDB 子 shell 中，提示符是 MariaDB 提示符。普通的 Bash 命令在这里不能使用，只能用 MariaDB 命令。输入 help （或 ?）查看命令列表。这些是你的 MariaDB shell 的管理命令，使用它们可以定制你的 shell，但它们不属于 SQL 语言。\n学习 SQL 基本知识 结构化查询语言是基于它们的能力定义的：一种通过有规则且一致的语法来查询数据库中的内容以得到有用的结果的方法。SQL 看起来像是普通的英文语句，有一点点生硬。例如，如果你登入数据库服务器，想查看有哪些库，输入 SHOW DATABASES; 并回车就能看到结果。\nSQL 命令以分号作为结尾。如果你忘记输入分号，MariaDB 会认为你是想在下一行继续输入你的查询命令，在下一行你可以继续输入命令也可以输入分号结束命令。\nMariaDB [(NONE)]\u0026gt; SHOW DATABASES; +--------------------+ | DATABASE | +--------------------+ | information_schema | | mysql | | performance_schema | | test | +--------------------+ 4 ROWS IN SET (0.000 sec) 上面的例子显示当前有四个数据库：information_schema、mysql、performance_schema 和 test。你必须指定 MariaDB 使用哪个库，才能对该库使用查询语句。指定数据库的命令是 use。当你选择了一个库后，MariaDB 提示框会切换为选择的库。\nMariaDB [(NONE)]\u0026gt; USE test; MariaDB [(test)]\u0026gt; 显示数据库的表 数据库里有表，与电子表格类似：有一系列的行（在数据库中称为记录）和列。一个行和一个列唯一确定一个字段。\n查看一个数据库中可用的表（可以理解为多表单电子表格中的一页），使用 SQL 关键字 SHOW：\nMariaDB [(test)]\u0026gt; SHOW TABLES; empty SET test 数据库是空的，所以使用 use 命令切换到 mysql 数据库：\nMariaDB [(test)]\u0026gt; USE mysql; MariaDB [(mysql)]\u0026gt; SHOW TABLES; +---------------------------+ | Tables_in_mysql | +---------------------------+ | column_stats | | columns_priv | | db | [...] | time_zone_transition_type | | transaction_registry | | USER | +---------------------------+ 31 ROWS IN SET (0.000 sec) 这个数据库中有很多表！mysql 数据库是这个 MariaDB 实例的系统管理数据库。它里面包含重要数据，比如用来管理数据库权限的用户结构。这个数据库很重要，你不需要经常直接与它交互，但是使用 SQL 脚本来操作它却很常见。当你学习 MariaDB 时理解 mysql 数据库很有用，因为它有助于说明一些基本的 SQL 命令。\n检查一个表 这个实例的 mysql 数据库的最后一个表名为 USER。这个表包含了可以访问这个数据库的用户。当前里面只有一个 root 用户，但是你可以添加不同权限的用户，赋予它们查看、更新或创建数据的权限。你可以查看一个表的列首来了解一个 MariaDB 用户的所有属性：\n\u0026gt; SHOW COLUMNS IN USER; MariaDB [mysql]\u0026gt; SHOW COLUMNS IN USER; +-------------+---------------+------+-----+----------+ | FIELD | TYPE | NULL | KEY | DEFAULT | +-------------+---------------+------+-----+----------+ | Host | CHAR(60) | NO | PRI | | | USER | CHAR(80) | NO | PRI | | | Password | CHAR(41) | NO | | | | Select_priv | enum(\u0026#39;N\u0026#39;,\u0026#39;Y\u0026#39;) | NO | | N | | Insert_priv | enum(\u0026#39;N\u0026#39;,\u0026#39;Y\u0026#39;) | NO | | N | | Update_priv | enum(\u0026#39;N\u0026#39;,\u0026#39;Y\u0026#39;) | NO | | N | | Delete_priv | enum(\u0026#39;N\u0026#39;,\u0026#39;Y\u0026#39;) | NO | | N | | Create_priv | enum(\u0026#39;N\u0026#39;,\u0026#39;Y\u0026#39;) | NO | | N | | Drop_priv | enum(\u0026#39;N\u0026#39;,\u0026#39;Y\u0026#39;) | NO | | N | [...] 47 ROWS IN SET (0.001 sec) 创建一个新的用户 不论你是否需要一个普通的账号来管理数据库或者为计算机配置数据库（例如安装 WordPress、Drupal 或 Joomla时），在 MariaDB 中多建一个用户账号是很普遍的。你可以通过向 mysql 数据库的 USER 表中添加一个用户或使用 SQL 关键字 CREATE 来提示 MariaDB 创建一个 MariaDB 用户。使用 CREATE 来创建新用户会默认执行一些有用的方法，因此你不需要手动生成所有的信息：\n\u0026gt; CREATE USER \u0026#39;tux\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;really_secure_password\u0026#39;; 查看表的字段 你可以使用 SELECT 关键字来查看数据库表的字段和值。这本例中，你创建了一个名为 tux 的用户，因此查询 USER 表中的列：\n\u0026gt; SELECT USER,host FROM USER; +------+------------+ | USER | host | +------+------------+ | root | localhost | [...] | tux | localhost | +------+------------+ 7 ROWS IN SET (0.000 sec) 为一个用户赋予权限 通过查看 USER 表列出的信息，你可以看到用户的状态。例如，新用户 tux 对这个数据库没有任何权限。使用 WHERE 语句你可以只查 tux 那一条记录。\n\u0026gt; SELECT USER,select_priv,insert_priv,update_priv FROM USER WHERE USER=\u0026#39;tux\u0026#39;; +------+-------------+-------------+-------------+ | USER | select_priv | insert_priv | update_priv | +------+-------------+-------------+-------------+ | tux | N | N | N | +------+-------------+-------------+-------------+ 使用 GRANT 命令修改用户的权限：\n\u0026gt; GRANT SELECT ON *.* TO \u0026#39;tux\u0026#39;@\u0026#39;localhost\u0026#39;; \u0026gt; FLUSH PRIVILEGES; 验证你的修改：\n\u0026gt; SELECT USER,select_priv,insert_priv,update_priv FROM USER WHERE USER=\u0026#39;tux\u0026#39;; +------+-------------+-------------+-------------+ | USER | select_priv | insert_priv | update_priv | +------+-------------+-------------+-------------+ | tux | Y | N | N | +------+-------------+-------------+-------------+ tux 用户现在有了从所有表中查询记录的权限。\n创建自定义的数据库 到目前为止，你一直在与默认的数据库进行交互。除了用户管理，大部分人很少会与默认的数据库进行交互。通常，你会用自定义的数据来填充创建的数据库。\n创建一个 MariaDB 数据库 你可能已经可以自己在 MariaDB 中创建新数据库了。创建数据库跟新建用户差不多。\n\u0026gt; CREATE DATABASE example; Query OK, 1 ROW affected (0.000 sec) \u0026gt; SHOW DATABASES; +--------------------+ | DATABASE | +--------------------+ | example | [...] 使用 use 命令来把这个新建的数据库作为当前使用的库：\n\u0026gt; USE example; 创建一个表 创建表比创建数据库要复杂，因为你必须定义列首。MariaDB 提供了很多方便的函数，可以用于创建列，引入数据类型定义，自增选项，对空值的约束，自动时间戳等等。\n下面是用来描述一系列用户的一个简单的表：\n\u0026gt; CREATE TABLE IF NOT EXISTS member ( -\u0026gt; id INT AUTO_INCREMENT PRIMARY KEY, -\u0026gt; name VARCHAR(128) NOT NULL, -\u0026gt; startdate TIMESTAMP DEFAULT CURRENT_TIMESTAMP); Query OK, 0 ROWS affected (0.030 sec) 这个表通过使用一个自动递增的方法来唯一标识每一行。表示用户名字的字段不能为空（或 null），每一行被创建时会自动生成时间戳。\n使用 SQL 关键字 INSERT 向这个表填充一些示例数据：\n\u0026gt; INSERT INTO member (name) VALUES (\u0026#39;Alice\u0026#39;); Query OK, 1 ROW affected (0.011 sec) \u0026gt; INSERT INTO member (name) VALUES (\u0026#39;Bob\u0026#39;); Query OK, 1 ROW affected (0.011 sec) \u0026gt; INSERT INTO member (name) VALUES (\u0026#39;Carol\u0026#39;); Query OK, 1 ROW affected (0.011 sec) \u0026gt; INSERT INTO member (name) VALUES (\u0026#39;David\u0026#39;); Query OK, 1 ROW affected (0.011 sec) 验证一下表里的数据：\n\u0026gt; SELECT * FROM member; +----+-------+---------------------+ | id | name | startdate | +----+-------+---------------------+ | 1 | Alice | 2020-10-03 15:25:06 | | 2 | Bob | 2020-10-03 15:26:43 | | 3 | Carol | 2020-10-03 15:26:46 | | 4 | David | 2020-10-03 15:26:51 | +----+-------+---------------------+ 4 ROWS IN SET (0.000 sec) 同时增加多行数据 再创建一个表：\n\u0026gt; CREATE TABLE IF NOT EXISTS linux ( -\u0026gt; id INT AUTO_INCREMENT PRIMARY KEY, -\u0026gt; distro VARCHAR(128) NOT NULL); Query OK, 0 ROWS affected (0.030 sec) 填充一些示例数据，这次使用 VALUES 快捷方式，这样你可以一次添加多行数据。VALUES 关键字需要一个用括号包围的列表作为参数，也可以用逗号分隔的多个列表作为参数。\n\u0026gt; INSERT INTO linux (distro) -\u0026gt; VALUES (\u0026#39;Slackware\u0026#39;), (\u0026#39;RHEL\u0026#39;),(\u0026#39;Fedora\u0026#39;),(\u0026#39;Debian\u0026#39;); Query OK, 4 ROWS affected (0.011 sec) Records: 4 Duplicates: 0 Warnings: 0 \u0026gt; SELECT * FROM linux; +----+-----------+ | id | distro | +----+-----------+ | 1 | Slackware | | 2 | RHEL | | 3 | Fedora | | 4 | Debian | +----+-----------+ 关联多个表 现在你有两个表，之间没有关联。两个表的数据是独立的，但是你可能需要表一中的一个值来识别表二的记录。\n你可以在表一中新增一列对应表二中的值。因为两个表都有唯一的标识符（自动递增的 id 字段），关联的它们的最简单的方式是，使用表一中的 id 字段作为表二的查询条件。\n在表一中创建一列用来表示表二中的一个值：\n\u0026gt; ALTER TABLE member ADD COLUMN (os INT); Query OK, 0 ROWS affected (0.012 sec) Records: 0 Duplicates: 0 Warnings: 0 \u0026gt; DESCRIBE member; DESCRIBE member; +-----------+--------------+------+-----+---------+------+ | FIELD | TYPE | NULL | KEY | DEFAULT | Extra| +-----------+--------------+------+-----+---------+------+ | id | INT(11) | NO | PRI | NULL | auto_| | name | VARCHAR(128) | NO | | NULL | | | startdate | TIMESTAMP | NO | | cur[...]| | | os | INT(11) | YES | | NULL | | +-----------+--------------+------+-----+---------+------+ 把 linux 表中的唯一 ID 分配给每个成员。因为记录已经存在，使用 UPDATE 关键字而不是 INSERT。尤其是当你想查询某行然后再更新某列值时。语法上，表达方式有点倒装，先更新后查询：\n\u0026gt; UPDATE member SET os=1 WHERE name=\u0026#39;Alice\u0026#39;; Query OK, 1 ROW affected (0.007 sec) ROWS matched: 1 Changed: 1 Warnings: 0 要填充数据，请对其他名字重复执行这个过程。为了数据的多样性，在四行记录中分配三个不同的值。\n连接表 现在这两个表彼此有了关联，你可以使用 SQL 来展示关联的数据。数据库中有很多种连接方式，你可以尽请尝试。下面的例子是关联 member 表中 os 字段和 linux 表中 id 字段：\nSELECT * FROM member JOIN linux ON member.os=linux.id; +----+-------+---------------------+------+----+-----------+ | id | name | startdate | os | id | distro | +----+-------+---------------------+------+----+-----------+ | 1 | Alice | 2020-10-03 15:25:06 | 1 | 1 | Slackware | | 2 | Bob | 2020-10-03 15:26:43 | 3 | 3 | Fedora | | 4 | David | 2020-10-03 15:26:51 | 3 | 3 | Fedora | | 3 | Carol | 2020-10-03 15:26:46 | 4 | 4 | Debian | +----+-------+---------------------+------+----+-----------+ 4 ROWS IN SET (0.000 sec) 连接 os 和 id 字段。\n在图形化的应用中，你可以想象 os 字段可以在下拉菜单中设置，值的来源是 linux 表中的 distro 字段。通过使用多个表中独立却有关联的数据，你可以保证数据的一致性和有效性，使用 SQL 你可以动态地关联它们。\n下载 MariaDB 和 MySQL 备忘单 MariaDB 是企业级的数据库。它是健壮、强大、高效的数据库引擎。学习它是你向管理 web 应用和编写语言库迈出的伟大的一步。你可以下载 MariaDB 和 MySQL 备忘单，在你使用 MariaDB 时可以快速参考。\nvia: https://opensource.com/article/20/10/mariadb-mysql-cheat-sheet\n作者：Seth Kenlon 选题：lujun9972 译者：lxbwolf 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2020-12-13T22:07:00Z","permalink":"https://lxb.wiki/3641869e/","title":"【译】备忘单：提升你的 MariaDB 和 MySQL 数据库技能"},{"content":" Fossil 是一个集版本控制系统、bug 追踪、维基、论坛以及文档解决方案于一体的系统。\n每个开发者都知道，追踪代码的修改是至关重要的。有时候你会处于好奇或者教育的目的需要展示你的项目开始和进化的历史。有时候你想让其他的开发者参与到你的项目中，因此你需要一种值得信赖的能合并不同代码分支的方法。更极端一点，有时候你为了解决一个问题而修改的代码导致已有的功能不能正常使用。\nFossil 源码管理系统是由著名的 SQLite 数据库的作者开发的一个集版本控制系统、bug 追踪、维基、论坛以及文档解决方案于一体的系统。\n安装 Fossil Fossil 是一个独立的 C 程序，因此你可以从它的网站上下载后放在环境变量 PATH 中的任意位置。例如，假定 /usr/local/bin 已经在你的环境变量中（默认情况下是在的）：\n$ wget https://fossil-scm.org/home/uv/fossil-linux-x64-X.Y.tar.gz $ sudo tar xvf fossil-linux-x64-X.Y.tar.gz --directory /usr/local/bin 你也可以通过包管理器从软件仓库中找到 Fossil，或者直接从源码编译。\n创建一个 Fossil 仓库 如果你已经有一个代码项目，想用 Fossil 来追踪，那么第一步就是创建一个 Fossil 仓库：\n$ fossil init myproject.fossil project-id: 010836ac6112fefb0b015702152d447c8c1d8604 server-id: 54d837e9dc938ba1caa56d31b99c35a4c9627f44 admin-user: klaatu (initial password is \u0026#34;14b605\u0026#34;) 创建 Fossil 仓库的过程中会返回三行信息：一个唯一的项目 ID、一个唯一的服务器 ID 以及管理员 ID 和密码。项目 ID 和服务器 ID 是版本数字。管理员凭证表明你对这个仓库的所有权，当你把 Fossil 作为服务器让其他用户来访问时可以使用管理员权限。\nFossil 仓库工作流 在你使用 Fossil 仓库之前，你需要先为它的数据创建一个工作路径。你可以把这个过程类比为使用 Python 时创建一个虚拟环境或者解压一个只用来备份的 ZIP 文件。\n创建一个工作目录并进入：\n$ mkdir myprojectdir $ cd myprojectdir 把你的 Fossil 打开到刚刚创建的目录：\n$ fossil open ../myproject project-name: \u0026lt;unnamed\u0026gt; repository: /home/klaatu/myprojectdir/../myproject local-root: /home/klaatu/myprojectdir/ config-db: /home/klaatu/.fossil project-code: 010836ac6112fefb0b015702152d447c8c1d8604 checkout: 9e6cd96dd675544c58a246520ad58cdd460d1559 2020-11-09 04:09:35 UTC tags: trunk comment: initial empty check-in (user: klaatu) check-ins: 1 你可能注意到了，Fossil 在你的家目录下创建了一个名为 .fossil 的隐藏文件，用来追踪你的全局 Fossil 配置。这个配置不是只适用于你的一个项目的；这个文件只会在你第一次使用 Fossil 时生成。\n添加文件 使用 add 和 commit 子命令来向你的仓库添加文件。例如，创建一个简单的 README 文件，把它添加到仓库：\n$ echo \u0026#34;My first Fossil project\u0026#34; \u0026gt; README $ fossil add README ADDED README $ fossil commit -m \u0026#39;My first commit\u0026#39; New_Version: 2472a43acd11c93d08314e852dedfc6a476403695e44f47061607e4e90ad01aa 使用分支 Fossil 仓库开始时默认使用的主分支名为 trunk。当你想修改代码而又不影响主干代码时，你可以从 trunk 分支切走。创建新分支需要使用 branch 子命令，这个命令需要两个参数：一个新分支的名字，一个新分支的基分支名字。在本例中，只有一个分支 trunk，因此尝试创建一个名为 dev 的新分支：\n$ fossil branch --help Usage: fossil branch new BRANCH-NAME BASIS ?OPTIONS? $ fossil branch new dev trunk New branch: cb90e9c6f23a9c98e0c3656d7e18d320fa52e666700b12b5ebbc4674a0703695 你已经创建了一个新分支，但是你当前所在的分支仍然是 trunk：\n$ fossil branch current trunk 使用 checkout 命令切换到你的新分支 dev：\n$ fossil checkout dev dev 合并修改 假设你在 dev 分支中添加了一个新文件，完成了测试，现在想把它合并到 trunk。这个过程叫做合并。\n首先，切回目标分支（本例中目标分支为 trunk）：\n$ fossil checkout trunk trunk $ ls README 这个分支中没有你的新文件（或者你对其他文件的修改），而那些内容是合并的过程需要的信息：\n$ fossil merge dev \u0026#34;fossil undo\u0026#34; is available to undo changes to the working checkout. $ ls myfile.lua README 查看 Fossil 时间线 使用 timeline 选项来查看仓库的历史。这个命令列出了你的仓库的所有活动的详细信息，包括用来表示每次修改的哈希值、每次提交时填写的信息以及提交者：\n$ fossil timeline === 2020-11-09 === 06:24:16 [5ef06e668b] added exciting new file (user: klaatu tags: dev) 06:11:19 [cb90e9c6f2] Create new branch named \u0026#34;dev\u0026#34; (user: klaatu tags: dev) 06:08:09 [a2bb73e4a3] *CURRENT* some additions were made (user: klaatu tags: trunk) 06:00:47 [2472a43acd] This is my first commit. (user: klaatu tags: trunk) 04:09:35 [9e6cd96dd6] initial empty check-in (user: klaatu tags: trunk) +++ no more data (5) +++ 公开你的 Fossil 仓库 因为 Fossil 有个内置的 web 界面，所以 Fossil 不像 GitLab 和 Gitea 那样需要主机服务。Fossil 就是它自己的主机服务，只要你把它放在一台机器上就行了。在你公开你的 Fossil 仓库之前，你还需要通过 web 用户界面（UI）来配置一些信息：\n使用 ui 子命令启动一个本地的实例：\n$ pwd /home/klaatu/myprojectdir/ $ fossil ui “Users” 和 “Settings” 是安全相关的，“Configuration” 是项目属性相关的（包括一个合适的标题）。web 界面不仅仅是一个方便的功能。 它是能在生产环境中使用并作为 Fossil 项目的宿主机来使用的。它还有一些其他的高级选项，比如用户管理（或者叫自我管理）、在同一个服务器上与其他的 Fossil 仓库进行单点登录（SSO）。\n当配置完成后，关掉 web 界面并按下 Ctrl+C 来停止 UI 引擎。像提交代码一样提交你的 web 修改。\n$ fossil commit -m \u0026#39;web ui updates\u0026#39; New_Version: 11fe7f2855a3246c303df00ec725d0fca526fa0b83fa67c95db92283e8273c60 现在你可以配置你的 Fossil 服务器了。\n把你的 Fossil 仓库（本例中是 myproject.fossil）复制到服务器，你只需要这一个文件。 如果你的服务器没有安装 Fossil，就在你的服务器上安装 Fossil。在服务器上安装的过程跟在本地一样。 在你的 cgi-bin 目录下（或它对应的目录，这取决于你的 HTTP 守护进程）创建一个名为 repo_myproject.cgi 的文件： #!/usr/local/bin/fossil repository: /home/klaatu/public_html/myproject.fossil 添加可执行权限：\n$ chmod +x repo_myproject.cgi 你需要做的都已经做完了。现在可以通过互联网访问你的项目了。\n你可以通过 CGI 脚本来访问 web UI，例如 https://example.com/cgi-bin/repo_myproject.cgi。\n你也可以通过命令行来进行交互：\n$ fossil clone https://klaatu@example.com/cgi-bin/repo_myproject.cgi 在本地的克隆仓库中工作时，你需要使用 push 子命令把本地的修改推送到远程的仓库，使用 pull 子命令把远程的修改拉取到本地仓库：\n$ fossil push https://klaatu@example.com/cgi-bin/repo_myproject.cgi 使用 Fossil 作为独立的托管 Fossil 将大量的权力交到了你的手中（以及你的合作者的手中），让你不再依赖托管服务。本文只是简单的介绍了基本概念。你的代码项目还会用到很多有用的 Fossil 功能。尝试一下 Fossil。它不仅会改变你对版本控制的理解；它会让你不再考虑其他的版本控制系统。\nvia: https://opensource.com/article/20/11/fossil\n作者：Klaatu 选题：lujun9972 译者：lxbwolf 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2020-12-10T21:54:47Z","permalink":"https://lxb.wiki/ff3c9770/","title":"【译】了解一下 Fossil，一个 Git 的替代品"},{"content":" 快速了解跳表 跳跃表(简称跳表)由美国计算机科学家William Pugh发明于1989年。他在论文《Skip lists: a probabilistic alternative to balanced trees》中详细介绍了跳表的数据结构和插入删除等操作。\n​\t跳表(SkipList，全称跳跃表)是用于有序元素序列快速搜索查找的一个数据结构，跳表是一个随机化的数据结构，实质就是一种可以进行二分查找的有序链表。跳表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。跳表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能。它在性能上和红黑树，AVL树不相上下，但是跳表的原理非常简单，实现也比红黑树简单很多。\n链表的优势就是更高效的插入、删除。痛点就是查询很慢很慢！每次查询都是一种O(n)复杂度的操作\n这是一个带头结点的链表(头结点相当于一个固定的入口，不存储有意义的值)，每次查找都需要一个个枚举，相当的慢，我们能不能稍微优化一下，让它稍微跳一跳呢？答案是可以的，我们知道很多算法和数据结构以空间换时间，我们在上面加一层索引，让部分节点在上层能够直接定位到，这样链表的查询时间近乎减少一半\n这样，在查询某个节点的时候，首先会从上一层快速定位节点所在的一个范围，如果找到具体范围向下然后查找代价很小，当然在表的结构设计上会增加一个向下的索引(指针)用来查找确定底层节点。平均查找速度平均为O(n/2)。但是当节点数量很大的时候，它依旧很慢很慢。我们都知道二分查找是每次都能折半的去压缩查找范围，要是有序链表也能这么跳起来那就太完美了。没错跳表就能让链表拥有近乎的接近二分查找的效率的一种数据结构，其原理依然是给上面加若干层索引，优化查找速度。\n通过上图可以看到，通过这样的一个数据结构对有序链表进行查找都能近乎二分的性能。就是在上面维护那么多层的索引，首先在最高级索引上查找最后一个小于当前查找元素的位置，然后再跳到次高级索引继续查找，直到跳到最底层为止，这时候以及十分接近要查找的元素的位置了(如果查找元素存在的话)。由于根据索引可以一次跳过多个元素，所以跳查找的查找速度也就变快了。\n对于理想的跳表，每向上一层索引节点数量都是下一层的1/2.那么如果n个节点增加的节点数量(1/2+1/4+…)\u0026lt;n。并且层数较低，对查找效果影响不大。但是对于这么一个结构，你可能会疑惑，这样完美的结构真的存在吗？大概率不存在的，因为作为一个链表，少不了增删该查的一些操作。而删除和插入可能会改变整个结构，所以上面的这些都是理想的结构，在插入的时候是否添加上层索引是个概率问题(1/2的概率)，\n跳表的增删改查 在实现本跳表的过程为了便于操作，我们将跳表的头结点(head)的key设为int的最小值(一定满足左小右大方便比较)。\n对于每个节点的设置，设置成SkipNode类，为了防止初学者将next向下还是向右搞混，直接设置right，down两个指针。\nclass SkipNode\u0026lt;T\u0026gt; { int key; T value; SkipNode right,down;//右下个方向的指针 public SkipNode (int key,T value) { this.key=key; this.value=value; } } 跳表的结构和初始化也很重要，其主要参数和初始化方法为：\npublic class SkipList \u0026lt;T\u0026gt; { SkipNode headNode;//头节点，入口 int highLevel;//当前跳表索引层数 Random random;// 用于投掷硬币 final int MAX_LEVEL = 32;//最大的层 SkipList(){ random=new Random(); headNode=new SkipNode(Integer.MIN_VALUE,null); highLevel=0; } //其他方法 } 查询操作 很多时候链表也可能这样相连仅仅是某个元素或者key作为有序的标准。所以有可能链表内部存在一些value。不过修改和查询其实都是一个操作，找到关键数字(key)。并且查找的流程也很简单，设置一个临时节点team=head。当team不为null其流程大致如下：\n(1) 从team节点出发，如果当前节点的key与查询的key相等，那么返回当前节点(如果是修改操作那么一直向下进行修改值即可)。\n(2) 如果key不相等，且右侧为null，那么证明只能向下(结果可能出现在下右方向)，此时team=team.down\n(3) 如果key不相等，且右侧不为null，且右侧节点key小于待查询的key。那么说明同级还可向右，此时team=team.right\n(4)（否则的情况）如果key不相等，且右侧不为null，且右侧节点key大于待查询的key 。那么说明如果有结果的话就在这个索引和下个索引之间，此时team=team.down。\n最终将按照这个步骤返回正确的节点或者null(说明没查到)。\n例如上图查询12节点，首先第一步从head出发发现右侧不为空，且7\u0026lt;12,向右；第二步右侧为null向下；第三步节点7的右侧10\u0026lt;12继续向右；第四步10右侧为null向下；第五步右侧12小于等于向右。第六步起始发现相等返回节点结束。\n而这块的代码也非常容易：\npublic SkipNode search(int key) { SkipNode team=headNode; while (team!=null) { if(team.key==key) { return team; } else if(team.right==null)//右侧没有了，只能下降 { team=team.down; } else if(team.right.key\u0026gt;key)//需要下降去寻找 { team=team.down; } else //右侧比较小向右 { team=team.right; } } return null; } 删除操作 删除操作比起查询稍微复杂一丢丢，但是比插入简单。删除需要改变链表结构所以需要处理好节点之间的联系。对于删除操作你需要谨记以下几点：\n(1)删除当前节点和这个节点的前后节点都有关系\n(2)删除当前层节点之后，下一层该key的节点也要删除，一直删除到最底层\n根据这两点分析一下：如果找到当前节点了，它的前面一个节点怎么查找呢？这个总不能在遍历一遍吧！有的使用四个方向的指针(上下左右)用来找到左侧节点。是可以的，但是这里可以特殊处理一下 ，不直接判断和操作节点，先找到待删除节点的左侧节点。通过这个节点即可完成删除，然后这个节点直接向下去找下一层待删除的左侧节点。设置一个临时节点team=head，当team不为null具体循环流程为：\n(1)如果team右侧为null，那么team=team.down(之所以敢直接这么判断是因为左侧有头结点在左侧，不用担心特殊情况)\n(2)如果team右侧不 为null，并且右侧的key等于待删除的key，那么先删除节点，再team向下team=team.down为了删除下层节点。\n(3)如果team右侧不 为null，并且右侧key小于待删除的key，那么team向右team=team.right。\n(4)如果team右侧不 为null，并且右侧key大于待删除的key，那么team向下team=team.down，在下层继续查找删除节点。\n例如上图删除10节点，首先team=head从team出发，7\u0026lt;10向右(team=team.right后面省略)；第二步右侧为null只能向下；第三部右侧为10在当前层删除10节点然后向下继续查找下一层10节点；第四步8\u0026lt;10向右；第五步右侧为10删除该节点并且team向下。team为null说明删除完毕退出循环。\n删除操作实现的代码如下：\npublic void delete(int key)//删除不需要考虑层数 { SkipNode team=headNode; while (team!=null) { if (team.right == null) {//右侧没有了，说明这一层找到，没有只能下降 team=team.down; } else if(team.right.key==key)//找到节点，右侧即为待删除节点 { team.right=team.right.right;//删除右侧节点 team=team.down;//向下继续查找删除 } else if(team.right.key\u0026gt;key)//右侧已经不可能了，向下 { team=team.down; } else { //节点还在右侧 team=team.right; } } } 插入操作 插入操作在实现起来是最麻烦的，需要的考虑的东西最多。回顾查询，不需要动索引；回顾删除，每层索引如果有删除就是了。但是插入不一样了，插入需要考虑是否插入索引，插入几层等问题。由于需要插入删除所以我们肯定无法维护一个完全理想的索引结构，因为它耗费的代价太高。但我们使用随机化的方法去判断是否向上层插入索引。即产生一个[0-1]的随机数如果小于0.5就向上插入索引，插入完毕后再次使用随机数判断是否向上插入索引。运气好这个值可能是多层索引，运气不好只插入最底层(这是100%插入的)。但是索引也不能不限制高度，我们一般会设置索引最高值如果大于这个值就不往上继续添加索引了。\n我们一步步剖析该怎么做，其流程为\n(1)首先通过上面查找的方式，找到待插入的左节点。插入的话最底层肯定是需要插入的，所以通过链表插入节点(需要考虑是否为末尾节点)\n(2)插入完这一层，需要考虑上一层是否插入，首先判断当前索引层级，如果大于最大值那么就停止(比如已经到最高索引层了)。否则设置一个随机数1/2的概率向上插入一层索引(因为理想状态下的就是每2个向上建一个索引节点)。\n(3)继续(2)的操作，直到概率退出或者索引层数大于最大索引层。\n在具体向上插入的时候，实质上还有非常重要的细节需要考虑。首先如何找到上层的待插入节点 ？\n这个各个实现方法可能不同，如果有左、上指向的指针那么可以向左向上找到上层需要插入的节点，但是如果只有右指向和下指向的我们也可以巧妙的借助查询过程中记录下降的节点。因为曾经下降的节点倒序就是需要插入的节点，最底层也不例外(因为没有匹配值会下降为null结束循环)。在这里我使用栈这个数据结构进行存储，当然使用List也可以。下图就是给了一个插入示意图。\n其次如果该层是目前的最高层索引，需要继续向上建立索引应该怎么办？\n首先跳表最初肯定是没索引的，然后慢慢添加节点才有一层、二层索引，但是如果这个节点添加的索引突破当前最高层，该怎么办呢？\n这时候需要注意了，跳表的head需要改变了，新建一个ListNode节点作为新的head，将它的down指向老head，将这个head节点加入栈中(也就是这个节点作为下次后面要插入的节点)，就比如上面的9节点如果运气够好在往上建立一层节点，会是这样的。\n插入上层的时候注意所有节点要新建(拷贝)，除了right的指向down的指向也不能忘记，down指向上一个节点可以用一个临时节点作为前驱节点。如果层数突破当前最高层，头head节点(入口)需要改变。\n这部分更多的细节在代码中注释解释了，详细代码为：\npublic void add(SkipNode node) { int key=node.key; SkipNode findNode=search(key); if(findNode!=null)//如果存在这个key的节点 { findNode.value=node.value; return; } Stack\u0026lt;SkipNode\u0026gt;stack=new Stack\u0026lt;SkipNode\u0026gt;();//存储向下的节点，这些节点可能在右侧插入节点 SkipNode team=headNode;//查找待插入的节点 找到最底层的哪个节点。 while (team!=null) {//进行查找操作 if(team.right==null)//右侧没有了，只能下降 { stack.add(team);//将曾经向下的节点记录一下 team=team.down; } else if(team.right.key\u0026gt;key)//需要下降去寻找 { stack.add(team);//将曾经向下的节点记录一下 team=team.down; } else //向右 { team=team.right; } } int level=1;//当前层数，从第一层添加(第一层必须添加，先添加再判断) SkipNode downNode=null;//保持前驱节点(即down的指向，初始为null) while (!stack.isEmpty()) { //在该层插入node team=stack.pop();//抛出待插入的左侧节点 SkipNode nodeTeam=new SkipNode(node.key, node.value);//节点需要重新创建 nodeTeam.down=downNode;//处理竖方向 downNode=nodeTeam;//标记新的节点下次使用 if(team.right==null) {//右侧为null 说明插入在末尾 team.right=nodeTeam; } //水平方向处理 else {//右侧还有节点，插入在两者之间 nodeTeam.right=team.right; team.right=nodeTeam; } //考虑是否需要向上 if(level\u0026gt;MAX_LEVEL)//已经到达最高级的节点啦 break; double num=random.nextDouble();//[0-1]随机数 if(num\u0026gt;0.5)//运气不好结束 break; level++; if(level\u0026gt;highLevel)//比当前最大高度要高但是依然在允许范围内 需要改变head节点 { highLevel=level; //需要创建一个新的节点 SkipNode highHeadNode=new SkipNode(Integer.MIN_VALUE, null); highHeadNode.down=headNode; headNode=highHeadNode;//改变head stack.add(headNode);//下次抛出head } } } 总结 对于上面，跳表完整分析就结束啦，当然，你可能看到不同品种跳表的实现，还有的用数组方式表示上下层的关系这样也可以，但本文只定义right和down两个方向的链表更纯正化的讲解跳表。\n对于跳表以及跳表的同类竞争产品：红黑树，为啥Redis的有序集合(zset) 使用跳表呢？因为跳表除了查找插入维护和红黑树有着差不多的效率，它是个链表，能确定范围区间，而区间问题在树上可能就没那么方便查询啦。而JDK中跳跃表ConcurrentSkipListSet和ConcurrentSkipListMap。 有兴趣的也可以查阅一下源码。\n完整代码：\nimport java.util.Random; import java.util.Stack; class SkipNode\u0026lt;T\u0026gt; { int key; T value; SkipNode right,down;//左右上下四个方向的指针 public SkipNode (int key,T value) { this.key=key; this.value=value; } } public class SkipList \u0026lt;T\u0026gt; { SkipNode headNode;//头节点，入口 int highLevel;//层数 Random random;// 用于投掷硬币 final int MAX_LEVEL = 32;//最大的层 SkipList(){ random=new Random(); headNode=new SkipNode(Integer.MIN_VALUE,null); highLevel=0; } public SkipNode search(int key) { SkipNode team=headNode; while (team!=null) { if(team.key==key) { return team; } else if(team.right==null)//右侧没有了，只能下降 { team=team.down; } else if(team.right.key\u0026gt;key)//需要下降去寻找 { team=team.down; } else //右侧比较小向右 { team=team.right; } } return null; } public void delete(int key)//删除不需要考虑层数 { SkipNode team=headNode; while (team!=null) { if (team.right == null) {//右侧没有了，说明这一层找到，没有只能下降 team=team.down; } else if(team.right.key==key)//找到节点，右侧即为待删除节点 { team.right=team.right.right;//删除右侧节点 team=team.down;//向下继续查找删除 } else if(team.right.key\u0026gt;key)//右侧已经不可能了，向下 { team=team.down; } else { //节点还在右侧 team=team.right; } } } public void add(SkipNode node) { int key=node.key; SkipNode findNode=search(key); if(findNode!=null)//如果存在这个key的节点 { findNode.value=node.value; return; } Stack\u0026lt;SkipNode\u0026gt;stack=new Stack\u0026lt;SkipNode\u0026gt;();//存储向下的节点，这些节点可能在右侧插入节点 SkipNode team=headNode;//查找待插入的节点 找到最底层的哪个节点。 while (team!=null) {//进行查找操作 if(team.right==null)//右侧没有了，只能下降 { stack.add(team);//将曾经向下的节点记录一下 team=team.down; } else if(team.right.key\u0026gt;key)//需要下降去寻找 { stack.add(team);//将曾经向下的节点记录一下 team=team.down; } else //向右 { team=team.right; } } int level=1;//当前层数，从第一层添加(第一层必须添加，先添加再判断) SkipNode downNode=null;//保持前驱节点(即down的指向，初始为null) while (!stack.isEmpty()) { //在该层插入node team=stack.pop();//抛出待插入的左侧节点 SkipNode nodeTeam=new SkipNode(node.key, node.value);//节点需要重新创建 nodeTeam.down=downNode;//处理竖方向 downNode=nodeTeam;//标记新的节点下次使用 if(team.right==null) {//右侧为null 说明插入在末尾 team.right=nodeTeam; } //水平方向处理 else {//右侧还有节点，插入在两者之间 nodeTeam.right=team.right; team.right=nodeTeam; } //考虑是否需要向上 if(level\u0026gt;MAX_LEVEL)//已经到达最高级的节点啦 break; double num=random.nextDouble();//[0-1]随机数 if(num\u0026gt;0.5)//运气不好结束 break; level++; if(level\u0026gt;highLevel)//比当前最大高度要高但是依然在允许范围内 需要改变head节点 { highLevel=level; //需要创建一个新的节点 SkipNode highHeadNode=new SkipNode(Integer.MIN_VALUE, null); highHeadNode.down=headNode; headNode=highHeadNode;//改变head stack.add(headNode);//下次抛出head } } } public void printList() { SkipNode teamNode=headNode; int index=1; SkipNode last=teamNode; while (last.down!=null){ last=last.down; } while (teamNode!=null) { SkipNode enumNode=teamNode.right; SkipNode enumLast=last.right; System.out.printf(\u0026#34;%-8s\u0026#34;,\u0026#34;head-\u0026gt;\u0026#34;); while (enumLast!=null\u0026amp;\u0026amp;enumNode!=null) { if(enumLast.key==enumNode.key) { System.out.printf(\u0026#34;%-5s\u0026#34;,enumLast.key+\u0026#34;-\u0026gt;\u0026#34;); enumLast=enumLast.right; enumNode=enumNode.right; } else{ enumLast=enumLast.right; System.out.printf(\u0026#34;%-5s\u0026#34;,\u0026#34;\u0026#34;); } } teamNode=teamNode.down; index++; System.out.println(); } } public static void main(String[] args) { SkipList\u0026lt;Integer\u0026gt;list=new SkipList\u0026lt;Integer\u0026gt;(); for(int i=1;i\u0026lt;20;i++) { list.add(new SkipNode(i,666)); } list.printList(); list.delete(4); list.delete(8); list.printList(); } } ","date":"2020-12-02T21:06:56Z","permalink":"https://lxb.wiki/942c23ec/","title":"跳表的增删改查"},{"content":" 1 Tmux 是什么？ 1.1 会话与进程 命令行的典型使用方式是，打开一个终端窗口（terminal window，以下简称\u0026quot;窗口\u0026quot;），在里面输入命令。用户与计算机的这种临时的交互，称为一次\u0026quot;会话\u0026quot;（session） 。\n会话的一个重要特点是，窗口与其中启动的进程是连在一起的。打开窗口，会话开始；关闭窗口，会话结束，会话内部的进程也会随之终止，不管有没有运行完。\n一个典型的例子就是，SSH 登录远程计算机，打开一个远程窗口执行命令。这时，网络突然断线，再次登录的时候，是找不回上一次执行的命令的。因为上一次 SSH 会话已经终止了，里面的进程也随之消失了。\n为了解决这个问题，会话与窗口可以\u0026quot;解绑\u0026quot;：窗口关闭时，会话并不终止，而是继续运行，等到以后需要的时候，再让会话\u0026quot;绑定\u0026quot;其他窗口。\n1.2 Tmux 的作用 Tmux 就是会话与窗口的\u0026quot;解绑\u0026quot;工具，将它们彻底分离。\n（1）它允许在单个窗口中，同时访问多个会话。这对于同时运行多个命令行程序很有用。\n（2） 它可以让新窗口\u0026quot;接入\u0026quot;已经存在的会话。\n（3）它允许每个会话有多个连接窗口，因此可以多人实时共享会话。\n（4）它还支持窗口任意的垂直和水平拆分。\n类似的终端复用器还有 GNU Screen。Tmux 与它功能相似，但是更易用，也更强大。\n2 基本用法 2.1 安装 Tmux 一般需要自己安装。\n# Ubuntu 或 Debian $ sudo apt-get install tmux # CentOS 或 Fedora $ sudo yum install tmux # Mac $ brew install tmux 2.2 启动与退出 安装完成后，键入tmux命令，就进入了 Tmux 窗口。\n$ tmux 上面命令会启动 Tmux 窗口，底部有一个状态栏。状态栏的左侧是窗口信息（编号和名称），右侧是系统信息。\n按下Ctrl+d或者显式输入exit命令，就可以退出 Tmux 窗口。\n$ exit 2.3 前缀键 Tmux 窗口有大量的快捷键。所有快捷键都要通过前缀键唤起。默认的前缀键是Ctrl+b，即先按下Ctrl+b，快捷键才会生效。\n举例来说，帮助命令的快捷键是Ctrl+b ?。它的用法是，在 Tmux 窗口中，先按下Ctrl+b，再按下?，就会显示帮助信息。\n然后，按下 ESC 键或q键，就可以退出帮助。\n3 会话管理 3.1 新建会话 第一个启动的 Tmux 窗口，编号是0，第二个窗口的编号是1，以此类推。这些窗口对应的会话，就是 0 号会话、1 号会话。\n使用编号区分会话，不太直观，更好的方法是为会话起名。\n$ tmux new -s \u0026lt;session-name\u0026gt; 上面命令新建一个指定名称的会话。\n3.2 分离会话 在 Tmux 窗口中，按下Ctrl+b d或者输入tmux detach命令，就会将当前会话与窗口分离。\n$ tmux detach 上面命令执行后，就会退出当前 Tmux 窗口，但是会话和里面的进程仍然在后台运行。\ntmux ls命令可以查看当前所有的 Tmux 会话。\n$ tmux ls # or $ tmux list-session 3.3 接入会话 tmux attach命令用于重新接入某个已存在的会话。\n# 使用会话编号 $ tmux attach -t 0 # 使用会话名称 $ tmux attach -t \u0026lt;session-name\u0026gt; 3.4 杀死会话 tmux kill-session命令用于杀死某个会话。\n# 使用会话编号 $ tmux kill-session -t 0 # 使用会话名称 $ tmux kill-session -t \u0026lt;session-name\u0026gt; 3.5 切换会话 tmux switch命令用于切换会话。\n# 使用会话编号 $ tmux switch -t 0 # 使用会话名称 $ tmux switch -t \u0026lt;session-name\u0026gt; 3.6 重命名会话 tmux rename-session命令用于重命名会话。\n$ tmux rename-session -t 0 \u0026lt;new-name\u0026gt; 上面命令将0号会话重命名。\n3.7 会话快捷键 下面是一些会话相关的快捷键。\nCtrl+b d：分离当前会话。 Ctrl+b s：列出所有会话。 Ctrl+b $：重命名当前会话。 4 最简操作流程 综上所述，以下是 Tmux 的最简操作流程。\n新建会话tmux new -s my_session。 在 Tmux 窗口运行所需的程序。 按下快捷键Ctrl+b d将会话分离。 下次使用时，重新连接到会话tmux attach-session -t my_session。 5 窗格操作 Tmux 可以将窗口分成多个窗格（pane），每个窗格运行不同的命令。以下命令都是在 Tmux 窗口中执行。\n5.1 划分窗格 tmux split-window命令用来划分窗格。\n# 划分上下两个窗格 $ tmux split-window # 划分左右两个窗格 $ tmux split-window -h 5.2 移动光标 tmux select-pane命令用来移动光标位置。\n# 光标切换到上方窗格 $ tmux select-pane -U # 光标切换到下方窗格 $ tmux select-pane -D # 光标切换到左边窗格 $ tmux select-pane -L # 光标切换到右边窗格 $ tmux select-pane -R 5.3 交换窗格位置 tmux swap-pane命令用来交换窗格位置。\n# 当前窗格上移 $ tmux swap-pane -U # 当前窗格下移 $ tmux swap-pane -D 5.4 窗格快捷键 下面是一些窗格操作的快捷键。\nCtrl+b %：划分左右两个窗格。 Ctrl+b \u0026quot;：划分上下两个窗格。 Ctrl+b \u0026lt;arrow key\u0026gt;：光标切换到其他窗格。\u0026lt;arrow key\u0026gt;是指向要切换到的窗格的方向键，比如切换到下方窗格，就按方向键↓。 Ctrl+b ;：光标切换到上一个窗格。 Ctrl+b o：光标切换到下一个窗格。 Ctrl+b {：当前窗格与上一个窗格交换位置。 Ctrl+b }：当前窗格与下一个窗格交换位置。 Ctrl+b Ctrl+o：所有窗格向前移动一个位置，第一个窗格变成最后一个窗格。 Ctrl+b Alt+o：所有窗格向后移动一个位置，最后一个窗格变成第一个窗格。 Ctrl+b x：关闭当前窗格。 Ctrl+b !：将当前窗格拆分为一个独立窗口。 Ctrl+b z：当前窗格全屏显示，再使用一次会变回原来大小。 Ctrl+b Ctrl+\u0026lt;arrow key\u0026gt;：按箭头方向调整窗格大小。 Ctrl+b q：显示窗格编号。 6 窗口管理 除了将一个窗口划分成多个窗格，Tmux 也允许新建多个窗口。\n6.1 新建窗口 tmux new-window命令用来创建新窗口。\n$ tmux new-window # 新建一个指定名称的窗口 $ tmux new-window -n \u0026lt;window-name\u0026gt; 6.2 切换窗口 tmux select-window命令用来切换窗口。\n# 切换到指定编号的窗口 $ tmux select-window -t \u0026lt;window-number\u0026gt; # 切换到指定名称的窗口 $ tmux select-window -t \u0026lt;window-name\u0026gt; 6.3 重命名窗口 tmux rename-window命令用于为当前窗口起名（或重命名）。\n$ tmux rename-window \u0026lt;new-name\u0026gt; 6.4 窗口快捷键 下面是一些窗口操作的快捷键。\nCtrl+b c：创建一个新窗口，状态栏会显示多个窗口的信息。 Ctrl+b p：切换到上一个窗口（按照状态栏上的顺序）。 Ctrl+b n：切换到下一个窗口。 Ctrl+b \u0026lt;number\u0026gt;：切换到指定编号的窗口，其中的\u0026lt;number\u0026gt;是状态栏上的窗口编号。 Ctrl+b w：从列表中选择窗口。 Ctrl+b ,：窗口重命名。 7 其他命令 下面是一些其他命令。\n# 列出所有快捷键，及其对应的 Tmux 命令 $ tmux list-keys # 列出所有 Tmux 命令及其参数 $ tmux list-commands # 列出当前所有 Tmux 会话的信息 $ tmux info # 重新加载当前的 Tmux 配置 $ tmux source-file ~/.tmux.conf 8 参考链接 A Quick and Easy Guide to tmux Tactical tmux: The 10 Most Important Commands Getting started with Tmux ","date":"2020-11-30T23:46:08Z","permalink":"https://lxb.wiki/176a23be/","title":"Tmux 使用教程"},{"content":" \u0026ldquo;守护进程\u0026rdquo;（daemon）就是一直在后台运行的进程（daemon）。\n如何将一个 Web 应用，启动为守护进程。\n1 问题的由来 Web应用写好后，下一件事就是启动，让它一直在后台运行。\n这并不容易。举例来说，下面是一个最简单的Node应用server.js，只有6行。\nvar http = require(\u0026#39;http\u0026#39;); http.createServer(function(req, res) { res.writeHead(200, {\u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39;}); res.end(\u0026#39;Hello World\u0026#39;); }).listen(5000); 你在命令行下启动它。\n$ node server.js 看上去一切正常，所有人都能快乐地访问 5000 端口了。但是，一旦你退出命令行窗口，这个应用就一起退出了，无法访问了。\n怎么才能让它变成系统的守护进程（daemon），成为一种服务（service），一直在那里运行呢？\n2 前台任务与后台任务 上面这样启动的脚本，称为\u0026quot;前台任务\u0026quot;（foreground job）。它会独占命令行窗口，只有运行完了或者手动中止，才能执行其他命令。\n变成守护进程的第一步，就是把它改成\u0026quot;后台任务\u0026quot;（background job）。\n$ node server.js \u0026amp; 只要在命令的尾部加上符号\u0026amp;，启动的进程就会成为\u0026quot;后台任务\u0026quot;。如果要让正在运行的\u0026quot;前台任务\u0026quot;变为\u0026quot;后台任务\u0026quot;，可以先按ctrl + z，然后执行bg命令（让最近一个暂停的\u0026quot;后台任务\u0026quot;继续执行）。\n\u0026ldquo;后台任务\u0026quot;有两个特点。\n继承当前 session （对话）的标准输出（stdout）和标准错误（stderr）。因此，后台任务的所有输出依然会同步地在命令行下显示。 不再继承当前 session 的标准输入（stdin）。你无法向这个任务输入指令了。如果它试图读取标准输入，就会暂停执行（halt）。 可以看到，\u0026ldquo;后台任务\u0026quot;与\u0026quot;前台任务\u0026quot;的本质区别只有一个：是否继承标准输入。所以，执行后台任务的同时，用户还可以输入其他命令。\n3 SIGHUP信号 变为\u0026quot;后台任务\u0026quot;后，一个进程是否就成为了守护进程呢？或者说，用户退出 session 以后，\u0026ldquo;后台任务\u0026quot;是否还会继续执行？\nLinux系统是这样设计的。\n用户准备退出 session 系统向该 session 发出SIGHUP信号 session 将SIGHUP信号发给所有子进程 子进程收到SIGHUP信号后，自动退出 上面的流程解释了，为什么\u0026quot;前台任务\u0026quot;会随着 session 的退出而退出：因为它收到了SIGHUP信号。\n那么，\u0026ldquo;后台任务\u0026quot;是否也会收到SIGHUP信号？\n这由 Shell 的huponexit参数决定的。\n$ shopt | grep huponexit 执行上面的命令，就会看到huponexit参数的值。\n大多数Linux系统，这个参数默认关闭（off）。因此，session 退出的时候，不会把SIGHUP信号发给\u0026quot;后台任务\u0026rdquo;。所以，一般来说，\u0026ldquo;后台任务\u0026quot;不会随着 session 一起退出。\n4 disown 命令 通过\u0026quot;后台任务\u0026quot;启动\u0026quot;守护进程\u0026quot;并不保险，因为有的系统的huponexit参数可能是打开的（on）。\n更保险的方法是使用disown命令。它可以将指定任务从\u0026quot;后台任务\u0026quot;列表（jobs命令的返回结果）之中移除。一个\u0026quot;后台任务\u0026quot;只要不在这个列表之中，session 就肯定不会向它发出SIGHUP信号。\n$ node server.js \u0026amp; $ disown 执行上面的命令以后，server.js进程就被移出了\u0026quot;后台任务\u0026quot;列表。你可以执行jobs命令验证，输出结果里面，不会有这个进程。\ndisown的用法如下。\n​\n# 移出最近一个正在执行的后台任务 $ disown # 移出所有正在执行的后台任务 $ disown -r # 移出所有后台任务 $ disown -a # 不移出后台任务，但是让它们不会收到SIGHUP信号 $ disown -h # 根据jobId，移出指定的后台任务 $ disown %2 $ disown -h %2 5 标准 I/O 使用disown命令之后，还有一个问题。那就是，退出 session 以后，如果后台进程与标准I/O有交互，它还是会挂掉。\n还是以上面的脚本为例，现在加入一行。\nvar http = require(\u0026#39;http\u0026#39;); http.createServer(function(req, res) { console.log(\u0026#39;server starts...\u0026#39;); // 加入此行 res.writeHead(200, {\u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39;}); res.end(\u0026#39;Hello World\u0026#39;); }).listen(5000); 启动上面的脚本，然后再执行disown命令。\n$ node server.js \u0026amp; $ disown 接着，你退出 session，访问5000端口，就会发现连不上。\n这是因为\u0026quot;后台任务\u0026quot;的标准 I/O 继承自当前 session，disown命令并没有改变这一点。一旦\u0026quot;后台任务\u0026quot;读写标准 I/O，就会发现它已经不存在了，所以就报错终止执行。\n为了解决这个问题，需要对\u0026quot;后台任务\u0026quot;的标准 I/O 进行重定向。\n$ node server.js \u0026gt; stdout.txt 2\u0026gt; stderr.txt \u0026lt; /dev/null \u0026amp; $ disown 上面这样执行，基本上就没有问题了。\n6 nohup 命令 还有比disown更方便的命令，就是nohup。\n$ nohup node server.js \u0026amp; nohup命令对server.js进程做了三件事。\n阻止SIGHUP信号发到这个进程。 关闭标准输入。该进程不再能够接收任何输入，即使运行在前台。 重定向标准输出和标准错误到文件nohup.out。 也就是说，nohup命令实际上将子进程与它所在的 session 分离了。\n注意，nohup命令不会自动把进程变为\u0026quot;后台任务\u0026rdquo;，所以必须加上\u0026amp;符号。\n7 Screen 命令与 Tmux 命令 另一种思路是使用 terminal multiplexer （终端复用器：在同一个终端里面，管理多个session），典型的就是 Screen 命令和 Tmux 命令。\n它们可以在当前 session 里面，新建另一个 session。这样的话，当前 session 一旦结束，不影响其他 session。而且，以后重新登录，还可以再连上早先新建的 session。\nScreen 的用法如下。\n# 新建一个 session $ screen $ node server.js 然后，按下ctrl + A和ctrl + D，回到原来的 session，从那里退出登录。下次登录时，再切回去。\n$ screen -r 如果新建多个后台 session，就需要为它们指定名字。\n$ screen -S name # 切回指定 session $ screen -r name $ screen -r pid_number # 列出所有 session $ screen -ls 如果要停掉某个 session，可以先切回它，然后按下ctrl + c和ctrl + d。\nTmux 比 Screen 功能更多、更强大，它的基本用法如下。\n$ tmux $ node server.js # 返回原来的session $ tmux detach 除了tmux detach，另一种方法是按下Ctrl + B和d ，也可以回到原来的 session。\n# 下次登录时，返回后台正在运行服务session $ tmux attach 如果新建多个 session，就需要为每个 session 指定名字。\n# 新建 session $ tmux new -s session_name # 切换到指定 session $ tmux attach -t session_name # 列出所有 session $ tmux list-sessions # 退出当前 session，返回前一个 session $ tmux detach # 杀死指定 session $ tmux kill-session -t session-name 8 Node 工具 对于 Node 应用来说，可以不用上面的方法，有一些专门用来启动的工具：forever，nodemon 和 pm2。\nforever 的功能很简单，就是保证进程退出时，应用会自动重启。\n# 作为前台任务启动 $ forever server.js # 作为服务进程启动 $ forever start app.js # 停止服务进程 $ forever stop Id # 重启服务进程 $ forever restart Id # 监视当前目录的文件变动，一有变动就重启 $ forever -w server.js # -m 参数指定最多重启次数 $ forever -m 5 server.js # 列出所有进程 $ forever list nodemon一般只在开发时使用，它最大的长处在于 watch 功能，一旦文件发生变化，就自动重启进程。\n# 默认监视当前目录的文件变化 $ nodemon server.js ＃ 监视指定文件的变化 $ nodemon --watch app --watch libs server.js pm2 的功能最强大，除了重启进程以外，还能实时收集日志和监控。\n# 启动应用 $ pm2 start app.js # 指定同时起多少个进程（由CPU核心数决定），组成一个集群 $ pm2 start app.js -i max # 列出所有任务 $ pm2 list # 停止指定任务 $ pm2 stop 0 ＃ 重启指定任务 $ pm2 restart 0 # 删除指定任务 $ pm2 delete 0 # 保存当前的所有任务，以后可以恢复 $ pm2 save # 列出每个进程的统计数据 $ pm2 monit # 查看所有日志 $ pm2 logs # 导出数据 $ pm2 dump # 重启所有进程 $ pm2 kill $ pm2 resurect # 启动web界面 http://localhost:9615 $ pm2 web 9 Systemd 除了专用工具以外，Linux系统有自己的守护进程管理工具 Systemd 。它是操作系统的一部分，直接与内核交互，性能出色，功能极其强大。我们完全可以将程序交给 Systemd ，让系统统一管理，成为真正意义上的系统服务。\n","date":"2020-11-03T20:49:04Z","permalink":"https://lxb.wiki/2e3ff18f/","title":"Linux 守护进程的启动方法"},{"content":" 目录栈指令 目录栈是用户最近访问过的系统目录列表，并以堆栈的形式管理。栈中的内容与Shell环境变量 DIRSTACK 的值对应\n1 dirs 1.1 功能 显示当前目录栈中的所有记录（不带参数的dirs命令显示当前目录栈中的记录）\n1.2 语法 格式：\ndirs [-clpv] [+n] [-n]\n选项\n-c 删除目录栈中的所有记录 -l 以完整格式显示(绝对路径) -p 一个目录一行的方式显示 -v 每行一个目录来显示目录栈的内容，每个目录前加上的编号 +N 显示从左到右的第n个目录，数字从0开始 -N 显示从右到左的第n个日录，数字从0开始 注意：dirs始终显示当人们目录, 再是堆栈中的内容；即使目录堆栈为空, dirs命令仍然只显示当前目录\n2 pushd 2.1 功能 将目录加入到栈顶部，并切换到该目录；若 pushd 命令不加任何参数，则会将位于记录栈最上面的2个目录对换位置\n2.2 语法 格式：\npushd [目录 | -N | +N] [-n]\n选项\n目录 将该目录加入到栈顶，并执行\u0026quot;cd 目录\u0026quot;，切换到该目录 +N 将第N个目录移至栈顶（从左边数起，数字从0开始） -N 将第N个目录移至栈顶（从右边数起，数字从0开始） -n 将目录入栈时，不切换目录 3 popd 3.1 功能 删除目录栈中的记录；如果popd命令不加任何参数，则会先删除目录栈最上面的记录，然后切换到删除过后的目录栈中的最上面的目录\n3.2 语法 格式：\npushd [-N | +N] [-n]\n选项\n+N 将第N个目录删除（从左边数起，数字从0开始） -N 将第N个目录删除（从右边数起，数字从0开始） -n 将目录出栈时，不切换目录 4 示例 入栈与出栈\n[root@root]:~# mkdir /root/dir{1,2,3,4} [root@root]:~# for ((i=1;i\u0026lt;=4;i++)); do pushd /root/dir${i}; done /root/dir1 ~ /root/dir2 /root/dir1 ~ /root/dir3 /root/dir2 /root/dir1 ~ /root/dir4 /root/dir3 /root/dir2 /root/dir1 ~ [root@root:/root/dir4]# dirs /root/dir4 /root/dir3 /root/dir2 /root/dir1 ~ dirs显出了栈中的所有目录 [root@root:/root/dir4]# popd（相当于popd +0） /root/dir3 /root/dir2 /root/dir1 ~ [root@root:/root/dir3]# dirs /root/dir3 /root/dir2 /root/dir1 ~ 可以看出/root/dir4目录已被清除，此时栈里已经没有了dir4目录，切当前目录切换为dir3 [root@root:/root/dir3]# pushd /root/dir4 /root/dir4 /root/dir3 /root/dir2 /root/dir1 ~ [root@root:/root/dir4] 不推荐以上面的方法进行切换，因为这种方式和cd没有区别。 [root@root:/root/dir4]# popd +1 /root/dir4 /root/dir2 /root/dir1 ~ 推荐以这种方式进行切换，尤其是目录层次比较多时 [root@root:/root/dir4]# popd -2 /root/dir4 /root/dir1 ~ [root@root:/root/dir2]# pushd -1 /root/dir1 ~ /root/dir2 /root/dir3 /root/dir4 [root@root:/root/dir3] 注意：最左边表示栈顶，最右边表示栈底 清空栈\n[root@root]:~# dirs ~ /root/dir2 /root/dir3 /root/dir4 /root/dir1 [root@root]:~# dirs -c [root@root](mailto:root@root):~# dirs ~ 列表形式显示的栈的内容\n[root@root:/root/dir4]# dirs -l -v 0 /root/dir4 1 /root/dir3 2 /root/dir2 3 /root/dir1 4 /root 注：如果只是两个目录之间的切换 cd -足矣，而且方便。\n","date":"2020-11-01T21:05:57Z","permalink":"https://lxb.wiki/1ca354f7/","title":"目录切换：dirs、pushd、popd命令"},{"content":" 来学习下 Go 语言的安全检查工具 gosec。\nGo 语言写的代码越来越常见，尤其是在容器、Kubernetes 或云生态相关的开发中。Docker 是最早采用 Golang 的项目之一，随后是 Kubernetes，之后大量的新项目在众多编程语言中选择了 Go。\n像其他语言一样，Go 也有它的长处和短处（如安全缺陷）。这些缺陷可能会因为语言本身的缺陷加上程序员编码不当而产生，例如，C 代码中的内存安全问题。\n无论它们出现的原因是什么，安全问题都应该在开发过程的早期修复，以免在封装好的软件中出现。幸运的是，静态分析工具可以帮你以更可重复的方式处理这些问题。静态分析工具通过解析用某种编程语言写的代码来找到问题。\n这类工具中很多被称为 linter。传统意义上，linter 更注重的是检查代码中编码问题、bug、代码风格之类的问题，它们可能不会发现代码中的安全问题。例如，Coverity 是一个很流行的工具，它可以帮助寻找 C/C++ 代码中的问题。然而，也有一些工具专门用来检查源码中的安全问题。例如，Bandit 可以检查 Python 代码中的安全缺陷。而 gosec 则用来搜寻 Go 源码中的安全缺陷。gosec 通过扫描 Go 的 AST（抽象语法树abstract syntax tree抽象语法树abstract syntax tree）来检查源码中的安全问题。\n开始使用 gosec 在开始学习和使用 gosec 之前，你需要准备一个 Go 语言写的项目。有这么多开源软件，我相信这不是问题。你可以在 GitHub 的 热门 Golang 仓库中找一个。\n本文中，我随机选了 Docker CE 项目，但你可以选择任意的 Go 项目。\n安装 Go 和 gosec 如果你还没安装 Go，你可以先从仓库中拉取下来。如果你用的是 Fedora 或其他基于 RPM 的 Linux 发行版本：\n$ dnf install golang.x86_64 如果你用的是其他操作系统，请参照 Golang 安装页面。\n使用 version 参数来验证 Go 是否安装成功：\n$ go version go version go1.14.6 linux/amd64 运行 go get 命令就可以轻松地安装 gosec：\n$ go get github.com/securego/gosec/cmd/gosec 上面这行命令会从 GitHub 下载 gosec 的源码，编译并安装到指定位置。在仓库的 README 中你还可以看到安装该工具的其他方法。\ngosec 的源码会被下载到 $GOPATH 的位置，编译出的二进制文件会被安装到你系统上设置的 bin 目录下。你可以运行下面的命令来查看 $GOPATH 和 $GOBIN 目录：\n$ go env | grep GOBIN GOBIN=\u0026#34;/root/go/gobin\u0026#34; $ go env | grep GOPATH GOPATH=\u0026#34;/root/go\u0026#34; 如果 go get 命令执行成功，那么 gosec 二进制应该就可以使用了：\n$ ls -l ~/go/bin/ total 9260 -rwxr-xr-x. 1 root root 9482175 Aug 20 04:17 gosec 你可以把 $GOPATH 下的 bin 目录添加到 $PATH 中。这样你就可以像使用系统上的其他命令一样来使用 gosec 命令行工具（CLI）了。\n$ which gosec /root/go/bin/gosec $ 使用 gosec 命令行工具的 -help 选项来看看运行是否符合预期：\n$ gosec -help gosec - Golang security checker gosec analyzes Go source code to look for common programming mistakes that can lead to security problems. VERSION: dev GIT TAG: BUILD DATE: USAGE: 之后，创建一个目录，把源码下载到这个目录作为实例项目（本例中，我用的是 Docker CE）：\n$ mkdir gosec-demo $ cd gosec-demo/ $ pwd /root/gosec-demo $ git clone https://github.com/docker/docker-ce.git Cloning into \u0026#39;docker-ce\u0026#39;... remote: Enumerating objects: 1271, done. remote: Counting objects: 100% (1271/1271), done. remote: Compressing objects: 100% (722/722), done. remote: Total 431003 (delta 384), reused 981 (delta 318), pack-reused 429732 Receiving objects: 100% (431003/431003), 166.84 MiB | 28.94 MiB/s, done. Resolving deltas: 100% (221338/221338), done. Updating files: 100% (10861/10861), done. 代码统计工具（本例中用的是 cloc）显示这个项目大部分是用 Go 写的，恰好迎合了 gosec 的功能。\n$ ./cloc /root/gosec-demo/docker-ce/ 10771 text files. 8724 unique files. 2560 files ignored. ----------------------------------------------------------------------------------- Language files blank comment code ----------------------------------------------------------------------------------- Go 7222 190785 230478 1574580 YAML 37 4831 817 156762 Markdown 529 21422 0 67893 Protocol Buffers 149 5014 16562 10071 使用默认选项运行 gosec 在 Docker CE 项目中使用默认选项运行 gosec，执行 gosec ./... 命令。屏幕上会有很多输出内容。在末尾你会看到一个简短的 “Summary”，列出了浏览的文件数、所有文件的总行数，以及源码中发现的问题数。\n$ pwd /root/gosec-demo/docker-ce $ time gosec ./... [gosec] 2020/08/20 04:44:15 Including rules: default [gosec] 2020/08/20 04:44:15 Excluding rules: default [gosec] 2020/08/20 04:44:15 Import directory: /root/gosec-demo/docker-ce/components/engine/opts [gosec] 2020/08/20 04:44:17 Checking package: opts [gosec] 2020/08/20 04:44:17 Checking file: /root/gosec-demo/docker-ce/components/engine/opts/address_pools.go [gosec] 2020/08/20 04:44:17 Checking file: /root/gosec-demo/docker-ce/components/engine/opts/env.go [gosec] 2020/08/20 04:44:17 Checking file: /root/gosec-demo/docker-ce/components/engine/opts/hosts.go # End of gosec run Summary: Files: 1278 Lines: 173979 Nosec: 4 Issues: 644 real 0m52.019s user 0m37.284s sys 0m12.734s $ 滚动屏幕你会看到不同颜色高亮的行：红色表示需要尽快查看的高优先级问题，黄色表示中优先级的问题。\n关于误判 在开始检查代码之前，我想先分享几条基本原则。默认情况下，静态检查工具会基于一系列的规则对测试代码进行分析，并报告出它们发现的所有问题。这是否意味着工具报出来的每一个问题都需要修复？非也。这个问题最好的解答者是设计和开发这个软件的人。他们最熟悉代码，更重要的是，他们了解软件会在什么环境下部署以及会被怎样使用。\n这个知识点对于判定工具标记出来的某段代码到底是不是安全缺陷至关重要。随着工作时间和经验的积累，你会慢慢学会怎样让静态分析工具忽略非安全缺陷，使报告内容的可执行性更高。因此，要判定 gosec 报出来的某个问题是否需要修复，让一名有经验的开发者对源码做人工审计会是比较好的办法。\n高优先级问题 从输出内容看，gosec 发现了 Docker CE 的一个高优先级问题，它使用的是低版本的 TLS（传输层安全Transport Layer Security传输层安全Transport Layer Security）。无论什么时候，使用软件和库的最新版本都是确保它更新及时、没有安全问题的最好的方法。\n[/root/gosec-demo/docker-ce/components/engine/daemon/logger/splunk/splunk.go:173] - G402 (CWE-295): TLS MinVersion too low. (Confidence: HIGH, Severity: HIGH) 172: \u0026gt; 173: tlsConfig := \u0026amp;tls.Config{} 174: 它还发现了一个弱随机数生成器。它是不是一个安全缺陷，取决于生成的随机数的使用方式。\n[/root/gosec-demo/docker-ce/components/engine/pkg/namesgenerator/names-generator.go:843] - G404 (CWE-338): Use of weak random number generator (math/rand instead of crypto/rand) (Confidence: MEDIUM, Severity: HIGH) 842: begin: \u0026gt; 843: name := fmt.Sprintf(\u0026#34;%s_%s\u0026#34;, left[rand.Intn(len(left))], right[rand.Intn(len(right))]) 844: if name == \u0026#34;boring_wozniak\u0026#34; /* Steve Wozniak is not boring */ { 中优先级问题 这个工具还发现了一些中优先级问题。它标记了一个通过与 tar 相关的解压炸弹这种方式实现的潜在的 DoS 威胁，这种方式可能会被恶意的攻击者利用。\n[/root/gosec-demo/docker-ce/components/engine/pkg/archive/copy.go:357] - G110 (CWE-409): Potential DoS vulnerability via decompression bomb (Confidence: MEDIUM, Severity: MEDIUM) 356: \u0026gt; 357: if _, err = io.Copy(rebasedTar, srcTar); err != nil { 358: w.CloseWithError(err) 它还发现了一个通过变量访问文件的问题。如果恶意使用者能访问这个变量，那么他们就可以改变变量的值去读其他文件。\n[/root/gosec-demo/docker-ce/components/cli/cli/context/tlsdata.go:80] - G304 (CWE-22): Potential file inclusion via variable (Confidence: HIGH, Severity: MEDIUM) 79: if caPath != \u0026#34;\u0026#34; { \u0026gt; 80: if ca, err = ioutil.ReadFile(caPath); err != nil { 81: return nil, err 文件和目录通常是操作系统安全的最基础的元素。这里，gosec 报出了一个可能需要你检查目录的权限是否安全的问题。\n[/root/gosec-demo/docker-ce/components/engine/contrib/apparmor/main.go:41] - G301 (CWE-276): Expect directory permissions to be 0750 or less (Confidence: HIGH, Severity: MEDIUM) 40: // make sure /etc/apparmor.d exists \u0026gt; 41: if err := os.MkdirAll(path.Dir(apparmorProfilePath), 0755); err != nil { 42: log.Fatal(err) 你经常需要在源码中启动命令行工具。Go 使用内建的 exec 库来实现。仔细地分析用来调用这些工具的变量，就能发现安全缺陷。\n[/root/gosec-demo/docker-ce/components/engine/testutil/fakestorage/fixtures.go:59] - G204 (CWE-78): Subprocess launched with variable (Confidence: HIGH, Severity: MEDIUM) 58: \u0026gt; 59: cmd := exec.Command(goCmd, \u0026#34;build\u0026#34;, \u0026#34;-o\u0026#34;, filepath.Join(tmp, \u0026#34;httpserver\u0026#34;), \u0026#34;github.com/docker/docker/contrib/httpserver\u0026#34;) 60: cmd.Env = append(os.Environ(), []string{ 低优先级问题 在这个输出中，gosec 报出了一个 unsafe 调用相关的低优先级问题，这个调用会绕开 Go 提供的内存保护。再仔细分析下你调用 unsafe 的方式，看看是否有被别人利用的可能性。\n[/root/gosec-demo/docker-ce/components/engine/pkg/archive/changes_linux.go:264] - G103 (CWE-242): Use of unsafe calls should be audited (Confidence: HIGH, Severity: LOW) 263: for len(buf) \u0026gt; 0 { \u0026gt; 264: dirent := (*unix.Dirent)(unsafe.Pointer(\u0026amp;buf[0])) 265: buf = buf[dirent.Reclen:] [/root/gosec-demo/docker-ce/components/engine/pkg/devicemapper/devmapper_wrapper.go:88] - G103 (CWE-242): Use of unsafe calls should be audited (Confidence: HIGH, Severity: LOW) 87: func free(p *C.char) { \u0026gt; 88: C.free(unsafe.Pointer(p)) 89: } 它还标记了源码中未处理的错误。源码中出现的错误你都应该处理。\n[/root/gosec-demo/docker-ce/components/cli/cli/command/image/build/context.go:172] - G104 (CWE-703): Errors unhandled. (Confidence: HIGH, Severity: LOW) 171: err := tar.Close() \u0026gt; 172: os.RemoveAll(dockerfileDir) 173: return err 自定义 gosec 扫描 使用 gosec 的默认选项会带来很多的问题。然而，经过人工审计，随着时间推移你会掌握哪些问题是不需要标记的。你可以自己指定排除和包含哪些测试。\n我上面提到过，gosec 是基于一系列的规则从 Go 源码中查找问题的。下面是它使用的完整的规则列表：\nG101：查找硬编码凭证 G102：绑定到所有接口 G103：审计 unsafe 块的使用 G104：审计未检查的错误 G106：审计 ssh.InsecureIgnoreHostKey 的使用 G107: 提供给 HTTP 请求的 url 作为污点输入 G108: /debug/pprof 上自动暴露的剖析端点 G109: strconv.Atoi 转换到 int16 或 int32 时潜在的整数溢出 G110: 潜在的通过解压炸弹实现的 DoS G201：SQL 查询构造使用格式字符串 G202：SQL 查询构造使用字符串连接 G203：在 HTML 模板中使用未转义的数据 G204：审计命令执行情况 G301：创建目录时文件权限分配不合理 G302：使用 chmod 时文件权限分配不合理 G303：使用可预测的路径创建临时文件 G304：通过污点输入提供的文件路径 G305：提取 zip/tar 文档时遍历文件 G306: 写到新文件时文件权限分配不合理 G307: 把返回错误的函数放到 defer 内 G401：检测 DES、RC4、MD5 或 SHA1 的使用 G402：查找错误的 TLS 连接设置 G403：确保最小 RSA 密钥长度为 2048 位 G404：不安全的随机数源（rand） G501：导入黑名单列表：crypto/md5 G502：导入黑名单列表：crypto/des G503：导入黑名单列表：crypto/rc4 G504：导入黑名单列表：net/http/cgi G505：导入黑名单列表：crypto/sha1 G601: 在 range 语句中使用隐式的元素别名 排除指定的测试 你可以自定义 gosec 来避免对已知为安全的问题进行扫描和报告。你可以使用 -exclude 选项和上面的规则编号来忽略指定的问题。\n例如，如果你不想让 gosec 检查源码中硬编码凭证相关的未处理的错误，那么你可以运行下面的命令来忽略这些错误：\n$ gosec -exclude=G104 ./... $ gosec -exclude=G104,G101 ./... 有时候你知道某段代码是安全的，但是 gosec 还是会报出问题。然而，你又不想完全排除掉整个检查，因为你想让 gosec 检查新增的代码。通过在你已知为安全的代码块添加 #nosec 标记可以避免 gosec 扫描。这样 gosec 会继续扫描新增代码，而忽略掉 #nosec 标记的代码块。\n运行指定的检查 另一方面，如果你只想检查指定的问题，你可以通过 -include 选项和规则编号来告诉 gosec 运行哪些检查：\n$ gosec -include=G201,G202 ./... 扫描测试文件 Go 语言自带对测试的支持，通过单元测试来检验一个元素是否符合预期。在默认模式下，gosec 会忽略测试文件，你可以使用 -tests 选项把它们包含进来：\ngosec -tests ./... 修改输出的格式 找出问题只是它的一半功能；另一半功能是把它检查到的问题以用户友好同时又方便工具处理的方式报告出来。幸运的是，gosec 可以用不同的方式输出。例如，如果你想看 JSON 格式的报告，那么就使用 -fmt 选项指定 JSON 格式并把结果保存到 results.json 文件中：\n$ gosec -fmt=json -out=results.json ./... $ ls -l results.json -rw-r--r--. 1 root root 748098 Aug 20 05:06 results.json $ { \u0026#34;severity\u0026#34;: \u0026#34;LOW\u0026#34;, \u0026#34;confidence\u0026#34;: \u0026#34;HIGH\u0026#34;, \u0026#34;cwe\u0026#34;: { \u0026#34;ID\u0026#34;: \u0026#34;242\u0026#34;, \u0026#34;URL\u0026#34;: \u0026#34;https://cwe.mitre.org/data/definitions/242.html\u0026#34; }, \u0026#34;rule_id\u0026#34;: \u0026#34;G103\u0026#34;, \u0026#34;details\u0026#34;: \u0026#34;Use of unsafe calls should be audited\u0026#34;, \u0026#34;file\u0026#34;: \u0026#34;/root/gosec-demo/docker-ce/components/engine/daemon/graphdriver/graphtest/graphtest_unix.go\u0026#34;, \u0026#34;code\u0026#34;: \u0026#34;304: \\t// Cast to []byte\\n305: \\theader := *(*reflect.SliceHeader)(unsafe.Pointer(\\u0026buf))\\n306: \\theader. Len *= 8\\n\u0026#34;, \u0026#34;line\u0026#34;: \u0026#34;305\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;36\u0026#34; }, 用 gosec 检查容易被发现的问题 静态检查工具不能完全代替人工代码审计。然而，当代码量变大、有众多开发者时，这样的工具往往有助于以可重复的方式找出容易被发现的问题。它对于帮助新开发者识别和在编码时避免引入这些安全缺陷很有用。\nvia: https://opensource.com/article/20/9/gosec\n作者：Gaurav Kamathe 选题：lujun9972 译者：lxbowlf 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2020-10-19T23:36:00Z","permalink":"https://lxb.wiki/a59515fd/","title":"【译】使用 gosec 检查 Go 代码中的安全问题"},{"content":" header(\u0026#34;Content-type: text/html; charset=utf-8\u0026#34;); function checkHex($img) { $status = 0; $tips = array( \u0026#34;0\u0026#34; =\u0026gt; \u0026#34;文件没问题\u0026#34;, \u0026#34;5\u0026#34; =\u0026gt; \u0026#34;文件有毒\u0026#34;, \u0026#34;-1\u0026#34; =\u0026gt; \u0026#34;文件没有上传\u0026#34; ); if (file_exists($img)) { $resource = fopen($img, \u0026#39;rb\u0026#39;); $fileSize = filesize($img); fseek($resource, 0); if ($fileSize \u0026gt; 512) { // 取头和尾 $hexCode = bin2hex(fread($resource, 512)); fseek($resource, $fileSize - 512); $hexCode .= bin2hex(fread($resource, 512)); } else { // 取全部 $hexCode = bin2hex(fread($resource, $fileSize)); } fclose($resource); /* 匹配16进制中的 \u0026lt;% ( ) %\u0026gt; */ /* 匹配16进制中的 \u0026lt;? ( ) ?\u0026gt; */ /* 匹配16进制中的 \u0026lt;script | /script\u0026gt; 大小写亦可 */ if (preg_match(\u0026#34;/(3c25.*?28.*?29.*?253e)|(3c3f.*?28.*?29.*?3f3e)|(3C534352495054)|(2F5343524950543E)|(3C736372697074)|(2F7363726970743E)/is\u0026#34;, $hexCode)) { $status = 5; } } else { $status = -1; } return $tips[$status]; } $rs = checkHex(\u0026#34;du.png\u0026#34;); print_r($rs); ","date":"2020-10-15T19:59:17Z","permalink":"https://lxb.wiki/9a49b652/","title":"PHP检测图片是否有木马"},{"content":" goreplay简介 https://github.com/buger/goreplay\nhttps://goreplay.org\nGoReplay是一个开源工具，用于捕获实时HTTP流量并将其重放到测试环境中，以便使用真实数据持续测试系统。 GoReplay不是代理，而是监听网络接口上的流量，不需要更改生产基础架构，而是在与服务相同的计算机上运行GoReplay守护程序。\ngoreplay工作原理 goreplay常见用法 1. 简单的 HTTP 流量复制： gor –input-raw :80 –output-http “http://staging.com” 2.HTTP 流量复制频率控制： gor –input-tcp :28020 –output-http “http://staging.com|10″ 3.HTTP 流量复制缩小： gor –input-raw :80 –output-tcp “replay.local:28020|10%” 4.HTTP 流量记录到本地文件： gor –input-raw :80 –output-file requests.gor 5.HTTP 流量回放和压测： gor –input-file “requests.gor|200%” –output-http “staging.com” 6.HTTP 流量过滤复制： gor –input-raw :8080 –output-http staging.com –output-http-url-regexp ^www. 7.HTTP指定接口流量复制： gor --input-raw :80 --http-allow-url \u0026#39;/api/v1\u0026#39; --output-stdout //--output-stdout表示直接在控制台输出 gor参数 [root@~]# gor --help Gor is a simple http traffic replication tool written in Go. Its main goal is to replay traffic from production servers to staging and dev environments. Project page: https://github.com/buger/gor Author: \u0026lt;Leonid Bugaev\u0026gt; leonsbox@gmail.com Current Version: 1.0.0 -copy-buffer-size int Set the buffer size for an individual request (default 5M) (default 5242880) -cpuprofile string write cpu profile to file -debug verbose\t//打开debug模式，显示所有接口的流量 Turn on debug output, shows all intercepted traffic. Works only when with verbose flag -exit-after duration exit after specified duration -http-allow-header value //用一个正则表达式来匹配http头部，如果请求的头部没有匹配上，则被拒绝 A regexp to match a specific header against. Requests with non-matching headers will be dropped: gor --input-raw :8080 --output-http staging.com --http-allow-header api-version:^v1 -http-allow-method value // 类似于一个白名单机制来允许通过的http请求方法，除此之外的方法都被拒绝. Whitelist of HTTP methods to replay. Anything else will be dropped: gor --input-raw :8080 --output-http staging.com --http-allow-method GET --http-allow-method OPTIONS -http-allow-url value //一个正则表达式用来匹配url， 用来过滤完全匹配的的url，在此之外的都被过滤掉 A regexp to match requests against. Filter get matched against full url with domain. Anything else will be dropped: gor --input-raw :8080 --output-http staging.com --http-allow-url ^www. -http-basic-auth-filter value //匹配认证头重放 A regexp to match the decoded basic auth string against. Requests with non-matching headers will be dropped: gor --input-raw :8080 --output-http staging.com --http-basic-auth-filter \u0026#34;^customer[0-9].*\u0026#34; -http-disallow-header value //用一个正则表达式来匹配http头部，匹配到的请求会被拒绝掉 A regexp to match a specific header against. Requests with matching headers will be dropped: gor --input-raw :8080 --output-http staging.com --http-disallow-header \u0026#34;User-Agent: Replayed by Gor\u0026#34; -http-disallow-url value //用一个正则表达式来匹配url，如果请求匹配上了，则会被拒绝 A regexp to match requests against. Filter get matched against full url with domain. Anything else will be forwarded: gor --input-raw :8080 --output-http staging.com --http-disallow-url ^www. -http-header-limiter value\t//读取请求，基于FNV32-1A散列来拒绝一定比例的特殊请求 Takes a fraction of requests, consistently taking or rejecting a request based on the FNV32-1A hash of a specific header: gor --input-raw :8080 --output-http staging.com --http-header-limiter user-id:25% -http-original-host //在--output-http的输出中，通常gor会使用取代请求的http头，所以应该禁用该选项，保留原始的主机头 Normally gor replaces the Host http header with the host supplied with --output-http. This option disables that behavior, preserving the original Host header. -http-param-limiter value Takes a fraction of requests, consistently taking or rejecting a request based on the FNV32-1A hash of a specific GET param: gor --input-raw :8080 --output-http staging.com --http-param-limiter user_id:25% -http-pprof :8181 Enable profiling. Starts http server on specified port, exposing special /debug/pprof endpoint. Example: :8181 -http-rewrite-header value Rewrite the request header based on a mapping: gor --input-raw :8080 --output-http staging.com --http-rewrite-header Host: (.*).example.com,$1.beta.example.com -http-rewrite-url value Rewrite the request url based on a mapping: gor --input-raw :8080 --output-http staging.com --http-rewrite-url /v1/user/([^\\/]+)/ping:/v2/user/$1/ping -http-set-header value Inject additional headers to http reqest: gor --input-raw :8080 --output-http staging.com --http-set-header \u0026#39;User-Agent: Gor\u0026#39; -http-set-param value Set request url param, if param already exists it will be overwritten: gor --input-raw :8080 --output-http staging.com --http-set-param api_key=1 -input-dummy value Used for testing outputs. Emits \u0026#39;Get /\u0026#39; request every 1s -input-file value\t//从一个文件中读取请求 Read requests from file: gor --input-file ./requests.gor --output-http staging.com -input-file-loop Loop input files, useful for performance testing. -input-kafka-host string Send request and response stats to Kafka: gor --output-stdout --input-kafka-host \u0026#39;192.168.0.1:9092,192.168.0.2:9092\u0026#39; -input-kafka-json-format If turned on, it will assume that messages coming in JSON format rather than GoReplay text format. -input-kafka-topic string Send request and response stats to Kafka: gor --output-stdout --input-kafka-topic \u0026#39;kafka-log\u0026#39; -input-raw value Capture traffic from given port (use RAW sockets and require *sudo* access): # Capture traffic from 8080 port gor --input-raw :8080 --output-http staging.com -input-raw-bpf-filter string BPF filter to write custom expressions. Can be useful in case of non standard network interfaces like tunneling or SPAN port. Example: --input-raw-bpf-filter \u0026#39;dst port 80\u0026#39; -input-raw-buffer-size int Controls size of the OS buffer (in bytes) which holds packets until they dispatched. Default value depends by system: in Linux around 2MB. If you see big package drop, increase this value. -input-raw-engine libpcap Intercept traffic using libpcap (default), and `raw_socket` (default \u0026#34;libpcap\u0026#34;) -input-raw-expire duration How much it should wait for the last TCP packet, till consider that TCP message complete. (default 2s) -input-raw-immediate-mode Set pcap interface to immediate mode. -input-raw-override-snaplen Override the capture snaplen to be 64k. Required for some Virtualized environments -input-raw-realip-header string If not blank, injects header with given name and real IP value to the request payload. Usually this header should be named: X-Real-IP -input-raw-timestamp-type string Possible values: PCAP_TSTAMP_HOST, PCAP_TSTAMP_HOST_LOWPREC, PCAP_TSTAMP_HOST_HIPREC, PCAP_TSTAMP_ADAPTER, PCAP_TSTAMP_ADAPTER_UNSYNCED. This values not supported on all systems, GoReplay will tell you available values of you put wrong one. -input-raw-track-response If turned on Gor will track responses in addition to requests, and they will be available to middleware and file output. -input-tcp value\t// 用来在多个gor之间流转流量 Used for internal communication between Gor instances. Example: # Receive requests from other Gor instances on 28020 port, and redirect output to staging gor --input-tcp :28020 --output-http staging.com -input-tcp-certificate string Path to PEM encoded certificate file. Used when TLS turned on. -input-tcp-certificate-key string Path to PEM encoded certificate key file. Used when TLS turned on. -input-tcp-secure Turn on TLS security. Do not forget to specify certificate and key files. -memprofile string write memory profile to this file -middleware string Used for modifying traffic using external command -output-dummy value\t//用来测试输入，打印出接收的数据. DEPRECATED: use --output-stdout instead -output-file value\t//把进入的请求写入一个文件中 Write incoming requests to file: gor --input-raw :80 --output-file ./requests.gor -output-file-append The flushed chunk is appended to existence file or not. -output-file-flush-interval duration Interval for forcing buffer flush to the file, default: 1s. (default 1s) -output-file-max-size-limit value Max size of output file, Default: 1TB (default -1) -output-file-queue-limit int The length of the chunk queue. Default: 256 (default 256) -output-file-size-limit value Size of each chunk. Default: 32mb (default 33554432) -output-http value\t//转发进入的请求到一个http地址上 Forwards incoming requests to given http address. # Redirect all incoming requests to staging.com address gor --input-raw :80 --output-http http://staging.com -output-http-compatibility-mode Use standard Go client, instead of built-in implementation. Can be slower, but more compatible. -output-http-debug Enables http debug output. -output-http-elasticsearch string\t//把请求和响应状态发送到ElasticSearch Send request and response stats to ElasticSearch: gor --input-raw :8080 --output-http staging.com --output-http-elasticsearch \u0026#39;es_host:api_port/index_name\u0026#39; -output-http-header --output-http-header WARNING: --output-http-header DEPRECATED, use `--http-set-header` instead -output-http-header-filter --output-http-header-filter WARNING: --output-http-header-filter DEPRECATED, use `--http-allow-header` instead -output-http-header-hash-filter output-http-header-hash-filter WARNING: output-http-header-hash-filter DEPRECATED, use `--http-header-hash-limiter` instead -output-http-method --output-http-method WARNING: --output-http-method DEPRECATED, use `--http-allow-method` instead -output-http-queue-len int Number of requests that can be queued for output, if all workers are busy. default = 1000 (default 1000) -output-http-redirects int\t//设置多少次重定向被允许 Enable how often redirects should be followed. -output-http-response-buffer int HTTP response buffer size, all data after this size will be discarded. -output-http-rewrite-url --output-http-rewrite-url WARNING: --output-http-rewrite-url DEPRECATED, use `--http-rewrite-url` instead -output-http-stats\t//每5秒钟输出一次输出队列的状态 Report http output queue stats to console every N milliseconds. See output-http-stats-ms -output-http-stats-ms int Report http output queue stats to console every N milliseconds. default: 5000 (default 5000) -output-http-timeout duration\t//指定http的request/response超时时间，默认是5秒 Specify HTTP request/response timeout. By default 5s. Example: --output-http-timeout 30s (default 5s) -output-http-track-response If turned on, HTTP output responses will be set to all outputs like stdout, file and etc. -output-http-url-regexp --output-http-url-regexp WARNING: --output-http-url-regexp DEPRECATED, use `--http-allow-url` instead -output-http-workers int\t// gor默认是动态的扩展工作者数量，你也可以指定固定数量的工作者 Gor uses dynamic worker scaling. Enter a number to set a maximum number of workers. default = 0 = unlimited. -output-http-workers-min int Gor uses dynamic worker scaling. Enter a number to set a minimum number of workers. default = 1. -output-kafka-host string Read request and response stats from Kafka: gor --input-raw :8080 --output-kafka-host \u0026#39;192.168.0.1:9092,192.168.0.2:9092\u0026#39; -output-kafka-json-format If turned on, it will serialize messages from GoReplay text format to JSON. -output-kafka-topic string Read request and response stats from Kafka: gor --input-raw :8080 --output-kafka-topic \u0026#39;kafka-log\u0026#39; -output-null Used for testing inputs. Drops all requests. -output-stdout Used for testing inputs. Just prints to console data coming from inputs. -output-tcp value\t//用来在多个gor之间流转流量 Used for internal communication between Gor instances. Example: # Listen for requests on 80 port and forward them to other Gor instance on 28020 port gor --input-raw :80 --output-tcp replay.local:28020 -output-tcp-secure Use TLS secure connection. --input-file on another end should have TLS turned on as well. -output-tcp-stats\t//每5秒钟报告一次tcp输出队列的状态 Report TCP output queue stats to console every 5 seconds. -prettify-http If enabled, will automatically decode requests and responses with: Content-Encodning: gzip and Transfer-Encoding: chunked. Useful for debugging, in conjuction with --output-stdout -split-output true By default each output gets same traffic. If set to true it splits traffic equally among all outputs. -stats\t//打开输出队列的状态 Turn on queue stats output -verbose Turn on more verbose output ","date":"2020-10-04T23:17:17Z","permalink":"https://lxb.wiki/8c9efcce/","title":"流量复制重放工具goreplay"},{"content":" 问题描述 sed -i \u0026quot;s/old/new/g\u0026quot; file.txt\n如果 new 是个路径，即字符串中含有/，这么执行会报错\n初级思路 把 new 中的 / 进行转义\n比如 new 为 /home/users/config.yaml\n替换时\nsed -i \u0026quot;s/old/\\/home\\/users\\/config.yaml/g\u0026quot; file.txt\n如果 new 是变量，\nnew=\u0026#34;/home/users/config.yaml\u0026#34; new_sed=$(echo $new | sed -e \u0026#39;s/\\//\\\\\\//g\u0026#39;) sed -i \u0026#34;s/old/${new_sed}/g\u0026#34; file.txt 更好的解决方案 转义会降低可读性，只需用其他特殊字符作为sed表达式的“分隔符”（取代默认的/）即可。 例如：sed 's#\\$CONFIG#/home/users/config.yaml#g'，使用#代替/从而避免大量转义。\n你可以尝试一下 echo aabbccdd | sed 's#aa#bb#g' | sed 's?bb?cc?g' | sed 's@cc@dd@g' | sed 's%dd%ee%g' 用任意字符作间隔\n这是 sed 命令方便用户的一个特性，vim 中的 :s 也同样支持\n","date":"2020-09-13T21:16:00Z","permalink":"https://lxb.wiki/e4c7cf89/","title":"sed替换含有路径的字符串"},{"content":" 现象 使用 hexo-toc 生成文章目录时，点击某个目录，url 变成\nhttp://localhost:4000/690c8418/#null 原因 插件在把 markdown 编译成 HTML 时，\n## title 会编译为\n\u0026lt;h2\u0026gt;\u0026lt;span id=\u0026#34;title\u0026#34;\u0026gt;title\u0026lt;/span\u0026gt;\u0026lt;/h2\u0026gt; 而在插件源码的这次提交之前，是会编译成\n\u0026lt;h2 id=\u0026#34;title\u0026#34;\u0026gt;title\u0026lt;/h2\u0026gt; 因此新版本的 hexo-toc 生成 TOC 时，元素没有 id 这个属性，进而导致 TOC 中的锚点失效。\n修复方法 修改 node_modules/hexo-toc/lib/filter.js\n把 28 行的 $title.attr('id', id); 注释打开\n把 31 行的 $title.removeAttr('id'); 注释掉\n","date":"2020-09-03T21:02:23Z","permalink":"https://lxb.wiki/b4c41686/","title":"hexo使用hexo-toc锚点失效问题"},{"content":" Lambda 表达式是现代 C++ 中最重要的特性之一，而 Lambda 表达式，实际上就是提供了一个类似匿名函数的特性， 而匿名函数则是在需要一个函数，但是又不想费力去命名一个函数的情况下去使用的。这样的场景其实有很多很多， 所以匿名函数几乎是现代编程语言的标配。\n基础 Lambda 表达式的基本语法如下：\n[捕获列表](参数列表) mutable(可选) 异常属性 -\u0026gt; 返回类型 { // 函数体 } 上面的语法规则除了 [捕获列表] 内的东西外，其他部分都很好理解，只是一般函数的函数名被略去， 返回值使用了一个 -\u0026gt; 的形式进行（我们在上一节前面的尾返回类型已经提到过这种写法了）。\n所谓捕获列表，其实可以理解为参数的一种类型，lambda 表达式内部函数体在默认情况下是不能够使用函数体外部的变量的， 这时候捕获列表可以起到传递外部数据的作用。根据传递的行为，捕获列表也分为以下几种：\n1. 值捕获 与参数传值类似，值捕获的前提是变量可以拷贝，不同之处则在于，被捕获的变量在 lambda 表达式被创建时拷贝， 而非调用时才拷贝：\nvoid lambda_value_capture() { int value = 1; auto copy_value = [value] { return value; }; value = 100; auto stored_value = copy_value(); std::cout \u0026lt;\u0026lt; \u0026#34;stored_value = \u0026#34; \u0026lt;\u0026lt; stored_value \u0026lt;\u0026lt; std::endl; // 这时, stored_value == 1, 而 value == 100. // 因为 copy_value 在创建时就保存了一份 value 的拷贝 } 2. 引用捕获 与引用传参类似，引用捕获保存的是引用，值会发生变化。\nvoid lambda_reference_capture() { int value = 1; auto copy_value = [\u0026amp;value] { return value; }; value = 100; auto stored_value = copy_value(); std::cout \u0026lt;\u0026lt; \u0026#34;stored_value = \u0026#34; \u0026lt;\u0026lt; stored_value \u0026lt;\u0026lt; std::endl; // 这时, stored_value == 100, value == 100. // 因为 copy_value 保存的是引用 } 3. 隐式捕获 手动书写捕获列表有时候是非常复杂的，这种机械性的工作可以交给编译器来处理，这时候可以在捕获列表中写一个 \u0026amp; 或 = 向编译器声明采用引用捕获或者值捕获.\n总结一下，捕获提供了lambda 表达式对外部值进行使用的功能，捕获列表的最常用的四种形式可以是：\n[] 空捕获列表 [name1, name2, …] 捕获一系列变量 [\u0026amp;] 引用捕获, 让编译器自行推导捕获列表 [=] 值捕获, 让编译器执行推导引用列表 4. 表达式捕获 上面提到的值捕获、引用捕获都是已经在外层作用域声明的变量，因此这些捕获方式捕获的均为左值，而不能捕获右值。\nC++14 给与了我们方便，允许捕获的成员用任意的表达式进行初始化，这就允许了右值的捕获， 被声明的捕获变量类型会根据表达式进行判断，判断方式与使用 auto 本质上是相同的：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;utility\u0026gt; int main() { auto important = std::make_unique\u0026lt;int\u0026gt;(1); auto add = [v1 = 1, v2 = std::move(important)](int x, int y) -\u0026gt; int { return x+y+v1+(*v2); }; std::cout \u0026lt;\u0026lt; add(3,4) \u0026lt;\u0026lt; std::endl; return 0; } 在上面的代码中，important 是一个独占指针，是不能够被捕获到的，这时候我们需要将其转移为右值， 在表达式中初始化。\n泛型 Lambda 上一节中我们提到了 auto 关键字不能够用在参数表里，这是因为这样的写法会与模板的功能产生冲突。 但是 Lambda 表达式并不是普通函数，所以 Lambda 表达式并不能够模板化。 这就为我们造成了一定程度上的麻烦：参数表不能够泛化，必须明确参数表类型。\n幸运的是，这种麻烦只存在于 C++11 中，从 C++14 开始， Lambda 函数的形式参数可以使用 auto 关键字来产生意义上的泛型：\nauto add = [](auto x, auto y) { return x+y; }; add(1, 2); add(1.1, 2.2); ","date":"2020-08-21T07:13:27Z","permalink":"https://lxb.wiki/e4d97659/","title":"C++ Lambda 表达式"},{"content":" Pillow(PIL) 库中的 Image 类\n\u0026gt;\u0026gt;\u0026gt; from PIL import Image \u0026gt;\u0026gt;\u0026gt; im = Image.open(\u0026#34;lena.ppm\u0026#34;) \u0026gt;\u0026gt;\u0026gt; from __future__ import print_function \u0026gt;\u0026gt;\u0026gt; print(im.format, im.size, im.mode) PPM (512, 512) RGB format 这个属性代表图片文件的扩展名, 如果图片文件打开失败, 则其值为None. size 这个属性代表图片的大小, 以像素为单位, 使用包含两个元素的元组来返回. mode 这个属性代表图片的band属性, 一般情况(黑白)下为 “L”, 当图片是彩色的时候是 “RGB”, 如果图片经过压缩, 则是 “CMYK”.\nPIL中所涉及的基本概念 通道（bands）、模式（mode）、尺寸（size）、坐标系统（coordinate system）、调色板（palette）、信息（info）和滤波器（filters）。\nPIL中有九种不同模式。 分别为1，L，P，RGB，RGBA，CMYK，YCbCr，I，F。\n模式 1 二值图像\n模式“1”为二值图像，非黑即白。但是它每个像素用8个bit表示，0表示黑，255表示白。\n\u0026gt;\u0026gt;\u0026gt;from PIL import Image \u0026gt;\u0026gt;\u0026gt; lena =Image.open(\u0026#34;D:\\\\Code\\\\Python\\\\test\\\\img\\\\lena.jpg\u0026#34;) \u0026gt;\u0026gt;\u0026gt; lena.mode \u0026#39;RGB\u0026#39; \u0026gt;\u0026gt;\u0026gt; lena.getpixel((0,0)) (197, 111, 78) \u0026gt;\u0026gt;\u0026gt; lena_1 = lena.convert(\u0026#34;1\u0026#34;) \u0026gt;\u0026gt;\u0026gt; lena_1.mode \u0026#39;1\u0026#39; \u0026gt;\u0026gt;\u0026gt; lena_1.size (512, 512) \u0026gt;\u0026gt;\u0026gt;lena_1.getpixel((0,0)) 255 \u0026gt;\u0026gt;\u0026gt; lena_1.getpixel((10,10)) 255 \u0026gt;\u0026gt;\u0026gt;lena_1.getpixel((10,120)) 0 \u0026gt;\u0026gt;\u0026gt;lena_1.getpixel((130,120)) 255 模式 L\n模式“L”为灰色图像，它的每个像素用8个bit表示，0表示黑，255表示白，其他数字表示不同的灰度\n模式 P\n模式“P”为8位彩色图像，它的每个像素用8个bit表示，其对应的彩色值是按照调色板查询出来的\n模式“RGBA”\n模式“RGBA”为32位彩色图像，它的每个像素用32个bit表示，其中24bit表示红色、绿色和蓝色三个通道，另外8bit表示alpha通道，即透明通道。\n从实例中可以看到，使用当前这个方式将“RGB”图像转为“RGBA”图像时，alpha通道全部设置为255，即完全不透明。\n模式“CMYK”\n模式“CMYK”为32位彩色图像，它的每个像素用32个bit表示。模式“CMYK”就是印刷四分色模式，它是彩色印刷时采用的一种套色模式，利用色料的三原色混色原理，加上黑色油墨，共计四种颜色混合叠加，形成所谓“全彩印刷”。\n四种标准颜色是：C：Cyan = 青色，又称为‘天蓝色’或是‘湛蓝’M：Magenta = 品红色，又称为‘洋红色’；Y：Yellow = 黄色；K：Key Plate(blacK) = 定位套版色（黑色）。\n\u0026gt;\u0026gt;\u0026gt;from PIL import Image \u0026gt;\u0026gt;\u0026gt; lena =Image.open(\u0026#34;D:\\\\Code\\\\Python\\\\test\\\\img\\\\lena.jpg\u0026#34;) \u0026gt;\u0026gt;\u0026gt; lena_cmyk =lena.convert(\u0026#34;CMYK\u0026#34;) \u0026gt;\u0026gt;\u0026gt; lena_cmyk.mode \u0026#39;CMYK\u0026#39; \u0026gt;\u0026gt;\u0026gt;lena_cmyk.getpixel((0,0)) (58, 144, 177, 0) \u0026gt;\u0026gt;\u0026gt; lena_cmyk.getpixel((0,1)) (59, 145, 178, 0) \u0026gt;\u0026gt;\u0026gt;lena.getpixel((0,0)) (197, 111, 78) \u0026gt;\u0026gt;\u0026gt;lena.getpixel((0,1)) (196, 110, 77) 从实例中可以得知PIL中“RGB”转换为“CMYK”的公式如下：\nC = 255 - R M = 255 - G Y = 255 - B K = 0 由于该转换公式比较简单，转换后的图像颜色有些失真。\n模式“YCbCr”\n模式“YCbCr”为24位彩色图像，它的每个像素用24个bit表示。YCbCr其中Y是指亮度分量，Cb指蓝色色度分量，而Cr指红色色度分量。人的肉眼对视频的Y分量更敏感，因此在通过对色度分量进行子采样来减少色度分量后，肉眼将察觉不到的图像质量的变化。\n模式“RGB”转换为“YCbCr”的公式如下：\nY= 0.257*R+0.504*G+0.098*B+16 Cb = -0.148*R-0.291*G+0.439*B+128 Cr = 0.439*R-0.368*G-0.071*B+128 模式“I”\n模式“I”为32位整型灰色图像，它的每个像素用32个bit表示，0表示黑，255表示白，(0,255)之间的数字表示不同的灰度。在PIL中，从模式“RGB”转换为“I”模式是按照下面的公式转换的：\nI = R * 299/1000 + G * 587/1000 + B * 114/1000\n模式“F”\n模式“F”为32位浮点灰色图像，它的每个像素用32个bit表示，0表示黑，255表示白，(0,255)之间的数字表示不同的灰度。在PIL中，从模式“RGB”转换为“F”模式是按照下面的公式转换的：\nF = R * 299/1000+ G * 587/1000 + B * 114/1000\n请注意，GIF文件总是以灰度形式读取。（ L ）或调色板模式（ P ）图像。 ","date":"2020-08-01T21:10:55Z","permalink":"https://lxb.wiki/ab6bf24d/","title":"Pillow 库"},{"content":" 一个GIF文件主要由以下几部分组成。\n文件头 图像帧信息 注释 文件头 GIF格式文件头和一般文件头差别不大，也包含有\n格式声明 逻辑屏幕描述块 全局调色盘 格式声明\nSignature 为“GIF”3 个字符；Version 为“87a”或“89a”3 个字符。\n逻辑屏幕描述块\n前两字节为像素单位的宽、高，用以标识图片的视觉尺寸。\nPacket里是调色盘信息，分别来看——\nGlobal Color Table Flag 为全局颜色表标志，即为1时表明全局颜色表有定义。\nColor Resolution 代表颜色表中每种基色位长（需要+1），为111时，每个颜色用8bit表示，即我们熟悉的RGB表示法，一个颜色三字节。\nSort Flag 表示是否对颜色表里的颜色进行优先度排序，把常用的排在前面，这个主要是为了适应一些颜色解析度低的早期渲染器，现在已经很少使用了。\nGlobal Color Table 表示颜色表的长度，计算规则是值+1作为2的幂，得到的数字就是颜色表的项数，取最大值111时，项数=256，也就是说GIF格式最多支持256色的位图，再乘以Color Resolution算出的字节数，就是调色盘的总长度。\n这四个字段一起定义了调色盘的信息。\nBackground color Index 定义了图像透明区域的背景色在调色盘里的索引。\nPixel Aspect Ratio 定义了像素宽高比，一般为0。\n帧信息描述 帧信息描述就是每一帧的图像信息和相关标志位\n大部分GIF存储时采用了公共区域排除和透明区域叠加的优化\n帧数据说明\n","date":"2020-07-28T21:25:36Z","permalink":"https://lxb.wiki/2bf7952d/","title":"gif图片文件信息"},{"content":" char hexVals[16] = {\u0026#39;0\u0026#39;,\u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39;,\u0026#39;5\u0026#39;,\u0026#39;6\u0026#39;,\u0026#39;7\u0026#39;,\u0026#39;8\u0026#39;,\u0026#39;9\u0026#39;,\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;,\u0026#39;C\u0026#39;,\u0026#39;D\u0026#39;,\u0026#39;E\u0026#39;,\u0026#39;F\u0026#39;}; string CURLEncode::csUnsafeString= \u0026#34;\\\u0026#34;\u0026lt;\u0026gt;%\\\\^[]`+$,@:;/!#?=\u0026amp;\u0026#34;; string convert(char val) { string csRet; csRet += \u0026#34;%\u0026#34;; csRet += decToHex(val, 16); return csRet; } string decToHex(char num, int radix) { int temp=0; string csTmp; int num_char; num_char = (int) num; // ISO-8859-1 // IF THE IF LOOP IS COMMENTED, THE CODE WILL FAIL TO GENERATE A // PROPER URL ENCODE FOR THE CHARACTERS WHOSE RANGE IN 127-255(DECIMAL) if (num_char \u0026lt; 0) num_char = 256 + num_char; while (num_char \u0026gt;= radix) { temp = num_char % radix; num_char = (int)floor((num_char / radix) * 1.0); csTmp = hexVals[temp]; } csTmp += hexVals[num_char]; if(csTmp.length() \u0026lt; 2) { csTmp += \u0026#39;0\u0026#39;; } string strdecToHex = csTmp; // Reverse the String std::reverse(strdecToHex.begin(), strdecToHex.end()); return strdecToHex; } bool isUnsafe(char compareChar) { bool bcharfound = false; char tmpsafeChar; int m_strLen = 0; m_strLen = csUnsafeString.length(); for(int ichar_pos = 0; ichar_pos \u0026lt; m_strLen ;ichar_pos++) { tmpsafeChar = csUnsafeString[ichar_pos]; if(tmpsafeChar == compareChar) { bcharfound = true; break; } } int char_ascii_value = 0; //char_ascii_value = __toascii(compareChar); char_ascii_value = (int) compareChar; if(bcharfound == false \u0026amp;\u0026amp; char_ascii_value \u0026gt; 32 \u0026amp;\u0026amp; char_ascii_value \u0026lt; 123) { return false; } // found no unsafe chars, return false else { return true; } return true; } string URLEncode(string strEncode) { string strSrc; string strDest; strSrc = strEncode; for(int i = 0; i \u0026lt; strSrc.length(); i++) { char ch = strSrc[i]; if (ch \u0026lt; \u0026#39; \u0026#39;) { ch = ch; } if(!isUnsafe(ch)) { // Safe Character strDest += ch; } else { // get Hex Value of the Character strDest += convert(ch); } } return strDest; } ","date":"2020-07-10T06:45:47Z","permalink":"https://lxb.wiki/c587a198/","title":"URL特殊字符处理"},{"content":" #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #define BURSIZE 2048 int hex2dec(char c) { if (\u0026#39;0\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;9\u0026#39;) { return c - \u0026#39;0\u0026#39;; } else if (\u0026#39;a\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;f\u0026#39;) { return c - \u0026#39;a\u0026#39; + 10; } else if (\u0026#39;A\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;F\u0026#39;) { return c - \u0026#39;A\u0026#39; + 10; } else { return -1; } } char dec2hex(short int c) { if (0 \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= 9) { return c + \u0026#39;0\u0026#39;; } else if (10 \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= 15) { return c + \u0026#39;A\u0026#39; - 10; } else { return -1; } } //编码一个url void urlencode(char url[]) { int i = 0; int len = strlen(url); int res_len = 0; char res[BURSIZE]; for (i = 0; i \u0026lt; len; ++i) { char c = url[i]; if ( (\u0026#39;0\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;9\u0026#39;) || (\u0026#39;a\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;z\u0026#39;) || (\u0026#39;A\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;Z\u0026#39;) || c == \u0026#39;/\u0026#39; || c == \u0026#39;.\u0026#39;) { res[res_len++] = c; } else { int j = (short int)c; if (j \u0026lt; 0) j += 256; int i1, i0; i1 = j / 16; i0 = j - i1 * 16; res[res_len++] = \u0026#39;%\u0026#39;; res[res_len++] = dec2hex(i1); res[res_len++] = dec2hex(i0); } } res[res_len] = \u0026#39;\\0\u0026#39;; strcpy(url, res); } // 解码url void urldecode(char url[]) { int i = 0; int len = strlen(url); int res_len = 0; char res[BURSIZE]; for (i = 0; i \u0026lt; len; ++i) { char c = url[i]; if (c != \u0026#39;%\u0026#39;) { res[res_len++] = c; } else { char c1 = url[++i]; char c0 = url[++i]; int num = 0; num = hex2dec(c1) * 16 + hex2dec(c0); res[res_len++] = num; } } res[res_len] = \u0026#39;\\0\u0026#39;; strcpy(url, res); } int main(int argc, char *argv[]) { char url[100] = \u0026#34;http://\u0026#39;测试/@mike\u0026#34;; urlencode(url); //编码后 printf(\u0026#34;http://\u0026#39;测试/@mike ----\u0026gt; %s\\n\u0026#34;, url); char buf[100] = \u0026#34;http%3A//%27%E6%B5%8B%E8%AF%95/%40mike\u0026#34;; urldecode(buf); //解码后 printf(\u0026#34;http%%3A//%%27%%E6%%B5%%8B%%E8%%AF%%95/%%40mike ----\u0026gt; %s\\n\u0026#34;, buf); return 0; } ","date":"2020-06-25T06:37:14Z","permalink":"https://lxb.wiki/fdc9c210/","title":"url编码解码"},{"content":" 图片文件头标识分析 一个图片文件的后缀名并不能说明这个图片的真正格式什么，读取图片文件的文件头标识可以获取图片的格式。用十六进制编辑器察看图片的文件头\n1.JPEG\n文件头标识 (2 bytes): $ff, $d8 (SOI) (JPEG 文件标识) 文件结束标识 (2 bytes): $ff, $d9 (EOI) 2.TGA\n未压缩的前5字节 00 00 02 00 00 RLE压缩的前5字节 00 00 10 00 00 3.PNG\n文件头标识 (8 bytes) 89 50 4E 47 0D 0A 1A 0A 4.GIF\n文件头标识 (6 bytes) 47 49 46 38 39(37) 61 G I F 8 9 (7) a 5.BMP\n文件头标识 (2 bytes) 42 4D B M 6.PCX\n文件头标识 (1 bytes) 0A 7.TIFF\n文件头标识 (2 bytes) 4D 4D 或 49 49 8.ICO\n文件头标识 (8 bytes) 00 00 01 00 01 00 20 20 9.CUR\n文件头标识 (8 bytes) 00 00 02 00 01 00 20 20 10.IFF\n文件头标识 (4 bytes) 46 4F 52 4D F O R M 11.ANI\n文件头标识 (4 bytes) 52 49 46 46 R I F F 文件头标识比对 根据这些文件头标识的收集，我可以写一个识别图像格式的模块了。但是在写这个模块之前可以对收集到的文件头标识进行优化，使得程序中字符串比对次数尽量的少。\n1.JPEG我们知需要比对文件头的$ff, $d8这两个字符，而不用读取最后的两个结束标识了\n2.TGA，ICO，CUR只需比对第三个与第五个字符即可。\n3.PNG 比对[89][50]这两个字符。\n4.GIF 比对[47][49][46]与第五个字符。\n模块代码如下：\n\u0026#39;枚举图片格式种类 Public Enum ImageForm [BMP] = 0 [JPEG] = 1 [GIF87] = 2 [GIF89] = 3 [PNG] = 4 [TGA Normal] = 5 \u0026#39;TGA未压缩 [TGA RLE] = 6 \u0026#39;TGA经过RLE压缩后的 [PCX] = 7 [TIFF] = 8 [ICO] = 9 [CUR] = 10 [IFF] = 11 [ANI] = 12 [Other] = 13 [FileError] = 14 End Enum 常用的图片格式有以下几种。\nPNG JPEG GIF WebP 是 Google 制造的一个图片格式，针对网络上快速传输就行了优化 TIFF/TIF 在数字影响、遥感、医学等领域中得到了广泛的应用。TIFF文件的后缀是.tif或者.tiff HEIC iOS11 后，苹果拍照图片的默认格式 HEIF 用于存储动态图像 JPGE 二进制数据前两个字节数据为 Hex Signature FF D8 PNG Hex Signature 89 50 4E 47 0D 0A 1A 0A GIF Hex Signature 47 49 46 38 37 61 or 47 49 46 38 39 61 TIFF Hex Signature 49 20 49 or 49 49 2A 00 or 4D 4D 00 2B or 4D 4D 00 2A HEIC Hex Signature 00 HEIF Hex Signature 00 WEBP Hex Signature 52 判断 Webp 为什么是截取 0-12 的长度？转换成 ASCII 之后判断的依据？\n在 Google 官方介绍中找到了此图。说明的是：头文件的大小是 12Bytes\nWEBP的 header 中写明了 ASCII 是 RIFF 或者 WEBP Google Developer: https://developers.google.com/speed/webp/docs/riff_container\n代码 demo 代码\nenum ImageFormat { case Unknow case JPEG case PNG case GIF case TIFF case WebP case HEIC case HEIF } extension Data { func getImageFormat() -\u0026gt; ImageFormat { var buffer = [UInt8](repeating: 0, count: 1) self.copyBytes(to: \u0026amp;buffer, count: 1) switch buffer { case [0xFF]: return .JPEG case [0x89]: return .PNG case [0x47]: return .GIF case [0x49],[0x4D]: return .TIFF case [0x52] where self.count \u0026gt;= 12: if let str = String(data: self[0...11], encoding: .ascii), str.hasPrefix(\u0026#34;RIFF\u0026#34;), str.hasSuffix(\u0026#34;WEBP\u0026#34;) { return .WebP } case [0x00] where self.count \u0026gt;= 12: if let str = String(data: self[8...11], encoding: .ascii) { let HEICBitMaps = Set([\u0026#34;heic\u0026#34;, \u0026#34;heis\u0026#34;, \u0026#34;heix\u0026#34;, \u0026#34;hevc\u0026#34;, \u0026#34;hevx\u0026#34;]) if HEICBitMaps.contains(str) { return .HEIC } let HEIFBitMaps = Set([\u0026#34;mif1\u0026#34;, \u0026#34;msf1\u0026#34;]) if HEIFBitMaps.contains(str) { return .HEIF } } default: break; } return .Unknow } } C++ 代码1\nImage_file.cpp\n#include \u0026#34;config.h\u0026#34; #include \u0026#34;ImageFile.h\u0026#34; #include \u0026lt;fstream\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;cstring\u0026gt; namespace blink { #define JPEG_FILE_TYPE 1 #define BMP_FILE_TYPE 2 #define PNG_FILE_TYPE 3 #define GIF_FILE_TYPE 4 /* 通过文件头标识判断图片格式， jpg： FF, D8 bmp： 42 4D gif： 47 49 46 38 png： 89 50 4E 47 */ int check_fileType(const unsigned char *buf) { if(buf[0] == 0xFF \u0026amp;\u0026amp; buf[1] == 0xd8 \u0026amp;\u0026amp; buf[2] == 0xFF) { return JPEG_FILE_TYPE; } if(buf[0] == 0x42 \u0026amp;\u0026amp; buf[1] == 0x4d) { return BMP_FILE_TYPE; } if(buf[0] == 0x47 \u0026amp;\u0026amp; buf[1] == 0x49 \u0026amp;\u0026amp; buf[2] == 0x46 \u0026amp;\u0026amp; buf[3] == 0x38) { return GIF_FILE_TYPE; } if(buf[0] == 0x89 \u0026amp;\u0026amp; buf[1] == 0x50 \u0026amp;\u0026amp; buf[2] == 0x4e \u0026amp;\u0026amp; buf[3] == 0x47) { return PNG_FILE_TYPE; } else return 0; } /*在构造函数内获取像素宽高：mwidth、mheigh*/ ImageFile::ImageFile(const String\u0026amp; path) { int type; mpath = path; mwidth = 0; mheight = 0; mtype = \u0026#34;\u0026#34;; src = (char *)path.utf8().data(); int i = 0; int size; unsigned char *buff = NULL; FILE *fp; if((fp = fopen(src,\u0026#34;rb+\u0026#34;)) == NULL) { mtype = \u0026#34;The file was not opened!\u0026#34;; return; } fseek(fp,0,SEEK_END); size = ftell(fp); buff = (unsigned char*)malloc(size); if(buff) memset(buff,0,size); fseek(fp,0,SEEK_SET); if(fread(buff,1,size,fp)!=size) { mtype =\u0026#34;read error!\u0026#34;; return; } type = check_fileType(buff); switch(type) { case JPEG_FILE_TYPE: mtype = \u0026#34;jpg file!\u0026#34;; for(i = 0; i \u0026lt; size ; i++) { if(buff[i] == 0xff \u0026amp;\u0026amp; buff[i+1] == 0xc0) { mwidth = (buff[i+7]\u0026lt;\u0026lt;8) | buff[i+8]; mheight = (buff[i+5]\u0026lt;\u0026lt;8) | buff[i+6]; break; } } break; case BMP_FILE_TYPE: mtype = \u0026#34;bmp file!\u0026#34;; for(i = 0; i \u0026lt; size ; i++) { if(buff[i] == 0x28 \u0026amp;\u0026amp; buff[i+1] == 0x00) { mwidth = (buff[i+7]\u0026lt;\u0026lt;24) | buff[i+6]\u0026lt;\u0026lt;16 | buff[i+5]\u0026lt;\u0026lt;8 | buff[i+4]; mheight = (buff[i+11]\u0026lt;\u0026lt;24) | buff[i+10]\u0026lt;\u0026lt;16 | buff[i+9]\u0026lt;\u0026lt;8 | buff[i+8]; break; } } break; case PNG_FILE_TYPE: mtype = \u0026#34;png file!\u0026#34;; for(i = 0; i \u0026lt; size ; i++) { if(buff[i] == 0x49 \u0026amp;\u0026amp; buff[i+1] == 0x48) { mheight = (buff[i+8]\u0026lt;\u0026lt;24) | buff[i+9]\u0026lt;\u0026lt;16 | buff[i+10]\u0026lt;\u0026lt;8 | buff[i+11]; mwidth = (buff[i+4]\u0026lt;\u0026lt;24) | buff[i+5]\u0026lt;\u0026lt;16 | buff[i+6]\u0026lt;\u0026lt;8 | buff[i+7]; break; } } break; case GIF_FILE_TYPE: mtype = \u0026#34;gif file!\u0026#34;; for(i = 0; i \u0026lt; size ; i++) { if(buff[i] == 0x00 \u0026amp;\u0026amp; buff[i+1] == 0x2c) { mwidth = (buff[i+7]\u0026lt;\u0026lt;8) | buff[i+6]; mheight = (buff[i+9]\u0026lt;\u0026lt;8) | buff[i+8]; break; } } break; default: break; } fclose(fp); free(buff); } String ImageFile::type() const { return mtype; } String ImageFile::location() const { int length = mpath.length(); int pos = mpath.reverseFind(\u0026#39;/\u0026#39;); while (pos == length - 1) { pos = mpath.reverseFind(\u0026#39;/\u0026#39; ,pos - 1); length--; } if (pos \u0026lt; 0) { return \u0026#34;\u0026#34;; } return mpath.substring(0,pos + 1); } String ImageFile::fileName() const { int length = mpath.length(); int pos = mpath.reverseFind(\u0026#39;/\u0026#39;); while (pos == length - 1) { pos = mpath.reverseFind(\u0026#39;/\u0026#39; , pos - 1); length--; } if (pos \u0026lt; 0) { return \u0026#34;\u0026#34;; } return mpath.substring(pos + 1,length); } double ImageFile::width() const { return mwidth; } double ImageFile::height() const { return mheight; } } image_file.h\n#ifndef ImageFile_H #define ImageFile_H namespace blink { class ImageFile { public: static ImageFile* create(const String\u0026amp; path) { FILE* fS; fS =fopen(path.utf8().data(),\u0026#34;r\u0026#34;); if(fS !=NULL) { int i; int iLen = path.length() ; int iPos = path.reverseFind(\u0026#39;.\u0026#39;); if (iPos \u0026lt;= 0) { return NULL; } String name=path.substring(iPos + 1, iLen); char s1[10]; char s2[]=\u0026#34;jpg\u0026#34;; char s3[]=\u0026#34;bmp\u0026#34;; char s4[]=\u0026#34;gif\u0026#34;; char s5[]=\u0026#34;png\u0026#34;; char s6[]=\u0026#34;jpeg\u0026#34;; for(i=0;i\u0026lt;name.length();i++) s1[i] = name[i]; s1[i] = \u0026#39;\\0\u0026#39;; if(strncmp(s1,s2,3)==0 || strncmp(s1,s3,3)==0 || strncmp(s1,s4,3)==0 || strncmp(s1,s5,3)==0|| strncmp(s1,s6,4)==0) return new NGBImageFile(path); //路径正确且图片文件格式是以上四种，创建文件对象 else return NULL; } return NULL; } String type() const; String location() const; String fileName() const; double width() const; double height() const; private: ImageFile(const String\u0026amp; path); char* src; String mpath; String mtype; double mwidth; double mheight; }; } // namespace blink #endif // ImageFile_H Qt 代码\nimageinfo.h\n#ifndef IMAGEINFO_H #define IMAGEINFO_H #include \u0026lt;QObject\u0026gt; #include \u0026lt;QDebug\u0026gt; #include \u0026lt;QUrl\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;QSize\u0026gt; #include \u0026lt;QDate\u0026gt; class ImageInfo : public QObject { Q_OBJECT enum IMAGE_FORMAT{ BMP_FORMAT, JPG_FORMAT, GIF_FORMAT, PNG_FORMAT, NVL_FORMAT }; public: explicit ImageInfo(QObject *parent = 0); ~ImageInfo(); public: Q_INVOKABLE QString getImageFormat(QString imageUrl); Q_INVOKABLE QString getImageSize(QString imageUrl); Q_INVOKABLE QSize getImageDimension(QString imageUrl); Q_INVOKABLE QDate getImageDate(QString imageUrl); Q_INVOKABLE QString getImageTitle(QString imageUrl); Q_SIGNALS: public Q_SLOTS : private: int getImageFormat(std::string path); long getBMPSize(std::string path); long getGIFSize(std::string path); long getPNGSize(std::string path); long getJPGSize(std::string path); QSize getBMPDimension(std::string path); QSize getPNGDimension(std::string path); QSize getJPGDimension(std::string path); QSize getGIFDimension(std::string path); }; #endif // IMAGEINFO_H imageinfo.cpp\n#include \u0026#34;imageinfo.h\u0026#34; #include \u0026lt;iostream\u0026gt; #include \u0026lt;fstream\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;QFile\u0026gt; #include \u0026lt;QFileInfo\u0026gt; ImageInfo::ImageInfo(QObject *parent) : QObject(parent) { qDebug() \u0026lt;\u0026lt; \u0026#34;---------------------------- image info constructed \u0026#34;; } ImageInfo::~ImageInfo() { } QDate ImageInfo::getImageDate(QString imageUrl) { QDate date; if(!imageUrl.isEmpty()) { QUrl fileUrl(imageUrl); QString filePath = fileUrl.toLocalFile(); if(QFile::exists(filePath)) { QFileInfo fileinfo(filePath); date = fileinfo.lastModified().date(); } } return date; } //从文件头中读取相应字段以判断图片格式 //详情参看: http://www.garykessler.net/library/file_sigs.html int ImageInfo::getImageFormat(std::string path) { //BMP格式特征码 unsigned char BMPHeader[] = {0x42, 0x4d}; //JPG,JPEG格式特征码 unsigned char JPGHeader1[] = {0xff, 0xd8, 0xff, 0xdb}; unsigned char JPGHeader2[] = {0xff, 0xd8, 0xff, 0xe0}; unsigned char JPGHeader3[] = {0xff, 0xd8, 0xff, 0xe1}; unsigned char JPGHeader4[] = {0xff, 0xd8, 0xff, 0xe2}; unsigned char JPGHeader5[] = {0xff, 0xd8, 0xff, 0xe3}; unsigned char JPGHeader6[] = {0xff, 0xd8, 0xff, 0xe8}; //GIF格式特征码 unsigned char GIFHeader1[] = {0x47, 0x49, 0x46, 0x38, 0x37, 0x61}; unsigned char GIFHeader2[] = {0x47, 0x49, 0x46, 0x38, 0x39, 0x61}; //PNG格式特征码 unsigned char PNGHeader[] = {0x89, 0x50, 0x4E, 0x47}; int count = 0; int step = 2; //以二进制方式打开文件并读取前几个字节 unsigned char header[16]; qDebug()\u0026lt;\u0026lt;\u0026#34;文件路径: \u0026#34;\u0026lt;\u0026lt;path.c_str(); std::ifstream readf(path.c_str(), std::ios::binary); if(!readf.is_open()) { qDebug()\u0026lt;\u0026lt;\u0026#34;打开文件失败\u0026#34;; return NVL_FORMAT; } //先读两个，判断是否BMP格式 for(int i=0; i\u0026lt;step; i++) { readf\u0026gt;\u0026gt;header[count+i]; } count = count + step; if(memcmp(header, BMPHeader, count) == 0) { qDebug()\u0026lt;\u0026lt;\u0026#34;文件格式特征码:\u0026#34;; for(int i=0; i\u0026lt;count; i++) { printf(\u0026#34;%0x\\t\u0026#34;,header[i]); } printf(\u0026#34;\\n\u0026#34;); qDebug()\u0026lt;\u0026lt;\u0026#34;BMP格式\u0026#34;; return BMP_FORMAT; } //再读两个，判断是否JPG格式、PNG格式 for(int i=0; i\u0026lt;step; i++) { readf\u0026gt;\u0026gt;header[count+i]; } count = count + step; if((memcmp(header, JPGHeader1, count) == 0) || (memcmp(header, JPGHeader2, count) == 0) || (memcmp(header, JPGHeader3, count) == 0) || (memcmp(header, JPGHeader4, count) == 0) || (memcmp(header, JPGHeader5, count) == 0) || (memcmp(header, JPGHeader6, count) == 0)) { qDebug()\u0026lt;\u0026lt;\u0026#34;文件格式特征码:\u0026#34;; for(int i=0; i\u0026lt;count; i++) { printf(\u0026#34;%0x\\t\u0026#34;,header[i]); } printf(\u0026#34;\\n\u0026#34;); qDebug()\u0026lt;\u0026lt;\u0026#34;JPG格式\u0026#34;; return JPG_FORMAT; } else if(memcmp(header, PNGHeader, count) == 0) { qDebug()\u0026lt;\u0026lt;\u0026#34;文件格式特征码:\u0026#34;; for(int i=0; i\u0026lt;count; i++) { printf(\u0026#34;%0x\\t\u0026#34;,header[i]); } printf(\u0026#34;\\n\u0026#34;); qDebug()\u0026lt;\u0026lt;\u0026#34;PNG格式\u0026#34;; return PNG_FORMAT; } //再读两个，判断是否GIF格式 for(int i=0; i\u0026lt;step; i++) { readf\u0026gt;\u0026gt;header[count+i]; } count = count + step; if((memcmp(header, GIFHeader1, count) == 0) || (memcmp(header, GIFHeader2, count) == 0)) { qDebug()\u0026lt;\u0026lt;\u0026#34;文件格式特征码:\u0026#34;; for(int i=0; i\u0026lt;count; i++) { printf(\u0026#34;%0x\\t\u0026#34;,header[i]); } printf(\u0026#34;\\n\u0026#34;); qDebug()\u0026lt;\u0026lt;\u0026#34;GIF格式\u0026#34;; return GIF_FORMAT; } qDebug()\u0026lt;\u0026lt;\u0026#34;文件格式特征码:\u0026#34;; for(int i=0; i\u0026lt;count; i++) { printf(\u0026#34;%0x\\t\u0026#34;,header[i]); } printf(\u0026#34;\\n\u0026#34;); qDebug()\u0026lt;\u0026lt;\u0026#34;不属于以上任何一种格式\u0026#34;; return NVL_FORMAT; } QString ImageInfo::getImageFormat(QString imageUrl) { QString strFormat = \u0026#34;NA\u0026#34;; if(!imageUrl.isEmpty()) { QUrl fileUrl(imageUrl); QString filePath = fileUrl.toLocalFile(); if(QFile::exists(filePath)) { std::string path = filePath.toStdString(); int iFormat = getImageFormat(path); switch(iFormat) { case BMP_FORMAT: strFormat = \u0026#34;BMP\u0026#34;; break; case JPG_FORMAT: strFormat = \u0026#34;JPG\u0026#34;; break; case GIF_FORMAT: strFormat = \u0026#34;GIF\u0026#34;; break; case PNG_FORMAT: strFormat = \u0026#34;PNG\u0026#34;; break; default: break; } } } return strFormat; } QString ImageInfo::getImageSize(QString imageUrl) { QString strSize; long size = 0; if(!imageUrl.isEmpty()) { QUrl fileUrl(imageUrl); QString filePath = fileUrl.toLocalFile(); if(QFile::exists(filePath)) { QFile file(filePath); bool ret = file.open(QIODevice::ReadOnly); if (!ret) { qDebug()\u0026lt;\u0026lt;\u0026#34;打开文件失败\u0026#34;; size = 0; } else { size = file.size(); } file.close(); } } qDebug()\u0026lt;\u0026lt;\u0026#34;!!!!!\u0026#34;\u0026lt;\u0026lt;size; strSize = QString::number(size, 10); qDebug()\u0026lt;\u0026lt;strSize; return strSize; } //BMP文件头的第2、3字为文件大小信息 long ImageInfo::getBMPSize(std::string path) { FILE *fid; long int size; if((fid=fopen(path.c_str(),\u0026#34;rb+\u0026#34;))==NULL) { qDebug()\u0026lt;\u0026lt;\u0026#34;打开文件失败\u0026#34;; return 0; } //跳过图片特征码 fseek(fid, 2, SEEK_SET); fread(\u0026amp;size, sizeof(long), 1, fid); fclose(fid); qDebug()\u0026lt;\u0026lt;\u0026#34;size=\u0026#34;\u0026lt;\u0026lt;size; return size; } long ImageInfo::getGIFSize(std::string path) { Q_UNUSED(path); return 0; } long ImageInfo::getPNGSize(std::string path) { Q_UNUSED(path); return 0; } long ImageInfo::getJPGSize(std::string path) { FILE *fid; long int size; if((fid = fopen(path.c_str(),\u0026#34;rb+\u0026#34;)) == NULL) { qDebug()\u0026lt;\u0026lt;\u0026#34;打开文件失败\u0026#34;; return 0; } fseek(fid, 0, SEEK_END); size = ftell(fid); fclose(fid); qDebug()\u0026lt;\u0026lt;\u0026#34;size=\u0026#34;\u0026lt;\u0026lt;size; return size; } //BMP文件头的第10、11字为文件宽度信息 //BMP文件头的第12、13字为文件高度信息 QSize ImageInfo::getBMPDimension(std::string path) { FILE *fid; if((fid=fopen(path.c_str(),\u0026#34;rb+\u0026#34;))==NULL) { qDebug()\u0026lt;\u0026lt;\u0026#34;打开文件失败\u0026#34;; return QSize(0, 0); } long int width; long int height; //读取宽度和高度 fseek(fid, 18, SEEK_SET); //偏移18个字节 fread(\u0026amp;width, sizeof(long), 1, fid); fread(\u0026amp;height, sizeof(long), 1, fid); qDebug()\u0026lt;\u0026lt;\u0026#34;width=\u0026#34;\u0026lt;\u0026lt;width; qDebug()\u0026lt;\u0026lt;\u0026#34;height=\u0026#34;\u0026lt;\u0026lt;height; fclose(fid); return QSize(width, height); } //参考： http://mcljc.blog.163.com/blog/static/83949820102239610974/ //http://download.csdn.net/download/chp845/4255011 QSize ImageInfo::getJPGDimension(std::string path) { FILE *fid; if((fid = fopen(path.c_str(),\u0026#34;rb+\u0026#34;)) == NULL) { qDebug()\u0026lt;\u0026lt;\u0026#34;打开文件失败\u0026#34;; return QSize(0, 0); } long int width; long int height; fseek(fid,0,SEEK_END); long length = ftell(fid); unsigned char *buffer = new unsigned char[length]; unsigned char *buffer_bakup = buffer; fseek(fid, 0, SEEK_SET); fread(buffer, length, 1, fid); fclose(fid); unsigned char *temp = buffer + length; unsigned char *temp_ori = buffer; unsigned char ff; unsigned char type=0xff; int m_pos = 0; //跳过文件头中标志文件类型的两个字节 for(int i=0; i\u0026lt;2; i++) { buffer++; } while((temp \u0026gt; buffer) \u0026amp;\u0026amp; (type != 0xDA)) { do{ ff = *buffer++; } while(ff != 0xff); do{ type = *buffer++; } while(type == 0xff); switch(type) { case 0x00: case 0x01: case 0xD0: case 0xD1: case 0xD2: case 0xD3: case 0xD4: case 0xD5: case 0xD6: case 0xD7: break; case 0xC0://SOF0段 temp_ori = buffer; m_pos = (*buffer++)\u0026lt;\u0026lt;8; m_pos += *buffer++; buffer++; //舍弃精度值 height = (*buffer++)\u0026lt;\u0026lt;8; height += *buffer++; width = (*buffer++)\u0026lt;\u0026lt;8; width += *buffer; break; case 0xE0: //APP0段 qDebug()\u0026lt;\u0026lt;\u0026#34;APP0段\u0026#34;; temp_ori = buffer; m_pos = (*buffer++)\u0026lt;\u0026lt;8; m_pos += *buffer++; buffer = buffer + 12; //丢弃APP0标记(5bytes)、主版本号(1bytes)、次版本号(1bytes)、像素点单位(1bytes)、垂直像素点(2bytes)、 水平像素点(2bytes) break; default: temp_ori = buffer; m_pos = (*buffer++)\u0026lt;\u0026lt;8; m_pos += *buffer++; break; } buffer = temp_ori + m_pos; } qDebug()\u0026lt;\u0026lt;\u0026#34;width=\u0026#34;\u0026lt;\u0026lt;width; qDebug()\u0026lt;\u0026lt;\u0026#34;height=\u0026#34;\u0026lt;\u0026lt;height; //记得释放内存 delete[] buffer_bakup; return QSize(width, height); } //PNG文件头的第9字为文件宽度信息 //PNG文件头的第10字为文件高度信息 //参考：http://blog.chinaunix.net/uid-25799257-id-3358174.html QSize ImageInfo::getPNGDimension(std::string path) { FILE *fid = NULL; if((fid=fopen(path.c_str(),\u0026#34;rb+\u0026#34;))==NULL) { qDebug()\u0026lt;\u0026lt;\u0026#34;打开文件失败\u0026#34;; return QSize(0, 0); } long int width; long int height; unsigned char wtmp[4]={\u0026#39;0\u0026#39;}; //宽度 unsigned char htmp[4]={\u0026#39;0\u0026#39;}; //高度 fseek(fid, 16, SEEK_SET); fread(wtmp, 4, 1, fid); // example 00000080 fread(htmp, 4, 1, fid); // example 00000080 fclose(fid); width = ((int)(unsigned char)wtmp[2]) * 256 + (int)(unsigned char)wtmp[3]; height = ((int)(unsigned char)htmp[2]) * 256 + (int)(unsigned char)htmp[3]; qDebug()\u0026lt;\u0026lt;\u0026#34;width=\u0026#34;\u0026lt;\u0026lt;width; qDebug()\u0026lt;\u0026lt;\u0026#34;height=\u0026#34;\u0026lt;\u0026lt;height; return QSize(width, height); } //GIF文件头的第4字为文件宽度信息 //GIF文件头的第5字为文件高度信息 //参考：http://blog.csdn.net/zhaoweikid/article/details/156422 //参考：http://blog.csdn.net/asaasa66/article/details/5875340 QSize ImageInfo::getGIFDimension(std::string path) { std::ifstream ffin(path.c_str(), std::ios::binary); if (!ffin){ std::cout\u0026lt;\u0026lt;\u0026#34;Can not open this file.\u0026#34;\u0026lt;\u0026lt;std::endl; return QSize(0, 0); } long int width; long int height; char s1[2] = {0}, s2[2] = {0}; ffin.seekg(6); ffin.read(s1, 2); ffin.read(s2, 2); width = (unsigned int)(s1[1])\u0026lt;\u0026lt;8|(unsigned int)(s1[0]); height = (unsigned int)(s2[1])\u0026lt;\u0026lt;8|(unsigned int)(s2[0]); ffin.close(); qDebug()\u0026lt;\u0026lt;\u0026#34;width=\u0026#34;\u0026lt;\u0026lt;width; qDebug()\u0026lt;\u0026lt;\u0026#34;height=\u0026#34;\u0026lt;\u0026lt;height; return QSize(width, height); } QSize ImageInfo::getImageDimension(QString imageUrl) { QSize dimension; if(!imageUrl.isEmpty()) { QUrl fileUrl(imageUrl); QString filePath = fileUrl.toLocalFile(); if(QFile::exists(filePath)) { std::string path = filePath.toStdString(); int iFormat = getImageFormat(path); switch(iFormat) { case BMP_FORMAT: dimension = getBMPDimension(path); break; case JPG_FORMAT: dimension = getJPGDimension(path); break; case GIF_FORMAT: dimension = getGIFDimension(path); break; case PNG_FORMAT: dimension = getPNGDimension(path); break; default: break; } } } qDebug()\u0026lt;\u0026lt;\u0026#34;图片尺寸:\u0026#34;\u0026lt;\u0026lt;dimension; return dimension; } QString ImageInfo::getImageTitle(QString imageUrl) { QString title; if(!imageUrl.isEmpty()) { QUrl fileUrl(imageUrl); QString filePath = fileUrl.toLocalFile(); if(QFile::exists(filePath)) { QFileInfo fileinfo(filePath); title = fileinfo.baseName(); } } return title; } ","date":"2020-06-15T06:26:23Z","permalink":"https://lxb.wiki/be14bd28/","title":"从图片头信息中获取图片格式"},{"content":"按照部分重叠的接口提议，Go 1.14 现在允许嵌入有部分方法重叠的接口。本文是一篇解释这次修改的简要说明。\n我们先来看 io 包中的三个关键接口：io.Reader、io.Writer 和 io.Closer：\npackage io type Reader interface { Read([]byte) (int, error) } type Writer interface { Write([]byte) (int, error) } type Closer interface { Close() error } 在结构体中嵌入类型时，如果在结构体中声明了被嵌入的类型，那么该类型的字段和方法允许被访问1，对于接口来说这个处理也成立。因此下面两种方式：显式声明\ntype ReadCloser interface { Read([]byte) (int, error) Close() error } 和使用嵌入来组成接口\ntype ReadCloser interface { Reader Closer } 没有区别。\n你甚至可以混合使用：\ntype WriteCloser interface { Write([]byte) (int, error) Closer } 然而，在 Go 1.14 之前，如果你用这种方式来声明接口，你可能会得到类似这样的结果：\ntype ReadWriteCloser interface { ReadCloser WriterCloser } 编译错误：\n% Go build interfaces.go command-line-arguments ./interfaces.go:27:2: duplicate method Close 幸运的是，在 Go 1.14 中这不再是一个限制了，因此这个改动解决了在菱形嵌入时出现的问题。\n然而，在我向本地的用户组解释这个特性时也陷入了麻烦 — 只有 Go 编译器使用 1.14（或更高版本）语言规范时才支持这个特性。\n我理解的编译过程中 Go 语言规范所使用的版本的规则似乎是这样的：\n如果你的源码是在 GOPATH 下（或者你用 GO111MODULE=off 关闭了 module），那么 Go 语言规范会使用你编译器的版本来编译。换句话说，如果安装了 Go 1.13，那么你的 Go 版本就是 1.13。如果你安装了 Go 1.14，那么你的版本就是 1.14。这里符合认知。 如果你的源码保存在 GOPATH 外（或你用 GO111MODULE=on 强制开启了 module），那么 Go tool 会从 go.mod 文件中获取 Go 版本。 如果 go.mod 中没有列出 Go 版本，那么语言规范会使用安装的 Go 的版本。这跟第 1 点是一致的。 如果你用的是 Go module 模式，不管是源码在 GOPATH 外还是设置了 GO111MODULE=on，但是在当前目录或所有父目录中都没有 go.mod 文件，那么 Go 语言规范会默认用 Go 1.13 版本来编译你的代码。 我曾经遇到过第 4 点的情况。\nvia: https://dave.cheney.net/2020/05/24/diamond-interface-composition-in-go-1-14\n作者：Dave Cheney\n译者：Xiaobin.Liu\n校对：polaris1119\n本文由 GCTT 原创编译，Go 中文网 荣誉推出\n也就是说，嵌入提升了类型的字段和方法。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-06-01T21:00:20Z","permalink":"https://lxb.wiki/ace0b2ab/","title":"【译】Go 1.14 中接口的菱形组合"},{"content":"Tiny Tiny RSS（TT-RSS）是一个自由开源的基于 Web 的新闻馈送feed（RSS/Atom）阅读器和聚合工具。它非常适合那些注重隐私，并且仍然依赖 RSS 来获取日常新闻的人。TT-RSS 是自行托管的软件，因此你可以 100% 的掌控你的服务器、数据以及你的全部隐私。它还支持大量的插件、扩展和主题。你喜欢黑暗模式的界面？没问题。想基于关键词过滤发来的消息？TT-RSS 也能让你得偿所愿。\n现在你知道 TT-RSS 是什么了，那么为什么你可能会想用它。我会讲述要把它安装到树莓派或 Debian 10 服务器上你需要了解的所有的东西。\n安装和配置 TT-RSS 要把 TT-RSS 安装到树莓派上，你还需要安装和配置最新版本的 PHP（本文撰写时 PHP 最新版本是 7.3）、后端数据库 PostgreSQL、Nginx web 服务器、Git，最后才是 TT-RSS。\n1、安装 PHP 7 安装 PHP 7 是整个过程中最复杂的部分。幸运的是，它并不像看起来那样困难。从安装下面的支持包开始：\n$ sudo apt install -y ca-certificates apt-transport-https 现在，添加存储库 PGP 密钥：\n$ wget -q https://packages.sury.org/php/apt.gpg -O- | sudo apt-key add - 下一步，把 PHP 库添加到你的 apt 源：\n$ echo \u0026#34;deb https://packages.sury.org/php/ buster main\u0026#34; | sudo tee /etc/apt/sources.list.d/php.list 然后更新你的存储库索引：\n$ sudo apt update 最后，安装 PHP 7.3（或最新版本）和一些通用组件：\n$ sudo apt install -y php7.3 php7.3-cli php7.3-fpm php7.3-opcache php7.3-curl php7.3-mbstring php7.3-pgsql php7.3-zip php7.3-xml php7.3-gd php7.3-intl 上面的命令默认你使用的后端数据库是 PostgreSQL，会安装 php7.3-pgsql。如果你想用 MySQL 或 MariaDB，你可以把命令参数改为 php7.3-mysql。\n下一步，确认 PHP 已安装并在你的树莓派上运行着：\n$ php -v 现在是时候安装和配置 Web 服务器了。\n2、安装 Nginx 可以用下面的命令安装 Nginx：\n$ sudo apt install -y nginx 修改默认的 Nginx 虚拟主机配置，这样 Web 服务器才能识别 PHP 文件以及知道如何处理它们。\n$ sudo nano /etc/nginx/sites-available/default 你可以安全地删除原文件中的所有内容，用下面的内容替换：\nserver { listen 80 default_server; listen [::]:80 default_server; root /var/www/html; index index.html index.htm index.php; server_name _; location / { try_files $uri $uri/ =404; } location ~ \\.php$ { include snippets/fastcgi-php.conf; fastcgi_pass unix:/run/php/php7.3-fpm.sock; } } 按 Ctrl+O 保存修改后的配置文件，然后按 Ctrl+X 退出 Nano。你可以用下面的命令测试你的新配置文件：\n$ nginx -t 如果没有报错，重启 Nginx 服务：\n$ systemctl restart nginx 3、安装 PostgreSQL 接下来是安装数据库服务器。在树莓派上安装 PostgreSQL 超级简单：\n$ sudo apt install -y postgresql postgresql-client postgis 输入下面的命令看一下数据库服务器安装是否成功：\n$ psql --version 4、创建 Tiny Tiny RSS 数据库 在做其他事之前，你需要创建一个数数据库，用来给 TT-RSS 软件保存数据。首先，登录 PostgreSQL 服务器：\nsudo -u postgres psql 下一步，新建一个用户，设置密码：\nCREATE USER username WITH PASSWORD \u0026#39;your_password\u0026#39; VALID UNTIL \u0026#39;infinity\u0026#39;; 然后创建一个给 TT-RSS 用的数据库：\nCREATE DATABASE tinyrss; 最后，给新建的用户赋最高权限：\nGRANT ALL PRIVILEGES ON DATABASE tinyrss to user_name; 这是安装数据库的步骤。你可以输入 \\q 来退出 psql 程序。\n5、安装 Git 安装 TT-RSS 需要用 Git，所以输入下面的命令安装 Git：\n$ sudo apt install git -y 现在，进入到 Nginx 服务器的根目录：\n$ cd /var/www/html 下载 TT-RSS 最新源码：\n$ git clone https://git.tt-rss.org/fox/tt-rss.git tt-rss 注意，这一步会创建一个 tt-rss 文件夹。\n6、安装和配置Tiny Tiny RSS 现在是安装和配置你的新 TT-RSS 服务器的最后时刻了。首先，确认下你在浏览器中能打开 http://your.site/tt-rss/install/index.php。如果浏览器显示 403 Forbidden，那么就证明 /var/www/html 文件夹的权限没有设置正确。下面的命令通常能解决这个问题：\n$ chmod 755 /var/www/html/ -v 如果一切正常，你会看到 TT-RSS 安装页面，它会让你输入一些数据的信息。你只需要输入前面你创建的数据库用户名和密码；数据库名；主机名填 localhost；端口填 5432。\n点击“Test Configuration”。如果一切正常，你会看到一个标记着“Initialize Database”的红色按钮。点击它来开始安装。结束后，你会看到一个配置文件，你可以把它复制到 TT-RSS 的目录，另存为 config.php。\n安装过程结束后，浏览器输入 http://yoursite/tt-rss/ 打开 TT-RSS，使用默认的凭证登录（用户名：admin，密码：password）。登录后系统会提示你修改密码。我强烈建议你尽快修改密码。\n配置 TT-RSS 如果一切正常，你现在就可以开始使用 TT-RSS 了。建议你新建一个非管理员用户，使用新用户名登录，并开始导入你的馈送、订阅，按照你的意愿来配置它。\n最后，并且是超级重要的事，不要忘了阅读 TT-RSS 维基上的 Updating Feeds 部分。它讲述了如何创建一个简单的 systemd 服务来更新馈送。如果你跳过了这一步，你的 RSS 馈送就不会自动更新。\n总结 呵！工作量不小，但是你做完了！你现在有自己的 RSS 聚合服务器了。想了解 TT-RSS 更多的知识？我推荐你去看官方的 FAQ、支持论坛，和详细的安装笔记。如果你有任何问题，尽情地在下面评论吧。\nvia: https://opensource.com/article/20/2/ttrss-raspberry-pi\n作者：Patrick H. Mullins 选题：lujun9972 译者：lxbwolf 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2020-05-30T22:05:48Z","permalink":"https://lxb.wiki/afdc720c/","title":"树莓派安装TT-RSS"},{"content":" 大家常规的认知是，Go 程序中声明的类型越多，生成的二进制文件就越大。这个符合直觉，毕竟如果你写的代码不去操作定义的类型，那么定义一堆类型就没有意义了。然而，链接器的部分工作就是检测没有被程序引用的函数（比如说它们是一个库的一部分，其中只有一个子集的功能被使用），然后把它们从最后的编译产出中删除。常言道，“类型越多，二进制文件越大”，对于多数 Go 程序还是正确的。\n本文中我会深入讲解在 Go 程序的上下文中“相等”的意义，以及为什么像这样的修改会对 Go 程序的大小有重大的影响。\n定义两个值相等 Go 的语法定义了“赋值”和“相等”的概念。赋值是把一个值赋给一个标识符的行为。并不是所有声明的标识符都可以被赋值，如常量和函数就不可以。相等是通过检查标识符的内容是否相等来比较两个标识符的行为。\n作为强类型语言，“相同”的概念从根源上被植入标识符的类型中。两个标识符只有是相同类型的前提下，才有可能相同。除此之外，值的类型定义了如何比较该类型的两个值。\n例如，整型是用算数方法进行比较的。对于指针类型，是否相等是指它们指向的地址是否相同。映射和通道等引用类型，跟指针类似，如果它们指向相同的地址，那么就认为它们是相同的。\n上面都是按位比较相等的例子，即值占用的内存的位模式是相同的，那么这些值就相等。这就是所谓的 memcmp，即内存比较，相等是通过比较两个内存区域的内容来定义的。\n记住这个思路，我过会儿再来谈。\n结构体相等 除了整型、浮点型和指针等标量类型，还有复合类型：结构体。所有的结构体以程序中的顺序被排列在内存中。因此下面这个声明：\ntype S struct { a, b, c, d int64 } 会占用 32 字节的内存空间；a 占用 8 个字节，b 占用 8 个字节，以此类推。Go 的规则说如果结构体所有的字段都是可以比较的，那么结构体的值就是可以比较的。因此如果两个结构体所有的字段都相等，那么它们就相等。\na := S{1, 2, 3, 4} b := S{1, 2, 3, 4} fmt.Println(a == b) // 输出 true 编译器在底层使用 memcmp 来比较 a 的 32 个字节和 b 的 32 个字节。\n填充和对齐 然而，在下面的场景下过分简单化的按位比较的策略会返回错误的结果：\ntype S struct { a byte b uint64 c int16 d uint32 } func main() a := S{1, 2, 3, 4} b := S{1, 2, 3, 4} fmt.Println(a == b) // 输出 true } 编译代码后，这个比较表达式的结果还是 true，但是编译器在底层并不能仅依赖比较 a 和 b 的位模式，因为结构体有填充。\nGo 要求结构体的所有字段都对齐。2 字节的值必须从偶数地址开始，4 字节的值必须从 4 的倍数地址开始，以此类推。编译器根据字段的类型和底层平台加入了填充来确保字段都对齐。在填充之后，编译器实际上看到的是：\ntype S struct { a byte _ [7]byte // 填充 b uint64 c int16 _ [2]int16 // 填充 d uint32 } 填充的存在保证了字段正确对齐，而填充确实占用了内存空间，但是填充字节的内容是未知的。你可能会认为在 Go 中 填充字节都是 0，但实际上并不是 — 填充字节的内容是未定义的。由于它们并不是被定义为某个确定的值，因此按位比较会因为分布在 s 的 24 字节中的 9 个填充字节不一样而返回错误结果。\nGo 通过生成所谓的相等函数来解决这个问题。在这个例子中，s 的相等函数只比较函数中的字段略过填充部分，这样就能正确比较类型 s 的两个值。\n类型算法 呵，这是个很大的设置，说明了为什么，对于 Go 程序中定义的每种类型，编译器都会生成几个支持函数，编译器内部把它们称作类型的算法。如果类型是一个映射的键，那么除相等函数外，编译器还会生成一个哈希函数。为了维持稳定，哈希函数在计算结果时也会像相等函数一样考虑诸如填充等因素。\n凭直觉判断编译器什么时候生成这些函数实际上很难，有时并不明显，（因为）这超出了你的预期，而且链接器也很难消除没有被使用的函数，因为反射往往导致链接器在裁剪类型时变得更保守。\n通过禁止比较来减小二进制文件的大小 现在，我们来解释一下 Brad 的修改。向类型添加一个不可比较的字段，结构体也随之变成不可比较的，从而强制编译器不再生成相等函数和哈希函数，规避了链接器对那些类型的消除，在实际应用中减小了生成的二进制文件的大小。作为这项技术的一个例子，下面的程序：\npackage main import \u0026#34;fmt\u0026#34; func main() { type t struct { // _ [0][]byte // 取消注释以阻止比较 a byte b uint16 c int32 d uint64 } var a t fmt.Println(a) } 用 Go 1.14.2（darwin/amd64）编译，大小从 2174088 降到了 2174056，节省了 32 字节。单独看节省的这 32 字节似乎微不足道，但是考虑到你的程序中每个类型及其传递闭包都会生成相等和哈希函数，还有它们的依赖，这些函数的大小随类型大小和复杂度的不同而不同，禁止它们会大大减小最终的二进制文件的大小，效果比之前使用 -ldflags=\u0026quot;-s -w\u0026quot; 还要好。\n最后总结一下，如果你不想把类型定义为可比较的，可以在源码层级强制实现像这样的奇技淫巧，会使生成的二进制文件变小。\nvia: https://dave.cheney.net/2020/05/09/ensmallening-go-binaries-by-prohibiting-comparisons\n作者：Dave Cheney 选题：lujun9972 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","date":"2020-05-23T12:24:34Z","permalink":"https://lxb.wiki/27d7ea27/","title":"【译】通过禁止比较让 Go 二进制文件变小"},{"content":"\nℹ️ 本文基于 Go 1.14。\n抢占是调度器的重要部分，基于抢占调度器可以在各个协程中分配运行的时间。实际上，如果没有抢占机制，一个长时间占用 CPU 的协程会阻塞其他的协程被调度。1.14 版本引入了一项新的异步抢占的技术，赋予了调度器更大的能力和控制力。\n我推荐你阅读我的文章”Go：协程和抢占“来了解更多之前的特性和它的弊端。\n工作流 我们以一个需要抢占的例子来开始。下面一段代码开启了几个协程，在几个循环中没有其他的函数调用，意味着调度器没有机会抢占它们：\n然而，当把这个程序的追踪过程可视化后，我们清晰地看到了协程间的抢占和切换：\n我们还可以看到表示协程的每个块儿的长度都相等。所有的协程运行时间相同（约 10 到 20 毫秒）。\n异步抢占是基于一个时间条件触发的。当一个协程运行超过 10ms 时，Go 会尝试抢占它。\n抢占是由线程 sysmon 初始化的，该线程专门用于监控包括长时间运行的协程在内的运行时。当某个协程被检测到运行超过 10ms 后，sysmon 向当前的线程发出一个抢占信号。\n之后，当信息被信号处理器接收到时，线程中断当前的操作来处理信号，因此不会再运行当前的协程，在我们的例子中是 G7。取而代之的是，gsignal 被调度为管理发送来的信号。当它发现它是一个抢占指令后，在程序处理信号后恢复时它准备好指令来中止当前的协程。下面是这第二个阶段的示意图：\n如果你想了解更多关于 gsignal 的信息，我推荐你读一下我的文章”Go：gsignal，信号的掌控者“。\n实现 我们在被选中的信号 SIGURG 中第一次看到了实现的细节。这个选择在提案”提案：非合作式协程抢占“中有详细的解释：\n它应该是调试者默认传递过来的一个信号。 它不应该是 Go/C 混合二进制中 libc 内部使用的信号。 它应该是一个可以伪造而没有其他后果的信号。 我们需要在没有实时信号时与平台打交道。 然后，当信号被注入和接收时，Go 需要一种在程序恢复时能终止当前协程的方式。为了实现这个过程，Go 会把一条指令推进程序计数器，这样看起来运行中的程序调用了运行时的函数。该函数暂停了协程并把它交给了调度器，调度器之后还会运行其他的协程。 我们应该注意到 Go 不能做到在任何地方终止程序；当前的指令必须是一个安全点。例如，如果程序现在正在调用运行时，那么抢占协程并不安全，因为运行时很多函数不应该被抢占。\n这个新的抢占机制也让垃圾回收器受益，可以用更高效的方式终止所有的协程。诚然，STW 现在非常容易，Go 仅需要向所有运行的线程发出一个信号就可以了。下面是垃圾回收器运行时的一个例子：\n然后，所有的线程都接收到这个信号，在垃圾回收器重新开启全局之前会暂停执行。\n如果你想了解更多关于 STW 的信息，我建议你阅读我的文章”Go：Go 怎样实现 STW？“。\n最后，这个特性被封装在一个参数中，你可以用这个参数关闭异步抢占。你可以用 GODEBUG=asyncpreemptoff=1 来运行你的程序，如果你因为升级到了 Go 1.14 发现了不正常的现象就可以调试你的程序，或者观察你的程序有无异步抢占时的不同表现。\nvia: https://medium.com/a-journey-with-go/go-asynchronous-preemption-b5194227371c\n作者：Vincent Blanchon 译者：Xiaobin.Liu 校对：polaris1119\n本文由 GCTT 原创编译，Go 中文网 荣誉推出\n","date":"2020-05-05T15:24:46Z","permalink":"https://lxb.wiki/5698ca18/","title":"【译】Go：异步抢占"},{"content":"Go 中的内联优化 本文讨论 Go 编译器是如何实现内联的，以及这种优化方法如何影响你的 Go 代码。\n*请注意：*本文重点讨论 gc，这是来自 golang.org 的事实标准的 Go 编译器。讨论到的概念可以广泛适用于其它 Go 编译器，如 gccgo 和 llgo，但它们在实现方式和功效上可能有所差异。\n内联是什么？ 内联inlining就是把简短的函数在调用它的地方展开。在计算机发展历程的早期，这个优化是由程序员手动实现的。现在，内联已经成为编译过程中自动实现的基本优化过程的其中一步。\n为什么内联很重要？ 有两个原因。第一个是它消除了函数调用本身的开销。第二个是它使得编译器能更高效地执行其他的优化策略。\n函数调用的开销 在任何语言中，调用一个函数 1 都会有消耗。把参数编组进寄存器或放入栈中（取决于 ABI），在返回结果时的逆反过程都会有开销。引入一次函数调用会导致程序计数器从指令流的一点跳到另一点，这可能导致管道滞后。函数内部通常有前置处理preamble，需要为函数执行准备新的栈帧，还有与前置相似的后续处理epilogue，需要在返回给调用方之前释放栈帧空间。\n在 Go 中函数调用会消耗额外的资源来支持栈的动态增长。在进入函数时，goroutine 可用的栈空间与函数需要的空间大小进行比较。如果可用空间不同，前置处理就会跳到运行时runtime的逻辑中，通过把数据复制到一块新的、更大的空间的来增长栈空间。当这个复制完成后，运行时就会跳回到原来的函数入口，再执行栈空间检查，现在通过了检查，函数调用继续执行。这种方式下，goroutine 开始时可以申请很小的栈空间，在有需要时再申请更大的空间。2\n这个检查消耗很小，只有几个指令，而且由于 goroutine 的栈是成几何级数增长的，因此这个检查很少失败。这样，现代处理器的分支预测单元可以通过假定检查肯定会成功来隐藏栈空间检查的消耗。当处理器预测错了栈空间检查，不得不放弃它在推测性执行所做的操作时，与为了增加 goroutine 的栈空间运行时所需的操作消耗的资源相比，管道滞后的代价更小。\n虽然现代处理器可以用预测性执行技术优化每次函数调用中的泛型和 Go 特定的元素的开销，但那些开销不能被完全消除，因此在每次函数调用执行必要的工作过程中都会有性能消耗。一次函数调用本身的开销是固定的，与更大的函数相比，调用小函数的代价更大，因为在每次调用过程中它们做的有用的工作更少。\n因此，消除这些开销的方法必须是要消除函数调用本身，Go 的编译器就是这么做的，在某些条件下通过用函数的内容来替换函数调用来实现。这个过程被称为内联，因为它在函数调用处把函数体展开了。\n改进的优化机会 Cliff Click 博士把内联描述为现代编译器做的优化措施，像常量传播（LCTT 译注：此处作者笔误，原文为 constant proportion，修正为 constant propagation）和死代码消除一样，都是编译器的基本优化方法。实际上，内联可以让编译器看得更深，使编译器可以观察调用的特定函数的上下文内容，可以看到能继续简化或彻底消除的逻辑。由于可以递归地执行内联，因此不仅可以在每个独立的函数上下文处进行这种优化决策，也可以在整个函数调用链中进行。\n实践中的内联 下面这个例子可以演示内联的影响：\npackage main import \u0026#34;testing\u0026#34; //go:noinline func max(a, b int) int { if a \u0026gt; b { return a } return b } var Result int func BenchmarkMax(b *testing.B) { var r int for i := 0; i \u0026lt; b.N; i++ { r = max(-1, i) } Result = r } 运行这个基准，会得到如下结果：3\n% go test -bench=. BenchmarkMax-4 530687617 2.24 ns/op 在我的 2015 MacBook Air 上 max(-1, i) 的耗时约为 2.24 纳秒。现在去掉 //go:noinline 编译指令，再看下结果：\n% go test -bench=. BenchmarkMax-4 1000000000 0.514 ns/op 从 2.24 纳秒降到了 0.51 纳秒，或者从 benchstat 的结果可以看出，有 78% 的提升。\n% benchstat {old,new}.txt name old time/op new time/op delta Max-4 2.21ns ± 1% 0.49ns ± 6% -77.96% (p=0.000 n=18+19) 这个提升是从哪儿来的呢？\n首先，移除掉函数调用以及与之关联的前置处理 4 是主要因素。把 max 函数的函数体在调用处展开，减少了处理器执行的指令数量并且消除了一些分支。\n现在由于编译器优化了 BenchmarkMax，因此它可以看到 max 函数的内容，进而可以做更多的提升。当 max 被内联后，BenchmarkMax 呈现给编译器的样子，看起来是这样的：\nfunc BenchmarkMax(b *testing.B) { var r int for i := 0; i \u0026lt; b.N; i++ { if -1 \u0026gt; i { r = -1 } else { r = i } } Result = r } 再运行一次基准，我们看一下手动内联的版本和编译器内联的版本的表现：\n% benchstat {old,new}.txt name old time/op new time/op delta Max-4 2.21ns ± 1% 0.48ns ± 3% -78.14% (p=0.000 n=18+18) 现在编译器能看到在 BenchmarkMax 里内联 max 的结果，可以执行以前不能执行的优化措施。例如，编译器注意到 i 初始值为 0，仅做自增操作，因此所有与 i 的比较都可以假定 i 不是负值。这样条件表达式 -1 \u0026gt; i 永远不是 true。5\n证明了 -1 \u0026gt; i 永远不为 true 后，编译器可以把代码简化为：\nfunc BenchmarkMax(b *testing.B) { var r int for i := 0; i \u0026lt; b.N; i++ { if false { r = -1 } else { r = i } } Result = r } 并且因为分支里是个常量，编译器可以通过下面的方式移除不会走到的分支：\nfunc BenchmarkMax(b *testing.B) { var r int for i := 0; i \u0026lt; b.N; i++ { r = i } Result = r } 这样，通过内联和由内联解锁的优化过程，编译器把表达式 r = max(-1, i)) 简化为 r = i。\n内联的限制 本文中我论述的内联称作叶子内联leaf inlining：把函数调用栈中最底层的函数在调用它的函数处展开的行为。内联是个递归的过程，当把函数内联到调用它的函数 A 处后，编译器会把内联后的结果代码再内联到 A 的调用方，这样持续内联下去。例如，下面的代码：\nfunc BenchmarkMaxMaxMax(b *testing.B) { var r int for i := 0; i \u0026lt; b.N; i++ { r = max(max(-1, i), max(0, i)) } Result = r } 与之前的例子中的代码运行速度一样快，因为编译器可以对上面的代码重复地进行内联，也把代码简化到 r = i 表达式。\n下一篇文章中，我会论述当 Go 编译器想要内联函数调用栈中间的某个函数时选用的另一种内联策略。最后我会论述编译器为了内联代码准备好要达到的极限，这个极限 Go 现在的能力还达不到。\n相关文章： 使 Go 变快的 5 件事 为什么 Goroutine 的栈空间会无限增长？ Go 中怎么写基准测试 Go 中隐藏的编译指令 via: https://dave.cheney.net/2020/04/25/inlining-optimisations-in-go\n作者：Dave Cheney 选题：lujun9972 译者：Xiaobin.Liu 校对：wxy\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n[3]: tmp.gBQ2tEtMHc#easy-footnote-bottom-2-4053 \u0026ldquo;Up until Go 1.14 the stack check preamble was also used by the garbage collector to stop the world by setting all active goroutine’s stacks to zero, forcing them to trap into the runtime the next time they made a function call. This system was recently replaced with a mechanism which allowed the runtime to pause an goroutine without waiting for it to make a function call.\u0026rdquo; [4]: tmp.gBQ2tEtMHc#easy-footnote-bottom-3-4053 \u0026ldquo;I’m using the //go:noinline pragma to prevent the compiler from inlining max. This is because I want to isolate the effects of inlining on max rather than disabling optimisations globally with -gcflags=\u0026rsquo;-l -N\u0026rsquo;. I go into detail about the //go: comments in this presentation.\u0026rdquo; [5]: tmp.gBQ2tEtMHc#easy-footnote-bottom-4-4053 \u0026ldquo;You can check this for yourself by comparing the output of go test -bench=. -gcflags=-S with and without the //go:noinline annotation.\u0026rdquo; [6]: tmp.gBQ2tEtMHc#easy-footnote-bottom-5-4053 \u0026ldquo;You can check this yourself with the -gcflags=-d=ssa/prove/debug=on flag.\u0026rdquo; [7]: tmp.gBQ2tEtMHc#easy-footnote-1-4053 [8]: https://github.com/golang/proposal/blob/master/design/24543-non-cooperative-preemption.md [9]: tmp.gBQ2tEtMHc#easy-footnote-2-4053 [10]: https://dave.cheney.net/2018/01/08/gos-hidden-pragmas [11]: tmp.gBQ2tEtMHc#easy-footnote-3-4053 [12]: tmp.gBQ2tEtMHc#easy-footnote-4-4053 [13]: tmp.gBQ2tEtMHc#easy-footnote-5-4053 [14]: https://dave.cheney.net/2014/06/07/five-things-that-make-go-fast \u0026ldquo;Five things that make Go fast\u0026rdquo; [15]: https://dave.cheney.net/2013/06/02/why-is-a-goroutines-stack-infinite \u0026ldquo;Why is a Goroutine’s stack infinite ?\u0026rdquo; [16]: https://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go \u0026ldquo;How to write benchmarks in Go\u0026rdquo; [17]: https://dave.cheney.net/2018/01/08/gos-hidden-pragmas \u0026ldquo;Go’s hidden #pragmas\u0026rdquo;\n在 Go 中，一个方法就是一个有预先定义的形参和接受者的函数。假设这个方法不是通过接口调用的，调用一个无消耗的函数所消耗的代价与引入一个方法是相同的。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n在 Go 1.14 以前，栈检查的前置处理也被垃圾回收器用于 STW，通过把所有活跃的 goroutine 栈空间设为 0，来强制它们切换为下一次函数调用时的运行时状态。这个机制[最近被替换][8]为一种新机制，新机制下运行时可以不用等 goroutine 进行函数调用就可以暂停 goroutine。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n我用 //go:noinline 编译指令来阻止编译器内联 max。这是因为我想把内联 max 的影响与其他影响隔离开，而不是用 -gcflags='-l -N' 选项在全局范围内禁止优化。关于 //go: 注释在[这篇文章][10]中详细论述。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n你可以自己通过比较 go test -bench=. -gcflags=-S 有无 //go:noinline 注释时的不同结果来验证一下。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n你可以用 -gcflags=-d=ssa/prove/debug=on 选项来自己验证一下。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-04-29T21:05:10Z","permalink":"https://lxb.wiki/6ce34c49/","title":"【译】Inlining Optimisations in Go"},{"content":"可以用 transmission，它提供了 Web 界面\n1. 安装 transmission： sudo apt-get install transmission-daemon 2. 创建下载目录，一个是下载完成的目录，一个是未完成的目录 mkdir Public/bt_complete mkdir Public/bt_incomplete 3. 配置目录权限 sudo usermod -a -G debian-transmission pi sudo chgrp debian-transmission bt_complete sudo chgrp debian-transmission bt_incomplete sudo chmod 770 bt_complete sudo chmod 770 bt_incomplete 4. 修改配置文件 /etc/transmission-daemon/settings.json \u0026#34;download-dir\u0026#34;:\u0026#34;/home/pi/Public/bt_complete\u0026#34; \u0026#34;incomplete-dir\u0026#34;:\u0026#34;/home/pi/Public/bt_incomplete\u0026#34; \u0026#34;rpc-host-whitelist\u0026#34;: \u0026#34;192.168.1.*\u0026#34;, 5. 重启 transmission sudo service transmission-daemon reload sudo service transmission-daemon restart 两个命令按顺序执行，单独 restart 的话配置不会保存：\n浏览器中输入 http://192.168.1.8:9091/，默认用户名密码：transmission\n修改 transmission 用户名和密码的方法：\n先停止服务： sudo service transmission-daemon stop 修改配置文件，看到这个是加密的密码，直接把密码改为密码明文就可以： “rpc-username”: “明文”, “rpc-password”: “密文”, 再此启动服务 ：sudo service transmission-daemon start 启动的时候 transmission 会自动把新密码加密。 transmission 默认监听 51413 端口，最好在路由器上做个端口转发，把这个端口转到它的 IP 地址\n","date":"2020-03-11T22:29:00Z","permalink":"https://lxb.wiki/fb1d9193/","title":"树莓派做BT下载器"},{"content":"1. 树莓派上创建 git 账号，创建用于存放代码的目录 /srv/\n2. GitHub 库 clone 到树莓派 git clone git@github.com:user/XXXX.git /srv/\n3. 添加 remote git remote add upstream https://github.com/abcd/XXXX\n4. 修改 hook #.git/hooks/post-update param=\u0026#34;$1\u0026#34; push_branch=${param##refs/heads/} #获取到更新的分支名 git push origin $push_branch 5. 添加定时任务 5,35 * * * * cd /srv/XXXX \u0026amp;\u0026amp; git pull upstream master\n6. 在本地代码添加 remote 6.1 有多个项目时，为避免修改每个项目的 remote，直接添加 host 192.168.1.8 gitsrv\n6.2 在每个项目在添加一次 remote git remote add pi git@192.168.1.8:/srv/XXXX\n这样即使以后地址改变，只需要改一次 host 就可以了\n7. 推拉代码时，从 pi 推拉 git pull pi branch\ngit push pi branch\n","date":"2020-03-10T19:03:42Z","permalink":"https://lxb.wiki/2073ae8b/","title":"树莓派搭建GitHub镜像服务"},{"content":"信号类型 Linux系统共定义了64种信号，分为两大类：可靠信号与不可靠信号，前32种信号为不可靠信号，后32种为可靠信号。\n概念 不可靠信号： 也称为非实时信号，不支持排队，信号可能会丢失, 比如发送多次相同的信号, 进程只能收到一次. 信号值取值区间为1~31； 可靠信号： 也称为实时信号，支持排队, 信号不会丢失, 发多少次, 就可以收到多少次. 信号值取值区间为32~64\n信号表 在终端，可通过kill -l查看所有的signal信号\n取值 名称 解释 默认动作 1 SIGHUP 挂起 2 SIGINT 中断 3 SIGQUIT 退出 4 SIGILL 非法指令 5 SIGTRAP 断点或陷阱指令 6 SIGABRT abort发出的信号 7 SIGBUS 非法内存访问 8 SIGFPE 浮点异常 9 SIGKILL kill信号 不能被忽略、处理和阻塞 10 SIGUSR1 用户信号1 11 SIGSEGV 无效内存访问 12 SIGUSR2 用户信号2 13 SIGPIPE 管道破损，没有读端的管道写数据 14 SIGALRM alarm发出的信号 15 SIGTERM 终止信号 16 SIGSTKFLT 栈溢出 17 SIGCHLD 子进程退出 默认忽略 18 SIGCONT 进程继续 19 SIGSTOP 进程停止 不能被忽略、处理和阻塞 20 SIGTSTP 进程停止 21 SIGTTIN 进程停止，后台进程从终端读数据时 22 SIGTTOU 进程停止，后台进程想终端写数据时 23 SIGURG I/O有紧急数据到达当前进程 默认忽略 24 SIGXCPU 进程的CPU时间片到期 25 SIGXFSZ 文件大小的超出上限 26 SIGVTALRM 虚拟时钟超时 27 SIGPROF profile时钟超时 28 SIGWINCH 窗口大小改变 默认忽略 29 SIGIO I/O相关 30 SIGPWR 关机 默认忽略 31 SIGSYS 系统调用异常 ","date":"2020-02-15T19:19:45Z","permalink":"https://lxb.wiki/c77ce28f/","title":"非实时信号表"},{"content":"cgo 的大量文档都提到过，它提供了四个用于转换 Go 和 C 类型的字符串的函数，都是通过复制数据来实现。在 CGo 的文档中有简洁的解释，但我认为解释得太简洁了，因为文档只涉及了定义中的某些特定字符串，而忽略了两个很重要的注意事项。我曾经踩过这里的坑，现在我要详细解释一下。\n四个函数分别是：\nfunc C.CString(string) *C.char func C.GoString(*C.char) string func C.GoStringN(*C.char, C.int) string func C.GoBytes(unsafe.Pointer, C.int) []byte C.CString() 等价于 C 的 strdup()，像文档中提到的那样，把 Go 的字符串复制为可以传递给 C 函数的 C 的 char *。很讨厌的一件事是，由于 Go 和 CGo 类型的定义方式，调用 C.free 时需要做一个转换：\ncs := C.CString(\u0026#34;a string\u0026#34;) C.free(unsafe.Pointer(cs)) 请留意，Go 字符串中可能嵌入了 \\0 字符，而 C 字符串不会。如果你的 Go 字符串中有 \\0 字符，当你调用 C.CString() 时，C 代码会从 \\0 字符处截断你的字符串。这往往不会被注意到，但有时文本并不保证不含 null 字符。\nC.GoString() 也等价于 strdup()，但与 C.CString() 相反，是把 C 字符串转换为 Go 字符串。你可以用它定义结构体的字段，或者是声明为 C 的 char *（在 Go 中叫 *C.cahr） 的其他变量，抑或其他的一些变量（我们后面会看到）。\nC.GoStringN() 等价于 C 的 memmove()，与 C 中普通的字符串函数不同。**它把整个 N 长度的 C buffer 复制为一个 Go 字符串，不单独处理 null 字符。**再详细点，它也通过复制来实现。如果你有一个定义为 char feild[64] 的结构体的字段，然后调用了 C.GoStringN(\u0026amp;field, 64)，那么你得到的 Go 字符串一定是 64 个字符，字符串的末尾有可能是一串 \\0 字符。\n(我认为这是 cgo 文档中的一个 bug。它宣称 GoStringN 的入参是一个 C 的字符串，但实际上很明显不是，因为 C 的字符串不能以 null 字符结束，而 GoStringN 不会在 null 字符处结束处理。)\nC.GoBytes() 是 C.GoStringN() 的另一个版本，不返回 string 而是返回 []byte。它没有宣称以 C 字符串作为入参，它仅仅是对整个 buffer 做了内存拷贝。\n如果你要拷贝的东西不是以 null 字符结尾的 C 字符串，而是固定长度的 memory buffer，那么 C.GoString() 正好能满足需求；它避开了 C 中传统的问题处理不是 C 字符串的 ’string‘。然而，如果你要处理定义为 char field[N] 的结构体字段这种限定长度的 C 字符串时，这些函数都不能满足需求。\n传统语义的结构体中固定长度的字符串变量，定义为 char field[N] 的字段，以及“包含一个字符串”等描述，都表示当且仅当字符串有足够空间时以 null 字符结尾，换句话说，字符串最多有 N-1 个字符。如果字符串正好有 N 个字符，那么它不会以 null 字符结尾。这是 C 代码中诸多 bug 的根源，也不是一个好的 API，但我们却摆脱不了这个 API。每次我们遇到这样的字段，文档不会明确告诉你字段的内容并不一定是 null 字符结尾的，你需要自己假设你有这种 API。\nC.GoString() 或 C.GoStringN() 都不能正确处理这些字段。使用 GoStringN() 相对来说出错更少；它仅仅返回一个末尾有一串 \\0 字符长度为 N 的 Go 字符串（如果你仅仅是把这些字段打印出来，那么你可能不会留意到；我经常干这种事）。使用有诱惑力的 GoString() 更是引狼入室，因为它内部会对入参做 strlen()；如果字符末尾没有 null 字符，strlen() 会访问越界的内存地址。如果你走运，你得到的 Go 字符串末尾会有大量的垃圾。如果你不走运，你的 Go 程序出现段错误，因为 strlen() 访问了未映射的内存地址。\n（总的来说，如果字符串末尾出现了大量垃圾，通常意味着在某处有不含结束符的 C 字符串。）\n你需要的是与 C 的 strndup() 等价的 Go 函数，以此来确保复制不超过 N 个字符且在 null 字符处终止。下面是我写的版本，不保证无错误：\nfunc strndup(cs *C.char, len int) string { s := C.GoStringN(cs, C.int(len)) i := strings.IndexByte(s, 0) if i == -1 { return s } return C.GoString(cs) } 由于有 Go 的字符串怎样占用内存的问题，这段代码做了些额外的工作来最小化额外的内存占用。你可能想用另一种方法，返回一个 GoStringN() 字符串的切片。你也可以写复杂的代码，根据 i 和 len 的不同来决定选用哪种方法。\n更新：Ian Lance Taylor 给我展示了份更好的代码：\nfunc strndup(cs *C.char, len int) string { return C.GoStringN(cs, C.int(C.strnlen(cs, C.size_t(len)))) } 是的，这里有大量的转换。这篇文章就是你看到的 Go 和 Gco 类型的结合。\nvia: https://utcc.utoronto.ca/~cks/space/blog/programming/GoCGoStringFunctions\n作者：ChrisSiebenmann 译者：Xiaobin.Liu 校对：polaris1119\n本文由 GCTT 原创编译，Go 中文网 荣誉推出\n","date":"2020-02-09T20:55:26Z","permalink":"https://lxb.wiki/8c45788a/","title":"【译】关于 CGo 的字符串函数的解释"},{"content":"在我之前的文章 Go 中我喜欢的东西中提到过，我喜欢的 Go 的东西其中之一就是它的字符串（通常还有切片）。从一个 Python 开发者的角度看，它们之所以伟大，是因为创建它们时开销很少，因为它们通常不需要复制。在 Python 中，任何时候操作字符串都需要复制一部分或全部字符串，而 这很容易对性能造成影响。想要写高性能的 Python 代码需要谨慎考虑复制的问题。在 Go 中，几乎所有的字符串操作都是不复制的，仅仅是从原字符串取一个子集（例如去除字符串首尾的空白字符），因此你可以更自由地操作字符串。这个机制可以非常直接地解决你的问题，并且非常高效。\n（当然，不是所有的字符串操作都不复制。例如，把一个字符串转换成大写需要复制，尽管 Go 中的实现已经足够智能，在不需要改变原字符串时 — 例如由于它已经是一个全大写的字符串 — 可以规避掉复制。）\n但是这个优势也带来了潜在的坏处，那些没有开销的子字符串使原来的整个字符串一直存在于内存中。Go 中的字符串（和切片）操作之所以内存开销很少，是因为它们只是底层存储（字符串或切片底层的数组的真实数据）的一些部分的引用；创建一个字符串做的操作就是创建了一个新的引用。但是 Go（目前）不会对字符串数据或数组进行部分的垃圾回收，所以即使它一个很小的 bit 被其它元素引用，整个对象也会一直保持在内存中。换句话说，一个单字符的字符串（目前）足够让一个巨大的字符串不被 GC 回收。\n当然，不会有很多人遇到这个问题。为了遇到它，你需要处理一个非常庞大的原字符串，或造成大量的内存消耗（或者两者都做），在这个基础上，你必须创建那些不持久的字符串的持久的小子字符串（好吧，你是多么希望它是非持久的）。很多使用场景不会复现这个问题；要么你的原字符串不够大，要么你的子集获取了大部分原字符串（例如你把原字符串进行了分词处理），要么子字符串生命周期不够长。简而言之，如果你是一个普通的 Go 开发者，你可以忽略这个问题。处理长字符串并且长时间维持原字符串的很小部分的人才会关注这个问题。\n（我之所以关注到这个问题，是因为一次我花了大量精力用尽可能少的内存写 Python 程序，尽管它是从一个大的配置文件解析结果然后分块储存。这让我联想到了一些其他的事，如字符串的生命周期、限制字符串只复制一次，等等。然后我用 Go 语言写了一个解析器，这让我由重新考虑了一下这些问题，我意识到由于我的解析器截取出和维持的 bit 一直存在于内存中，从输入文件解析出的庞大字符串也会一直存在与内存中。）\n顺便说一下，我认为这是 Go 做了权衡之后的正确结果。大部分使用字符串的开发者不会遇到这个问题，而且截取子字符串开销很小对于开发者来说用处很大。这种低开销的截取操作也减轻了 GC 的负担；当代码使用大量的子字符串截取（像 Python 中那样）时，你只需要处理固定长度的字符串引用就可以了，而不是需要处理长度变化的字符串。\n当你的代码遇到这个问题时，当然有明显的解决方法：创建一个函数，通过把字符串转换成 []byte 来 ”最小化“ 字符串，然后返回。这种方法生成了一个最小化的字符串，内存开销是理论上最完美实现的只复制一次，而 Go 现在很容易就可以实现。\n附加问题：strings.ToUpper() 等怎样规避没有必要的复制 所有的主动转换函数像 ToUpper() 和 ToTitle() 是用 strings.Map() 和 unicode 包 中的函数实现的。Map() 足够智能，在映射的函数返回一个与已存在的 rune 不同的结果之前不会创建新的字符串。因此，你代码中所有类似的直接使用 Map() 的地方都不会有内存开销。\nvia: https://utcc.utoronto.ca/~cks/space/blog/programming/GoStringsMemoryHolding\n作者：Chris Siebenmann 译者：lxbwolf 校对：校对者ID\n本文由 GCTT 原创编译，Go 中文网 荣誉推出\n","date":"2020-01-17T00:12:58Z","permalink":"https://lxb.wiki/10e5e8ba/","title":"【译】Go 字符串中的潜在问题"},{"content":"\nℹ️ 本文基于 Go 1.13。关于内存管理的概念的讨论在我的文章 Go 中的内存管理和分配 中有详细的解释。\nGo GC 的作用是回收不再使用的内存。实现的算法是并发的三色标记和清除回收法。本中文，我们研究三色标记法，以及各个颜色的不同用处。\n你可以在 Ken Fox 的 解读垃圾回收算法 中了解更多关于不同垃圾回收机制的信息。\n标记阶段 这个阶段浏览内存来了解哪些块儿是在被我们的代码使用和哪些块儿应该被回收。\n然而，因为 GC 和我们的 Go 程序并行，GC 扫描期间内存中某些对象的状态可能被改变，所以需要一个检测这种可能的变化的方法。为了解决这个潜在的问题，实现了 写屏障 算法，GC 可以追踪到任何的指针修改。使写屏障生效的唯一条件是短暂终止程序，又名 “Stop the World”。\n在进程启动时，Go 也在每个 processor 起了一个标记 worker 来辅助标记内存。\n然后，当 root 被加入到处理队列中后，标记阶段就开始遍历和用颜色标记内存。\n为了了解在标记阶段的每一步，我们来看一个简单的程序示例：\ntype struct1 struct { a, b int64 c, d float64 e *struct2 } type struct2 struct { f, g int64 h, i float64 } func main() { s1 := allocStruct1() s2 := allocStruct2() func () { _ = allocStruct2() }() runtime.GC() fmt.Printf(\u0026#34;s1 = %X, s2 = %X\\n\u0026#34;, \u0026amp;s1, \u0026amp;s2) } //go:noinline func allocStruct1() *struct1 { return \u0026amp;struct1{ e: allocStruct2(), } } //go:noinline func allocStruct2() *struct2 { return \u0026amp;struct2{} } struct2 不包含指针，因此它被储存在一个专门存放不被其他对象引用的对象的 span 中。\n这减少了 GC 的工作，因为标记内存时不需要扫描这个 span。\n分配工作结束后，我们的程序强迫 GC 重复前面的步骤。下面是流程图：\nGC 从栈开始，递归地顺着指针找指针指向的对象，遍历内存。扫描到被标记为 no scan 的 span 时，停止扫描。然而，这个工作是在多个协程中完成的，每个指针被加入到一个 work pool 中的队列。然后，后台运行的标记 worker 从这个 work pool 中拿到前面出列的 work，扫描这个对象然后把在这个对象里找到的指针加入到队列。\n颜色标记 worker 需要一种记录哪些内存需要扫描的方法。GC 使用一种 三色标记算法，工作流程如下：\n开始时，所有对象都被认为是白色 root 对象（栈，堆，全局变量）被标记为灰色 这个初始步骤完成后，GC 会：\n选择一个灰色的对象，标记为黑色 追踪这个对象的所有指针，把所有引用的对象标记为灰色 然后，GC 重复以上两步，直到没有对象可被标记。在这一时刻，对象非黑即白，没有灰色。白色的对象表示没有其他对象引用，可以被回收。\n下面是前面例子的图示：\n初始状态下，所有的对象被认为是白色的。然后，遍历到的且被其他对象引用的对象，被标记为灰色。如果一个对象在被标记为 no scan 的 span 中，因为它不需要被扫描，所以可以标记为黑色。\n现在灰色的对象被加入到扫描队列并被标记为黑色：\n对加入到扫描队列的所有对象重复做相同的操作，直到没有对象需要被处理：\n处理结束时，黑色对象表示内存中在使用的对象，白色对象是要被回收的对象。我们可以看到，由于 struct2 的实例是在一个匿名函数中创建的且不再存在于栈上，因此它是白色的且可以被回收。\n归功于每一个 span 中的名为 gcmarkBits 的 bitmap 属性，三色被原生地实现了，bitmap 对 scan 中相应的 bit 设为 1 来追踪 scan。\n我们可以看到，黑色和灰色表示的意义相同。处理的不同之处在于，标记为灰色时是把对象加入到扫描队列，而标记为黑色时，不再扫描。\nGC 最终 STW，清除每一次写屏障对 work pool 做的改变，继续后续的标记。\n你可以在我的文章 Go GC 怎样监控你的应用 中找到关于并发处理和 GC 的标记阶段更详细的描述。\nruntime 分析器 Go 提供的工具使我们可以对每一步进行可视化，观察 GC 在我们的程序中的影响。开启 tracing 运行我们的代码，可以看到前面所有步骤的一个概览。下面是追踪结果：\n标记 worker 的生命周期也可以在追踪结果中以协程等级可视化。下面是在启动之前先在后台等待标记内存的 goroutine #33 的例子。\nvia: https://medium.com/a-journey-with-go/go-how-does-the-garbage-collector-mark-the-memory-72cfc12c6976\n作者：Vincent Blanchon 译者：lxbwolf 校对：polaris1119\n本文由 GCTT 原创编译，Go 中文网 荣誉推出\n","date":"2020-01-14T00:06:31Z","permalink":"https://lxb.wiki/b3baee92/","title":"[译]Go GC 怎么标记内存"},{"content":"今天我们来讨论微服务架构中的自我恢复能力。通常情况下，服务间会通过同步或异步的方式进行通信。我们假定把一个庞大的系统分解成一个个的小块能将各个服务解耦。管理服务内部的通信可能有点困难了。你可能听说过这两个著名的概念：熔断和重试。\n熔断器 想象一个简单的场景：用户发出的请求访问服务 A 随后访问另一个服务 B。我们可以称 B 是 A 的依赖服务或下游服务。到服务 B 的请求在到达各个实例前会先通过负载均衡器。\n后端服务发生系统错误的原因有很多，例如慢查询、network blip 和内存争用。在这种场景下，如果返回 A 的 response 是 timeout 和 server error，我们的用户会再试一次。在混乱的局面中我们怎样来保护下游服务呢？\n熔断器可以让我们对失败率和资源有更好的控制。熔断器的设计思路是不等待 TCP 的连接 timeout 快速且优雅地处理 error。这种 fail fast 机制会保护下游的那一层。这种机制最重要的部分就是立刻向调用方返回 response。没有被 pending request 填充的线程池，没有 timeout，而且极有可能烦人的调用链中断者会更少。此外，下游服务也有了充足的时间来恢复服务能力。完全杜绝错误很难，但是减小失败的影响范围是有可能的。\n通过 hystrix 熔断器，我们可以采用降级方案，对上游返回降级后的结果。例如，服务 B 可以访问一个备份服务或 cache，不再访问原来的服务 C。引入这种降级方案需要集成测试，因为我们在 happy path（译注：所谓 happy path，即测试方法的默认场景，没有异常和错误信息。具体可参见 wikipedia）可能不会遇到这种网络模式。\n状态 熔断器有三个主要的状态：\nClosed：让所有请求都通过的默认状态。在阈值下的请求不管成功还是失败，熔断器的状态都不会改变。可能出现的错误是 Max Concurrency（最大并发数）和 Timeout（超时）。 Open：所有的请求都会返回 Circuit Open 错误并被标记为失败。这是一种不等待处理结束的 timeout 时间的 fail-fast 机制。 Half Open：周期性地向下游服务发出请求，检查它是否已恢复。如果下游服务已恢复，熔断器切换到 Closed 状态，否则熔断器保持 Open 状态。 熔断器原理 控制熔断的设置共有 5 个主要参数。\n// CommandConfig is used to tune circuit settings at runtime type CommandConfig struct { Timeout int `json:\u0026#34;timeout\u0026#34;` MaxConcurrentRequests int `json:\u0026#34;max_concurrent_requests\u0026#34;` RequestVolumeThreshold int `json:\u0026#34;request_volume_threshold\u0026#34;` SleepWindow int `json:\u0026#34;sleep_window\u0026#34;` ErrorPercentThreshold int `json:\u0026#34;error_percent_threshold\u0026#34;` } 查看源码\n可以通过根据两个服务的 SLA（‎ Service Level Agreement，服务级别协议）来定出阈值。如果在测试时把依赖的其他服务也涉及到了，这些值会得到很好的调整。\n一个好的熔断器的名字应该能精确指出哪个服务连接出了问题。实际上，请求一个服务时可能会有很多个 API endpoint。每一个 endpoint 都应该有一个对应的熔断器。\n生产上的熔断器 熔断器通常被放在聚合点上。尽管熔断器提供了一种 fail-fast 机制，但我们仍然需要确保可选的降级方案可行。如果我们因为假定需要降级方案的场景出现的可能性很小就不去测试它，那（之前的努力）就是白费力气了。即使在最简单的演练中，我们也要确保阈值是有意义的。以我的个人经验，把参数配置在 log 中 print 出来对于 debug 很有帮助。\nDemo 这段实例代码用的是 hystrix-go 库，hystrix Netflix 库在 Golang 的实现。\npackage main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;github.com/afex/hystrix-go/hystrix\u0026#34; ) const commandName = \u0026#34;producer_api\u0026#34; func main() { hystrix.ConfigureCommand(commandName, hystrix.CommandConfig{ Timeout: 500, MaxConcurrentRequests: 100, ErrorPercentThreshold: 50, RequestVolumeThreshold: 3, SleepWindow: 1000, }) http.HandleFunc(\u0026#34;/\u0026#34;, logger(handle)) log.Println(\u0026#34;listening on :8080\u0026#34;) http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } func handle(w http.ResponseWriter, r *http.Request) { output := make(chan bool, 1) errors := hystrix.Go(commandName, func() error { // talk to other services err := callChargeProducerAPI() // err := callWithRetryV1() if err == nil { output \u0026lt;- true } return err }, nil) select { case out := \u0026lt;-output: // success log.Printf(\u0026#34;success %v\u0026#34;, out) case err := \u0026lt;-errors: // failure log.Printf(\u0026#34;failed %s\u0026#34;, err) } } // logger is Handler wrapper function for logging func logger(fn http.HandlerFunc) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { log.Println(r.URL.Path, r.Method) fn(w, r) } } func callChargeProducerAPI() error { fmt.Println(os.Getenv(\u0026#34;SERVER_ERROR\u0026#34;)) if os.Getenv(\u0026#34;SERVER_ERROR\u0026#34;) == \u0026#34;1\u0026#34; { return errors.New(\u0026#34;503 error\u0026#34;) } return nil } demo 中分别测试了请求调用链 closed 和 open 两种情况：\n/* Experiment 1: success path */ // server go run main.go // client for i in $(seq 10); do curl -x \u0026#39;\u0026#39; localhost:8080 ;done /* Experiment 2: circuit open */ // server SERVER_ERROR=1 Go run main.go // client for i in $(seq 10); do curl -x \u0026#39;\u0026#39; localhost:8080 ;done 查看源码\n重试问题 在上面的熔断器模式中，如果服务 B 缩容，会发生什么？大量已经从 A 发出的请求会返回 5xx error。可能会触发熔断器切换到 open 的错误报警。因此我们需要重试以防间歇性的 network hiccup 发生。\n一段简单的重试代码示例：\npackage main func callWithRetryV1() (err error) { for index := 0; index \u0026lt; 3; index++ { // call producer API err := callChargeProducerAPI() if err != nil { return err } } // adding backoff // adding jitter return nil } 查看源码\n重试模式 为了实现乐观锁，我们可以为不同的服务配置不同的重试次数。因为立即重试会对下游服务产生爆发性的请求，所以不能用立即重试。加一个 backoff 时间可以缓解下游服务的压力。一些其他的模式会用一个随机的 backoff 时间（或在等待时加 jitter）。\n一起来看下列算法：\nExponential: bash * 2attemp Full Jitter: sleep = rand(0, base * 2attempt) Equal Jitter: temp = base * 2attemp; sleep = temp/2+rand(0, temp/2) De-corredlated Jitter: sleep = rand(base, sleep*3) 【译注】关于这几个算法，可以参考这篇文章 。Full Jitter、 Equal Jitter、 De-corredlated 等都是原作者自己定义的名词。\n客户端的数量与服务端的总负载和处理完成时间是有关联的。为了确定什么样的重试模式最适合你的系统，在客户端数量增加时很有必要运行基准测试。详细的实验过程可以在这篇文章中看到。我建议的算法是 de-corredlated Jitter 和 full jitter 选择其中一个。\n两者结合 熔断器被广泛用在无状态线上事务系统中，尤其是在聚合点上。重试应该用于调度作业或不被 timeout 约束的 worker。经过深思熟虑后我们可以同时用熔断器和重试。在大型系统中，service mesh 是一种能更精确地编排不同配置的理想架构。\n参考文章 https://github.com/afex/hystrix-go/ https://github.com/eapache/go-resiliency https://github.com/Netflix/Hystrix/wiki https://www.awsarchitectureblog.com/2015/03/backoff.html https://dzone.com/articles/go-microservices-part-11-hystrix-and-resilience via: https://medium.com/@trongdan_tran/circuit-breaker-and-retry-64830e71d0f6\n作者：Dan Tran 译者：Xiaobin.Liu 校对：polaris1119\n本文由 GCTT 原创编译，Go语言中文网 荣誉推出\n","date":"2019-12-12T23:02:17Z","permalink":"https://lxb.wiki/c9399f4/","title":"【译】微服务中的熔断器和重试"},{"content":"\nℹ️ 本文运行环境为 Go 1.13\n对于一个程序来说，从内存和性能角度讲创建一个 OS 线程或切换线程花费巨大。Go 志在极尽所能地充分利用内核资源。从第一天开始，它就是为并发而生的。\nM, P, G 编排 为了解决这个问题，Go 有它自己的在线程间调度协程的调度器。这个调度器定义了三个主要概念，如源码中解释的这样：\nThe main concepts are: G - goroutine. M - worker thread, or machine. P - processor, a resource that is required to execute Go code. M must have an associated P to execute Go code[...]. P, M, G 模型图解：\n每个协程（G）运行在与一个逻辑 CPU（P）相关联的 OS 线程（M）上。我们一起通过一个简单的示例来看 Go 是怎么管理他们的：\nfunc main() { var wg sync.WaitGroup wg.Add(2) go func() { println(`hello`) wg.Done() }() go func() { println(`world`) wg.Done() }() wg.Wait() } 首先，Go 根据机器逻辑 CPU 的个数来创建不同的 P，并且把它们保存在一个空闲 P 的 list 里。\n然后，为了更好地工作新创建的已经准备好的协程会唤醒一个 P。这个 P 通过与之相关联的 OS 线程来创建一个 M：\n然而，像 P 那样，系统调用返回的甚至被 gc 强行停止的空闲的 M — 比如没有协程在等待运行 — 也会被加到一个空闲 list：\n在程序启动阶段，Go 就已经创建了一些 OS 线程并与 M 想关联了。在我们的例子中，打印 hello 的第一个协程会使用主协程，第二个会从这个空闲 list 中获取一个 M 和 P：\n现在我们已经掌握了协程和线程管理的基本要义，来一起看看什么情形下 Go 会用比 P 多的 M，在系统调用时怎么管理协程。\n系统调用 Go 会优化系统调用 — 无论阻塞与否 — 通过运行时封装他们。封装的那一层会把 P 和线程 M 分离，并且可以让另一个线程在它上面运行。我们拿文件读取举例：\nfunc main() { buf := make([]byte, 0, 2) fd, _ := os.Open(\u0026#34;number.txt\u0026#34;) fd.Read(buf) fd.Close() println(string(buf)) // 42 } 文件读取的流程如下：\nP0 现在在空闲 list 中，有可能被唤醒。当系统调用 exit 时，Go 会遵守下面的规则，直到有一个命中了。\n尝试去捕获相同的 P，在我们的例子中就是 P0，然后 resume 执行过程 尝试从空闲 list 中捕获一个 P，然后 resume 执行过程 把协程放到全局队列里，把与之相关联的 M 放回空闲 list 去 然而，在像 http 请求等 non-blocking I/O 情形下，Go 在资源没有准备好时也会处理请求。在这种情形下，第一个系统调用 — 遵循上述流程图 — 由于资源还没有准备好所以不会成功，（这样就）迫使 Go 使用 network poller 并使协程停驻。请看示例：\nfunc main() { http.Get(`https://httpstat.us/200`) } 当第一个系统调用完成且显式地声明了资源还没有准备好，协程会在 network poller 通知它资源准备就绪之前一直处于停驻状态。在这种情形下，线程 M 不会阻塞：\n在 Go 调度器在等待信息时协程会再次运行。调度器在获取到等待的信息后会询问 network poller 是否有协程在等待被运行。\n如果多个协程都准备好了，只有一个会被运行，其他的会被加到全局的可运行队列中，以备后续的调度。\nOS 线程方面的限制 在系统调用中，Go 不会限制可阻塞的 OS 线程数，源码中有解释：\nThe GOMAXPROCS variable limits the number of operating system threads that can execute user-level Go code simultaneously. There is no limit to the number of threads that can be blocked in system calls on behalf of Go code; those do not count against the GOMAXPROCS limit. This package’s GOMAXPROCS function queries and changes the limit.\n译注：GOMAXPROCS 变量表示可同时运行用户级 Go 代码的操作系统线程的最大数量。系统调用中可被阻塞的最大线程数并没有限制；可被阻塞的线程数对 GOMAXPROCS 没有影响。这个包的 GOMAXPROCS 函数查询和修改这个最大数限制。\n对这种情形举例：\nfunc main() { var wg sync.WaitGroup for i := 0;i \u0026lt; 100 ;i++ { wg.Add(1) go func() { http.Get(`https://httpstat.us/200?sleep=10000`) wg.Done() }() } wg.Wait() } 利用追踪工具得到的线程数如下：\n由于 Go 优化了线程使用，所以当协程阻塞时，它仍可复用，这就解释了为什么图中的数跟示例代码循环中的数不一致。\nvia: https://medium.com/a-journey-with-go/go-goroutine-os-thread-and-cpu-management-2f5a5eaf518a\n作者：Vincent Blanchon 译者：Xiaobin.Liu 校对：polaris1119\n本文由 GCTT 原创编译，Go语言中文网 荣誉推出\n","date":"2019-12-12T23:01:35Z","permalink":"https://lxb.wiki/4e717bb5/","title":"【译】协程，操作系统线程和 CPU 管理"},{"content":"符号\t英文名\t中文名 ~\ttilde or swung dash\t波浪字符或代字号 !\texclamation mark\t惊叹号 @\tat sign or commercial at\t爱特或小老鼠 #\tnumber sign\t井号 $\tdollar sign\t美元符 %\tpercent sign\t百分号 ^\tcaret\t脱字符 \u0026amp;\tampersand\t与和符 *\tasterisk\t星号 ()\tparentheses, round brackets, soft brackets, or circle brackets 小括号，圆括号 []\tbrackets (US), square brackets, closed brackets or hard brackets\t中括号，方括号 {}\tbraces (UK and US), French brackets, curly brackets\t大括号，花括号 \u0026lt;\u0026gt; angle brackets or chevrons\t尖括号 _\tunderscore\t下划线 +\tplus sign\t加号 −\tminus sign\t减号 =\tequals sign\t等号 \u0026lt; less-than sign\t小于号 \u0026gt; greater-than sign\t大于号 .\tperiod, full stop or dot\t句号，点 ,\tcomma\t逗号 :\tcolon 冒号 ;\tsemicolon\t分号 ?\tquestion mark\t问号 -\thyphen\t连字符 ...\tellipsis\t省略号 –\tdash\t破折号 /\tslash, forward slash\t斜线 \\\tbackslash\t反斜线 |\tvertical bar\t竖线 “\tquotation mark\t双引号 ‘\tapostrophe\t单引号，省略符号 ","date":"2019-12-07T10:22:50Z","permalink":"https://lxb.wiki/2d9f52fc/","title":"Symbol Names of Keyboard"},{"content":"[toc]\n如果类型定义了 String() 方法，它会被用在 fmt.Printf() 中生成默认的输出：等同于使用格式化描述符 %v 产生的输出。还有 fmt.Print() 和 fmt.Println() 也会自动使用 String() 方法。\n那么我们看看下面的例子：\ntype Customer struct { mutex sync.RWMutex id string age int } func (c *Customer) UpdateAge(age int) error { c.mutex.Lock() defer c.mutex.Unlock() if age \u0026lt; 0 { return fmt.Errorf(\u0026#34;age should be positive for customer %v\u0026#34;, c) } c.age = age return nil } func (c *Customer) String() string { fmt.Println(\u0026#34;enter string method\u0026#34;) c.mutex.RLock() defer c.mutex.RUnlock() return fmt.Sprintf(\u0026#34;id %s, age %d\u0026#34;, c.id, c.age)} 这个例子中，如果调用 UpdateAge 方法 age 小于0会调用 fmt.Errorf，格式化输出，这个时候 String() 方法里面也进行了加锁，那么这样会造成死锁。\nmutex.Lock -\u0026gt; check age -\u0026gt; Format error -\u0026gt; call String() -\u0026gt; mutex.RLock 解决方法也很简单，一个是缩小锁的范围，在 check age 之后再加锁，另一种方法是 Format error 的时候不要 Format 整个结构体，可以改成 Format id 就行了。\n","date":"2019-11-19T23:03:37+08:00","permalink":"https://lxb.wiki/1dadf84f/","title":"Go语言的坑: String Format 带来的 Dead Lock"},{"content":"函数变量(函数值) 在 Go 语言中，函数被看作是第一类值，这意味着函数像变量一样，有类型、有值，其他普通变量能做的事它也可以。\nfunc square(x int) { println(x * x) } 直接调用：square(1) 把函数当成变量一样赋值：s := square；接着可以调用这个函数变量：s(1)。 注意：这里 square 后面没有圆括号，调用才有。 调用 nil 的函数变量会导致 panic。 函数变量的零值是 nil，这意味着它可以跟 nil 比较，但两个函数变量之间不能比较。 匿名函数 作用: 在go语言中目前了解的作用就是用于构成闭包\n闭包 闭包通过引用的方式使用外部函数的变量 函数与 与其(直接)相关的环境形成闭包\n简单来说: 因为把返回的函数赋给了一个变量, 虽然函数在执行完一瞬间会销毁其执行环境, 但是如果有闭包的话, 闭包会保存外部函数的活动对象(变量), 所以如果不对闭包的引用消除掉, 闭包会一直存在内存中, 垃圾收集器不会销毁闭包占用的内存\n实例1 //函数A是一个不带参数，返回值是一个匿名函数，且该函数 //带有一个int类型参数，返回值为一个int类型 func A() func(int) int { sum := 0 return func(bb int) int { sum += bb fmt.Println(\u0026#34;bb=\u0026#34;, bb, \u0026#34;\\tsum=\u0026#34;, sum) return sum } } 调用1:\nfunc main() { a := A()//定义变量a,并将函数A的返回值赋给a // 这个时候, 虽然有小括号, 但是func A()还未真正执行, 只是赋值给了变量a b := a(4) //真正执行func A() fmt.Println(b) } /* ** 输出： ** bb= 4 sum= 4 ** 4 */ 调用2\nfunc main() { a := A() a(0) a(1) a(5) } /* **　输出： **　bb= 0 sum= 0 **　bb= 1 sum= 1 **　bb= 5 sum= 6 */ 以上调用通过闭包实现了sum的累加\n调用3\nfunc main() { a := A() c := A() a(0) a(5) c(10) c(20) } /* **　输出： **　bb= 0 sum= 0 **　bb= 5 sum= 5 **　bb= 10 sum= 10 **　bb= 20 sum= 30 */ 可以看出，上例中调用了两次函数A，构成了两个闭包，这两个闭包维护的变量sum不是同一个变量。 实例2 func B() []func() { b := make([]func(), 3, 3) for i := 0; i \u0026lt; 3; i++ { b[i] = func() { fmt.Println(i) } } return b } func main() { c := B() // 这个时候并未真正执行函数, 只是定义, 所以不会print c[0]() // 这个时候真正执行, 但是由于闭包, c[0] 中拿的i的引用 c[1]() c[2]() } /* **　输出： **　3 **　3 **　3 */ 闭包通过引用的方式使用外部函数的变量。\n上例中只调用了一次函数B,构成一个闭包(func() {fmt.Println(i)} 与它的环境func B() []func(){} 构成闭包)，i 在外部函数B中定义，所以闭包维护该变量 i ，c[0]、c[1]、c[2]中的 i 都是闭包中 i 的引用。\n因此执行c:=B()后，i 的值已经变为3，故再调用c0时的输出是3而不是0。 可作如下修改：\nfunc B() []func() { b := make([]func(), 3, 3) for i := 0; i \u0026lt; 3; i++ { b[i] = (func(j int) func() { return func() { fmt.Println(j) } })(i) // 这个地方的小括号是真正执行了 } return b } func main() { c := B() c[0]() c[1]() c[2]() } /* ** 输出： ** 0 ** 1 ** 2 */ 函数func() {fmt.Println(j)} 与它的环境func(j int) func() {} 构成闭包, 变量i(实参) 并没有在它的环境范围内, 且 j是形参 以上修改可能没有什么实际意义，此处仅为说明问题使用。\n在使用defer的时候可能出现类似问题，需要注意：\nfor j := 0; j \u0026lt; 2; j++ { defer (func() { fmt.Println(j) })() } /* ** 输出： ** 2 ** 2 */ 实例3: func incr() func() int { var x int return func() int { x++ return x } } 调用这个函数会返回一个函数变量。 i := incr() : 通过把这个函数变量赋值给i, i 就成为了一个闭包 所以i 保存着对x 的引用, 可以想象i 中有着一个指针指向x 或者 i 中有x 的地址\n由于i 有着指向x 的指针, 所以可以修改x , 且保持着状态:\nprintln(i()) // 1 println(i()) // 2 println(i()) // 3 也就是说, x 逃逸了, 它的声明周期没有随着它的作用域结束而结束 但是这段代码却不会递增：\nprintln(incr()()) // 1 println(incr()()) // 1 println(incr()()) // 1 这是因为这里调用了三次 incr()，返回了三个闭包，这三个闭包引用着三个不同的 x，它们的状态是各自独立的。\n实例4: 闭包引用产生的问题 x := 1 f := func() { println(x) } x = 2 x = 3 f() // 3 因为闭包对外层词法域变量是引用的，所以这段代码会输出 3。 可以想象 f 中保存着 x 的地址，它使用 x 时会直接解引用，所以 x 的值改变了会导致 f 解引用得到的值也会改变。 但是，这段代码却会输出 1：\nx := 1 func() { println(x) // 1 }() x = 2 x = 3 这是因为 f 调用时就已经解引用取值了，这之后的修改就与它无关了。\n不过如果再次调用 f 还是会输出 3，这也再一次证明了 f 中保存着 x 的地址。 可以通过在闭包内外打印所引用变量的地址来证明：\nx := 1 func() { println(\u0026amp;x) // 0xc0000de790 }() println(\u0026amp;x) // 0xc0000de790 可以看到引用的是同一个地址。\n实例5.1: 循环闭包引用 for i := 0; i \u0026lt; 3; i++ { func() { println(i) // 0, 1, 2 }() } 这段代码相当于：\nfor i := 0; i \u0026lt; 3; i++ { f := func() { println(i) // 0, 1, 2 } f() } 每次迭代后都对 i 进行了解引用并使用得到的值且不再使用，所以这段代码会正常输出。\n实例5.2 正常代码：输出 0, 1, 2：\nvar dummy [3]int for i := 0; i \u0026lt; len(dummy); i++ { println(i) // 0, 1, 2 } 然而这段代码会输出 3：\nvar dummy [3]int var f func() for i := 0; i \u0026lt; len(dummy); i++ { f = func() { println(i) } } f() // 3 这个地方i最后的值是3, 而不是2, 因为只有i的值是3时, 才会跳出循环 实例5.3 var funcSlice []func() for i := 0; i \u0026lt; 3; i++ { funcSlice = append(funcSlice, func() { println(i) }) } for j := 0; j \u0026lt; 3; j++ { funcSlice[j]() // 3, 3, 3 } 为了解决上面这种情况, 可以声明新的匿名函数并传参:\nvar funcSlice []func() for i := 0; i \u0026lt; 3; i++ { func(k int) { funcSlice = append(funcSlice, func() { println(k) }) }(i) } for j := 0; j \u0026lt; 3; j++ { funcSlice[j]() // 0, 1, 2 } 现在 println(k) 使用的 k 是通过函数参数传递进来的，并且 Go 语言的函数参数是按值传递的。(把k换成i也没有问题, 即使它与for条件的中的i 和func的入参i 重名也能正常运行)\n所以相当于在这个新的匿名函数内声明了三个变量，被三个闭包函数独立引用。原理跟第一种方法是一样的。\n这里的解决方法可以用在大多数跟闭包引用有关的问题上，不局限于第三个例子。\n","date":"2019-11-17T14:38:20Z","permalink":"https://lxb.wiki/e2c91def/","title":"go匿名函数和闭包"},{"content":"[toc]\n创建 goroutine 发生先于 goroutine 执行，所以下面这段代码先读一个变量，然后在 goroutine 中写变量不会发生 data race 问题：\ni := 0 go func() { i++ }() goroutine 退出没有任何 happen before保证，例如下面代码会有 data race ：\ni := 0 go func() { i++ }() fmt.Println(i) channel 操作中 send 操作是 happens before receive 操作 ：\nvar c = make(chan int, 10) var a string func f() { a = \u0026#34;hello, world\u0026#34; c \u0026lt;- 0 } func main() { go f() \u0026lt;-c print(a) } 上面执行顺序应该是：\nvariable change -\u0026gt; channel send -\u0026gt; channel receive -\u0026gt; variable read 上面能够保证一定输出 \u0026ldquo;hello, world\u0026rdquo;。\nclose channel 是 happens before receive 操作，所以下面这个例子中也不会有 data race 问题：\ni := 0 ch := make(chan struct{}) go func() { \u0026lt;-ch fmt.Println(i) }() i++ close(ch) 在无缓冲的 channel 中 receive 操作是 happens before send 操作的，例如：\nvar c = make(chan int) var a string func f() { a = \u0026#34;hello, world\u0026#34; \u0026lt;-c } func main() { go f() c \u0026lt;- 0 print(a) } 这里同样能保证输出 hello, world。\n","date":"2019-11-16T23:01:24+08:00","permalink":"https://lxb.wiki/a81f14e2/","title":"Go语言的坑: Happens Before 保证"},{"content":"[toc]\n迭代带来的问题 在 Go 语言中，字符串是一种基本类型，默认是通过 utf8 编码的字符序列，当字符为 ASCII 码时则占用 1 个字节，其他字符根据需要占用 2-4 个字节，比如中文编码通常需要 3 个字节。\n那么我们在做 string 迭代的时候可能会产生意想不到的问题：\ns := \u0026#34;hêllo\u0026#34; for i := range s { fmt.Printf(\u0026#34;position %d: %c\\n\u0026#34;, i, s[i]) } fmt.Printf(\u0026#34;len=%d\\n\u0026#34;, len(s)) 输出：\nposition 0: h position 1: Ã position 3: l position 4: l position 5: o len=6 上面的输出中发现第二个字符是 Ã，不是 ê，并且位置2的输出”消失“了，这其实就是因为 ê 在 utf8 里面实际上占用 2 个 byte：\ns h ê l l o []byte(s) 68 c3 aa 6c 6c 6f 所以我们在迭代的时候 s[1] 等于 c3 这个 byte 等价 Ã 这个 utf8 值，所以输出的是 hÃllo 而不是 hêllo。\n那么根据上面的分析，我们就可以知道在迭代获取字符的时候不能只获取单个 byte，应该使用 range 返回的 value值：\ns := \u0026#34;hêllo\u0026#34; for i, v := range s { fmt.Printf(\u0026#34;position %d: %c\\n\u0026#34;, i, v) } 或者我们可以把 string 转成 rune 数组，在 go 中 rune 代表 Unicode码位，用它可以输出单个字符：\ns := \u0026#34;hêllo\u0026#34; runes := []rune(s) for i, _ := range runes { fmt.Printf(\u0026#34;position %d: %c\\n\u0026#34;, i, runes[i]) } 输出：\nposition 0: h position 1: ê position 2: l position 3: l position 4: o 截断带来的问题 Go 中在对slice使用 ：操作符进行截断的时候，底层的数组实际上指向同一个，在 string 里面也需要注意这个问题，比如下面：\nfunc (s store) handleLog(log string) error { if len(log) \u0026lt; 36 { return errors.New(\u0026#34;log is not correctly formatted\u0026#34;) } uuid := log[:36] s.store(uuid) // Do something } 这段代码用了 ：操作符进行截断，但是如果 log 这个对象很大，比如上面的 store 方法把 uuid 一直存在内存里，可能会造成底层的数组一直不释放，从而造成内存泄露。\n为了解决这个问题，我们可以先复制一份再处理：\nfunc (s store) handleLog(log string) error { if len(log) \u0026lt; 36 { return errors.New(\u0026#34;log is not correctly formatted\u0026#34;) } uuid := strings.Clone(log[:36]) // copy一份 s.store(uuid) // Do something } ","date":"2019-11-15T22:58:48+08:00","permalink":"https://lxb.wiki/b23a493c/","title":"Go语言的坑: String 相关"},{"content":"[toc]\n注意 defer 的调用时机 有时候我们会像下面一样使用 defer 去关闭一些资源：\nfunc readFiles(ch \u0026lt;-chan string) error { for path := range ch { file, err := os.Open(path) if err != nil { return err } defer file.Close() // Do something with file } return nil } 因为defer会在方法结束的时候调用，但是如果上面的 readFiles 函数永远没有 return，那么 defer 将永远不会被调用，从而造成内存泄露。并且 defer 写在 for 循环里面，编译器也无法做优化，会影响代码执行性能。\n为了避免这种情况，我们可以 wrap 一层：\nfunc readFiles(ch \u0026lt;-chan string) error { for path := range ch { if err := readFile(path); err != nil { return err } } return nil } func readFile(path string) error { file, err := os.Open(path) if err != nil { return err } defer file.Close() // Do something with file return nil } 注意 defer 的参数 defer 声明时会先计算确定参数的值。\nfunc a() { i := 0 defer notice(i) // 0 i++ return } func notice(i int) { fmt.Println(i) } 在这个例子中，变量 i 在 defer 被调用的时候就已经确定了，而不是在 defer执行的时候，所以上面的语句输出的是 0。\n所以我们想要获取这个变量的真实值，应该用引用：\nfunc a() { i := 0 defer notice(\u0026amp;i) // 1 i++ return } defer 下的闭包 func a() int { i := 0 defer func() { fmt.Println(i + 1) //12 }() i++ return i+10 } func TestA(t *testing.T) { fmt.Println(a()) //11 } 如果换成闭包的话，实际上闭包中对变量i是通过指针传递的，所以可以读到真实的值。但是上面的例子中 a 函数返回的是 11 是因为执行顺序是：\n先计算（i+10）-\u0026gt; (call defer) -\u0026gt; (return) ","date":"2019-11-14T22:56:42+08:00","permalink":"https://lxb.wiki/725e70e6/","title":"Go语言的坑: Defer"},{"content":"[toc]\ncopy 的问题 使用 range 的时候如果我们直接修改它返回的数据会不生效，因为返回的数据并不是原始数据：\ntype account struct { balance float32 } accounts := []account{ {balance: 100.}, {balance: 200.}, {balance: 300.}, } for _, a := range accounts { a.balance += 1000 } 如果像上面这么做，那么输出的 accounts 是：\n[{100} {200} {300}] 所以我们想要改变 range 中的数据可以这么做：\nfor i := range accounts { accounts[i].balance += 1000 } range slice 的话也会 copy 一份：\ns := []int{0, 1, 2} for range s { s = append(s, 10) } 这份代码在 range 的时候会 copy 一份，因此只会调用三次 append 后停止。\n指针问题 比方我们想要 range slice 并将返回值存到 map 里面供后面业务使用，类似这样：\ntype Customer struct { ID string Balance float64 } test := []Customer{ {ID: \u0026#34;1\u0026#34;, Balance: 10}, {ID: \u0026#34;2\u0026#34;, Balance: -10}, {ID: \u0026#34;3\u0026#34;, Balance: 0}, } var m map[string]*Customer for _, customer := range test { m[customer.ID] = \u0026amp;customer } 但是这样遍历 map 里面存的并不是我们想要的，你会发现存的 value 都是最后一个：\n{\u0026#34;1\u0026#34;:{\u0026#34;ID\u0026#34;:\u0026#34;3\u0026#34;,\u0026#34;Balance\u0026#34;:0},\u0026#34;2\u0026#34;:{\u0026#34;ID\u0026#34;:\u0026#34;3\u0026#34;,\u0026#34;Balance\u0026#34;:0},\u0026#34;3\u0026#34;:{\u0026#34;ID\u0026#34;:\u0026#34;3\u0026#34;,\u0026#34;Balance\u0026#34;:0}} 这是因为当我们使用 range 遍历 slice 的时候，返回的 customer 变量实际上是一个固定的地址：\nfor _, customer := range test { fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;customer) //我们想要获取这个指针的时候 } 输出：\n0x1400000e240 0x1400000e2400x1400000e240 这是因为迭代器会把数据都放入到 0x1400000e240 这块空间里面：\n所以我们可以这样在 range 里面获取指针：\nfor _, customer := range test { current := customer // 使用局部变量 fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;current) // 这里获取的指针是 range copy 出来元素的指针 } 或者：\nfor i := range test { current := \u0026amp;test[i] // 使用局部变量 fmt.Printf(\u0026#34;%p\\n\u0026#34;, current) } ","date":"2019-11-13T22:53:37+08:00","permalink":"https://lxb.wiki/ad6a336e/","title":"Go语言的坑: Range"},{"content":"[toc]\nslice 的 length 和 capacity s := make([]int, 3, 6) 在 make 函数里面，capacity 是可选的参数。上面这段代码我们创建了一个 length 是 3，capacity 是 6 的 slice，那么底层的数据结构是这样的：\nslice 的底层实际上指向了一个数组。当然，由于我们的 length 是 3，所以这样设置 s[4] = 0 会 panic 的。需要使用 append 才能添加新元素。\npanic: runtime error: index out of range [4] with length 3 当 appned 超过 cap 大小的时候，slice 会自动帮我们扩容，在元素数量小于 1024 的时候每次会扩大一倍，当超过了 1024 个元素每次扩大 25%。\n有时候我们会使用 ：操作符从另一个 slice 上面创建一个新切片：\ns1 := make([]int, 3, 6) s2 := s1[1:3] 实际上这两个 slice 还是指向了底层同样的数组，构如下：\n由于指向了同一个数组，那么当我们改变第一个槽位的时候，比如 s1[1]=2，实际上两个 slice 的数据都会发生改变：\n但是当我们使用 append 的时候情况会有所不同：\ns2 = append(s2, 3) fmt.Println(s1) // [0 2 0] fmt.Println(s2) // [2 0 3] s1 的 len 并没有被改变，所以看到的还是3元素。\n还有一件比较有趣的细节是，如果再接着 append s1 那么第四个元素会被覆盖掉：\ns1 = append(s1, 4) fmt.Println(s1) // [0 2 0 4] fmt.Println(s2) // [2 0 4] 再继续 append s2 直到 s2 发生扩容，这个时候会发现 s2 实际上和 s1 指向的不是同一个数组了：\ns2 = append(s2, 5, 6, 7) fmt.Println(s1) //[0 2 0 4] fmt.Println(s2) //[2 0 4 5 6 7] 除了上面这种情况，还有一种情况 append 会产生意想不到的效果：\ns1 := []int{1, 2, 3} s2 := s1[1:2] s3 := append(s2, 10) 如果 print 它们应该是这样：\ns1=[1 2 10], s2=[2], s3=[2 10] slice 初始化 slice 的初始化有很多种方式：\nfunc main() { var s []string log(1, s) s = []string(nil) log(2, s) s = []string{} log(3, s) s = make([]string, 0) log(4, s) } func log(i int, s []string) { fmt.Printf(\u0026#34;%d: empty=%t\\tnil=%t\\n\u0026#34;, i, len(s) == 0, s == nil) } 输出：\n1: empty=true nil=true 2: empty=true nil=true 3: empty=true nil=false 4: empty=true nil=false 前两种方式会创建一个 nil 的 slice，后两种会进行初始化，并且这些 slice 的大小都为 0 。\n对于 var s []string 这种方式来说，好处就是不用做任何的内存分配。比如下面场景可能可以节省一次内存分配:\nfunc f() []string { var s []string if foo() { s = append(s, \u0026#34;foo\u0026#34;) } if bar() { s = append(s, \u0026#34;bar\u0026#34;) } return s } 对于 s := []string{} 这种方式来说，它比较适合初始化一个已知元素的 slice：\ns := []string{\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;} 如果没有这个需求其实用 var s []string 比较好，反正在使用的适合都是通过 append 添加元素， var s []string 还能节省一次内存分配。\n如果我们初始化了一个空的 slice， 那么最好是使用 len(xxx) == 0来判断 slice 是不是空的，如果使用 nil 来判断可能会永远非空的情况，因为对于 s := []string{} 和 s = make([]string, 0) 这两种初始化都是非 nil 的。\n对于 []string(nil) 这种初始化的方式，使用场景很少，一种比较方便地使用场景是用它来进行 slice 的 copy：\nsrc := []int{0, 1, 2} dst := append([]int(nil), src...) 对于 make 来说，它可以初始化 slice 的 length 和 capacity，如果我们能确定 slice 里面会存放多少元素，从性能的角度考虑最好使用 make 初始化好，因为对于一个空的 slice append 元素进去每次达到阈值都需要进行扩容，下面是填充 100 万元素的 benchmark：\nBenchmarkConvert_EmptySlice-4 22 49739882 ns/op BenchmarkConvert_GivenCapacity-4 86 13438544 ns/op BenchmarkConvert_GivenLength-4 91 12800411 ns/op 可以看到，如果我们提前填充好 slice 的容量大小，性能是空 slice 的四倍，因为少了扩容时元素复制以及重新申请新数组的开销。\ncopy slice src := []int{0, 1, 2} var dst []int copy(dst, src) fmt.Println(dst) // [] 使用 copy 函数 copy slice 的时候需要注意，上面这种情况实际上会 copy 失败，因为对 slice 来说是由 length 来控制可用数据，copy 并没有复制这个字段，要想 copy 我们可以这么做：\nsrc := []int{0, 1, 2} dst := make([]int, len(src)) copy(dst, src) fmt.Println(dst) //[0 1 2] 除此之外也可以用上面提到的：\nsrc := []int{0, 1, 2} dst := append([]int(nil), src...) slice capacity内存释放问题 type Foo struct { v []byte } func keepFirstTwoElementsOnly(foos []Foo) []Foo { return foos[:2] } func main() { foos := make([]Foo, 1_000) printAlloc() for i := 0; i \u0026lt; len(foos); i++ { foos[i] = Foo{ v: make([]byte, 1024*1024), } } printAlloc() two := keepFirstTwoElementsOnly(foos) runtime.GC() printAlloc() runtime.KeepAlive(two) } 上面这个例子中使用 printAlloc 函数来打印内存占用：\nfunc printAlloc() { var m runtime.MemStats runtime.ReadMemStats(\u0026amp;m) fmt.Printf(\u0026#34;%d KB\\n\u0026#34;, m.Alloc/1024) } 上面 foos 初始化了 1000 个容量的 slice ，里面 Foo struct 每个都持有 1M 内存的 slice，然后通过 keepFirstTwoElementsOnly 返回持有前两个元素的 Foo 切片，我们的想法是手动执行 GC 之后其他的 998 个 Foo 会被 GC 销毁，但是输出结果如下：\n387 KB 1024315 KB1024319 KB 实际上并没有，原因就是实际上 keepFirstTwoElementsOnly 返回的 slice 底层持有的数组是和 foos 持有的同一个：\n所以我们真的要只返回 slice 的前2个元素的话应该这样做：\nfunc keepFirstTwoElementsOnly(foos []Foo) []Foo { res := make([]Foo, 2) copy(res, foos) return res } 不过上面这种方法会初始化一个新的 slice，然后将两个元素 copy 过去。不想进行多余的分配可以这么做：\nfunc keepFirstTwoElementsOnly(foos []Foo) []Foo { for i := 2; i \u0026lt; len(foos); i++ { foos[i].v = nil } return foos[:2] } ","date":"2019-11-12T22:35:22+08:00","permalink":"https://lxb.wiki/46d0864d/","title":"Go语言的坑: Slice 相关"},{"content":"[toc]\n在 Go 中浮点数表示方式和其他语言一样，都是通过科学计数法表示，float 在存储中分为三部分：\n符号位（Sign）: 0代表正，1代表为负 指数位（Exponent）:用于存储科学计数法中的指数数据，并且采用移位存储 尾数部分（Mantissa）：尾数部分\n这种计数法在 Go 里面会有哪些问题。\na := 100000.001 b := 1.0001 c := 1.0002 fmt.Println(a * (b + c)) fmt.Println(a*b + a*c) 输出：\n200030.00200030004 200030.0020003 如果想要准确计算浮点的话，可以尝试 https://github.com/shopspring/decimal\na := decimal.NewFromFloat(100000.001) b := decimal.NewFromFloat(1.0001) c := decimal.NewFromFloat(1.0002) fmt.Println(a.Mul(b.Add(c))) //200030.0020003 其他 在 Go 中探索 IEEE-754 标准 - Go语言中文网 - Golang中文社区 (studygolang.com)\n","date":"2019-11-10T22:26:32+08:00","permalink":"https://lxb.wiki/b936d10f/","title":"Go语言的坑: Float 的精度"},{"content":"[toc]\nsum := 100 + 011 fmt.Println(sum) 运行之后，不会输出 111，而是 108， 因为在 Go 中以 0 开头的整数表示八进制\n它经常用在处理 Linux 权限相关的代码上，如下面打开一个文件：\nfile, err := os.OpenFile(\u0026#34;foo\u0026#34;, os.O_RDONLY, 0644) 所以为了可读性，我们在用八进制的时候最好使用 \u0026ldquo;0o\u0026rdquo; 的方式表示，比如上面这段代码可以表示为：\nfile, err := os.OpenFile(\u0026#34;foo\u0026#34;, os.O_RDONLY, 0o644) ","date":"2019-11-09T22:23:08+08:00","permalink":"https://lxb.wiki/8f80ddfc/","title":"Go语言的坑: 八进制整数"},{"content":"[toc]\ninit 函数会在全局变量之后被执行 init 函数并不是最先被执行的，如果声明了 const 或全局变量，那么 init 函数会在它们之后执行：\npackage main import \u0026#34;fmt\u0026#34; var a = func() int { fmt.Println(\u0026#34;a\u0026#34;) return 0 }() func init() { fmt.Println(\u0026#34;init\u0026#34;) } func main() { fmt.Println(\u0026#34;main\u0026#34;) } // output a initmain init 初始化按解析的依赖关系顺序执行 比如 main 包里面有 init 函数，依赖了 redis 包，main 函数执行了 redis 包的 Store 函数，恰好 redis 包里面也有 init 函数，那么执行顺序会是：\n还有一种情况，如果是使用 \u0026ldquo;import _ foo\u0026rdquo; 这种方式引入的，也是会先调用 foo 包中的 init 函数。\n扰乱单元测试 比如我们在 init 函数中初始了一个全局的变量，但是单测中并不需要，那么实际上会增加单测得复杂度，比如：\nvar db *sql.DB func init(){ dataSourceName := os.Getenv(\u0026#34;MYSQL_DATA_SOURCE_NAME\u0026#34;) d, err := sql.Open(\u0026#34;mysql\u0026#34;, dataSourceName) if err != nil { log.Panic(err) } db = d } 在上面这个例子中 init 函数初始化了一个 db 全局变量，那么在单测的时候也会初始化一个这样的变量，但是很多单测其实是很简单的，并不需要依赖这个东西。\n","date":"2019-11-08T22:19:41+08:00","permalink":"https://lxb.wiki/dc53dc63/","title":"Go语言的坑: Init 函数"},{"content":"[toc]\nvar client *http.Client if tracing { client, err := createClientWithTracing() if err != nil { return err } log.Println(client) } else { client, err := createDefaultClient() if err != nil { return err } log.Println(client) } 在上面这段代码中，声明了一个 client 变量，然后使用 tracing 控制变量的初始化，可能是因为没有声明 err 的缘故，使用的是 := 进行初始化，那么会导致外层的 client 变量永远是 nil。这个例子实际上是很容易发生在我们实际的开发中，尤其需要注意。\n如果是因为 err 没有初始化的缘故，我们在初始化的时候可以这么做：\nvar client *http.Client var err error if tracing { client, err = createClientWithTracing() } else { ... } if err != nil { // 防止重复代码 return err } 或者内层的变量声明换一个变量名字，这样就不容易出错了。\n我们也可以使用工具分析代码是否有 shadow，先安装一下工具：\ngo install golang.org/x/tools/go/analysis/passes/shadow/cmd/shadow 然后使用 shadow 命令：\ngo vet -vettool=/path/to/shadow ./main.go # command-line-arguments ./main.go:15:3: declaration of \u0026#34;client\u0026#34; shadows declaration at line 13 ./main.go:21:3: declaration of \u0026#34;client\u0026#34; shadows declaration at line 13 ","date":"2019-11-07T22:13:56+08:00","permalink":"https://lxb.wiki/7edb3d45/","title":"Go语言的坑: Shadow 变量"},{"content":"给出一个区间的集合，请合并所有重叠的区间。\n示例 1:\n输入: [[1,3],[2,6],[8,10],[15,18]] 输出: [[1,6],[8,10],[15,18]] 解释: 区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6]. 示例 2:\n输入: [[1,4],[4,5]] 输出: [[1,5]] 解释: 区间 [1,4] 和 [4,5] 可被视为重叠区间。 思路:\n怎么判断重叠: 两区间的最小的右边界 大于或等于 两区间最大的左边界. 如[1,5]和[2,8] 入参是切片的切片(intervals), 拿intervals[0]与它后面的所有区间对比, 从intervals[1]开始, 如果有与之重叠的区间, 就把合并后的新区间赋给intervals[0], 并删除参与合并的那个旧区间 intervals[0]完成后, 拿``intervals[1]与它后边的所有区间对比, 从intervals[2] 开始, 如果有与之重叠的区间, 就把合并后的新区间赋给intervals[1]`, 并删除参与合并的那个就区间 拿intervals[i] 与它后边的所有区间对比, 从intervals[i+1] 开始, 如果有与之重叠的区间intervals[j] , 就把合并后的新区间赋给 intervals[i] , 并删除参与合并的intervals[j] 如果第3步出现了有重叠的区间intervals[j], 那么合并后i 的值变了, 就有可能由原来 在i 到j 之间没有重叠的区间 变成 有重叠的区间, 所以需要从头(i+1) 再遍历一次, 直到再也没有重叠的区间 重复, 一直到切片末尾 code\nfunc min(x, y int) int { if x \u0026lt; y { return x } return y } func max(x, y int) int { if x \u0026gt; y { return x } return y } func merge(intervals [][]int) [][]int { for i := 0; i \u0026lt; len(intervals); { merged := false for j := i + 1; j \u0026lt; len(intervals); j++ { x, y := intervals[i], intervals[j] if min(x[1], y[1]) \u0026gt;= max(x[0], y[0]) { merged = true //重新赋值 intervals[i][0], intervals[i][1] = min(x[0], y[0]), max(x[1], y[1]) //删除j intervals[j] = intervals[len(intervals) - 1] intervals = intervals[:len(intervals) - 1] } } if merged { continue } i++ } return intervals } ","date":"2019-11-06T23:31:03Z","permalink":"https://lxb.wiki/a2b71d73/","title":"合并区间56"},{"content":"编程语言中反射的概念 在计算机科学领域，反射是指一类应用，它们能够自描述和自控制。也就是说，这类应用通过采用某种机制来实现对自己行为的描述（self-representation）和监测（examination），并能根据自身行为的状态和结果，调整或修改应用所描述行为的状态和相关的语义。\n每种语言的反射模型都不同，并且有些语言根本不支持反射。Golang语言实现了反射，反射机制就是在运行时动态的调用对象的方法和属性，官方自带的reflect包就是反射相关的，只要包含这个包就可以使用。\nGolang的gRPC也是通过反射实现的。\ninterface 和反射 先来看看Golang关于类型设计的一些原则\n变量包括（value, type）两部分 理解这一点就知道为什么nil != nil了 type 包括 static type和concrete type. 简单来说 static type是你在编码是看见的类型(如int、string)，concrete type是runtime系统看见的类型 类型断言能否成功，取决于变量的concrete type，而不是static type. 因此，一个 reader变量如果它的concrete type也实现了write方法的话，它也可以被类型断言为writer. 反射，就是建立在类型之上的，Golang的指定类型的变量的类型是静态的（也就是指定int、string这些的变量，它的type是static type），在创建变量的时候就已经确定，反射主要与Golang的interface类型相关（它的type是concrete type），只有interface类型才有反射一说。\n在Golang的实现中，每个interface变量都有一个对应pair，pair中记录了实际变量的值和类型:\n(value, type)\nvalue是实际变量值，type是实际变量的类型。一个interface{}类型的变量包含了2个指针，一个指针指向值的类型【对应concrete type】，另外一个指针指向实际的值【对应value】。\n例如，创建类型为*os.File的变量，然后将其赋给一个接口变量r：\ntty, err := os.OpenFile(\u0026#34;/dev/tty\u0026#34;, os.O_RDWR, 0) var r io.Reader r = tty 接口变量r的pair中将记录如下信息：(tty, *os.File)，这个pair在接口变量的连续赋值过程中是不变的，将接口变量r赋给另一个接口变量w:\nvar w io.Writer w = r.(io.Writer) 接口变量w的pair与r的pair相同，都是:(tty, *os.File)，即使w是空接口类型，pair也是不变的。\ninterface及其pair的存在，是Golang中实现反射的前提，理解了pair，就更容易理解反射。反射就是用来检测存储在接口变量内部(值value；类型concrete type) pair对的一种机制。\nreflect 基本功能TypeOf和ValueOf 既然反射就是用来检测存储在接口变量内部(值value；类型concrete type) pair对的一种机制。那么在Golang的reflect反射包中有什么样的方式可以让我们直接获取到变量内部的信息呢？ 它提供了两种类型（或者说两个方法）让我们可以很容易的访问接口变量内容，分别是reflect.ValueOf() 和 reflect.TypeOf()，看看官方的解释\n// ValueOf returns a new Value initialized to the concrete value // stored in the interface i. ValueOf(nil) returns the zero func ValueOf(i interface{}) Value {...} 翻译一下：ValueOf用来获取输入参数接口中的数据的值，如果接口为空则返回0 // TypeOf returns the reflection Type that represents the dynamic type of i. // If i is a nil interface value, TypeOf returns nil. func TypeOf(i interface{}) Type {...} 翻译一下：TypeOf用来动态获取输入参数接口中的值的类型，如果接口为空则返回nil reflect.TypeOf()是获取pair中的type，reflect.ValueOf()获取pair中的value，示例如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { var num float64 = 1.2345 fmt.Println(\u0026#34;type: \u0026#34;, reflect.TypeOf(num)) fmt.Println(\u0026#34;value: \u0026#34;, reflect.ValueOf(num)) } 运行结果: type: float64 value: 1.2345 说明 reflect.TypeOf： 直接给到了我们想要的type类型，如float64、int、各种pointer、struct 等等真实的类型 reflect.ValueOf：直接给到了我们想要的具体的值，如1.2345这个具体数值，或者类似\u0026amp;{1 \u0026ldquo;Allen.Wu\u0026rdquo; 25} 这样的结构体struct的值 也就是说明反射可以将“接口类型变量”转换为“反射类型对象”，反射类型指的是reflect.Type和reflect.Value这两种 从relfect.Value中获取接口interface的信息 当执行reflect.ValueOf(interface)之后，就得到了一个类型为”relfect.Value”变量，可以通过它本身的Interface()方法获得接口变量的真实内容，然后可以通过类型判断进行转换，转换为原有真实类型。不过，我们可能是已知原有类型，也有可能是未知原有类型，因此，下面分两种情况进行说明。\n已知原有类型【进行“强制转换”】\n已知类型后转换为其对应的类型的做法如下，直接通过Interface方法然后强制转换，如下\nrealValue := value.Interface().(已知的类型) 示例:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { var num float64 = 1.2345 pointer := reflect.ValueOf(\u0026amp;num) value := reflect.ValueOf(num) // 可以理解为“强制转换”，但是需要注意的时候，转换的时候，如果转换的类型不完全符合，则直接panic // Golang 对类型要求非常严格，类型一定要完全符合 // 如下两个，一个是*float64，一个是float64，如果弄混，则会panic convertPointer := pointer.Interface().(*float64) convertValue := value.Interface().(float64) fmt.Println(convertPointer) fmt.Println(convertValue) } 运行结果： 0xc42000e238 1.2345 说明 转换的时候，如果转换的类型不完全符合，则直接panic，类型要求非常严格！ 转换的时候，要区分是指针还是指 也就是说反射可以将“反射类型对象”再重新转换为“接口类型变量” 未知原有类型【遍历探测其Filed】\n很多情况下，我们可能并不知道其具体类型，那么这个时候，该如何做呢？需要我们进行遍历探测其Filed来得知，示例如下:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) type User struct { Id int Name string Age int } func (u User) ReflectCallFunc() { fmt.Println(\u0026#34;Allen.Wu ReflectCallFunc\u0026#34;) } func main() { user := User{1, \u0026#34;Allen.Wu\u0026#34;, 25} DoFiledAndMethod(user) } // 通过接口来获取任意参数，然后一一揭晓 func DoFiledAndMethod(input interface{}) { getType := reflect.TypeOf(input) fmt.Println(\u0026#34;get Type is :\u0026#34;, getType.Name()) getValue := reflect.ValueOf(input) fmt.Println(\u0026#34;get all Fields is:\u0026#34;, getValue) // 获取方法字段 // 1. 先获取interface的reflect.Type，然后通过NumField进行遍历 // 2. 再通过reflect.Type的Field获取其Field // 3. 最后通过Field的Interface()得到对应的value for i := 0; i \u0026lt; getType.NumField(); i++ { field := getType.Field(i) value := getValue.Field(i).Interface() fmt.Printf(\u0026#34;%s: %v = %v\\n\u0026#34;, field.Name, field.Type, value) } // 获取方法 // 1. 先获取interface的reflect.Type，然后通过.NumMethod进行遍历 for i := 0; i \u0026lt; getType.NumMethod(); i++ { m := getType.Method(i) fmt.Printf(\u0026#34;%s: %v\\n\u0026#34;, m.Name, m.Type) } } 运行结果： get Type is : User get all Fields is: {1 Allen.Wu 25} Id: int = 1 Name: string = Allen.Wu Age: int = 25 ReflectCallFunc: func(main.User) 说明 通过运行结果可以得知获取未知类型的interface的具体变量及其类型的步骤为：\n先获取interface的reflect.Type，然后通过NumField进行遍历 再通过reflect.Type的Field获取其Field 最后通过Field的Interface()得到对应的value 通过运行结果可以得知获取未知类型的interface的所属方法（函数）的步骤为：\n先获取interface的reflect.Type，然后通过NumMethod进行遍历 再分别通过reflect.Type的Method获取对应的真实的方法（函数） 最后对结果取其Name和Type得知具体的方法名 也就是说反射可以将“反射类型对象”再重新转换为“接口类型变量” struct 或者 struct 的嵌套都是一样的判断处理方式 通过reflect.Value设置实际变量的值\nreflect.Value是通过reflect.ValueOf(X)获得的，只有当X是指针的时候，才可以通过reflec.Value修改实际变量X的值，即：要修改反射类型的对象就一定要保证其值是“addressable”的。\n示例如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { var num float64 = 1.2345 fmt.Println(\u0026#34;old value of pointer:\u0026#34;, num) // 通过reflect.ValueOf获取num中的reflect.Value，注意，参数必须是指针才能修改其值 pointer := reflect.ValueOf(\u0026amp;num) newValue := pointer.Elem() fmt.Println(\u0026#34;type of pointer:\u0026#34;, newValue.Type()) fmt.Println(\u0026#34;settability of pointer:\u0026#34;, newValue.CanSet()) // 重新赋值 newValue.SetFloat(77) fmt.Println(\u0026#34;new value of pointer:\u0026#34;, num) //////////////////// // 如果reflect.ValueOf的参数不是指针，会如何？ pointer = reflect.ValueOf(num) //newValue = pointer.Elem() // 如果非指针，这里直接panic，“panic: reflect: call of reflect.Value.Elem on float64 Value” } 运行结果： old value of pointer: 1.2345 type of pointer: float64 settability of pointer: true new value of pointer: 77 说明 需要传入的参数是* float64这个指针，然后可以通过pointer.Elem()去获取所指向的Value，注意一定要是指针。 如果传入的参数不是指针，而是变量，那么 通过Elem获取原始值对应的对象则直接panic 通过CanSet方法查询是否可以设置返回false newValue.CantSet()表示是否可以重新设置其值，如果输出的是true则可修改，否则不能修改，修改完之后再进行打印发现真的已经修改了。 reflect.Value.Elem() 表示获取原始值对应的反射对象，只有原始对象才能修改，当前反射对象是不能修改的 也就是说如果要修改反射类型对象，其值必须是“addressable”【对应的要传入的是指针，同时要通过Elem方法获取原始值对应的反射对象】 struct 或者 struct 的嵌套都是一样的判断处理方式 通过reflect.ValueOf来进行方法的调用\n这算是一个高级用法了，前面我们只说到对类型、变量的几种反射的用法，包括如何获取其值、其类型、如果重新设置新值。但是在工程应用中，另外一个常用并且属于高级的用法，就是通过reflect来进行方法【函数】的调用。比如我们要做框架工程的时候，需要可以随意扩展方法，或者说用户可以自定义方法，那么我们通过什么手段来扩展让用户能够自定义呢？关键点在于用户的自定义方法是未可知的，因此我们可以通过reflect来搞定\n示例如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) type User struct { Id int Name string Age int } func (u User) ReflectCallFuncHasArgs(name string, age int) { fmt.Println(\u0026#34;ReflectCallFuncHasArgs name: \u0026#34;, name, \u0026#34;, age:\u0026#34;, age, \u0026#34;and origal User.Name:\u0026#34;, u.Name) } func (u User) ReflectCallFuncNoArgs() { fmt.Println(\u0026#34;ReflectCallFuncNoArgs\u0026#34;) } // 如何通过反射来进行方法的调用？ // 本来可以用u.ReflectCallFuncXXX直接调用的，但是如果要通过反射，那么首先要将方法注册，也就是MethodByName，然后通过反射调动mv.Call func main() { user := User{1, \u0026#34;Allen.Wu\u0026#34;, 25} // 1. 要通过反射来调用起对应的方法，必须要先通过reflect.ValueOf(interface)来获取到reflect.Value，得到“反射类型对象”后才能做下一步处理 getValue := reflect.ValueOf(user) // 一定要指定参数为正确的方法名 // 2. 先看看带有参数的调用方法 methodValue := getValue.MethodByName(\u0026#34;ReflectCallFuncHasArgs\u0026#34;) args := []reflect.Value{reflect.ValueOf(\u0026#34;wudebao\u0026#34;), reflect.ValueOf(30)} methodValue.Call(args) // 一定要指定参数为正确的方法名 // 3. 再看看无参数的调用方法 methodValue = getValue.MethodByName(\u0026#34;ReflectCallFuncNoArgs\u0026#34;) args = make([]reflect.Value, 0) methodValue.Call(args) } 运行结果： ReflectCallFuncHasArgs name: wudebao , age: 30 and origal User.Name: Allen.Wu ReflectCallFuncNoArgs 说明 要通过反射来调用起对应的方法，必须要先通过reflect.ValueOf(interface)来获取到reflect.Value，得到“反射类型对象”后才能做下一步处理 reflect.Value.MethodByName这.MethodByName，需要指定准确真实的方法名字，如果错误将直接panic，MethodByName返回一个函数值对应的reflect.Value方法的名字。 []reflect.Value，这个是最终需要调用的方法的参数，可以没有或者一个或者多个，根据实际参数来定。 reflect.Value的 Call 这个方法，这个方法将最终调用真实的方法，参数务必保持一致，如果reflect.Value\u0026rsquo;Kind不是一个方法，那么将直接panic。 本来可以用u.ReflectCallFuncXXX直接调用的，但是如果要通过反射，那么首先要将方法注册，也就是MethodByName，然后通过反射调用methodValue.Call golang的反射reflect性能\nGolang的反射很慢，这个和它的API设计有关。在 java 里面，我们一般使用反射都是这样来弄的。\nField field = clazz.getField(\u0026#34;hello\u0026#34;); field.get(obj1); field.get(obj2); 这个取得的反射对象类型是 java.lang.reflect.Field。它是可以复用的。只要传入不同的obj，就可以取得这个obj上对应的 field。\n但是Golang的反射不是这样设计的:\ntype_ := reflect.TypeOf(obj) field, _ := type_.FieldByName(\u0026#34;hello\u0026#34;) 这里取出来的 field 对象是 reflect.StructField 类型，但是它没有办法用来取得对应对象上的值。如果要取值，得用另外一套对object，而不是type的反射\ntype_ := reflect.ValueOf(obj) fieldValue := type_.FieldByName(\u0026#34;hello\u0026#34;) 这里取出来的 fieldValue 类型是 reflect.Value，它是一个具体的值，而不是一个可复用的反射对象了，每次反射都需要malloc这个reflect.Value结构体，并且还涉及到GC。\nGolang reflect慢主要有两个原因\n涉及到内存分配以及后续的GC； reflect实现里面有大量的枚举，也就是for循环，比如类型之类的。 总结 上述详细说明了Golang的反射reflect的各种功能和用法，都附带有相应的示例，相信能够在工程应用中进行相应实践，总结一下就是：\n反射可以大大提高程序的灵活性，使得interface{}有更大的发挥余地 反射必须结合interface才玩得转 变量的type要是concrete type的（也就是interface变量）才有反射一说 反射可以将“接口类型变量”转换为“反射类型对象” 反射使用 TypeOf 和 ValueOf 函数从接口中获取目标对象信息 反射可以将“反射类型对象”转换为“接口类型变量 reflect.value.Interface().(已知的类型) 遍历reflect.Type的Field获取其Field 反射可以修改反射类型对象，但是其值必须是“addressable” 想要利用反射修改对象状态，前提是 interface.data 是 settable,即 pointer-interface 通过反射可以“动态”调用方法 因为Golang本身不支持模板，因此在以往需要使用模板的场景下往往就需要使用反射(reflect)来实现 ","date":"2019-11-03T21:21:59Z","permalink":"https://lxb.wiki/1d3c1f0e/","title":"Golang的反射"},{"content":"给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。\n为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。\n**说明：**不允许修改给定的链表。\n解题关键是理解 非环部分的长度与相遇点到环起点那部分环的长度 是相等的 这个数学关系\n假设非环部分长度为x, 从环起点到相遇点的长度为y , 环的长度为c\n慢指针(slow)走过的长度可以表示为``ds = x + n1 * c + y, 快指针(fast) 的速度是慢指针的两倍, 意味着 快指针走过的长度为df = 2(x + n1 * c + y)`\n还有一个约束是, fast 走过的路程一定比slow走的路程多出环长度的整数倍(记为n2 * c)\n所以\ndf - ds = n2 * c 2(x + n1 * c + y) - (x + n1 * c + y) = n2 * c x + n1 * c + y = n2 * c 解读下第三步的等式: 非环部分的长度 + 环起点到相遇点之间的长度 就是环的整数倍\n意味着, 当以环的起点为原点时, 已经走过y(即前面从环起点到相遇点的长度)的前提下, 如果再走x , 就刚好走了很多圈(n2 * c). \u0026ldquo;很多圈\u0026rdquo; 的意思, 就是从原点再到原点, 终点的位置和起点的位置重合.\n怎么才能再走x呢? 让一个指针从head 开始走, 另一个指针从相遇点开始走, 等这两个指针相遇, 就是走了x. 如果不能理解为何相遇恰好就在上面说的原点处, 应该反复琢磨斜体\u0026quot;很多圈\u0026quot;那句话\ncode\nfunc detectCycle(head *ListNode) *ListNode { fast, slow := head, head for fast != nil \u0026amp;\u0026amp; fast.Next != nil \u0026amp;\u0026amp; fast.Next.Next != nil { slow = slow.Next fast = fast.Next.Next if fast == slow { fast = head for fast != slow { fast = fast.Next slow = slow.Next } return fast } } return nil } ","date":"2019-10-31T00:09:51Z","permalink":"https://lxb.wiki/fb68a62c/","title":"环形链表142"},{"content":"1. 明确搜索仓库标题、仓库描述、README\nin:name 关键词\n如果想查找描述的内容，可以使用这样的方式：\nin:descripton 关键词\n这里就是搜索上面项目描述的内容。\n一般项目，都会有个README文件，如果要查该文件包含特定关键词的话\nin:readme 关键词\n2. 明确搜索 star、fork 数大于多少的\n一个项目 star 数的多少，一般代表该项目有受欢迎程度。虽然现在也有垃圾项目刷 star ，但毕竟是少数， star 依然是个不错的衡量标准。\nstars:\u0026gt; 数字 关键字\n比如要找 star 数大于 3000 的Spring Cloud 仓库，就可以这样\nstars:\u0026gt;3000 spring cloud\n如果不加 \u0026gt;= 的话，是要精确找 star 数等于具体数字的，这个一般有点困难。\n如果要找在指定数字区间的话，使用\nstars: 10..20 关键词\nfork 数同理，将上面的 stars 换成 fork，其它语法相同\n3. 明确搜索仓库大小的\n比如只想看个简单的 Demo，不想找特别复杂的且占用磁盘空间较多的，可以在搜索的时候直接限定仓库的 size 。\n使用方式：\nsize:\u0026gt;=5000 关键词\n这里注意下，这个数字代表K, 5000代表着5M。\n4. 明确仓库是否还在更新维护\n我们在确认是否要使用一些开源产品，框架的时候，是否继续维护是很重要的一点。如果已经过时没人维护的东西，踩了坑就不好办了。而在 GitHub 上找项目的时候，不再需要每个都点到项目里看看最近 push 的时间，直接在搜索框即可完成。\n元旦刚过，比如咱们要找临近年底依然在勤快更新的项目，就可以直接指定更新时间在哪个时间前或后的\n通过这样一条搜索 pushed:\u0026gt;2019-01-03 spring cloud\n就找到了1月3号之后，还在更新的项目\n想找指定时间之前或之后创建的仓库也是可以的，把 pushed 改成 created 就行。\n5. 明确搜索仓库的 LICENSE\n经常使用开源软件，一定都知道，开源软件也是分不同的「门派」不同的LICENSE。开源不等于一切免费，不同的许可证要求也大不相同。 2018年就出现了 Facebook 修改 React 的许可协议导致各个公司纷纷修改自己的代码，寻找替换的框架。\n例如要找协议是最为宽松的 Apache License 2 的代码，可以这样\nlicense:apache-2.0 spring cloud\n其它协议就把 apache-2.0 替换一下即可，比如换成 mit 之类的。\n6. 明确搜索仓库的语言\n比如咱们就找 Java 的库， 除了像上面在左侧点击选择之外，还可以在搜索中过滤。像这样：\nlanguage:java 关键词\n7.明确搜索某个人或组织的仓库\nuser:joshlong\n组合使用一下，把 Java 项目过滤出来，多个查询之间「空格」分隔即可。\nuser:joshlong language:java\n找某个组织的代码话，可以这样：\norg:spring-cloud\n就可以列出具体org 的仓库。\n","date":"2019-10-28T23:03:30Z","permalink":"https://lxb.wiki/a813d59a/","title":"如何使用GitHub搜索"},{"content":"leetcode-26\n给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。\n不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。\n给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 你不需要考虑数组中超出新长度后面的元素。 给定 nums = [0,0,1,1,1,2,2,3,3,4], 函数应该返回新的长度 5, 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4。 你不需要考虑数组中超出新长度后面的元素。 理解题意:\n1. 当给定数组为空时, 返回0 2. 不能引入其他数组空间, 即不能再使用一个新的数组来存放结果 3. 最终结果不重复, 整体思路是把数组后面的几个元素挪到前面去, 用后面的元素覆盖掉前面重复了的元素, 保持数组的长度始终不变. 数组中超出新长度(去重后的长度) 后的元素无视 用快慢指针的思路解答:\n给定两个游标 left和right 当给定数组的下标为left和right的值相等时, 就不管 当不相等时, 做一个操作: 把当前right的值赋给left的下一个坐标 code:\nfunc removeDuplicates(nums []int) int { //如果是空切片，那就返回0 if len(nums) == 0 { return 0 } //用两个标记来比较相邻位置的值 //当一样的话，那就不管继续 //当不一样的时候，就把right指向的值赋值给left下一位 left, right := 0, 1 for ; right \u0026lt; len(nums); right++ { if nums[left] == nums[right] { continue } left++ nums[left] = nums[right] } fmt.Println(nums[:left+1]) return left + 1 } ","date":"2019-10-23T22:50:21Z","permalink":"https://lxb.wiki/6a0b412d/","title":"删除排序数组中的重复项"},{"content":"字节切片（byte slice）相关的编译器漏洞和标准库设计失误\n假如一个类型MyByte定义如下，如何将一个[]MyByte切片值和一个[]byte切片值互相转换为对方的类型？\npackage main type MyByte byte var ( x = []byte{1, 2, 3} y = []MyByte{1, 2, 3} ) func main() { x = []byte(y) // error: 非法的转换 y = []MyByte(x) // error: 非法的转换 } 如上例所示，在Go中，这两个类型的值之间的类型转换是非法的。因为Go规定两个切片只有在它们的类型的底层类型（underlying type）相同的情况下才能转换到对方的类型。而一个非定义类型（undefined type）的底层类型为此非定义类型本身。类型[]MyByte和[]byte均为非定义类型，所以它们的底层类型不同，从而它们的值也就不能转换到对方的类型。\n难道真没有办法实现它们之间的转换了？有，而且有好几种。第一种方法是使用类型非安全指针来实现双向转换，另外两种方法只能实现单向转换。另外的这两种方法要么利用了编译器的漏洞，要么利用了reflect标准库包的设计失误。\n使用类型非安全指针的实现。\npackage main import \u0026#34;unsafe\u0026#34; type MyByte byte var ( x = []byte{1, 2, 3} y = []MyByte{1, 2, 3} ) func main() { p := unsafe.Pointer(\u0026amp;y) x = *(*[]byte)(p) x[0] = 99 println(y[0]) // 99 } 在使用类型非安全指针的实现中，转换结果和原切片共享底层元素。\n利用标准编译器的bug\n我们可以将一个[]byte切片值转换为string, 再把string转换为类型[]MyByte。转换结果和原切片不共享底层元素。\npackage main type MyByte byte var ( x = []byte{1, 2, 3} y = []MyByte{1, 2, 3} ) func main() { // 下一行利用了编译器漏洞 y = []MyByte(string(x)) y[0] = 99 println(x[0]) // 1 } Go白皮书提到一个字节切片可以转换为一个字符串，反之亦然。但是什么是字节切片类型呢？底层类型为[]byte的切片类型还是元素类型的底层类型为byte的切片类型？如果字节切片类型定义为元素类型的底层类型为byte的切片类型，则[]MyByte和[]byte都可称为字节切片类型。如果字节切片类型定义为底层类型为[]byte的切片类型，则只有[]byte可以被称为字节切片类型。我们认为标准编译器采纳了底层类型为[]byte的切片类型才称为字节切片这一定义，因为下面这个程序使用标准编译器是编译不过的。\npackage main type MyByte byte var ( x = []byte{1, 2, 3} y = []MyByte{1, 2, 3} ) func main() { _ = string(y) // error: 非法转换 } 但是，标准编译器（v1.12）却认为转换[]MyByte(\u0026ldquo;abc\u0026rdquo;)是合法的。这显然是一个漏洞。\n对于码点切片（rune slice）和字符串之间的转换，同样的情况也存在。\n对于gccgo编译器来说，此漏洞是对称的，因而更严重。此更严重的漏洞使得上述两种类型的值之间的转换是双向有效的。比如，下面这段代码使用gccgo（v8.0）编译是没问题的。\npackage main type MyByte byte var ( x = []byte{1, 2, 3} y = []MyByte{1, 2, 3} ) func main() { // 下一行利用了编译器漏洞 y = []MyByte(string(x)) y[0] = 99 println(x[0]) // 1 // 下一行利用了编译器漏洞 x = []byte(string(y)) x[0] = 127 println(y[0]) // 99 } 事实上，gccgo编译器在内置copy和append函数的实现中也存在着同样的漏洞。\npackage main type MyByte byte var ( x = []byte{1, 2, 3} y = []MyByte{1, 2, 3} ) func main() { // 下一行利用了编译器漏洞 copy(y, string(x)) y[0] = 99 println(x[0]) // 1 // 下一行利用了编译器漏洞 y = append([]MyByte(nil), string(x)...) y[0] = 99 println(x[0]) // 1 } 第三种方法利用了reflect标准库包的设计失误。此失误导致将[]MyByte值单向转换为类型[]byte是可行的，虽然这违反了Go类型系统确定的规则。使用第三种方法得到的结果切片和原切片共享底层元素。\npackage main import \u0026#34;reflect\u0026#34; type MyByte byte var ( x = []byte{1, 2, 3} y = []MyByte{1, 2, 3} ) func main() { v := reflect.ValueOf(y) x = v.Bytes() x[0] = 99 println(y[0]) // 99 } ","date":"2019-10-20T11:29:37Z","permalink":"https://lxb.wiki/4fe063a2/","title":"Golang编译器漏洞和标准库设计失误"},{"content":" 问题场景: 假如下单时，用分布式锁来防止库存超卖，但是是每秒上千订单的高并发场景，如何对分布式锁进行高并发优化来应对这个场景？\n库存超卖现象是怎么产生的？ 假设订单系统部署两台机器上，不同的用户都要同时买10台iphone，分别发了一个请求给订单系统。 接着每个订单系统实例都去数据库里查了一下，当前iphone库存是12台 于是乎，每个订单系统实例都发送SQL到数据库里下单，然后扣减了10个库存，其中一个将库存从12台扣减为2台，另外一个将库存从2台扣减为-8台\n用分布式锁如何解决库存超卖问题？ 分布式锁的实现原理: 同一个锁key，同一时间只能有一个客户端拿到锁，其他客户端会陷入无限的等待来尝试获取那个锁，只有获取到锁的客户端才能执行下面的业务逻辑。\n从上图可以看到，只有一个订单系统实例可以成功加分布式锁，然后只有他一个实例可以查库存、判断库存是否充足、下单扣减库存，接着释放锁。\n释放锁之后，另外一个订单系统实例才能加锁，接着查库存，一下发现库存只有2台了，库存不足，无法购买，下单失败。不会将库存扣减为-8的\n分布式锁的方案在高并发场景下 分布式锁一旦加了之后，对同一个商品的下单请求，会导致所有客户端都必须对同一个商品的库存锁key进行加锁。\n比如，对iphone这个商品的下单，都必对“iphone_stock”这个锁key来加锁。这样会导致对同一个商品的下单请求，就必须串行化，一个接一个的处理。\n假设加锁之后，释放锁之前，查库存 -\u0026gt; 创建订单 -\u0026gt; 扣减库存，这个过程性能很高吧，算他全过程20毫秒，这应该不错了。\n那么1秒是1000毫秒，只能容纳50个对这个商品的请求依次串行完成处理。\n比如一秒钟来50个请求，都是对iphone下单的，那么每个请求处理20毫秒，一个一个来，最后1000毫秒正好处理完50个请求。\n所以, 能看出来简单的使用分布式锁来处理库存超卖问题，存在的缺陷就是同一个商品多用户同时下单的时候，会基于分布式锁串行化处理，导致没法同时处理同一个商品的大量下单的请求。\n这种方案，要是应对那种低并发、无秒杀场景的普通小电商系统，可能还可以接受。\n因为如果并发量很低，每秒就不到10个请求，没有瞬时高并发秒杀单个商品的场景的话，其实也很少会对同一个商品在一秒内瞬间下1000个订单，因为小电商系统没那场景。\n如何对分布式锁进行高并发优化？ 现在按照刚才的计算，你一秒钟只能处理针对iphone的50个订单。\n其实说出来也很简单，相信很多人看过java里的ConcurrentHashMap的源码和底层原理，应该知道里面的核心思路，就是分段加锁！\n把数据分成很多个段，每个段是一个单独的锁，所以多个线程过来并发修改数据的时候，可以并发的修改不同段的数据。不至于说，同一时间只能有一个线程独占修改ConcurrentHashMap中的数据。\n另外，Java 8中新增了一个LongAdder类，也是针对Java 7以前的AtomicLong进行的优化，解决的是CAS类操作在高并发场景下，使用乐观锁思路，会导致大量线程长时间重复循环。\nLongAdder中也是采用了类似的分段CAS操作，失败则自动迁移到下一个分段进行CAS的思路。\n其实分布式锁的优化思路也是类似的，之前我们是在另外一个业务场景下落地了这个方案到生产中，不是在库存超卖问题里用的。\n但是库存超卖这个业务场景不错，很容易理解，所以我们就用这个场景来说一下。\n其实这就是分段加锁。你想，假如你现在iphone有1000个库存，那么你完全可以给拆成20个库存段，要是你愿意，可以在数据库的表里建20个库存字段，比如stock_01，stock_02，类似这样的，也可以在redis之类的地方放20个库存key。\n总之，就是把你的1000件库存给他拆开，每个库存段是50件库存，比如stock_01对应50件库存，stock_02对应50件库存。\n接着，每秒1000个请求过来了，好！此时其实可以是自己写一个简单的随机算法，每个请求都是随机在20个分段库存里，选择一个进行加锁。\n这样就好了，同时可以有最多20个下单请求一起执行，每个下单请求锁了一个库存分段，然后在业务逻辑里面，就对数据库或者是Redis中的那个分段库存进行操作即可，包括查库存 -\u0026gt; 判断库存是否充足 -\u0026gt; 扣减库存。\n这相当于什么呢？相当于一个20毫秒，可以并发处理掉20个下单请求，那么1秒，也就可以依次处理掉20 * 50 = 1000个对iphone的下单请求了。\n一旦对某个数据做了分段处理之后，有一个坑大家一定要注意：如果某个下单请求，咔嚓加锁，然后发现这个分段库存里的库存不足了，此时咋办？\n这时你得自动释放锁，然后立马换下一个分段库存，再次尝试加锁后尝试处理。这个过程一定要实现\n分布式锁并发优化方案有没有什么不足？ ","date":"2019-10-18T22:38:39Z","permalink":"https://lxb.wiki/7db296fb/","title":"分布式锁高并发优化"},{"content":"场景: 在前面的某些操作中, 启动某进程时, 监听8080 和 443 端口, 后进程关闭, 这两个端口却一直处于占用状态, 导致后面再起进程想监听这两个端口时, 启动报错\n1.输入netstat -tln,查看系统当前所有被占用端口,主要是为了查看你的端口是否真正的被占用着,搭建可以看到我的9001,和9002端口都已经被占用了,所以我需要释放这两个端口\n2.根据端口查询进程,输入lsof -i :9001,切记不要忘了添加冒号,如下图,就可以看到当前被占用的端口的进程 的进程编号\nkill 掉PID 再netstat -tln 确认下, 然后就可以起进程了 ","date":"2019-10-10T00:36:59Z","permalink":"https://lxb.wiki/2d1cc7f9/","title":"CentOS释放被占用端口"},{"content":" 源码地址: https://github.com/lxbwolf/UnblockNeteaseMusic\n原理: 使用其它音乐平台的歌曲替换网易云音乐无版权歌曲。 目前备用的平台有：网易云旧链 、QQ 、 虾米 、 百度 、酷狗 、酷我 、咕咪 、JOOX 音源替换变灰歌曲链接 (默认仅启用前四)。\n1、打开网易云音乐客户端的时候，客户端不再直接访问网易云服务器而是访问UnblockNeteaseMusic服务。\n2、UnblockNeteaseMusic收到客户端的请求后，透传给网易云音乐的服务器，并再拿到相关的数据后进行检查，如果发现其中的歌曲没有版权，那么去其它平台查询此歌曲的相关信息。\n3、将查到的数据返回给网易云客户端。\n4、至此完成网易云音乐的解锁。\n整个流程要解决两个重要的问题。\n核心工作: 1、将UnblockNeteaseMusic部署到服务器。可以是本地服务器也可以是云服务器。\n2、为网易云客户端设置代理，以达到访问UnblockNeteaseMusic项目的目的。\n部署服务部分\n安装node.js git clone https://github.com/lxbwolf/UnblockNeteaseMusic.git 在UnblockNeteaseMusic 目录下, 执行npx @nondanee/unblockneteasemusic(官方) 或者 用docker 启动docker run nondanee/unblockneteasemusic \u0026amp;\u0026amp; docker-compose up, 还有另一种方式: 在UnblockNeteaseMusic 目录下, 执行 node app.js -p 8080:443 -f 59.111.160.195 其中59.111.160.195 这个地址是通过 ping music.163.com 测出来的 正常情况下, 服务端启动进程, 客户端配置好IP Port, 就可以用了,\n此时服务端接收到请求会有log, 如果服务端log一直卡在\nHTTP Server running @ http://0.0.0.0:8080 HTTPS Server running @ https://0.0.0.0:443 说明客户端的请求并没有打到服务器上, 可能原因是8080和443端口还没有开启\n配置参数\n$ unblockneteasemusic -h usage: unblockneteasemusic [-v] [-p port] [-a address] [-u url] [-f host] [-o source [source ...]] [-t token] [-e url] [-s] [-h] optional arguments: -v, --version output the version number -p port, --port port specify server port -a address, --address address specify server host -u url, --proxy-url url request through upstream proxy -f host, --force-host host force the netease server ip -o source [source ...], --match-order source [source ...] set priority of sources -t token, --token token set up proxy authentication -e url, --endpoint url replace virtual endpoint with public host -s, --strict enable proxy limitation -h, --help output usage information 客户端配置\n源码中的README 有详细说明\n平台 基础设置 Windows 设置 \u0026gt; 工具 \u0026gt; 自定义代理 (客户端内) UWP Windows 设置 \u0026gt; 网络和 Internet \u0026gt; 代理 Linux 系统设置 \u0026gt; 网络 \u0026gt; 网络代理 macOS 系统偏好设置 \u0026gt; 网络 \u0026gt; 高级 \u0026gt; 代理 Android WLAN \u0026gt; 修改网络 \u0026gt; 高级选项 \u0026gt; 代理 iOS 无线局域网 \u0026gt; HTTP 代理 \u0026gt; 配置代理 Android 手机详细配置:\n设置 \u0026gt; WLAN \u0026gt; 修改网络 \u0026gt; 高级选项 \u0026gt; 代理\nIP: 106.13.86.198 Port: 8080 破解前效果\n破解后效果\n","date":"2019-10-08T18:07:13Z","permalink":"https://lxb.wiki/c6996379/","title":"网易云音乐破版权"},{"content":"斐波那契数列(Fibonacci sequence),又称黄金分割数列 .因数学家列昂纳多·斐波那契(Leonardoda Fibonacci)以兔子繁殖为例子而引入,故又称为“兔子数列”,指的是这样一个数列: 1、1、2、3、5、8、13、21、34、……在数学上,斐波那契数列以如下被以递推的方法定义: F(1)=1，F(2)=1, F(n)=F(n-1)+F(n-2)（n\u0026gt;=3，n∈N*）\n斐波那契数列就是形如 1 1 2 3 5 8 13 21 34 55 的递增数列,从第三项开始起,当前项是前两项之和. 为了计算方便,定义两个变量 a,b 表示前两项,初始值分别设置成 0,1 ,示例:\n// 0 1 1 2 3 5 8 13 21 34 55 // a b // a b a, b := 0, 1 初始化后下一轮移动,a, b = b, a+b 结果是 a , b = 1 , 1,刚好能够表示斐波那契数列的开头.\nfunc fibonacciByNormal() { a, b := 0, 1 a, b = b, a+b fmt.Print(a, \u0026#34; \u0026#34;) fmt.Println() } 但是上述示例只能生成斐波那契数列中的第一个数字,假如我们需要前十个数列,又该如何?\nfunc fibonacciByNormal() { a, b := 0, 1 for i := 0; i \u0026lt; 10; i++ { a, b = b, a+b fmt.Print(a, \u0026#34; \u0026#34;) } fmt.Println() } 通过指定循环次数再稍加修改上述单数列代码,现在就可以生成前十位数列:\n// 1 1 2 3 5 8 13 21 34 55 func TestFibonacciByNormal(t *testing.T) { fibonacciByNormal() } 这种做法是接触闭包概念前我们一直在采用的解决方案,相信稍微有一定编程经验的开发者都能实现,但是闭包却提供了另一种思路!\n// 1 1 2 3 5 8 13 21 34 55 func fibonacci() func() int { a, b := 0, 1 return func() int { a, b = b, a+b return a } } 不论是普通函数还是闭包函数,实现斐波那契数列生成器函数的逻辑不变,只是实现不同,闭包返回的是内部函数,留给使用者继续调用而普通函数是直接生成斐波那契数列.\n// 1 1 2 3 5 8 13 21 34 55 func TestFibonacci(t *testing.T) { f := fibonacci() for i := 0; i \u0026lt; 10; i++ { fmt.Print(f(), \u0026#34; \u0026#34;) } fmt.Println() } 对于这种函数内部嵌套另一个函数并且内部函数引用了外部变量的这种实现方式,称之为\u0026quot;闭包\u0026quot;!\n闭包自带独立的运行环境,每一次运行闭包的环境都是相互独立的,正如面向对象中类和对象实例化的关系那样,闭包是类,闭包的引用是实例化对象.\nfunc autoIncrease() func() int { i := 0 return func() int { i = i + 1 return i } } 上述示例是闭包实现的计算器自增,每一次引用 autoIncrease 函数获得的闭包环境都是彼此独立的,直接上单元测试用例.\nfunc TestAutoIncrease(t *testing.T) { a := autoIncrease() // 1 2 3 t.Log(a(), a(), a()) b := autoIncrease() // 1 2 3 t.Log(b(), b(), b()) } 函数引用 a 和 b 的环境是独立的,相当于另一个一模一样计数器重新开始计数,并不会影响原来的计数器的运行结果.\n普通函数内部定义的变量寿命有限,函数运行结束后也就被系统销毁了,结束了自己短暂而又光荣的一生.\n但是,闭包所引用的变量却不一样,只要一直处于使用中状态,那么变量就会\u0026quot;长生不老\u0026quot;,并不会因为出身于函数内就和普通变量拥有一样的短暂人生.\nfunc fightWithHorse() func() int { horseShowTime := 0 return func() int { horseShowTime++ fmt.Printf(\u0026#34;(%d)祖国需要我,我就提枪上马立即战斗!\\n\u0026#34;,horseShowTime) return horseShowTime } } func TestFightWithHorse(t *testing.T) { f := fightWithHorse() // 1 2 3 t.Log(f(), f(), f()) } 凡事有利必有弊,闭包不死则引用变量不灭,如果不理解变量长生不老的特性,编写闭包函数时可能一不小心就掉进作用域陷阱了,千万要小心! 下面以绑定循环变量为例讲解闭包作用域的陷阱,示例如下:\nfunc countByClosureButWrong() []func() int { var arr []func() int for i := 1; i \u0026lt;= 3; i++ { arr = append(arr, func() int { return i }) } return arr } countByClosureButWrong 闭包函数引用的自由变量不仅有 arr 数组还有循环变量 i ,函数的整体逻辑是: 闭包函数内部维护一个函数数组,保存的函数主要返回了循环变量.\nfunc TestCountByClosure(t *testing.T) { // 4 4 4 for _, c := range countByClosureButWrong() { t.Log(c()) } } 当我们运行 countByClosureButWrong 函数获得闭包返回的函数数组 arr,然后通过 range 关键字进行遍历数组,得到正在遍历的函数项 c.\n当我们运行 c() 时,期望输出的 1,2,3 循环变量的值,但是实际结果却是 4,4,4.\n原因仍然是变量长生不老的特性:遍历循环时绑定的变量值肯定是 1,2,3,但是循环变量 i 却没有像普通函数那样消亡而是一直长生不老,所以变量的引用发生变化了!\n长生不老的循环变量的值刚好是当初循环的终止条件 i=4,只要运行闭包函数,不论是数组中的哪一项函数引用的都是相同的变量 i,所以全部都是 4,4,4.\n既然是变量引用出现问题,那么解决起来就很简单了,不用变量引用就好了嘛!\n最简单的做法就是使用短暂的临时变量 n 暂存起来正在遍历的值,闭包内引用的变量不再是 i 而是临时变量 n.\nfunc countByClosureButWrong() []func() int { var arr []func() int for i := 1; i \u0026lt;= 3; i++ { n := i fmt.Printf(\u0026#34;for i=%d n=%d \\n\u0026#34;, i,n) arr = append(arr, func() int { fmt.Printf(\u0026#34;append i=%d n=%d\\n\u0026#34;, i, n) return n }) } return arr } 上述解决办法很简单就是采用临时变量绑定循环变量的值,而不是原来的长生不老的变量引用,但是这种做法不够优雅,还可以继续简化进行版本升级.\n既然是采用变量赋值的做法,是不是和参数传递中的值传递很相像?那我们就可以用值传递的方式重新复制一份变量的值传递给闭包函数.\nfunc countByClosureWithOk() []func() int { var arr []func() int for i := 1; i \u0026lt;= 3; i++ { fmt.Printf(\u0026#34;for i=%d \\n\u0026#34;, i) func(n int) { arr = append(arr, func() int { fmt.Printf(\u0026#34;append n=%d \\n\u0026#34;, n) return n }) }(i) } return arr } 采用匿名函数进行值传递进行改造后,我们再次运行测试用例验证一下改造结果:\nfunc TestCountByClosureWithOk(t *testing.T) { // 1 2 3 for _, c := range countByClosureWithOk() { t.Log(c()) } } 模拟类和对象的关系,也可以实现封装,具备一定面向对象能力 每次调用闭包函数所处的环境都是相互独立的,这种特性类似于面向对象中类和实例化对象的关系. 缓存复杂逻辑,常驻内存,避免滥用全局变量徒增维护成本. 长生不老的特性使得闭包引用变量可以常驻内存,用于缓存一些复杂逻辑代码非常合适,避免了原来的全局变量的滥用. 实现闭包成本较高,同时也增加了理解难度. 普通函数转变成闭包函数不仅实现起来有一定难度,而且理解起来也不容易,不仅要求多测试几遍还要理解闭包的特性. 滥用容易占用过多内存,可能造成内存泄漏. 过多使用闭包势必造成引用变量一直常驻内存,如果出现循环引用或者垃圾回收不及时有可能造成内存泄漏问题. ","date":"2019-10-04T19:25:07Z","permalink":"https://lxb.wiki/eb01d7dc/","title":"Go闭包技术"},{"content":"某篇文章说, CNAME 解析只支持 www 不支持@ 所以@ 只能 解析到一个一个的 IP\n1. source 添加 CNAME 文件 在源码的source 目录下, 添加一个CNAME文件 文件内容为\nlxb.wiki 2. DNS 设置 记录类型 主机记录 解析路线(isp) 记录值 MX优先级 TTL 状态 操作 CNAME www 默认 lxbwolf.github.io \u0026ndash; 10 分钟 正常 修改暂停删除备注 A @ 默认 185.199.108.153 \u0026ndash; 10 分钟 正常 修改暂停删除备注 A @ 默认 185.199.111.153 \u0026ndash; 10 分钟 正常 修改暂停删除备注 A @ 默认 185.199.110.153 \u0026ndash; 10 分钟 正常 修改暂停删除备注 A @ 默认 185.199.109.153 \u0026ndash; 10 分钟 正常 修改暂停删除备注 3. hexo 部署 hexo clean \u0026amp;\u0026amp; hexo g \u0026amp;\u0026amp; hexo d ","date":"2019-09-27T00:54:15Z","permalink":"https://lxb.wiki/e9fbcad9/","title":"github 博客绑定域名"},{"content":"xargs 是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。\nxargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。\nxargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。\nxargs 默认的命令是 echo，这意味着通过管道传递给 xargs 的输入将会包含换行和空白，不过通过 xargs 的处理，换行和空白将被空格取代。\nxargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。\n之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了 xargs 命令\n例如:\nfind /sbin -perm 700 |ls -l #这个命令是错误的 find /sbin -perm 700 |xargs ls -l #这样才是正确的 命令格式 somecommand |xargs -item command\n重要参数:\n-i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。 其他参数:\n-a file 从文件中读入作为sdtin -e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。 -p 当每次执行一个argument的时候询问一次用户。 -n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。 -t 表示先打印命令，然后再执行。 -r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。 -s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。 -L num 从标准输入一次读取 num 行送给 command 命令。 -l 同 -L。 -d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。 -x exit的意思，主要是配合-s使用。。 -P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧。 实例: 1. 多行变成单行 # cat test.txt a b c d e f g h i j k l m n o p q r s t u v w x y z # cat test.txt | xargs a b c d e f g h i j k l m n o p q r s t u v w x y z 2. 一次使用n个参数 # cat test.txt | xargs -n3 a b c d e f g h i j k l m n o p q r s t u v w x y z 3. d选项指定分隔符 # echo \u0026#34;nameXnameXnameXname\u0026#34; | xargs -dX name name name name 结合-n 选项使用\n# echo \u0026#34;nameXnameXnameXname\u0026#34; | xargs -dX -n2 name name name name 4. I选项的使用 4.1 获取参数并替换{} 假设一个命令为 sk.sh 和一个保存参数的文件 arg.txt：\n#!/bin/bash #sk.sh命令内容，打印出所有参数。 echo $* arg.txt.文件内容\n# cat arg.txt aaa bbb ccc xargs 的一个选项 -I，使用 -I 指定一个替换字符串 {}，这个字符串在 xargs 扩展时会被替换掉，当 -I 与 xargs 结合使用，每一个参数命令都会被执行一次：\n# cat arg.txt | xargs -I {} ./sk.sh sombefore {} someafter sombefore aaa someafter sombefore bbb someafter sombefore ccc someafter 4.2 复制文件实例 复制所有图片文件到 /data/images 目录下：\nls *.jpg | xargs -n1 -I {} cp {} /data/images/ 4.3 xargs 结合find 使用 用 rm 删除太多的文件时候，可能得到一个错误信息：/bin/rm Argument list too long. 用 xargs 去避免这个问题：\nfind . -type f -name \u0026quot;*.log\u0026quot; -print0 | xargs -0 rm -f xargs -0 将 \\0 作为定界符。\n统计一个源代码目录中所有 php 文件的行数： find . -type f -name \u0026quot;*.php\u0026quot; -print0 | xargs -0 wc -l\n查找所有的 jpg 文件，并且压缩它们： find . -type f -name \u0026quot;*.jpg\u0026quot; -print | xargs tar -czvf images.tar.gz\n4.4 下载多个文件 假如你有一个文件包含了很多你希望下载的 URL，你能够使用 xargs下载所有链接： # cat url-list.txt | xargs wget -c\n","date":"2019-08-20T01:14:58Z","permalink":"https://lxb.wiki/38dfadad/","title":"xargs"},{"content":"环境\nCentOS nginx 获取证书 HTTPS 证书分三类：1. DV 域名验证证书 2. OV 组织机构验证证书 3. EV 增强的组织机构验证证书。每类证书的审核要求不同，在浏览器地址栏也会有区分，对于个人网站而言，使用免费的 DV 证书就足够了。 我使用了大名鼎鼎的 Let\u0026rsquo;s Encrypt 来生成证书。\n1. 安装 certbot certbot 是 Let\u0026rsquo;s Encrypt 提供的一套自动化工具。\nyum install epel-release yum install certbot 2. 生成证书 这里采用 webroot 作为 Let\u0026rsquo;s Encrypt 的认证方式。\ncertbot certonly -a webroot --webroot-path=/your/project/path -d example.com -d www.example.com webroot-path就是项目根路径，使用 -d 可以添加多个域名。这时证书就已经生成成功了，默认保存在 /etc/letsencrypt/live/example.com/ 下。证书文件包括：\ncert.pem: 服务端证书 chain.pem: 浏览器需要的所有证书但不包括服务端证书，比如根证书和中间证书 fullchain.pem: 包括了cert.pem和chain.pem的内容 privkey.pem: 证书私钥 3. 生成迪菲-赫尔曼密钥交换组（ Strong Diffie-Hellman Group） 为了进一步提高安全性，也可以生成一个 Strong Diffie-Hellman Group。\nopenssl dhparam -out /etc/ssl/certs/dhparam.pem 2048 配置nginx 编辑 Nginx 配置文件，如果你不知道配置文件在哪，可以用 locate /nginx.conf 命令查找。添加以下内容，具体参数以你的实际情况为准。\nserver { listen 443 ssl; # 启用http2 # 需要安装 Nginx Http2 Module # listen 443 http2 ssl; server_name my_server_name; #证书文件 ssl_certificate /etc/letsencrypt/live/my_server_name/fullchain.pem; #私钥文件 ssl_certificate_key /etc/letsencrypt/live/my_server_name/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # 优先采取服务器算法 ssl_prefer_server_ciphers on; # 定义算法 ssl_ciphers \u0026amp;quot;EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH\u0026amp;quot;; ssl_ecdh_curve secp384r1; ssl_session_cache shared:SSL:10m; ssl_session_tickets off; ssl_stapling on; ssl_stapling_verify on; resolver 8.8.8.8 8.8.4.4 valid=300s; resolver_timeout 5s; add_header Strict-Transport-Security \u0026amp;quot;max-age=63072000; includeSubdomains\u0026amp;quot;; add_header X-Frame-Options DENY; add_header X-Content-Type-Options nosniff; # 使用DH文件 ssl_dhparam /etc/ssl/certs/dhparam.pem; location ~ /.well-known { allow all; } location ~ \\.php$ { root my_root; fastcgi_pass my_host:my_port; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } root my_root; index index.html index.php; location / { root my_root; autoindex on; index index.html index.php; client_max_body_size 1024m; } } 其中的几项配置: ssl_stapling on; 开启 OCSP Stapling，使服务端主动获取 OCSP 查询结果并随着证书一起发送给客户端，从而让客户端跳过自己去验证的过程，提高 TLS 握手效率。 add_header Strict-Transport-Security \u0026amp;quot;max-age=63072000; includeSubdomains\u0026amp;quot;; 启用 HSTS 策略，强制浏览器使用 HTTPS 连接，max-age设置单位时间内強制使用 HTTPS 连接；includeSubDomains 可选，设置所有子域同时生效。浏览器在获取该响应头后，在 max-age 的时间内，如果遇到 HTTP 连接，就会通过 307 跳转強制使用 HTTPS 进行连接 add_header X-Frame-Options DENY; 添加 X-Frame-Options 响应头，可以禁止网站被嵌入到 iframe 中，减少点击劫持 (clickjacking)攻击。 add_header X-Content-Type-Options nosniff; 添加 X-Content-Type-Options 响应头，防止 MIME 类型嗅探攻击 测试nginx.conf 是否有语法错误 nginx -t 重启nginx nginx -s reload\n","date":"2019-08-08T02:53:34Z","permalink":"https://lxb.wiki/ddf7de45/","title":"升级https"},{"content":"把宿主机的一个目录挂载到容器中的一个目录，当访问容器中的这个目录时，出现如下问题： ls: cannot open directory .: Permission denied 无法访问目录，权限拒绝。 该问题通常在centos7下出现。或者一个容器启动成功后，里面的服务无法成功访问，这是因为centos7中的安全模块selinux把权限禁掉了，一般的解决方案有以下两种： （1）临时关闭selinux 直接在centos服务器上执行以下命令即可。执行完成以后建议重新docker run。 setenforce 0 （2）给容器加权限 在docker run时给该容器加权限，加上以下参数即可： --privileged=true 一般都推荐使用这种方式。 按上述方法修改后, 如果执行下面命令失败 docker run --name rookie-nginx-test -d -p 8082:80 -v ~/nginx/www:/usr/share/nginx/html -v ~/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v ~/nginx/logs:/var/log/nginx -v ~/nginx/conf/conf.d:/etc/nginx/conf.d --link php7-fpm:php nginx 则是因为~/nginx/www/ 目录下没有index 文件导致. 手动创建index.php 文件解决\n","date":"2019-07-23T17:32:38Z","permalink":"https://lxb.wiki/498654c2/","title":"docker挂载目录失败/权限拒绝"},{"content":"【报错原因】：没有utf-8这个语系（没添加语言_国名前缀），LC_ALL又没设定值。 服务端解决方法： 在远程系统上， /etc/environment加入以下两行，重新登陆即可。\nLANG=en_US.utf-8 LC_ALL=en_US.utf-8 Mac终端解决方法： 编辑~/.bashrc或者~/.zshrc文件，添加\nexport LC_ALL=en_US.UTF-8 export LANG=en_US.UTF-8 ","date":"2019-07-02T11:48:53Z","permalink":"https://lxb.wiki/784beb8f/","title":"Mac iTerm2登陆CentOS提示warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory"},{"content":"现在很多WordPress的插件都推荐将php版本升级到7.0或者7.1以上，于是就折腾了一下把几个blog升级到了7.1.5，升级的过程不难，无非就是额外安装一个php，然后启动自带的配套php-fpm7，然后nginx里location转发到新的php socket文件，这里就不表了。 升级完了，phpinfo()发现一切都正常，但是访问WordPress，却意外提示Error establishing a database connection，但是db的连接信息明明没有问题，经过反复搜索尝试，发现只要将 /usr/share/nginx/html/wp-config.php 文件里的 define('DB_HOST', 'localhost'); 修改为 define('DB_HOST', '127.0.0.1'); 即可解决，猜测原因可能是php7.1中对域的resolve问题 另外, 为了 Debug, 可以把 /usr/share/nginx/html/wp-config.php 的 debug 改为 true define('WP_DEBUG', true); 改好了, 再改成 false.\n","date":"2019-06-12T23:37:00Z","permalink":"https://lxb.wiki/b6b408b2/","title":"升级到php7.1之后wordpress 网站出现Error establishing a database connection的解决方法"},{"content":"给定时间戳, 转换成日期 网上所有的命令都是 date -d @$stamp \u0026quot;+%Y-%m-%d\u0026quot; 但是一直提示 date: invalid date@stamp\u0026rsquo; 带上\u0026quot;@\u0026quot; 符号, 就参数错误 正确使用方法:date -d \u0026ldquo;1970-01-01 UTC 1287331200 seconds\u0026rdquo; +%F 或者使用awkawk \u0026lsquo;{print strftime(\u0026quot;%Y%m\u0026quot;, 1287331200)}\u0026rsquo; 调用外部命令耗时比较长, 更高效的方法:printf \u0026ldquo;%(%Y%m)T\\n\u0026rdquo; \u0026ldquo;$str\u0026rdquo; \u0026raquo; file 如果bash 版本低于4, printf 不支持打印日期格式, 因此使用 下面这个bash/opt/compiler/gcc-4.8.2/bin/bash`\n","date":"2019-06-10T16:59:14Z","permalink":"https://lxb.wiki/7b4019ad/","title":"date 命令转换时间戳"},{"content":"计算机系统中内存是以字节为单位进行编址的，每个地址单元都唯一的对应着1个字节（8 bit）。这可以应对char类型数据的存储要求，因为char类型长度刚好是1个字节，但是有些类型的长度是超过1个字节的（字符串虽然是多字节的，但它本质是由一个个char类型组成的类似数组的结构而已），比如C/C++中，short类型一般是2个字节，int类型一般4个字节等。因此这里就存在着一个如何安排多个字节数据中各字节存放顺序的问题。正是因为不同的安排顺序导致了大端存储模式和小端存储模式的存在。\n1. 解释 假如有一个4字节的数据为 0x12 34 56 78（十进制：305419896，0x12为高字节，0x78为低字节），若将其存放于地址 0x4000 8000中，则有：\n内存地址\n0x4000 8000（低地址）\n0x4000 8001\n0x4000 8002\n0x4000 8003（高地址）\n大端模式\n0x12（高字节）\n0x34\n0x56\n0x78（低字节）\n小端模式\n0x78（低字节）\n0x56\n0x34\n0x12（高字节）\n大端模式：是指数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中 小端模式，是指数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中 为什么截然相反的大小端存储模式能够并存至今？在标准化备受推崇的今天，为什么大小端谁都没有被另外一个所同化？我想这除了历史的惯性使然，还与它们各自的优缺点有关。 大端模式优点：符号位在所表示的数据的内存的第一个字节中，便于快速判断数据的正负和大小 小端模式优点：1. 内存的低地址处存放低字节，所以在强制转换数据时不需要调整字节的内容（注解：比如把int的4字节强制转换成short的2字节时，就直接把int数据存储的前两个字节给short就行，因为其前两个字节刚好就是最低的两个字节，符合转换逻辑）； 2. CPU做数值运算时从内存中依顺序依次从低位到高位取数据进行运算，直到最后刷新最高位的符号位，这样的运算方式会更高效 其各自的优点就是对方的缺点，正因为两者彼此不分伯仲，再加上一些硬件厂商的坚持（见1.3节），因此在多字节存储顺序上始终没有一个统一的标准\nIntel的80×86系列芯片使用小端存储模式 ARM芯片默认采用小端，但可以切换为大端 MIPS芯片采用大端，但可以在大小端之间切换 在网络上传输的数据普遍采用的都是大端 2. 判断 方法一：通过将多字节数据强制类型转换成单字节数据，再通过判断起始存储位置是数据高字节还是低字节进行检测\n// @Ret: 大端，返回true; 小端，返回false bool IsBigEndian_1() { int nNum = 0x12345678; char cLowAddressValue = *(char*)\u0026amp;nNum; // 低地址处是高字节，则为大端 if ( cLowAddressValue == 0x12 ) return true; return false; } 方法二：利用联合体union的存放顺序是所有成员都从低地址开始存放这一特性进行检测\n// @Ret: 大端，返回true; 小端，返回false bool isBigEndian_2() { union uendian { int nNum; char cLowAddressValue; }; uendian u; u.nNum = 0x12345678; if ( u.cLowAddressValue == 0x12 ) return true; return false; } 3. 转换 大小端转换\n// 实现16bit的数据之间的大小端转换 #define BLSWITCH16(A) ( ( ( (uint16)(A) \u0026amp; 0xff00 ) \u0026gt;\u0026gt; 8 ) | \\ ( ( (uint16)(A) \u0026amp; 0x00ff ) \u0026lt;\u0026lt; 8 ) ) // 实现32bit的数据之间的大小端转换 #define BLSWITCH32(A) ( ( ( (uint32)(A) \u0026amp; 0xff000000) \u0026gt;\u0026gt; 24) |\\ (((uint32)(A) \u0026amp; 0x00ff0000) \u0026gt;\u0026gt; 8) | \\ (((unit32)(A) \u0026amp; 0x0000ff00) \u0026lt;\u0026lt; 8) | \\ (((uint32)(A) \u0026amp; 0x000000ff) \u0026lt;\u0026lt; 32) ) 由于网络字节序一律为大端，而目前个人PC大部分都是X86的小端模式，因此网络编程中不可避免得要进行网络字节序和主机字节序之间的相互转换\n","date":"2019-05-24T18:37:53Z","permalink":"https://lxb.wiki/7ee0edaa/","title":"大小端"},{"content":"一 需求设计 分布式环境下，保证每个序列号（sequence）是全系统唯一的；\n序列号可排序，满足单调递增的规律；\n特定场景下，能生成无规则（或者看不出规则）的序列号；\n生成的序列号尽量短；\n序列号可进行二次混淆，提供可扩展的interface，业务方自定义实现。\n二 方案设计 为了满足上述需求，发号器必须能够支持不同的生成策略，最好是还能支持自定义的生成策略，这就对系统本身的可扩展性提出了要求。 目前，发号器设计了两种比较通用的基础策略，各有优缺点，但结合起来，能达到优势互补的目的。\n1. segment 第一种策略称之为『分段』（segment），下文将对其进行详细阐述： 整个segment发号器有两个重要的角色：Redis和MongoDB，理论上MongoDB是可以被MySQL或其他DB产品所替代的。 segment发号器所产生的号码满足单调递增的规律，短时间内产生的号码不会有过长的问题（可根据实际需要，设置初始值，比如 100）。\nRedis数据结构（Hash类型） key: \u0026lt;string\u0026gt;，表示业务主键/名称 value: { cur: \u0026lt;long\u0026gt;，表示当前序列号 max: \u0026lt;long\u0026gt;，表示这个号段最大的可用序列号 } 取号的大部分操作都集中在Redis，为了保证序列号递增的原子性，取号的功能可以用Lua脚本实现。\n--[[ 由于RedisTemplate设置的HashValueSerializer是GenericToStringSerializer，故此处的HASH结构中的 VALUE都是string类型，需要使用tonumber函数转换成数字类型。 ]] local max = redis.pcall(\u0026quot;HGET\u0026quot;, KEYS[1], \u0026quot;max\u0026quot;) --获取一段序列号的max local cur = redis.pcall(\u0026quot;HGET\u0026quot;, KEYS[1], \u0026quot;cur\u0026quot;) --获取当前发号位置 if tonumber(cur) \u0026gt;= tonumber(max) then --没有超过这段序列号的上限 local step = ARGV[1] if (step == nil) then --没有传入step参数 step = redis.pcall(\u0026quot;HGET\u0026quot;, KEYS[1], \u0026quot;step\u0026quot;) --获取这段序列号的step配置参数值 end redis.pcall(\u0026quot;HSET\u0026quot;, KEYS[1], \u0026quot;max\u0026quot;, tonumber(max) + tonumber(step)) --调整max参数值，扩展上限 end return redis.pcall(\u0026quot;HINCRBY\u0026quot;, KEYS[1], \u0026quot;cur\u0026quot;, 1) --触发HINCRBY操作，对cur自增，并返回自增后的值 ​\n注意：在redis执行lua script期间，redis处于BUSY状态，这个时候对redis的任何形式的访问都会抛出JedisBusyException异常，所以lua script中的处理逻辑不得太复杂。\n值得一提的是，即使切换到一个新的database，或者开启新线程执行lua script，都将会遇到同样的问题，毕竟redis是单进程单线程的。\n如果不幸遇到上述问题，需要使用redis-cli客户端连上redis-server，向其发送SCRIPT KILL命令，即可终止脚本执行。\n如果想避免上述问题，也可以直接使用Springboot提供的RedisTemplate，能支持绝大部分redis command。\nMongoDB 数据结构 { bizTag: \u0026lt;string\u0026gt;, 表示业务主键/名称 max: \u0026lt;long\u0026gt;, 表示这个号段最大的可用序列号 step: \u0026lt;int\u0026gt;, 每次分段的步长 timestamp: \u0026lt;long\u0026gt;, 更新数据的时间戳（毫秒） } MongoDB部分主要是对号段的分配进行管理，一个号段不能多发，也可以根据发号情况，适当放缩号段步长（step）。\n到此为止，segment发号器的雏形已经形成了。 一个比较突出的问题是在两个号段衔接的时间点，当一个segment派发完了后，会对MongoDB和Redis中的数据中的max扩容，I/O消耗比正常发号要稍多，会遇到“尖刺”\n为了消除“尖刺”，可以使用双Buffer模型\n这个模型的核心思想就是“预分配”。可以设置一个阈值（threshold），比如20%，当Buffer-1里面的号段已经消耗了20%，那么立刻根据Buffer-1的max和step，开辟Buffer-2。 当Buffer-1完全消耗了，可以无缝衔接Buffer-2,。\n如果Buffer-2的消耗也达到阈值了，又可以开辟Buffer-1，如此往复。\n接下来，我们来讨论一下异常/故障情况。\n① Redis宕机。因为大部分发号工作都是依靠Redis完成的，所以发生了这种情况是非常糟糕的。如果想有效降低此风险，最行之有效的办法是对Redis进行集群化，通常是1主2从，这样可以挺住非常高的QPS了。 当然也有退而求其次的办法，就是利用上述提到的双Buffer模型。不依赖Redis取号，直接通过程序控制，利用机器内存。所以当需要重启发号服务之前，要确保依赖的组件是运行良好的，不然号段就丢失了。\n② 要不要持久化的问题。这个问题主要是针对Redis，如果没有记录下当前的取号进度，那么随着Redis的宕机，取号现场就变得难以恢复了；如果每次都记录取号进度，那么这种I/O高密度型的作业会对服务性能 造成一定影响，并且随着取号的时间延长，恢复取号现场就变得越来越慢了，甚至到最后是无法忍受的。除了对Redis做高可用之外，引入MongoDB也是出于对Redis持久化功能辅助的考虑。 个人建议：如果Redis已经集群化了，而且还开启了双Buffer的策略，以及MongoDB的加持，可以不用再开启Redis的持久化了。 如果考虑到极端情况下，Redis还是宕机了，我们可以使用MongoDB里面存下来的max，就max+1赋值给cur（避免上个号段取完，正好宕机了）。\n③ MongoDB宕机。这个问题不是很严重，只要将step适当拉长一些（至少取号能支撑20分钟），利用Redis还在正常取号的时间来抢救MongoDB。不过，考虑到实际可能没这么快恢复mongo服务，可以在程序中采取 一些容错措施，比如号段用完了，mongo服务无法到达，直接关闭取号通道，直到MongoDB能正常使用；或者程序给一个默认的step，让MongoDB中的max延长到max+step*n（可能取了N个号段MongoDB才恢复过来）， 这样取号服务也可以继续。依靠程序本身继续服务，那么需要有相关的log，这样才有利于恢复MongoDB中的数据。\n④ 取号服务宕机。这个没什么好说的，只能尽快恢复服务运行了。\n⑤ Redis，MongoDB都宕机了。这种情况已经很极端了，只能利用双Buffer策略，以及程序默认的设置进行工作了，同样要有相关的log，以便恢复Redis和MongoDB。\n⑥ 都宕机了。我有一句mmp不知当讲不当讲……\n2、snowflake 第二种策略是Twitter出品，算法思想比较巧妙，实现的难度也不大。\n以上示意图描述了一个序列号的二进制组成结构。 第一位不用，恒为0，即表示正整数； 接下来的41位表示时间戳，精确到毫秒。为了节约空间，可以将此时间戳定义为距离某个时间点所经历的毫秒数（Java默认是1970-01-01 00:00:00）； 再后来的10位用来标识工作机器，如果出现了跨IDC的情况，可以将这10位一分为二，一部分用于标识IDC，一部分用于标识服务器； 最后12位是序列号，自增长。\nsnowflake的核心思想是64bit的合理分配，但不必要严格按照上图所示的分法。 如果在机器较少的情况下，可以适当缩短机器id的长度，留出来给序列号。\n当然，snowflake的算法将会面临两个挑战：\n① 机器id的指定。这个问题在分布式的环境下会比较突出，通常的解决方案是利用Redis或者Zookeeper进行机器注册，确保注册上去的机器id是唯一的。为了解决 强依赖Redis或者Zookeeper的问题，可以将机器id写入本地文件系统。\n② 机器id的生成规则。这个问题会有一些纠结，因为机器id的生成大致要满足三个条件：a. int类型(10bit)纯数字，b. 相对稳定，c. 与其他机器要有所区别。至于优雅美观，都是其次了。对于机器id的存储，可以使用HASH结构，KEY的规则是“application-name.port.ip”，其中ip是通过算法转换成了一段长整型的纯数字，VALUE则是机器id， 服务id，机房id，其中，可以通过服务id和机房id反推出机器id。\n假设服务id(workerId)占8bit，机房id(rackId)占2bit，从1开始，workerId=00000001，rackId=01，machineId=00000000101 如果用Redis存储，其表现形式如下：\n如果存储在文件中（建议properties文件），则文件名是sequence-client:8112:3232235742.properties，文件内容如下：\n如果发号服务上线，直接按照“application-name.port.ip”的规则取其内容。\n③ 时钟回拨。因为snowflake对系统时间是很依赖的，所以对于时钟的波动是很敏感的，尤其是时钟回拨，很有可能就会出现重复发号的情况。时钟回拨问题解决策略通常是直接拒绝发号，直到时钟正常，必要时进行告警。\n三 程序设计 整个发号过程可以分成三个层次：\n1、策略层(strategy layer)：这个层面决定的是发号方法/算法，涵盖了上述所讲的segment和snowflake两种方式，当然，用户也可以自己扩展实现其他发号策略。\n最顶上定义Sequence实际上就是发号的结果。bizType是对发号业务场景的定义，比如订单号，用户ID，邀请好友的分享码。 发号策略的init接口是发号前的初始化工作，而generate接口就是调用发号器的主入口了。 当然，考虑到各种异常情况，加入了拒绝发号的处理器（SequenceRejectedHandler），默认实现只是记录日志，用户可根据需求去实现该处理器，然后用set方法设置发号策略的拒绝处理器。\n2、插件层(plugin layer)：此处的插件可以理解是一种拦截器，贯穿SequenceStrategy的发号全周期。引入插件后，无疑是丰富了整个发号的操作过程，用户可以从中干预到发号的整个流程，以便达到其他的目的，比如：记录发号历史，统计发号速率，发号二次混淆等。\n可以看出，插件被设计成『注册式』的，发号策略只有注册了相关插件之后，插件才能生效， 当然，一个插件能被多个发号策略所注册，一个发号策略也能同时注册多个插件，所以两者是多对多的关系，PluginManager的出现就是解决插件的注册管理问题。 从SequencePlugin的定义中可以发现，插件是有优先级（Order）的，通过getOrder()可以获得，在这套发号系统里，Order值越小，表示该插件越优先执行。此外，插件有三个重要的操作： before，表示发号之前的处理。若返回了false，那么该插件后面的操作都失效了，否则继续执行发号流程。 after，表示发号之后的处理。 doException，表示插件发生异常的处理方法。\n3、持久层(persistence layer)：这个层面指代的是上述所提的MongoDB部分，如果不需要持久化的支持，可以不实现此接口，那么整个发号器就变成纯内存管理的了。\nPersistRepository定义了基本的CRUD方法，其中persistId可以理解成上述提到的BizType。 一切的持久化对象都是从PersistModel开始的，上图中的Segment、PersistDocument都是为了实现分段发号器而定义的。\n四 总结 这篇文章详细阐述了分布式发号器系统的设计，旨在能做出一个可扩展，易维护的发号系统。业界比较知名的发号算法似乎也不多，整个发号系统不一定就按照笔者所做的设计，还是要立足于具体的业务需求。\n","date":"2019-05-10T14:04:04Z","permalink":"https://lxb.wiki/3d5a1f1d/","title":"分布式发号器架构设计"},{"content":"有意思的变量和不安分的常量\n变量默认初始化有零值 func TestVariableZeroValue(t *testing.T) { var a int var s string // 0 t.Log(a, s) // 0 \u0026#34;\u0026#34; t.Logf(\u0026#34;%d %q\u0026#34;, a, s) } int 类型的变量初始化默认零值是零 0, string 类型的变量默认初始化零值是空字符串 ,其他类型也有相应的零值.\n多个变量可以同时赋值 func TestVariableInitialValue(t *testing.T) { var a, b int = 1, 2 var s string = \u0026#34;hello Go\u0026#34; // 1 2 hello Go t.Log(a, b, s) } 其他主要的编程语言大多支持多个变量初始化,但极少数有像 Go 语言这样,不仅支持同时初始化,还可以同时赋值.\n多个变量可以用小括号 () 统一定义 func TestVariableShorter(t *testing.T) { var ( a int = 1 b int = 2 s string = \u0026#34;hello go\u0026#34; ) // 1 2 hello Go t.Log(a, b, s) } 用小括号 () 方式,省略了相同的 var 关键字,看起来更加统一\n变量类型可以被自动推断 func TestVariableTypeDeduction(t *testing.T) { var a, b, s = 1, 2, \u0026#34;hello Go\u0026#34; // 1 2 hello Go t.Log(a, b, s) } Go 语言可以根据变量值推测出变量类型,所以可以省略变量类型,再一次简化了变量定义,但是变量类型仍然是强类型,并不像 Js 那样的弱类型.\n变量可以用 := 形式更加简化 func TestVariableTypeDeductionShorter(t *testing.T) { a, b, s := 1, 2, \u0026#34;hello Go\u0026#34; // 1 2 hello Go t.Log(a, b, s) s = \u0026#34;hello golang\u0026#34; // 1 2 hello golang t.Log(a, b, s) } 省略了关键字 var,转而使用 := 符号声明并初始化变量值且利用自动类型推断能力进一步就简化变量定义,再次赋值时不能再使用 := 符号.\n变量 var 声明作用域大于变量 := 声明 1. var globalTestId = 2 2. // globalTestName := \u0026#34;type_test\u0026#34; is not supported 3. var globalTestName = \u0026#34;type_test\u0026#34; 4. 5. func TestVariableScope(t *testing.T) { 6. ``` // 2 type_test ``` 7. ``` t.Log(globalTestId, globalTestName) ``` 8. 9. ``` globalTestName = \u0026#34;TestVariableScope\u0026#34; ``` 10. 11. ``` // 2 TestVariableScope ``` 12. ``` t.Log(globalTestId, globalTestName) ``` 13. } var 声明的变量可以作用于函数外或函数内,而 := 声明的变量只能作用于函数内, Go 并没有全局变量的概念,变量的作用范围只是针对包而言.\n常量的使用方式和变量一致 1. func TestConstant(t *testing.T) { 2. ``` const a, b = 3, 4 ``` 3. ``` const s = \u0026#34;hello Go\u0026#34; ``` 4. 5. ``` // 3 4 hello Go ``` 6. ``` t.Log(a, b, s) ``` 7. } 常量声明关键字 const,常量和变量的使用方式一致,具备类型推断能力,也存在多种简化常量定义的形式.\n虽然没有枚举类型,但可以用 iota 配合常量来实现枚举 1. func TestConstant2Enum(t *testing.T) { 2. ``` const ( ``` 3. ``` java = iota ``` 4. ``` golang ``` 5. ``` cpp ``` 6. ``` python ``` 7. ``` javascript ``` 8. ``` ) ``` 9. ``` // 0 1 2 3 4 ``` 10. ``` t.Log(java, golang,cpp,python,javascript) ``` 11. } iota 在一组常量定义中首次出现时,其值为 0,应用到下一个常量时,其值为开始自增 1,再次遇到 iota 恢复 0 .效果非常像 for 循环中的循环索引 i,明明是常量,偏偏玩出了变量的味道,也是我觉得 iota 不安分的原因.\n常量 iota 有妙用,还可以进行位运算 1. func TestConstantIotaBitCalculate(t *testing.T){ 2. ``` const ( ``` 3. ``` Readable = 1 \u0026lt;\u0026lt; iota ``` 4. ``` Writable ``` 5. ``` Executable ``` 6. ``` ) ``` 7. ``` // 0001 0010 0100 即 1 2 4 ``` 8. ``` t.Log(Readable, Writable, Executable) ``` 9. 10. ``` // 0111 即 7,表示可读,可写,可执行 ``` 11. ``` accessCode := 7 ``` 12. ``` t.Log(accessCode\u0026amp;Readable == Readable, accessCode\u0026amp;Writable == Writable, accessCode\u0026amp;Executable == Executable) ``` 13. } 定义二进制位最低位为 1 时表示可读的,左移一位表示可写的,左移两位表示可执行的,按照按位与运算逻辑,目标权限位若拥有可读权限,此时和可读常量进行按位与运算之后的结果一定是可读的,由此可见, iota 非常适合此类操作.\n总体来说, Go 语言中的变量很有意思,常量 iota 不那么安分,从上述归纳总结中不难看出, Go 语言和其他主流的编程语言还是有很大不同的,学习时要侧重于这些特殊之处.\n如果想要回顾本节知识点,可以关注公众号[雪之梦技术驿站]找到go 学习笔记之有意思的变量和不安分的常量 这篇文章进行查看.\n简洁的类型中格外关照了复数\n在学习 Go 语言中的变量和常量时,虽然没有特意强调变量或常量的类型,但是大多数编程语言的类型基本都是差不多的,毕竟大家所处的现实世界是一样的嘛!\n光是猜测是不够的,现在我们要梳理一遍 Go 语言的类型有哪些,和其他主流的编程语言相比有什么不同?\nGo 语言的变量类型大致可以分为以下几种:\nbool 布尔类型 bool,表示真假 true|false\n(u)int , (u)int8 , (u)int16, (u)int32, (u)int64, uintptr int 类型表示整数,虽然不带位数并不表示没有位数, 32 位操作系统时长度为 32 位, 64 位操作系统时长度为 64 位.最后一个 uintptr 是指针类型.\nbyte(uint8) , rune(int32), string byte 是字节类型,也是 uint8 的别名,而 rune 是 Go 中的字符类型,也是 int32 的别名.\nfloat32 , float64 , complex64 , complex128 只有 float 类型表示小数,没有 double 类型,类型越少对于开发者而言越简单,不是吗? complex64=float32+float32 是复数类型,没错!就是高中数学书本上的复数, 3+4i 那种奇怪的数字!\nGo 的类型还是比较简单的,整数,小数,复数,字节,字符和布尔类型,相同种类的类型没有继续细分不同的名称而是直接根据类型长度进行命名的,这样是非常直观的,见名知意,根据数据大小直接选用类型,不费脑!\n作为一种通用的编程语言, Go 内建类型中居然格外关照了复数这种数学概念类型,是一件有意思的事情,是不是意味着 Go 在工程化项目上做得更好?就像 Go 天生支持并发一样?\n既然为数不多的类型中格外关照了复数类型,那我们简单使用下复数类型吧,毕竟其他类型和其他主流的编程语言相差不大.\n1. func TestComplex(t *testing.T) { 2. ``` c := 3 + 4i ``` 3. 4. ``` // 5 ``` 5. ``` t.Log(cmplx.Abs(c)) ``` 6. } 生命苦短,直接利用变量类型推断简化变量声明,求出复数类型 c 的模(绝对值)\n既然学习了复数,怎么能少得了欧拉公式,毕竟是\u0026quot;世界上最美的公式\u0026quot;,刚好用到了复数的相关知识,那我们就简单验证一下吧!\neiπ + 1 = 0\n1. func TestEuler(t *testing.T) { 2. ``` // (0+1.2246467991473515e-16i) ``` 3. ``` t.Log(cmplx.Pow(math.E, 1i*math.Pi) + 1) ``` 4. 5. ``` // (0+1.2246467991473515e-16i) ``` 6. ``` t.Log(cmplx.Exp(1i*math.Pi) + 1) ``` 7. 8. ``` // (0.000+0.000i) ``` 9. ``` t.Logf(\u0026#34;%.3f\u0026#34;, cmplx.Exp(1i*math.Pi)+1) ``` 10. } 由于复数 complex 是使用 float 类型表示的,而 float 类型无论是什么编程语言都是不准确的,所以欧拉公式的计算结果非常非常接近于零,当只保留小数点后三位时,计算结果便是 (0.000+0.000i) ,复数的模也就是 0,至此验证了欧拉公式.\n看过复数还是要研究类型特点\n复数很重要,但其他类型也很重要,简单了解过复数的相关知识后,我们仍然要把注意力放到研究这些内建类型的特殊之处上或者说这些类型总体来说相对于其他主流的编程语言有什么异同.\n只有显示类型转换,不存在隐式类型转换 1. func TestExplicitTypeConvert(t *testing.T) { 2. ``` var a, b int = 3, 4 ``` 3. ``` var c int ``` 4. ``` c = int(math.Sqrt(float64(a*a + b*b))) ``` 5. 6. ``` // 3 4 5 ``` 7. ``` t.Log(a, b, c) ``` 8. } 已知勾股定理的两条直角边计算斜边,根据勾股定理得,直角边长度的平方和再开根号即斜边长度,然而 math.Sqrt 方法接收的 float64 类型,返回的也是 float64 类型,可实际值全是 int 类型,这种情况下并不会自动进行类型转换,只能进行强制类型转换才能得到我们的期望值,这就是显示类型转换.\n别名类型和原类型也不能进行隐式类型转换 1. func TestImplicitTypeConvert2(t *testing.T) { 2. ``` type MyInt64 int64 ``` 3. 4. ``` var a int64 = 1 ``` 5. ``` var b MyInt64 ``` 6. 7. ``` // b = a : cannot use a (type int64) as type MyInt64 in assignment ``` 8. ``` b = MyInt64(a) ``` 9. ``` t.Log(a, b) ``` 10. } MyInt64 是 int64 的别名,别名类型的 b 和原类型的 a 也不能进行也不能进行隐式类型转换,会报错 cannotusea(type int64)astypeMyInt64inassignment,只能进行显示类型转换.\n支持指针类型,但不支持任何形式的计算 1. func TestPointer(t *testing.T) { 2. ``` var a int = 1 ``` 3. ``` var pa *int = \u0026amp;a ``` 4. 5. ``` // 0xc0000921d0 1 1 ``` 6. ``` t.Log(pa, *pa, a) ``` 7. 8. ``` *pa = 2 ``` 9. 10. ``` // 0xc0000901d0 2 2 ``` 11. ``` t.Log(pa, *pa, a) ``` 12. } 同样的,指针类型也是其他编程语言反过来书写的,个人觉得这种反而不错,指向 int 类型的指针 *int, \u0026amp;a是变量 a 的内存地址,所以变量 pa 存的就是变量 a 的地址, *pa 刚好也就是变量 a 的值.\n上例显示声明了变量类型却没有利用到 Go 的类型推断能力,摆在那的能力却不利用简直是浪费,所以提供一种更简短的方式重写上述示例,并顺便解释后半句: \u0026ldquo;指针类型不支持任何形式的计算\u0026rdquo;\nfunc TestPointerShorter(t *testing.T) { a := 1 pa := \u0026amp;a // 0xc0000e6010 1 1 t.Log(pa, *pa, a) *pa = 2 // 0xc0000e6010 2 2\n11. ``` t.Log(pa, *pa, a) // pa = pa + 1 : invalid operation: pa + 1 (mismatched types *int and int)\n14. ``` //pa = pa + 1 // *int int int\n17. ``` t.Logf(\u0026#34;%T %T %T\u0026#34;, pa, *pa,a) } 变量 pa 是指针类型,存储的是变量的内存地址,只可远观而不可亵玩, *pa 就是指针所指向的变量的值,可以进行修改,当然没问题就像可以重新赋值变量 a 一样,但是指针 pa 是不可以进行任何形式的运算的, pa=pa+1 就会报错 invalid operation.\n你猜运算符操作有没有彩蛋呢\n变量和类型还只是孤立的声明语句,没有计算不成逻辑,并不是所有的程序都是预定义的变量, Go 的运算符是简单还是复杂呢,让我们亲自体验一下!\n算术运算符少了 ++i 和 \u0026ndash;i func TestArithmeticOperator(t *testing.T) { a := 0 // 0 t.Log(a) a = a + 1 // 1 t.Log(a) a = a * 2\n11. ``` // 2 t.Log(a)\n13. 14. ``` a = a % 2 // 0\n16. ``` t.Log(a) a++\n19. ``` // 1 t.Log(a)\n21. } 支持大部分正常的运算符,不支持前置自增,前置自减,这也是好事,再也不会弄错 i++ 和 ++i 的运算结果啦,因为根本不支持 ++i ! * 比较运算符是否相等有花样 1. func TestComparisonOperator(t *testing.T) { 2. ``` a, b := 0, 1 t.Log(a, b) // false true true t.Log(a \u0026gt; b, a \u0026lt; b, a != b) } 大于,小于,不等于这种关系很正常, Golang 也没玩出新花样,和其他主流的编程语言逻辑一样,不用特别关心.但是关于比较数组 ==, Go 表示有话要说!\nGo 中的数组是可以进行比较的,当待比较的两个数组的维度和数组元素的个数相同时,两个数组元素顺序一致且相同时,则两个数组相等,而其他主流的编程语言一般而言比较的都是数组的引用,所以这一点需要特别注意.\nfunc TestCompareArray(t *testing.T) { a := [...]int{1, 2, 3} //b := [...]int{2, 4} c := [...]int{1, 2, 3} d := [...]int{1, 2, 4} // a == b --\u0026gt; invalid operation: a == b (mismatched types [3]int and [2]int) //t.Log(a == b) // true false\n11. ``` t.Log(a == c,a == d) } 数组 a 和 c 均是一维数组且元素个数都是 3,因此两个数组可以比较且相等,若数组 a 和 b 进行比较,则报错 invalid operation,是因为两个数组的元素个数不相同,无法比较!\n逻辑运算符老实本分无异常 func TestLogicalOperator(t *testing.T) { a, b := true, false t.Log(a, b) // false true false true t.Log(a\u0026amp;\u0026amp;b,a||b,!a,!b) } 位运算符新增按位清零 \u0026amp;^ 很巧妙 Go 语言中定义按位清零运算符是 \u0026amp;^,计算规律如下:\n当右边操作位数为 1 时,左边操作为不论是 1 还是 0 ,结果均为 0; 当右边操作位数为 0 时,结果同左边操作位数.\nfunc TestClearZeroOperator(t *testing.T) { // 0 0 1 0 t.Log(1\u0026amp;^1, 0\u0026amp;^1, 1\u0026amp;^0, 0\u0026amp;^1) } 不知道还记不记得,在介绍常量 iota 时,曾经以文件权限为例,判断给定的权限码是否拥有特定权限,同样是给定的权限码,又该如何撤销特定权限呢?\nfunc TestClearZeroOperator(t *testing.T) { const ( Readable = 1 \u0026lt;\u0026lt; iota Writable Executable ) // 0001 0010 0100 即 1 2 4 t.Log(Readable, Writable, Executable) // 0111 即 7,表示可读,可写,可执行\n11. ``` accessCode := 7 t.Log(accessCode\u0026amp;Readable == Readable, accessCode\u0026amp;Writable == Writable, accessCode\u0026amp;Executable == Executable)\n13. 14. ``` // 0111 \u0026amp;^ 0001 = 0110 即清除可读权限 accessCode = accessCode \u0026amp;^ Readable\n16. ``` t.Log(accessCode\u0026amp;Readable == Readable, accessCode\u0026amp;Writing == Writing, accessCode\u0026amp;Executable == Executable) } accessCode=accessCode\u0026amp;^Readable 进行按位清零操作后就失去了可读权限, accessCode\u0026amp;Readable==Readable 再次判断时就没有可读权限了.\n流程控制语句也有自己的傲娇\nif 有话要说\n有了变量类型和各种运算符的加入,现在实现简单的语句已经不是问题了,如果再辅助流程控制语句,那么实现较为复杂拥有一定逻辑的语句便可更上一层楼.\nGo 语言的 if 条件语句和其他主流的编程语言的语义是一样的,不一样的是书写规则和一些细节上有着自己特点.\n条件表达式不需要小括号 () func TestIfCondition(t *testing.T) { for i := 0; i \u0026lt; 10; i++ { if i%2 == 0 { t.Log(i) } } } Go 语言的各种省略形式使得整体上非常简洁,但也让拥有其他主流编程语言的开发者初次接触时很不习惯,语句结束不用分号 ;,条件表达式不用小括号 () 等等细节,如果不用 IDE 的自动提示功能,这些细节肯定要耗费不少时间.\n条件表达式中可以定义变量,只要最后的表达式结果是布尔类型即可 func TestIfConditionMultiReturnValue(t *testing.T) {\nconst filename = \u0026#34;test.txt\u0026#34; if content, err := ioutil.ReadFile(filename); err != nil { t.Log(err) } else { t.Logf(\u0026#34;%s \u0026ldquo;, content)\n} }\nGo 语言的函数支持返回多个值,这一点稍后再细说, ioutil.ReadFile 函数返回文件内容和错误信息,当存在错误信息时 err!=nil,输出错误信息,否则输出文件内容.\n条件表达式中定义的变量作用域仅限于当前语句块 如果尝试在 if 语句块外访问变量 content,则报错 undefined:content\nswitch 不甘示弱\n同其他主流的编程语言相比, switch 语句最大的特点就是多个 case 不需要 break, Go 会自动进行 break,这一点很人性化.\nswitch 会自动 break,除非使用 fallthrough func TestSwitchCondition(t *testing.T) { switch os := runtime.GOOS; os { case \u0026#34;darwin\u0026#34;: t.Log(\u0026#34;Mac\u0026#34;) case \u0026#34;linux\u0026#34;: t.Log(\u0026#34;Linux\u0026#34;) case \u0026#34;windows\u0026#34;: t.Log(\u0026#34;Windows\u0026#34;) default: t.Log(os)\n11. ``` } } 条件表达式不限制为常量或整数 其他主流的编程语言中 switch 的条件表达式仅支持有限类型,使用方式存在一定局限性, Go 语言则不同,这一点变化也是很有意思的,使用 switch 做分支控制时不用担心变量类型了!\ncase 语言支持多种条件,用逗号 , 分开,逻辑或 func TestSwitchMultiCase(t *testing.T) { for i := 0; i \u0026lt; 10; i++ { switch i { case 0, 2, 4, 6, 8, 10: t.Log(\u0026#34;Even\u0026#34;, i) case 1, 3, 5, 7, 9: t.Log(\u0026#34;odd\u0026#34;, i) default: t.Log(\u0026#34;default\u0026#34;, i) }\n11. ``` } } 省略 switch 的条件表达式时, switch 的逻辑和多个 ifelse 逻辑相同 func TestSwitchCaseCondition(t *testing.T) { for i := 0; i \u0026lt; 10; i++ { switch { case i%2 == 0: t.Log(\u0026#34;Even\u0026#34;, i) case i%2 == 1: t.Log(\u0026#34;odd\u0026#34;, i) default: t.Log(\u0026#34;default\u0026#34;, i) }\n11. ``` } } for 姗姗来迟\n最后登场的是 for 循环,一个人完成了其他主流编程语言三个人的工作, Go 语言中既没有 while 循环也,也没有 dowhile 循环,有的只是 for 循环.\n循环条件不需要小括号 () func TestForLoop(t *testing.T) { sum := 0 for i := 1; i \u0026lt;= 100; i++ { sum += i } // 1+2+3+...+99+100=5050 t.Log(sum) } 再一次看到条件表达式不需要小括号 () 应该不会惊讶了吧? if 的条件语句表达式也是类似的,目前为止,接触到明确需要小括号的 () 也只有变量或常量定义时省略形式了.\n可以省略初始条件 func convert2Binary(n int) string { result := \u0026#34;\u0026#34; for ; n \u0026gt; 0; n /= 2 { lsb := n % 2 result = strconv.Itoa(lsb) + result } return result } func TestConvert2Binary(t *testing.T) { // 1 100 101 1101\n12. ``` t.Log( convert2Binary(1),\n14. ``` convert2Binary(4), convert2Binary(5),\n16. ``` convert2Binary(13), )\n18. } 利用整数相除法,不断取余相除,得到给定整数的二进制字符串,这里就省略了初始条件,只有结束条件和递增表达式.这种写法同样在其他主流的编程语言是没有的,体现了 Go 设计的简洁性,这种特性在以后的编程中会越来越多的用到,既然可以省略初始条件,相信你也能猜到可不可以省略其他两个条件呢? * 可以省略初始条件和递增表达式 1. func printFile(filename string) { 2. ``` if file, err := os.Open(filename); err != nil { panic(err) } else { scanner := bufio.NewScanner(file) for scanner.Scan() { fmt.Println(scanner.Text()) } } } func TestPrintFile(t *testing.T) { const filename = \u0026ldquo;test.txt\u0026rdquo;\n14. ``` printFile(filename) } 打开文件并逐行读取内容,其中 scanner.Scan() 的返回值类型是 bool,这里省略了循环的初始条件和递增表达式,只有循环的终止条件,也顺便实现了 while 循环的效果.\n初始条件,终止条件和递增表达式可以全部省略 func forever() { for { fmt.Println(\u0026#34;hello go\u0026#34;) } } func TestForever(t *testing.T) { forever() } for 循环中没有任何表达式,意味着这是一个死循环,常用于 Web 请求中监控服务端口,是不是比 while(true) 要更加简单?\n压轴的一等公民函数隆重登场\n虽然没有特意强制函数,但是示例代码中全部都是以函数形式给出的,函数是封装的一种形式,更是 Go语言的一等公民.\n返回值在函数声明的最后,多个返回值时用小括号 () func eval(a, b int, op string) int { var result int switch op { case \u0026#34;+\u0026#34;: result = a + b case \u0026#34;-\u0026#34;: result = a - b case \u0026#34;*\u0026#34;: result = a * b case \u0026ldquo;/\u0026rdquo;:\n11. ``` result = a / b default:\n13. ``` panic(\u0026#34;unsupported operator: \u0026#34; + op) }\n15. ``` return result } func TestEval(t *testing.T) { t.Log(\n20. ``` eval(1, 2, \u0026#34;+\u0026#34;), eval(1, 2, \u0026ldquo;-\u0026rdquo;),\n22. ``` eval(1, 2, \u0026#34;*\u0026#34;), eval(1, 2, \u0026ldquo;/\u0026rdquo;),\n24. ``` //eval(1, 2, \u0026#34;%\u0026#34;), )\n26. } 不论是变量的定义还是函数的定义, Go 总是和其他主流的编程语言相反,个人觉得挺符合思维顺序,毕竟都是先有输入才能输出,多个输出当然要统一隔离在一块了. * 可以有零个或一个或多个返回值 1. func divide(a, b int) (int, int) { 2. ``` return a / b, a % b } func TestDivide(t *testing.T) { // 2 1 t.Log(divide(5, 2)) } 小学时就知道两个整数相除,除不尽的情况下还有余数.只不过编程中商和余数都是分别计算的, Go 语言支持返回多个结果,终于可以实现小学除法了!\n返回多个结果时可以给返回值起名字 func divideReturnName(a, b int) (q, r int) { return a / b, a % b } func TestDivideReturnName(t *testing.T) { q, r := divideReturnName(5, 2) // 2 1 t.Log(q, r) } 还是整数除法的示例,只不过给返回值起了变量名称 (q,rint),但这并不影响调用者,某些 IDE 可能会基于次特性自动进行代码补全,调用者接收时的变量名不一定非要是 q,r .\n其他函数可以作为当前函数的参数 func apply(op func(int, int) int, a, b int) int {\np := reflect.ValueOf(op).Pointer() opName := runtime.FuncForPC(p).Name() fmt.Printf(\u0026#34;Calling function %s with args (%d,%d) \u0026ldquo;, opName, a, b)\nreturn op(a, b) }\nfunc pow(a, b int) int {\nreturn int(math.Pow(float64(a), float64(b)))\n11. } 12. 13. func TestApply(t *testing.T) { 14. ``` // 1 t.Log(apply(func(a int, b int) int {\n16. ``` return a % b }, 5, 2))\n18. 19. ``` // 25 t.Log(apply(pow, 5, 2))\n21. } apply 函数的第一个参数是 op 函数,第二,第三个参数是 int 类型的 a,b.其中 op 函数也接收两个 int参数,返回一个 int 结果,因此 apply 函数的功能就是将 a,b 参数传递给 op 函数去执行,这种方式比 switch 固定运算类型要灵活方便! * 没有默认参数,可选参数等复杂概念,只有可变参数列表 1. func sum(numbers ...int) int { 2. ``` result := 0 for i := range numbers { result += numbers[i] } return result } func TestSum(t *testing.T) { // 15\n11. ``` t.Log(sum(1, 2, 3, 4, 5)) } range 遍历方式后续再说,这里可以简单理解为其他主流编程语言中的 foreach 循环,一般包括当前循环索引和循环项.\n指针类型很方便同时也很简单\nGo 的语言整体上比较简单,没有太多花里胡哨的语法,稍微有点特殊的当属变量的定义方式了,由于具备类型推断能力,定义变量的方式有点多,反而觉得选择困难症,不知道这种情况后续会不会有所改变?\n在 Go 语言的为数不多的类型中就有指针类型,指针本来是 c 语言的概念,其他主流的编程语言也有类似的概念,可能不叫做指针而是引用,但 Go 语言的发展和 c++ 有一定关系,保留了指针的概念.\n但是这并不意味着 Go 语言的指针像 C 语言那样复杂,相反, Go 语言的指针很方便也很简单,方便是由于提供我们操作内存地址的方式,简单是因为不能对指针做任何运算!\n简单回忆一下指针的基本使用方法:\nfunc TestPointerShorter(t *testing.T) { a := 1 pa := \u0026amp;a // 0xc0000e6010 1 1 t.Log(pa, *pa, a) *pa = 2 // 0xc0000e6010 2 2\n11. ``` t.Log(pa, *pa, a) // pa = pa + 1 : invalid operation: pa + 1 (mismatched types *int and int)\n14. ``` //pa = pa + 1 // *int int int\n17. ``` t.Logf(\u0026#34;%T %T %T\u0026#34;, pa, *pa,a) } \u0026amp; 可以获取变量的指针类型, * 指向变量,但不可以对指针进行运算,所以指针很简单!\n当指针类型和其他类型和函数一起发生化学反应时,我们可能更加关心参数传递问题,其他主流的编程语言可能有值传递和引用传递两种方式, Go 语言进行参数传递时又是如何表现的呢?\nfunc swapByVal(a, b int) { a, b = b, a } func TestSwapByVal(t *testing.T) { a, b := 3, 4 swapByVal(a, b) // 3 4\n11. ``` t.Log(a, b) } swapByVal 函数内部实现了变量交换的逻辑,但外部函数 TestSwapByVal 调用后变量 a,b 并没有改变,可见 Go 语言这种参数传递是值传递而不是引用传递.\n上面示例中参数传递的类型都是普通类型,如果参数是指针类型的话,结果会不会不一样呢?\nfunc swapByRef(a, b *int) { *a, *b = *b, *a } func TestSwapByRef(t *testing.T) { a, b := 3, 4 swapByRef(\u0026amp;a, \u0026amp;b) // 4 3\n11. ``` t.Log(a, b) } 指针类型进行参数传递时可以交换变量的值,拷贝的是内存地址,更改内存地址的指向实现了原始变量的交换,参数传递的仍然是值类型.\n实际上, Go 语言进行参数传递的只有值类型一种,这一点不像其他主流的编程语言那样可能既存在值类型又存在引用类型.\n既然是值类型进行参数传递,也就意味着参数传递时直接拷贝一份变量供函数调用,函数内部如何修改参数并不会影响到调用者的原始数据.\n如果只是简单类型并且不希望参数值被修改,那最好不过,如果希望参数值被修改呢?那只能像上例那样传递指针类型.\n简单类型不论是传递普通类型还是指针类型,变量的拷贝过程不会太耗费内存也不会影响状态.\n如果传递的参数本身是比较复杂的类型,仍然进行变量拷贝过程估计就不能满足特定需求了,可能会设计成出传递复杂对象的某种内部指针,不然真的要进行值传递,那还怎么玩?\nGo 只有值传递一种方式,虽然简单,但实际中如何使用应该有特殊技巧,以后再具体分析,现在回到交换变量的例子,换一种思路.\nfunc swap(a, b int) (int, int) { return b, a } func TestSwap(t *testing.T) { a, b := 3, 4 a, b = swap(a, b) // 4 3\n11. ``` t.Log(a, b) } 利用 Go 函数可以返回多个值特性,返回交换后的变量值,调用者接收时相当于重新赋值,比传递指针类型要简单不少!\n基础语法知识总结和下文预告\n刚刚接触 Go 语言时觉得 Go 的语言很简单也很特别,和其他主流的编程语言相比,有着自己独特的想法.\n语句结束不用分号 ; 而是直接回车换行,这一点有些不习惯,好在强大的 IDE 可以纠正这些细节.\n变量声明时变量名在前,变量类型在后,可能更加符合大脑思维,但是习惯了先写变量类型再写变量名,这确实有一定程度的不方便,后来索性不写变量类型,自然就没有问题了.\n函数声明同变量声明类似,返回值放到了最后部分,并且还可以有多个返回值,经过了变量的洗礼,再熟悉函数的这一特点也就不那么惊讶了,先输入后输出,想一想也有道理,难道其他编程语言的顺序都是错的?\n接下来就是语法的细节,比如 if 的条件表达式可以进行变量赋值, switch 表达式可以不用 break,只有 for 循环一种形式等等.\n这些细节总体来说比较简单方便,不用关心细节,放心大胆使用,从而专注于业务逻辑,等到语法不对时, IDE 自然会给出相应的报错提醒,放心大胆 Go !\n本文主要介绍了 Go 的基本语法以及和其他主流的编程语言的异同,你 Get 到了吗?\n下文将开始介绍 Go 的内建容器类型,数组,切片, Map 来一遍!\n欢迎大家一起学习交流,如有不当之处,恳请指正,如需完整源码,请在公众号[雪之梦技术驿站]留言回复,感谢你的评论与转发!\n","date":"2019-05-03T23:19:02Z","permalink":"https://lxb.wiki/936ea20/","title":"Go 基础语法"},{"content":"mysqldump -u username -p dbname \u0026gt; dbname.sql mysqldump: Got error: 1044: Access denied for user XXX to database XXX when using LOCK TABLES 解决方法: mysqldump -u dbuser -ppass db --skip-lock-tables \u0026gt; db.sql\n","date":"2019-04-27T11:24:27Z","permalink":"https://lxb.wiki/a333bc04/","title":"mysqldump: Got error: 1044: Access denied for user"},{"content":"业务规模较小时，使用单机mysql作存储。但伴随业务发展，存储容量和并发能力会有瓶颈。\n首先，假设单机的硬盘为1.8T，也可以挂更大容量硬盘，但仍有限。\n其次，单机的读写并发能力有限，假设峰值写入qps1000，峰值读取qps3000，网卡对读取时流量也有要求，单次访问的读取量不应过大。\n单机的链接数也有限。\n那么，当使用单机mysql的业务发展，受到以上瓶颈时，一般的思路会是什么呢？一台机器不行，用两台呢，再不行，扩展更多台。\n一台扩展为两台，磁盘容量扩大了，通过分表，将表打散在不同机器上，共同承担写入任务，并发也提高了，感觉这个思路是对的。\n那么在这个过程中，我们需要做什么？\n业务发展到单机无法承受，即使在单机上，很多表应该也做过分表了。一般会根据业务选择分表键。单个表的大小mysql也有一定要求，一般存储量不大于1G，单条记录小一些，一般不超过1k，条数一般不超过1000万条，最多不超过5000万条，否则表的使用和维护效率都很低。假设业务已经做了足够多的分表，满足三年的数据增长需要，第一年过后，每个分表的条数达到200万条，整机存储容量使用了一半，此时我们想拆分为两台机器。\n此时我们可以将原机器上部分表数据同步到新机器上，并在model层抽象一个路由层，将对数据库的操作发到不同的机器上，上层业务仍可以认为在使用单机。此时可以将原机器上不归属自己管理范围的表删除，腾出空间。\n一台变成了两台，向分布式走了一步。此时存储容量和并发都提高了，由路由层管理两台机器。如果两台或今后的多台机器，并发数高于路由层处理能力怎么办？那还要把路由层机器也扩一下，把路由规则都写进去，大家按一个格则办事。\n经过上面的一番折腾，数据库机器水平扩展，解决了单机存在的一些问题。在这个扩展的过程中，是否会对业务产生中断影响呢？\n会有一点影响。至少在路由层改路由表时，会中断数据库的写入，读取此时可以不中断。\nddbs中，使用到的多台机器，都叫做分片。分片提高了系统存储容量和并发能力，引入分片，也是系统的复杂度提高了，需要引入路由层机器，路由机器也可能需要扩展，复杂操作，还需要添加更多逻辑功能。但至少可以可业务逻辑区分开，业务可以把ddbs当做单机在使用。\n那么ddbs有哪些不足呢？\nddbs还是要基于分表、分片实现的。那么对数据库的任何操作，首要条件是需要指明操作的分表键。没有这个维度的准确值，就不能对数据库操作，当然除非是备用库，那你随便扫表，因为备用库可以转为冗余安全，不走线上流量，可以做统计任务。\n单指明分表键还不行，还要注意操作的数据可能会分布在不同分表、不同分片中，这样的操作会引发ddbs产生大量并发操作，业务的一个请求就会占用多个机器多个链接，使ddbs得并发能力大打折扣。比如 ‘where 分表键 in （）’操作，这种操作要慎重，in中个数不可太多。\n分表键最好选用整形，字符串型，可能hash后分配不均，表大小不均衡。\n事物操作在ddbs中的实现，非常耗费系统性能。事务类操作需要路由控制层控制整个操作过程，期中可能涉及多个分片，多个不同的表的操作，对系统整体可用性要求高\n","date":"2019-04-10T14:00:41Z","permalink":"https://lxb.wiki/728c18a3/","title":"分布式数据库系统(DDBS)"},{"content":"25个人，每5个人一个跑道，最少经过几次比赛，得到前三名\n初步思路:\n每5人一组, 全跑完后, 每组的后两名一定不在最终要的\u0026quot;前三名\u0026quot; 结果内, 所以每组可以排除2人, 剩下25-2*5=15人. 共经过5次比赛\n剩下的15人, 每5人一组, 跑完后, 每组淘汰2人, 剩下 15-2*3=9人. 经过3次比赛\n剩下的9个人分两组, A组5人B组4人, 跑完后, A组淘汰2人, B组淘汰1人, 剩下 9-2-1=6人. 经过2次比赛\n剩下的6人分两组, C组5人D组1人, A组跑完后, 淘汰2人, B组1人不需要跑, 剩下 6-2=4人. 经过1次比赛\n剩下的4个人, 跑一次, 得出前三名. 经过1次比赛 共经过 5+3+2+1+1=12次\n思路2：\n在第一步中, 5组全跑完后, 每组的第一名再跑一次, 按速度快慢分别标为A1 B1 C1 D1 E1. 则A1 为25人中的第一名. 经过5+1=6次比赛\n在第6次比赛中, 落后的两名D1 和E1, 可以被排除, 进而整个D组和E组都可以排除. C1不可能是第二名. 第二名可能的人员有A2 B1, 第三名可能的人员有 B1 A3 B2 A2 C1. 第二名的集合是第三名集合的子集. 第三名所有可能的5个人跑一次, 得出第二名和第三名.经过1次比赛 共经过7次比赛\n另一种思路：\n5次跑完后，每组第一名再跑一次，这次跑的第1名，就是25中的第1名；跑完后，这个第1名出去，他原来所在的组的第2名补上，再与第6次中的其他4个人跑，这样决出最快的那个人，就是25中的第2名，同样过程，决出第3名。共 8 次\n","date":"2019-03-12T23:20:56Z","permalink":"https://lxb.wiki/81be14b5/","title":"跑道问题"},{"content":"GRASP 通用职责分配软件模式 来自 Craig Larman 的软件设计书《UML 和模式应用》[附录 1]，Larman 在书中提出软件设计的关键任务是职责分配，并提炼总结出 9 种 (5 种核心 +4 种扩展) 软件职责分配模式，这些模式是比 GoF 设计模式更抽象的元模式。\n1. 信息专家 (Information Expert)\n为对象分配职责的通用原则 – 把职责分配给拥有足够信息可以履行职责的专家\n2. 创建者 (Creator)\n将创建 A 的职责赋给 B，如果至少下面一种情况为真：\nB“包含”或者聚合 A B 记录 A 的实例 B 密切地使用 A B 拥有 A 的初始化数据 3. 低耦合 (Low Coupling)\n赋予职责使得对象间的耦合度尽可能低，最小化对象间的依赖和变更影响，最大化重用。\n4. 高内聚 (High Cohesion)\n赋予职责使得每个对象的职责尽可能保持聚焦和单一，易于管理和理解。\n5. 控制器 (Controller)\n把职责赋予系统、设备或者子系统的表示类 (门面控制器)，或者某个用例的表示类 (用例控制器)，让控制器接收事件并协调整个系统的运作。\n6. 多态 (Polymorphism)\n将职责分配给多个具有同名方法的多态子类，运行时根据需要动态切换子类，让系统行为变得可插拔。\n7. 纯虚构 (Pure Fabrication)\n针对真实问题域中不存在，但是设计建模中有用的概念，设计虚构类并赋予职责。\n8. 间接 (Indirection)\n在两个或者多个对象间有交互的情况下，为避免直接耦合，提高重用性，创建中间类并赋予职责，对象的交互交由中间类协调。\n9. 受保护的变化 (Protected Variation)\n简单讲就是封装变化。识别系统中可能的不稳定或者变化，在不稳定组件上创建稳定的抽象接口，将可能的变化封装在接口之后，使得系统内部的不稳定或者变化不会对系统的其它部分产生不良影响。\nSOLID 面向对象设计原则 S.O.L.I.D 是面向对象设计和编程 (OOD\u0026amp;OOP) 中几个重要原则的首字母缩写，受 Robert Martin 推崇。\n1. 单一职责原则 (The Single Responsibility Principle)\n修改某个类的理由应该只有一个，如果超过一个，说明类承担不止一个职责，要视情况拆分。\n2. 开放封闭原则 (The Open Closed Principle)\n软件实体应该对扩展开放，对修改封闭。一般不要直接修改类库源码（即使你有源代码），通过继承等方式扩展。\n3. 里氏替代原则 (The Liskov Substitution Principle)\n当一个子类的实例能够被替换成任何超类的实例时，它们之间才是真正的 is-a 关系。\n4. 依赖倒置原则 (The Dependency Inversion Principle)\n高层模块不应该依赖于底层模块，二者都应该依赖于抽象。换句话说，依赖于抽象，不要依赖于具体实现。比方说，你不会把电器电源线焊死在室内电源接口处，而是用标准的插头插在标准的插座 (抽象) 上。\n5. 接口分离原则 (The Interface Segregation Principle)\n不要强迫用户去依赖它们不使用的接口。换句话说，使用多个专门的接口比使用单一的大而全接口要好。\n备注\n高内聚 + 低耦合，就像道中的一阴一阳，是所有其它 OO 设计原则的原则 (元原则)，其它设计原则都是在这两个基础上泛化衍生出来的。 上述原则虽然是针对 OO 设计和编程提出，但是对于大规模系统架构仍然适用。比如，微服务架构就体现了： 单一职责：一个微服务尽可能要职责单一，提供的接口也尽可能单一 (接口分离原则)，安全 / 路由 / 限流等跨横切面的关注点 (Cross-Cutting Concerns) 由独立网关负责，体现关注分离 (Separation of Concerns)。 信息专家：当不确定哪个团队应该负责某个微服务时，一般原则也是谁拥有数据谁负责，基于有界上下文 Bounded Context（一般是边界比较清晰的领域数据源）构建微服务。 松散耦合：服务之间通过 HTTP/JSON 等轻量机制通信，服务之间不强耦合。 受保护的变化和依赖倒置：服务之间只依赖抽象接口，实现可能随时变化。 间接：网关在外面的客户端和内部的服务之间增加了一层间接，使两者不强耦合，可以相互独立演化。 作为架构师或者设计师，有两个设计能力是需要重点培养的，也是最难和最能体现架构设计水平的： 合理的职责分配能力，也就是每个类 / 组件 / 子系统应该承担什么职责，如何保证职责单一，它们之间如何协作； 系统抽象和核心领域建模能力，需要深入一线业务域。 分布式系统架构设计原则和理论 AKF 架构原则 这 15 个架构原则来自《架构即未来 (The Art of Scalability)》[附录 2] 一书，作者马丁 L. 阿伯特和迈克尔 T. 费舍尔分别是 eBay 和 PayPal 的前 CTO，他们经历过 eBay 和 PayPal 大规模分布式电商平台的架构演进，在一线实战经验的基础上总结并提炼出 15 条架构原则：\n1.N + 1 设计\n永远不要少于两个，通常为三个。比方说无状态的 Web/API 一般部署至少\u0026gt;=2 个。\n2. 回滚设计\n确保系统可以回滚到以前发布过的任何版本。可以通过发布系统保留历史版本，或者代码中引入动态开关切换机制 (Feature Switch)。\n3. 禁用设计\n能够关闭任何发布的功能。新功能隐藏在动态开关机制 (Feature Switch) 后面，可以按需一键打开，如发现问题随时关闭禁用。\n4. 监控设计\n在设计阶段就必须考虑监控，而不是在实施完毕之后补充。例如在需求阶段就要考虑关键指标监控项，这就是度量驱动开发 (Metrics Driven Development) 的理念。\n5. 设计多活数据中心\n不要被一个数据中心的解决方案把自己限制住。当然也要考虑成本和公司规模发展阶段。\n6. 使用成熟的技术\n只用确实好用的技术。商业组织毕竟不是研究机构，技术要落地实用，成熟的技术一般坑都被踩平了，新技术在完全成熟前一般需要踩坑躺坑。\n7. 异步设计\n能异步尽量用异步，只有当绝对必要或者无法异步时，才使用同步调用。\n8. 无状态系统\n尽可能无状态，只有当业务确实需要，才使用状态。无状态系统易于扩展，有状态系统不易扩展且状态复杂时更易出错。\n9. 水平扩展而非垂直升级\n永远不要依赖更大、更快的系统。一般公司成长到一定阶段普遍经历过买更大、更快系统的阶段，即使淘宝当年也买小型机扛流量，后来扛不住才体会这样做不 scalable，所以才有后来的去 IOE 行动。\n10. 设计时至少要有两步前瞻性\n在扩展性问题发生前考虑好下一步的行动计划。架构师的价值就体现在这里，架构设计对于流量的增长要有提前量。\n11. 非核心则购买\n如果不是你最擅长，也提供不了差异化的竞争优势则直接购买。避免 Not Invented Here 症状，避免凡事都要重造轮子，毕竟达成业务目标才是重点。\n12. 使用商品化硬件\n在大多数情况下，便宜的就是最好的。这点和第 9 点是一致的，通过商品化硬件水平扩展，而不是买更大、更快的系统。\n13. 小构建、小发布和快试错\n全部研发要小构建，不断迭代，让系统不断成长。这个和微服务理念一致。\n14. 隔离故障\n实现故障隔离设计，通过断路保护避免故障传播和交叉影响。通过舱壁泳道等机制隔离失败单元 (Failure Unit)，一个单元的失败不至影响其它单元的正常工作。\n15. 自动化\n设计和构建自动化的过程。如果机器可以做，就不要依赖于人。自动化是 DevOps 的基础。\n备注\n这 15 条架构原则基本上是 eBay 在发展，经历过流量数量级增长冲击过程中，通过不断踩坑踩出来的，是干货中的干货。消化吸收这 15 条原则，基本可保系统架构不会有原则性问题。 这 15 条原则同样适用于现在的微服务架构。eBay 发展较早，它内部其实很早 (差不多 2010 年前) 就已形成完善的微服务生态，只是没有提出微服务这个概念。 这 15 条原则可根据 TTM(Time To Market)，可用性 / 可扩展性 / 质量，成本 / 效率分布在三个环内，如下图所示。 12 要素应用 基于上百万应用的托管和运营经验，创始人 Adam Wiggins 提出了 12 要素应用宣言 。简单讲，满足这 12 个要素的应用是比较容易云化并居住在 Heroku 平台上的。\n1. 基准代码\n一份基准代码，多份部署。如果用镜像部署方式，则一个镜像可以部署到多个环境 (测试，预发，生产)，而不是给每个环境制作一个不同镜像。\n2. 依赖\n显式声明依赖。如果用镜像部署，则一般依赖被直接打在镜像中，或者声明在 docker file 中。\n3. 配置\n在环境中存储配置。在 Heroku 或者类似的 PaaS 平台上，配置一般是推荐注入到环境变量中的。现在采用集中式配置中心也是一种流行方式。\n4. 后端服务\n把后端服务 (例如缓存，数据库，MQ 等) 当作附加资源，相关配置和连接字符串通过环境变量注入，或者采用配置中心。\n5. 构建、发布和运行\n严格分离构建和运行。如果使用镜像部署，则构建、发布 / 运行是通过镜像这种中间格式严格分离的。\n6. 进程\n一个或者多个无状态的进程运行应用。容器运行时相当于进程，适用于无状态 Web/API。\n7. 端口绑定\n通过端口绑定提供服务。容器也是通过端口绑定对外提供服务。\n8. 并发\n通过进程模型进行扩展。容器运行时相当于进程，通过起多个容器可以任意扩展并发数量。\n9. 易处理\n快速启动和优雅终止可最大化健壮性。docker 容器支持秒级启动和关闭。\n10. 开发环境和线上环境等价\n尽可能保持开发、测试、预发和线上环境相同。容器可以保证容器内运行时环境的一致性，还需要保证不同环境的一致性，例如不同环境内的操作系统，负载均衡，服务发现，后台服务，监控告警等要尽可能一致。\n11. 日志\n把日志当作数据流。Heroku 不支持本地文件，所以必须以流方式把日志输送到后台日志服务。除了日志以外还要补充考虑 metrics 流的采集和输送。\n12. 管理进程\n后台管理任务当作一次性的进程。其实相当于在 Heroku 上以独立进程方式运行任务 Job。\n备注\n12 要素应用也是当前云原生应用 (Cloud Native App) 的参考标准，也称为云应用迁移原则。满足这 12 个要素的应用，可以比较顺利迁移到各种云平台 (Kubernetes, Marathon, Cloud Foundry 等) 上。 对于面临企业遗留应用改造和云化迁移的架构师，可以重点参考这 12 条迁移原则。 Docker 容器技术可以认为是为云迁移量身定制的技术。容器化是后续云迁移的捷径，所以遗留应用改造可以先想办法做到容器化。 CAP 定理 2000 年 7 月，加州大学伯克利分校的 Eric Brewer 教授在 ACM PODC 会议上提出 CAP 猜想。2 年后，麻省理工学院的 Seth Gilbert 和 Nancy Lynch 从理论上证明了 CAP。之后，CAP 理论正式成为分布式计算领域的公认定理。\nCAP 认为：一个分布式系统最多同时满足一致性 (Consistency)，可用性 (Availability) 和分区容忍性 (Partition Tolerance) 这三项中的两项。\n1.一致性 (Consistency)\n一致性指“all nodes see the same data at the same time”，即更新操作成功，所有节点在同一时间的数据完全一致。\n2.可用性 (Availability)\n可用性指“Reads and writes always succeed”，即服务一直可用，而且响应时间正常。\n3.分区容忍性 (Partition tolerance)\n分区容忍性指“the system continue to operate despite arbitrary message loss or failure of part of the system.”，即分布式系统在遇到某节点或网络分区故障时，仍然能够对外提供满足一致性和可用性的服务。\nBASE 理论 eBay 架构师 Dan Pritchett 基于对大规模分布式系统的实践总结，在 ACM 上发表文章提出了 BASE 理论，BASE 理论是对于 CAP 理论的延伸，核心思想是即使无法做到强一致性 (Strong Consistency，CAP 中的一致性指强一致性)，但是可以采用适当的方式达到最终一致性 (Eventual Consistency)。\nBASE 指基本可用 (Basically Available)、软状态 (Soft State) 和最终一致性 (Eventual Consistency)。\n1.基本可用 (Basically Available)\n基本可用是指分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。比如服务降级。\n2.软状态 (Soft State)\n软状态是指允许系统存在中间状态，而该中间状态不会影响系统的整体可用性。分布式存储中一般一份数据至少存三个副本，允许不同节点间副本同步的延迟就是软状态的体现。\n3.最终一致性 (Eventual Consistency)\n最终一致性是指系统中的所有数据副本经过一段时间后，最终能够达成一致状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。\n备注\nCAP 和 BASE 理论可以抠得很深，背后甚至有很复杂的数学证明。我理解得相对简单浅显：性能、高可用、不丢数据和数据一致性对分布式系统来说一般是强需求，随着流量的增长，复制和分区在所难免： 复制 (replication)：数据在多个节点上存多份保证不丢和高可用； 分区 (partition)：数据按某个纬度切分分布在不同节点上分摊流量压力保证高性能，同时也是为了降低每个节点的复杂性。例如数据库的分库分表，系统拆分微服务化也是一种分区。这两者都会带来一致性问题，一致性在时间上有一点妥协的余地 - 即是最终一致性；时间上要求强一致的话，只有可用性可以适当折中。系统架构的游戏很大部分是和状态一致性作斗争的游戏。 选择使用分布式产品时，比如 NoSQL 数据库，你需要了解它在 CAP 环中所在的位置，确保它满足你的场景需要。 组织和系统改进原则 康威法则 Melvin Conway 在 1967 年提出所谓康威法则 ，指出组织架构和系统架构之间有一种隐含的映射关系：\nOrganization which design system […] are constrained to produce designs which are copies of the communication structures of these organization. 设计系统的组织其产生的设计等价于组织间的沟通结构。\n康威法则也可以倒过来阐述：\nConway’s law reversed：You won’t be able to successfully establish an efficient organization structure that is not supported by your system design(architecture)。 如果系统架构不支持，你无法建立一个高效的组织；同样，如果你的组织架构不支持，你也无法建立一个高效的系统架构。\n系统改进三原则 IT 运维管理畅销书《凤凰项目》[附录 8] 的作者 Gene Kim 在调研了众多高效能 IT 组织后总结出支撑 DevOps 运作的三个原理 (The Three Ways: The Principles Underpinning DevOps)[附录 9]，我认为也是系统改进提升的一般性原理 [附录 7]，见下图：\n原理一：系统思考 (System Thinking)\n开发驱动的组织，其能力不是制作软件，而是持续的交付客户价值。价值从业务需求开始，经过研发测试，到部署运维，依次流动，并最终以服务形式交付到客户手中。整个价值链流速并不依赖单个部分 (团队或个人) 的杰出工作，而是受整个价值链最薄弱环节 (瓶颈) 的限制。所以局部优化通常无效，反而招致全局受损。\nGene Kim 特别指出：Any improvements made anywhere besides the bottleneck are an illusion. 在瓶颈之外的任何优化提升都只是幻象。\n原理二：强化反馈环 (Amplify Feedback Loops)\n过程改进常常通过加强反馈环来达成。原理二强调企业和客户之间、组织团队间、流程上和系统内的反馈环。没有测量就没有提升，反馈要以测量数据为准，通过反馈数据优化改进系统。\n原理三：持续试验和学习的文化 (Culture of Continual Experimentation And Learning)\n在企业管理文化层面强调勇于试错和持续试验、学习和改进的文化。\n备注\n康威法则给我们的启示：系统架构和组织架构之间有隐含的映射关系，你不能单方面改变一方的结构，调整时必须两边联动。系统架构如果是耦合的，就很难组织分散式的团队结构，两边映射不起来，团队之间容易摩擦导致生产率下降。所以一般先按业务边界对单块应用进行解耦拆分，同时做相应的团队拆分，使两边可以映射，每个团队可以独立开发、测试和部署各自的微服务，进而提升生产率。这就是近年流行的微服务架构背后的组织原则。详见我之前发表的文章《企业的组织架构是如何影响技术架构的》[附录 6]。 系统思考要求我们加强团队合作，培养流式思维和瓶颈约束思维，找出瓶颈并针对性地优化。在研发型组织中，常见的系统瓶颈如运维机器资源提供 (Provisioning) 缓慢，发布流程繁琐容易出错，开发 / 测试／UAT 环境缺失或不完善，遗留系统耦合历史负担重，基础研发平台薄弱等等。这些瓶颈点特别需要关注优化。 反馈原理要求我们关注基于数据的反馈，技术上的手段包括大数据分析和系统各个层次的测量监控。没有测量就没有反馈，没有反馈就没有提升。 在管理文化层面： 管理层要承认企业内部近 50% 的创新或流程改进项目是有可能失败的，即使失败，员工不会受到责罚，鼓励持续的试验和从中学习； 管理层要有技术偿债意识，勿追求 100% 员工利用率，要预留 20%~30% 的时间给员工做创新和系统改进提升项目 ","date":"2019-03-01T22:52:22Z","permalink":"https://lxb.wiki/88049151/","title":"架构设计原则"},{"content":"一、秒杀业务为什么难做 1）im系统，例如qq或者微博，每个人都读自己的数据（好友列表、群列表、个人信息）； 2）微博系统，每个人读你关注的人的数据，一个人读多个人的数据； 3）秒杀系统，库存只有一份，所有人会在集中的时间读和写这些数据，多个人读一个数据。\n例如：小米手机每周二的秒杀，可能手机只有1万部，但瞬时进入的流量可能是几百几千万。 又例如：12306抢票，票是有限的，库存一份，瞬时流量非常多，都读相同的库存。读写冲突，锁非常严重，这是秒杀业务难的地方。那我们怎么优化秒杀业务的架构呢？\n二、优化方向 优化方向有两个（今天就讲这两个点）： （1）将请求尽量拦截在系统上游（不要让锁冲突落到数据库上去）。传统秒杀系统之所以挂，请求都压倒了后端数据层，数据读写锁冲突严重，并发高响应慢，几乎所有请求都超时，流量虽大，下单成功的有效流量甚小。以12306为例，一趟火车其实只有2000张票，200w个人来买，基本没有人能买成功，请求有效率为0。\n（2）充分利用缓存，秒杀买票，这是一个典型的读多写少的应用场景，大部分请求是车次查询，票查询，下单和支付才是写请求。一趟火车其实只有2000张票，200w个人来买，最多2000个人下单成功，其他人都是查询库存，写比例只有0.1%，读比例占99.9%，非常适合使用缓存来优化。好，后续讲讲怎么个“将请求尽量拦截在系统上游”法，以及怎么个“缓存”法，讲讲细节。\n三、常见秒杀架构 （1）浏览器端，最上层，会执行到一些JS代码 （2）站点层，这一层会访问后端数据，拼html页面返回给浏览器 （3）服务层，向上游屏蔽底层数据细节，提供数据访问 （4）数据层，最终的库存是存在这里的，mysql是一个典型（当然还有会缓存）\n四、各层次优化细节 第一层，客户端怎么优化（浏览器层，APP层） 微信的摇一摇抢红包，每次摇一摇，就会往后端发送请求么？下单抢票的场景，点击了“查询”按钮之后，系统那个卡呀，进度条涨的慢呀，作为用户，我会不自觉的再去点击“查询”，对么？继续点，继续点，点点点。。。有用么？平白无故的增加了系统负载，一个用户点5次，80%的请求是这么多出来的，怎么整？\n（a）产品层面，用户点击“查询”或者“购票”后，按钮置灰，禁止用户重复提交请求； （b）JS层面，限制用户在x秒之内只能提交一次请求；\nAPP层面，可以做类似的事情，虽然你疯狂的在摇微信，其实x秒才向后端发起一次请求。这就是所谓的“将请求尽量拦截在系统上游”，越上游越好，浏览器层，APP层就给拦住，这样就能挡住80%+的请求，这种办法只能拦住普通用户（但99%的用户是普通用户）对于群内的高端程序员是拦不住的。firebug一抓包，http长啥样都知道，js是万万拦不住程序员写for循环，调用http接口的，这部分请求怎么处理？\n第二层，站点层面的请求拦截 怎么拦截？怎么防止程序员写for循环调用，有去重依据么？ip？cookie-id？…想复杂了，这类业务都需要登录，用uid即可。在站点层面，对uid进行请求计数和去重，甚至不需要统一存储计数，直接站点层内存存储（这样计数会不准，但最简单）。一个uid，5秒只准透过1个请求，这样又能拦住99%的for循环请求。\n5s只透过一个请求，其余的请求怎么办？缓存，页面缓存，同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面。同一个item的查询，例如车次，做页面缓存，x秒内到达站点层的请求，均返回同一页面。如此限流，既能保证用户有良好的用户体验（没有返回404）又能保证系统的健壮性（利用页面缓存，把请求拦截在站点层了）。\n页面缓存不一定要保证所有站点返回一致的页面，直接放在每个站点的内存也是可以的。优点是简单，坏处是http请求落到不同的站点，返回的车票数据可能不一样，这是站点层的请求拦截与缓存优化。\n好，这个方式拦住了写for循环发http请求的程序员，有些高端程序员（黑客）控制了10w个肉鸡，手里有10w个uid，同时发请求（先不考虑实名制的问题，小米抢手机不需要实名制），这下怎么办，站点层按照uid限流拦不住了。\n第三层 服务层来拦截（反正就是不要让请求落到数据库上去） 服务层怎么拦截？大哥，我是服务层，我清楚的知道小米只有1万部手机，我清楚的知道一列火车只有2000张车票，我透10w个请求去数据库有什么意义呢？没错，请求队列！\n对于写请求，做请求队列，每次只透有限的写请求去数据层（下订单，支付这样的写业务）\n1w部手机，只透1w个下单请求去db\n3k张火车票，只透3k个下单请求去db\n如果均成功再放下一批，如果库存不够则队列里的写请求全部返回“已售完”。\n对于读请求，怎么优化？cache抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的。如此限流，只有非常少的写请求，和非常少的读缓存mis的请求会透到数据层去，又有99.9%的请求被拦住了。\n当然，还有业务规则上的一些优化。回想12306所做的，分时分段售票，原来统一10点卖票，现在8点，8点半，9点，\u0026hellip;每隔半个小时放出一批：将流量摊匀。\n其次，数据粒度的优化：你去购票，对于余票查询这个业务，票剩了58张，还是26张，你真的关注么，其实我们只关心有票和无票？流量大的时候，做一个粗粒度的“有票”“无票”缓存即可。\n第三，一些业务逻辑的异步：例如下单业务与 支付业务的分离。这些优化都是结合 业务 来的，我之前分享过一个观点“一切脱离业务的架构设计都是耍流氓”架构的优化也要针对业务。\n第四层 最后是数据库层 浏览器拦截了80%，站点层拦截了99.9%并做了页面缓存，服务层又做了写请求队列与数据缓存，每次透到数据库层的请求都是可控的。db基本就没什么压力了，闲庭信步，单机也能扛得住，还是那句话，库存是有限的，小米的产能有限，透这么多请求来数据库没有意义。\n全部透到数据库，100w个下单，0个成功，请求有效率0%。透3k个到数据，全部成功，请求有效率100%。\n五、总结 上文应该描述的非常清楚了，没什么总结了，对于秒杀系统，再次重复下我个人经验的两个架构优化思路： （1）尽量将请求拦截在系统上游（越上游越好）； （2）读多写少的常用多使用缓存（缓存抗读压力）；\n浏览器和APP：做限速\n站点层：按照uid做限速，做页面缓存\n服务层：按照业务做写请求队列控制流量，做数据缓存\n数据层：闲庭信步\n并且：结合业务做优化\n","date":"2019-02-26T22:13:12Z","permalink":"https://lxb.wiki/bcca3074/","title":"秒杀系统优化思路"},{"content":"1.下载mktorrent git clone https://github.com/lxbwolf/mktorrent.git 2.下载完成后进入到文件夹里面 例如：cd mktorrent（如果是根目录的话） 3. make 4. make install 5. 默认安装目录位于/usr/local/bin，使用cd命令，从默认的/root路径切换到要制作成种子的文件上一级。 例如cd /Downloads 6. 制作种子命令为： mktorrent -v -p -l 22 -a tracker_address -o name.torrent file_name 参数说明： tracker_address为你要发布的网站的tracker。 name.torrent为对生成torrent种子文件的命名，规则为：xxx.torrent。 file_name为你要做种的文件或文件夹。避免含有空格。 7. 等待一会儿会提示做种完成，在当前目录下即可找到。\n","date":"2018-11-01T21:20:18Z","permalink":"https://lxb.wiki/7592d71b/","title":"制作种子"},{"content":"1. 下载路由器固件 从 官网 或者 百度网盘\n解压到指定目录如 /root/xunlei 进入目录 执行./portal 稍等片刻，会在最后输出一个激活码\n2. 在迅雷远程下载页面绑定树莓派 登录迅雷远程下载主页,登录之后，左侧会有一个添加按钮，点击添加按钮\n不需要选择绑定设备类型, 直接将树莓派上获得的激活码填入框中，点击绑定后左侧就会出现树莓派对应的设备列表了，但是，如果我们此时就在右侧点击新建之后会发现,弹出的新建页面中会提示找不到挂载磁盘\n3. 自定义迅雷的下载目录 进入/mnt目录，创建目录TDDOWNLOAD(名字随意) 执行mount --bind /data/TDDOWNLOAD /mnt/TDDOWNLOAD\n其中/data/TDDOWNLOAD就是自定义的下载目录，你可以指定为其他任何目录。\n然后再刚刚迅雷固件的解压目录下创建目录etc,同时在etc下创建文件thunder_mounts.cfg,编辑此文件, 写入内容\navaliable_mount_path_pattern { /mnt/TDDOWNLOAD } 重启路由器固件 ./root/xunlei/portal 再进入远程下载界面新建下载就没有了没挂载磁盘的提示了\n4. 迅雷路由器固件开机启动 在/etc/init.d/下新建xunlei脚本，写入:\n#!/bin/sh # # Xunlei initscript # ### BEGIN INIT INFO # Provides: xunlei # Required-Start: $network $local_fs $remote_fs # Required-Stop:: $network $local_fs $remote_fs # Should-Start: $all # Should-Stop: $all # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Start xunlei at boot time # Description: A downloader ### END INIT INFO do_start() { ./root/xunlei/portal } do_stop() { ./root/xunlei/portal -s } case \u0026quot;$1\u0026quot; in start) do_start ;; stop) do_stop ;; esac 然后将该脚本加入默认自启动中 update-rc.d xunlei defaults\n","date":"2018-11-01T20:09:55Z","permalink":"https://lxb.wiki/1846a864/","title":"树莓派搭建迅雷远程下载服务器"},{"content":"修改软件源 sudo -s echo -e \u0026quot;deb http://mirrors.ustc.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi \\n deb-src http://mirrors.ustc.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi\u0026quot; \u0026amp;gt; /etc/apt/sources.list echo -e \u0026quot;deb http://mirrors.ustc.edu.cn/archive.raspberrypi.org/ stretch main ui\u0026quot; \u0026amp;gt; /etc/apt/sources.list.d/raspi.list exit sudo apt update \u0026amp;amp;\u0026amp;amp; sudo apt -y upgrade 中文输入法 sudo apt-get install -y ttf-wqy-zenhei sudo apt-get install -y scim-pinyin 看门狗(防止树莓派死机的监控) 当利用树莓派来做一些需要长期待机的应用时，如下载机、云储存、家庭影院等应用，我们往往会遇到的一个问题就是树莓派会因为过热而死机，需要我们重新启动树莓派，然后再次开启树莓派上的应用。这会给我们的日常操作带来许多麻烦。 Watchdog（看门狗）就能让树莓派永不死机。\n//树莓派自带看门狗模块，我们需要添加进去就好。 sudo modprobe bcm2708_wdog echo -e \u0026quot;\\nbcm2708_wdog\u0026quot; \u0026amp;gt; sudo tee -a /etc/modules // 安装看门狗软件 sudo apt-get install -y chkconfig watchdog // 配置 sudo vim /etc/watchdog.conf // 去掉\u0026quot;watchdog-device=/dev/watchdog\u0026quot;这一行的#注释 // 其它配置参考如下: # 用于设定CPU温度重启条件 temperature-device = /sys/class/thermal/thermal_zone0/temp # 最大温度为100度，超过立即重启 max-temperature = 100000 # 1分钟最多进程为24个，超过即重启 max-load-15=12 # 5分钟最多进程为18个，超过即重启 max-load-15=12 # 15分钟最多进程为12个，超过即重启 max-load-15=12 // 完成配置后，启动看门狗 sudo /etc/init.d/watchdog start // 设置为开机自启 chkconfig watchdog on Screen(让树莓派永不失联) 利用SSH（Serare Shell，安全外壳协议）来远程控制树莓派应该是我们最常用的 操作树莓派的方式，但在用SSH连接时，我们常常会遇到连接突然断开的问题。连 接一旦断开，原米我们进行的操作也就中断了，若再使用，就得从头再来了。相信你肯定因为电脑待机而中断树莓派的任务而苦恼过。 Screen来让树莓派永不失联的方法。此方法下，就算连接断开了，当我们重新连接后依旧进行原来的操作，而不需要从头再来。\n// 直接安装Screen sudo apt-get install -y screen // 开启一个后台view（后台的终端，不会因为断开连接而终止） screen -S 终端名 // 然后就可以继续你的操作了 ","date":"2018-10-18T22:24:19Z","permalink":"https://lxb.wiki/5976aace/","title":"树莓派基础环境"},{"content":"安装步骤: 官网下载系统 -- 刷入TF卡 -- 设置开启显示器和SSH -- 通电 -- 进入系统\n0. 很重要 装完系统，写完 wpa_supplicant.conf 配置文件后，无论如何不要 reboot，不要 reboot， 不要 reboot ！！！ 3B+ 有极大的概率，reboot 后无法正常连接 WIFI，只能重新烧录系统。\n1. 进入官方网站下载系统镜像 官方系统 raspbian地址 https://www.raspberrypi.org/downloads/\n2. Windows系统下的安装 2.1 下载SD格式化工具 SDFormatter 地址 https://www.sdcard.org/downloads/formatter_4/eula_windows/\n安装后直接用默认选项 格式化SD卡\n2.2 下载写镜像工具 Win32 DiskImager 地址 http://sourceforge.net/projects/win32diskimager/\n3. MAC系统下的安装 3.1 查看当前已挂载的卷 [liuxb@liuxb-mac]$ df -h Filesystem Size Used Avail Capacity iused ifree %iused Mounted on /dev/disk1 112Gi 81Gi 30Gi 73% 1014786 4293952493 0% / devfs 188Ki 188Ki 0Bi 100% 654 0 100% /dev map -hosts 0Bi 0Bi 0Bi 100% 0 0 100% /net map auto_home 0Bi 0Bi 0Bi 100% 0 0 100% /home /dev/disk2s3 92Gi 51Gi 41Gi 56% 336662 42525054 1% /Volumes/系统 /dev/disk2s4 20Gi 15Gi 4.4Gi 78% 92859 4579733 2% /Volumes/数据 /dev/disk3s1 29Gi 2.3Mi 29Gi 1% 107876 8373436 2% /Volumes/未命名 对比Size和Name可以找到SD卡的分区在系统里对应的设备文件（这里是/dev/disk3s1），如果你有多个分区，可能还会有disk3s2之类的\n3.2 使用diskutil unmount将分区卸载 [liuxb@liuxb-mac]$ diskutil unmount /dev/disk3s1 Volume 未命名 on disk3s1 unmounted 3.3 先对下载的zip压缩包进行解压，然后使用dd命令将系统镜像写入，需要特别特别注意disk后的数字，不能搞错 这部分可以参考Mac 烧录系统\n说明：/dev/disk3s1是分区，/dev/disk3是块设备，/dev/rdisk3是原始字符设备\n[liuxb@liuxb-mac]$ unzip 2017-09-07-raspbian-stretch.zip [liuxb@liuxb-mac]$ sudo dd bs=16m if=2017-09-07-raspbian-stretch.img of=/dev/rdisk3 _ 输入用户密码 经过几分钟的等待，出现下面的提示，说明TF卡刷好了：\n1172+1 records in 1172+1 records out 4916019200 bytes transferred in 127.253638 secs (9691442 bytes/sec) 4. 开启SSH 在TF卡分区里创建一个名为\u0026quot;ssh\u0026quot;的不带后缀的空文件\n5. 开启强制HDMI输出 在TF卡分区，打开config.txt文件(开机后位置： /boot/config.txt)，修改如下：\nhdmi_safe=1 config_hdmi_boost=4 hdmi_ignore_edid=0xa5000080 hdmi_group=2 hdmi_mode=82 参数介绍:\n项\n解释\nhdmi_safe=1\n安全启动HDMI\nconfig_hdmi_boost=4\n开启热插拔\nhdmi_group=1\nCEA电视显示器\nhdmi_group=2\nDMT电脑显示器\nhdmi_ignore_edid=0xa5000080\n忽略自动探测的分辨率\n输出分辨率：\nhdmi_mode=4\n640x480 60Hz\nhdmi_mode=9\n800x600 60Hz\nhdmi_mode=16\n1024x768 60Hz\nhdmi_mode=82\n1080p 60Hz\n6.设置无线WI-FI连接：（假设没有网线，而且没能连接显示器） 在TF卡的boot分区，创建wpa_supplicant.conf文件，加入如下内容：\ncountry=CN ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=\u0026quot;lxb-wifi\u0026quot; psk=\u0026quot;123456789\u0026quot; priority=1 } 在树莓派通电后会自动添加到/etc/wpa_supplicant/wpa_supplicant.conf文件里面，进行自动连接。\n// 详细介绍： #ssid:网络的ssid #psk:密码 #priority:连接优先级，数字越大优先级越高（不可以是负数） #scan_ssid:连接隐藏WiFi时需要指定该值为1 // 如果WiFi 没有密码 network={ ssid=\u0026quot;无线网络名称（ssid）\u0026quot; key_mgmt=NONE } // 如果WiFi 使用WEP加密 network={ ssid=\u0026quot;无线网络名称（ssid）\u0026quot; key_mgmt=NONE wep_key0=\u0026quot;wifi密码\u0026quot; } // 如果你的 WiFi 使用WPA/WPA2加密 network={ ssid=\u0026quot;无线网络名称（ssid）\u0026quot; key_mgmt=WPA-PSK psk=\u0026quot;wifi密码\u0026quot; } 以上设置完成后, TF卡可以插入树莓派了, 通电. 默认登录账号:pi 密码: raspberry\nMac 烧录操作：\u0026gt;\n核心就一行指令 sudo dd bs=4m if=2017-11-29-raspbian-stretch.img of=/dev/rdisk4 其中if参数为镜像文件，of参数为设备名称。但是烧写系统进sd卡前需要一个准备工作，其一是将sd卡抹掉格式化一下，然后卸载sd卡分区，最后将系统烧进指定sd卡位置。 抹掉sd卡很简单，mac的磁盘工具，选中sd卡，点抹掉，格式选择MS-DOS(FAT)。 sd卡格式化之后，Mac命令行输入df -h，得到挂载的SD卡位置（卷），比如/dev/disk4s1。 然后使用 diskutil unmount /dev/disk4s1 卸载这个分区 最后，使用 diskutil list 这个命令，获得我们要安装系统的设备。 注意：此处我们看到的是 /dev/disk4，但是写核心指令的时候要加一个字母r，即/dev/rdisk4。 最终得到的就是 sudo dd bs=4m if=2017-11-29-raspbian-stretch.img of=/dev/rdisk4 最后安全退出sd卡 diskutil unmountDisk /dev/disk4 ","date":"2018-10-17T22:11:38Z","permalink":"https://lxb.wiki/cfbe6b0a/","title":"树莓派3B+ 安装系统"},{"content":"需要引入 smtp包 mail.go\npackage main import ( \u0026quot;bytes\u0026quot; \u0026quot;encoding/base64\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;net/smtp\u0026quot; \u0026quot;strings\u0026quot; ) const const_smtp_server = \u0026quot;server-ip:port\u0026quot; //const const_email_content_type = \u0026quot;Content-Type: text/plain; charset=UTF-8\u0026quot; const const_email_content_type = \u0026quot;Content-Type: text/html; charset=UTF-8\u0026quot; const const_boundary = \u0026quot;THIS_IS_THE_BOUNDARY_FOR_EMAIL_BY_LXB\u0026quot; func SendEmail(sender string, receivers []string, subject string, content string, attach_files []string) error { var buf bytes.Buffer buf.WriteString(\u0026quot;To: \u0026quot;) buf.WriteString(strings.Join(receivers, \u0026quot;,\u0026quot;)) buf.WriteString(\u0026quot;\\r\\nFrom: \u0026quot;) //nickname := strings.Split(sender,\u0026quot;@\u0026quot;)[0] //buf.WriteString(nickname) buf.WriteString(\u0026quot;\u0026lt;\u0026quot;) buf.WriteString(sender) buf.WriteString(\u0026quot;\u0026gt;\u0026quot;) buf.WriteString(\u0026quot;\\r\\nSubject: \u0026quot;) buf.WriteString(subject) buf.WriteString(\u0026quot;\\r\\nContent-Type: multipart/mixed; boundary=\u0026quot;) buf.WriteString(const_boundary) buf.WriteString(\u0026quot;\\r\\n--\u0026quot;) buf.WriteString(const_boundary) buf.WriteString(\u0026quot;\\r\\n\u0026quot;) buf.WriteString(const_email_content_type) buf.WriteString(\u0026quot;\\r\\n\\r\\n\u0026quot;) buf.WriteString(content) buf.WriteString(\u0026quot;\\r\\n\\r\\n--\u0026quot;) buf.WriteString(const_boundary) buf.WriteString(\u0026quot;\\r\\n\u0026quot;) for _, filepath := range attach_files { // 第一个附件 filedepts := strings.Split(filepath, \u0026quot;/\u0026quot;) filename := filedepts[len(filedepts)-1] buf.WriteString(\u0026quot;Content-Type: application/octet-stream\\r\\n\u0026quot;) buf.WriteString(\u0026quot;Content-Description: 附件\\r\\n\u0026quot;) buf.WriteString(\u0026quot;Content-Transfer-Encoding: base64\\r\\n\u0026quot;) buf.WriteString(\u0026quot;Content-Disposition: attachment; filename=\\\u0026quot;\u0026quot; + filename + \u0026quot;\\\u0026quot;\\r\\n\\r\\n\u0026quot;) //读取并编码文件内容 attaData, err := ioutil.ReadFile(filepath) if err != nil { print(err) return err } b := make([]byte, base64.StdEncoding.EncodedLen(len(attaData))) base64.StdEncoding.Encode(b, attaData) buf.Write(b) buf.WriteString(fmt.Sprintf(\u0026quot;\\r\\n--%s\\r\\n\u0026quot;, const_boundary)) } fmt.Println(buf.String()) err := smtp.SendMail(const_smtp_server, nil, sender, receivers, buf.Bytes()) fmt.Println(\u0026quot;send mail err:\u0026quot;, err) return err } main.go\npackage main import ( //\u0026quot;flag\u0026quot; //\u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) func main() { //var task string //flag.StringVar(\u0026amp;task, \u0026quot;t\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;task id\u0026quot;) //flag.Parse() //if task == \u0026quot;\u0026quot; { // fmt.Println(\u0026quot;task is required.\u0026quot;) // flag.Usage() // os.Exit(2) //} testStr := os.Args[1] cont := \u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;\u0026lt;p align=\\\u0026quot;center\\\u0026quot;\u0026gt;表: 1\u0026lt;/p\u0026gt;\u0026lt;table align=\\\u0026quot;center\\\u0026quot; border=\\\u0026quot;1\\\u0026quot; cellpadding=\\\u0026quot;10\\\u0026quot;\u0026gt;\u0026lt;tr\u0026gt;\u0026lt;td\u0026gt;任务ID\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;列1\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;列2\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;列3\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt;\u0026lt;td\u0026gt;\u0026quot; + testStr + \u0026quot;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026quot; + testStr + \u0026quot;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026quot; + testStr + \u0026quot;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026quot; + testStr + \u0026quot;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;/table\u0026gt;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; sender := \u0026quot;\u0026quot; rcvs := []string{} sbj := \u0026quot;test email\u0026quot; // cont := \u0026quot;This is content\u0026quot; file := []string{} SendEmail(sender, rcvs, sbj, cont, file) } ","date":"2018-09-01T22:26:49Z","permalink":"https://lxb.wiki/c296dcc8/","title":"Go 发送邮件"},{"content":"Bash shell 只支持一维数组. 初始化时不需要定义数组大小(与 PHP 类似). 数组元素的下标由0开始\nshell 数组用括号来表示, 元素用\u0026quot;空格\u0026quot;符号分隔开, 语法: array_name=(value1 value2 ...valuen)\n实例 #!/bin/bash my_array=(A B \u0026quot;C\u0026quot; D) 也可以用下标来定义数组\narray_name[0]=value0 array_name[1]=value1 array_name[2]=value2 读取数组 ${array_name[index]}\n实例 #!/bin/bash my_array=(A B \u0026quot;C\u0026quot; D) echo \u0026quot;第一个元素为: ${my_array[0]}\u0026quot; echo \u0026quot;第二个元素为: ${my_array[1]}\u0026quot; echo \u0026quot;第三个元素为: ${my_array[2]}\u0026quot; echo \u0026quot;第四个元素为: ${my_array[3]}\u0026quot; 获取数组中的所有元素 使用@ 或 * 可以后去数组中的所有元素\n#!/bin/bash my_array[0]=A my_array[1]=B my_array[2]=C my_array[3]=D echo \u0026quot;数组的元素为: ${my_array[*]}\u0026quot; echo \u0026quot;数组的元素为: ${my_array[@]}\u0026quot; 获取数组的长度 获取数组长度的方法与获取字符串长度的方法相同\n#!/bin/bash my_array[0]=A my_array[1]=B my_array[2]=C my_array[3]=D echo \u0026quot;数组元素个数为: ${#my_array[*]}\u0026quot; echo \u0026quot;数组元素个数为: ${#my_array[@]}\u0026quot; ","date":"2018-08-30T22:33:15Z","permalink":"https://lxb.wiki/21c4d609/","title":"Shell数组笔记"},{"content":"选项 -b 值为每一个输出档案的大小, 单位为byte -C 每一个输出档中, 单行的最大byte 数 -d 使用数字作为后缀 -l 值为每一个输出档的行数大小 实例 生成一个大小为100KB 的测试文件\ndd if=/dev/zero bs=100k count=1 of=date.file 1+0 records in 1+0 records out 102400 bytes (102 kB) copied, 0.00043 seconds, 238 MB/s 使用split 命令将上面创建的date.file文件分割成大小为10KB 的小文件\n$ split -b 10k date.file $ ls date.file xaa xab xac xad xae xaf xag xah xai xaj 文件被分割成带有字母的后缀文件, 如果想用数字后缀可使用-d参数, 同时可以使用-a length指定后缀的长度\n[root@localhost split]# split -b 10k date.file -d -a 3 [root@localhost split]# ls date.file x000 x001 x002 x003 x004 x005 x006 x007 x008 x009 为分割后的文件指定文件名的前缀\n[root@localhost split]# split -b 10k date.file -d -a 3 split_file [root@localhost split]# ls date.file split_file000 split_file001 split_file002 split_file003 split_file004 split_file005 split_file006 split_file007 split_file008 split_file009 使用-l选项根据文件的行数来分割文件,如把文件分割成每个包含10行的小文件\nsplit -l 10 date.file ","date":"2018-08-30T22:23:34Z","permalink":"https://lxb.wiki/aa4c47b6/","title":"split命令"},{"content":"先用free 命令查看剩余空间\n[root@tokyo mysqld]# free total used free shared buff/cache available Mem: 1016108 632132 205776 66344 178200 180496 Swap: 0 0 0 发现swap 为零了\n执行\ndd if=/dev/zero of=/swapfile bs=1M count=1024 mkswap /swapfile wapon /swapfile swapon /swapfile 再用free查看\n[root@tokyo ~]# free total used free shared buff/cache available Mem: 1016108 732148 63984 51400 219976 71132 Swap: 1048572 209240 839332 启动mysql, 解决\n","date":"2018-08-28T19:04:37Z","permalink":"https://lxb.wiki/77f38978/","title":"mysql启动时 \u0026quot;No space left on device\u0026quot;"},{"content":"当我们在终端或控制台工作时，可能不希望由于运行一个作业而占住了屏幕，因为可能还有更重要的事情要做，比如阅读电子邮件。对于密集访问磁盘的进程，我们更希望它能够在每天的非负荷高峰时间段运行(例如凌晨)。为了使这些进程能够在后台运行，也就是说不在终端屏幕上运行，有几种选择方法可供使用\n\u0026amp; nohup ctrl + z ctrl + c jobs bg fg \u0026amp; 当在前台运行某个作业时，终端被该作业占据；可以在命令后面加上\u0026amp; 实现后台运行。例如：sh test.sh \u0026amp; 适合在后台运行的命令有f i n d、费时的排序及一些s h e l l脚本。在后台运行作业时要当心：需要用户交互的命令不要放在后台执行，因为这样你的机器就会在那里傻等。不过，作业在后台运行一样会将结果输出到屏幕上，干扰你的工作。如果放在后台运行的作业会产生大量的输出，最好使用下面的方法把它的输出重定向到某个文件中：\ncommand \u0026gt; out.file 2\u0026gt;\u0026amp;1 \u0026amp; 当你成功地提交进程以后，就会显示出一个进程号，可以用它来监控该进程，或杀死它。(ps -ef | grep 进程号 或者 kill -9 进程号）\nnohup 使用\u0026amp;命令后，作业被提交到后台运行，当前控制台没有被占用，但是一但把当前控制台关掉(退出帐户时)，作业就会停止运行。nohup命令可以在你退出帐户之后继续运行相应的进程。nohup就是不挂起的意思( no hang up)。该命令的一般形式为：\nnohup command \u0026amp; 如果使用nohup命令提交作业，那么在缺省情况下该作业的所有输出都被重定向到一个名为nohup.out的文件中，除非另外指定了输出文件：\nnohup command \u0026gt; myout.file 2\u0026gt;\u0026amp;1 \u0026amp; 使用了nohup之后，很多人就这样不管了，其实这样有可能在当前账户非正常退出或者结束的时候，命令还是自己结束了。所以在使用nohup命令后台运行命令之后，需要使用exit正常退出当前账户，这样才能保证命令一直在后台运行\nctrl + z 可以将一个正在前台执行的命令放到后台，并且处于暂停状态\nctrl + c 终止前台命令\njobs 查看当前有多少在后台运行的命令。 jobs -l选项可显示所有任务的PID，jobs的状态可以是running, stopped, Terminated。但是如果任务被终止了（kill），shell 从当前的shell环境已知的列表中删除任务的进程标识\nbg 将一个在后台暂停的命令，变成继续执行 （在后台执行） 如果后台中有多个命令，可以用bg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid) 将任务转移到后台运行： 先ctrl + z；再bg，这样进程就被移到后台运行，终端还能继续接受命令。\nfg 将后台中的命令调至前台继续运行 如果后台中有多个命令，可以用 fg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid)\n","date":"2018-08-28T01:01:30Z","permalink":"https://lxb.wiki/be78f922/","title":"Linux 后台执行命令"},{"content":"基本使用 select 是 Go 中的一个控制结构, 类似于switch 语句, 用于处理异步 IO 操作. select 语句会监听 case语句中channel 的读写操作, 当case 中 channel 读写操作为非阻塞状态(即能读写)时, 将会触发相应的动作.\nselect 中的 case 语句必须是一个 channel 操作 select 中的 default 子句总是可运行的 如果有多个 case 都可以运行, select 会随机公平地选出一个执行, 其他不会执行 如果没有可运行的 case 语句, 且有 default 语句, 则会执行 default 的动作 如果没有可运行的 case 语句, 且没有 default 语句, select 将阻塞, 知道某个 case 通信可以运行 例\npackage main import \u0026quot;fmt\u0026quot; func main() { var c1, c2, c3 chan int var i1, i2 int select { case i1 = \u0026lt;-c1: fmt.Printf(\u0026quot;received \u0026quot;, i1, \u0026quot; from c1\\n\u0026quot;) case c2 \u0026lt;- i2: fmt.Printf(\u0026quot;sent \u0026quot;, i2, \u0026quot; to c2\\n\u0026quot;) case i3, ok := (\u0026lt;-c3): // same as: i3, ok := \u0026lt;-c3 if ok { fmt.Printf(\u0026quot;received \u0026quot;, i3, \u0026quot; from c3\\n\u0026quot;) } else { fmt.Printf(\u0026quot;c3 is closed\\n\u0026quot;) } default: fmt.Printf(\u0026quot;no communication\\n\u0026quot;) } } //输出：no communication 典型用法 1. 超时判断 //比如在下面的场景中，使用全局resChan来接受response，如果时间超过3S,resChan中还没有数据返回，则第二条case将执行 var resChan = make(chan int) // do request func test() { select { case data := \u0026lt;-resChan: doData(data) case \u0026lt;-time.After(time.Second * 3): fmt.Println(\u0026quot;request time out\u0026quot;) } } func doData(data int) { //... } 2. 退出 //主线程（协程）中如下： var shouldQuit=make(chan struct{}) fun main(){ { //loop } //...out of the loop select { case \u0026lt;-c.shouldQuit: cleanUp() return default: } //... } //再另外一个协程中，如果运行遇到非法操作或不可处理的错误，就向shouldQuit发送数据通知程序停止运行 close(shouldQuit) 3. 判断 channel 是否阻塞 //在某些情况下是存在不希望channel缓存满了的需求的，可以用如下方法判断 ch := make (chan int, 5) //... data：=0 select { case ch \u0026lt;- data: default: //做相应操作，比如丢弃data。视需求而定 } ","date":"2018-08-27T00:27:40Z","permalink":"https://lxb.wiki/e353ee8e/","title":"Golang select 的用法"},{"content":"数据类型 Redis 支持5中数据类型\n字符串(string) Redis 中字符串是一个字节序列. Redis 中的字符串是二进制安全的, 这意味着它们的长度不由任何特殊的终止字符决定。因此，可以在一个字符串中存储高达512兆字节的任何内容 例\nredis 127.0.0.1:6379\u0026gt; SET name \u0026quot;value\u0026quot; OK redis 127.0.0.1:6379\u0026gt; GET name \u0026quot;value\u0026quot; Redis命令不区分大小写.字符串的最大长度为512M 散列/哈希(Hash) Redis散列/哈希(Hashes)是键值对的集合。Redis散列/哈希是字符串字段和字符串值之间的映射。因此，它们用于表示对象。 例\nredis 127.0.0.1:6379\u0026gt; HMSET ukey username \u0026quot;yiibai\u0026quot; password \u0026quot;passswd123\u0026quot; points 200 散列/哈希数据类型用于存储包含用户的基本信息的用户对象。这里HMSET，HGETALL是Redis的命令，而ukey是键的名称。\n每个散列/哈希可以存储多达2^32 - 1个健-值对(超过40亿个)。\n列表(List) Redis列表只是字符串列表，按插入顺序排序。可以向Redis列表的头部或尾部添加元素。 例\nredis 127.0.0.1:6379\u0026gt; lpush alist redis (integer) 1 redis 127.0.0.1:6379\u0026gt; lpush alist mongodb (integer) 2 redis 127.0.0.1:6379\u0026gt; lpush alist sqlite (integer) 3 redis 127.0.0.1:6379\u0026gt; lrange alist 0 10 1) \u0026quot;sqlite\u0026quot; 2) \u0026quot;mongodb\u0026quot; 3) \u0026quot;redis\u0026quot; 集合(Set) Redis集合是字符串的无序集合。在Redis中，可以添加，删除和测试成员存在的时间O(1)复杂性 例\nredis 127.0.0.1:6379\u0026gt; sadd yiibailist redis (integer) 1 redis 127.0.0.1:6379\u0026gt; sadd yiibailist mongodb (integer) 1 redis 127.0.0.1:6379\u0026gt; sadd yiibailist sqlite (integer) 1 redis 127.0.0.1:6379\u0026gt; sadd yiibailist sqlite (integer) 0 redis 127.0.0.1:6379\u0026gt; smembers yiibailist 1) \u0026quot;sqlite\u0026quot; 2) \u0026quot;mongodb\u0026quot; 3) \u0026quot;redis\u0026quot; 注意 - 在上面的示例中，sqlite被添加了两次，但是由于集合的唯一属性，所以它只算添加一次 可排序集合(ZSET) Redis可排序集合类似于Redis集合，是不重复的字符集合。 不同之处在于，排序集合的每个成员都与分数相关联，这个分数用于按最小分数到最大分数来排序的排序集合。虽然成员是唯一的，但分数值可以重复 例\nredis 127.0.0.1:6379\u0026gt; zadd yiibaiset 0 redis (integer) 1 redis 127.0.0.1:6379\u0026gt; zadd yiibaiset 0 mongodb (integer) 1 redis 127.0.0.1:6379\u0026gt; zadd yiibaiset 1 sqlite (integer) 1 redis 127.0.0.1:6379\u0026gt; zadd yiibaiset 1 sqlite (integer) 0 redis 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE yiibaiset 0 1000 1) \u0026quot;mongodb\u0026quot; 2) \u0026quot;redis\u0026quot; 3) \u0026quot;sqlite\u0026quot; 因为 ‘sqlite‘ 的排序值是 1 ，其它两个元素的排序值是 0 ，所以 ‘sqlite‘ 排在最后一个位置上 ","date":"2018-07-19T18:51:37Z","permalink":"https://lxb.wiki/9f188831/","title":"Redis 笔记"},{"content":"GOROOT ，在Linux系统中一般安装在/usr/go或者/usr/local/go，这样Linux系统中的PATH变量一般都包含了这两个目录，所以就可以直接运行go命令，而Windows系统中一般默认安装在C:\\go中\n自定义 GO安装路径, 可修改环境变量配置文件 export GOROOT=$HOME/go\nGOPATH go的工作目录，这个目录指定了需要从哪个地方寻找GO的包、可执行程序等，这个目录可以是多个目录表示，go编译或者运行时会从这个环境变量中去对应查找，工作目录或者如官方文档中说的workspace 在这个目录进行编译、链接最后生成所需要的库、可执行文件，我们对比C程序的目录，也许更能方便理解，一般在C的工程项目中包含三个文件，一个include目录、src目录、Makefile文件。 include目录存放了所有的头文件可供其他地方包含 src目录则存放所有的.c后缀的源文件 Makefile则是该项目的编译，在编译整个工程时需要执行make命令，这里就发现GO就不需要去写什么Makefile了，执行go build xxx.go命令就可以编译\nGOPATH 下的目录下, 一般有三个 目录 bin pkg src bin目录包含了可执行程序，注意是可执行的，不需要解释执行。 pkg目录包含了使用的包或者说库。 src里面包含了go的代码源文件，其中仍按包的不同进行组织\n包名一般和目录名相同, 编译时, 可以在某个包下, 执行go build , 也可以在包上层直接编译包名go build pkg_name\ngo install \u0026lt;pkg_name/exe_name/all\u0026gt; 先编译后把编译生成的可执行文件复制到bin 下\n","date":"2018-07-18T00:57:36Z","permalink":"https://lxb.wiki/2ddd6919/","title":"Go 环境变量"},{"content":"下载源码 git clone https://github.com/lxbwolf/bashmarks.git 把bashmarks.sh复制到~/bin/\n添加环境变量 在环境变量文件里, 添加 . ~/bin/bashmarks.sh\n相关命令 s \u0026lt;bookmark_name\u0026gt; - Saves the current directory as \u0026quot;bookmark_name\u0026quot; g \u0026lt;bookmark_name\u0026gt; - Goes (cd) to the directory associated with \u0026quot;bookmark_name\u0026quot; p \u0026lt;bookmark_name\u0026gt; - Prints the directory associated with \u0026quot;bookmark_name\u0026quot; d \u0026lt;bookmark_name\u0026gt; - Deletes the bookmark l - Lists all available bookmarks ","date":"2018-07-13T00:34:43Z","permalink":"https://lxb.wiki/472d58f/","title":"Linux 安装bashmarks"},{"content":"下载源码 git clone https://github.com/lxbwolf/thefuck.git\n配置环境变量 把thefuck/**/libexec/bin 添加进环境变量 eval $(thefuck --alias fuck) ","date":"2018-07-13T00:30:33Z","permalink":"https://lxb.wiki/42c1114f/","title":"Linux 安装thefuck"},{"content":"下载源码 git clone https://github.com/lxbwolf/thefuck.git\n配置环境变量 把thefuck/**/libexec/bin 添加进环境变量 eval $(thefuck --alias fuck) ","date":"2018-07-13T00:30:33Z","permalink":"https://lxb.wiki/42c1114f/","title":"Linux 安装thefuck"},{"content":"开发机安装 samba yum install samba samba-client samba-swat\n添加账号 sampasswd -a 用户名 用户名只能为已经存在的账号\n配置共享文件夹 编辑etc/samba/smb.conf, 追加内容:\n[samba_share_dir] comment = samba_share path = /home/lxb/samba_share create mask = 0664 directory mask = 0775 writable = yes valid users = lxb browseable = yes 配置环境变量 环境变量文件添加:\nexport LD_LIBRARY_PATH=/usr/local/samba/lib:$LD_LIBRARY_PATH\nsamba 重启 sudo /etc/init.d/smb restart\nMAC客户端连接 Finder -\u0026gt; 前往 -\u0026gt; 连接服务器 -\u0026gt; 输入smb地址\nsmb://user_name@IP/samba_share_dir\n","date":"2018-07-13T00:22:04Z","permalink":"https://lxb.wiki/8f5b70d0/","title":"Linux 安装samba"},{"content":" 语法\nrewrite regex replacement flag\nflag有如下:\nlast\nbreak 中止 rewrite, 不再继续匹配\nredirect 返回临时重定向的 HTTP 状态302\npermanet 返回永久重定向的 HTTP 状态301\nlast 和 break 的不同:\nbreak 是终止当前location 的 rewrite 检测, 且不再进行 location 匹配;\nlast是终止当前location的rewrite检测,但会继续重试location匹配并处理区块中的rewrite规则\n下面是可以用来判断的表达式: -f 和!-f 判断是否存在文件 -d 和!-d 判断是否存在目录 -e 和!-e 判断是否存在文件或目录 -x 和!-x 判断文件是否可执行 2.下面是可以用作判断的全局变量\n$args 等于请求行中的参数 $content_length 请求头中的Content-length 字段 $content_type 请求头中的Content-Type 字段 $document_root 当前请求在root 指令中指定的值 $host 请求主机头字段, 否则为服务器名称 $http_user_agent 客户端agent 信息 $http_cookie 客户端cookie 信息 $limit_rate 这个变量可以限制连接速率 $request_body_file 客户端请求主题信息的临时文件名 $request_method #客户端请求的动作，通常为GET或POST。 $remote_addr #客户端的IP地址。 $remote_port #客户端的端口。 $remote_user #已经经过Auth Basic Module验证的用户名。 $request_filename #当前请求的文件路径，由root或alias指令与URI请求生成。 $query_string #与$args相同。 $scheme #HTTP方法（如http，https）。 $server_protocol #请求使用的协议，通常是HTTP/1.0或HTTP/1.1。 $server_addr #服务器地址，在完成一次系统调用后可以确定这个值。 $server_name #服务器名称。 $server_port #请求到达服务器的端口号。 $request_uri #包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。 $uri 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。 $document_uri #与$uri相同 例:\nhttp://localhost:88/test1/test2/test.php $host: localhost $server_post: 88 $request_uri: http://localhost:88/test1/test2/test.php $document_uri: /test1/test2/test.php $document_root: /usr/share/nginx/html (在nginx.conf里配置的) $request_filename: /usr/share/nginx/html/test1/test2/test.php (在nginx.conf里配置的) 详例:\n多目录转成参数\nabc.domain.com/sort/2 =\u0026gt; abc.domain.com/index.php?act=sort\u0026amp;name=abc\u0026amp;id=2\nif ($host ~* (.*)\\.domain\\.com) { set $sub_name $1; rewrite ^/sort\\/(\\d+)\\/?$ /index.php?act=sort\u0026amp;cid=$sub_name\u0026amp;id=$1 last; } 目录对换\n/123456/xxxx =\u0026gt; /xxxx?id=123456\nrewrite ^/(\\d+)\\/(.+)/ /$2?id=$1 last; // rewrite ^/\\/(\\d+)\\/(\\w+)\\/? /$2?id=$1 last; 如果使用IE浏览器, 则重定向到/nginx-ie 目录下\nif ($http_user_agent ~ MSIE) { rewrite ^(.*)$ /nginx-ie/$1 break; } 目录自动加 /\nif (-d $request_filename){ rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent; } 禁止htaccess\nlocation ~/\\.ht { deny all; } 禁止多个目录\nlocation ~ ^/(cron|templates)/ { deny all; break; } 禁止以/data开头的文件\n可以禁止/data/下多级目录下.log.txt等请求; location ~ ^/data { deny all; } 禁止单个目录\n不能禁止.log.txt能请求 location /searchword/cron/ { deny all; } 禁止单个文件\nlocation ~ /data/sql/data.sql { deny all; } 给 favicon.ico和 robots.txt设置过期时间;\n这里为 favicon.ico为99 天,robots.txt 为 7 天并不记录 404 错误日志\n1. location ~(favicon.ico) { 2. log_not_found off; 3. expires 99d; 4. break; 5. } 6. 7. location ~(robots.txt) { 8. log_not_found off; 9. expires 7d; 10. break; 11. } 设定某个文件的过期时间;这里为600秒，并不记录访问日志\n1. location ^~ /html/scripts/loadhead_1.js { 2. access_log off; 3. root /opt/lampp/htdocs/web; 4. expires 600; 5. break; 6. } 文件反盗链并设置过期时间\n这里的return 412 为自定义的http状态码，默认为403，方便找出正确的盗链的请求\n“rewrite ^/ http://leech.c1gstudio.com/leech.gif;”显示一张防盗链图片\n“access_log off;”不记录访问日志，减轻压力\n“expires 3d”所有文件3天的浏览器缓存\n1. location ~* ^.+\\.(jpg|jpeg|gif|png|swf|rar|zip|css|js)$ { 2. valid_referers none blocked *.c1gstudio.com *.c1gstudio.net localhost 208.97.167.194; 3. if ($invalid_referer) { 4. rewrite ^/ http://leech.c1gstudio.com/leech.gif; 5. return 412; 6. break; 7. } 8. access_log off; 9. root /opt/lampp/htdocs/web; 10. expires 3d; 11. break; 12. } 只充许固定ip访问网站，并加上密码\n1. root /opt/htdocs/www; 2. allow 208.97.167.194; 3. allow 222.33.1.2; 4. allow 231.152.49.4; 5. deny all; 6. auth_basic \u0026quot;C1G_ADMIN\u0026quot;; 7. auth_basic_user_file htpasswd; 将多级目录下的文件转成一个文件，增强seo效果\n/job-123-456-789.html 指向 /job/123/456/789.html\n1. rewrite ^/job-([0-9]+)-([0-9]+)-([0-9]+)\\.html$ /job/$1/$2/jobshow_$3.html last; 将根目录下某个文件夹指向2级目录\n如/shanghaijob/ 指向 /area/shanghai/ 如果你将last改成permanent，那么浏览器地址栏显是 /location/shanghai/\n1. rewrite ^/([0-9a-z]+)job/(.*)$ /area/$1/$2 last; 上面例子有个问题是访问/shanghai 时将不会匹配\n1. rewrite ^/([0-9a-z]+)job$ /area/$1/ last; 2. rewrite ^/([0-9a-z]+)job/(.*)$ /area/$1/$2 last; 这样/shanghai 也可以访问了，但页面中的相对链接无法使用， 如./list_1.html真实地址是/area /shanghia/list_1.html会变成/list_1.html,导至无法访问。\n那我加上自动跳转也是不行咯 (-d $request_filename)它有个条件是必需为真实目录，而我的rewrite不是的，所以没有效果\n1. if (-d $request_filename){ 2. rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent; 3. } 知道原因后就好办了，让我手动跳转吧\n1. rewrite ^/([0-9a-z]+)job$ /$1job/ permanent; 2. rewrite ^/([0-9a-z]+)job/(.*)$ /area/$1/$2 last; 文件和目录不存在的时候重定向：\n1. if (!-e $request_filename) { 2. proxy_pass http://127.0.0.1; 3. } 域名跳转\n1. server 2. { 3. listen 80; 4. server_name jump.c1gstudio.com; 5. index index.html index.htm index.php; 6. root /opt/lampp/htdocs/www; 7. rewrite ^/ http://www.c1gstudio.com/; 8. access_log off; 9. } 多域名转向\n1. server_name www.c1gstudio.com www.c1gstudio.net; 2. index index.html index.htm index.php; 3. root /opt/lampp/htdocs; 4. if ($host ~ \u0026quot;c1gstudio\\.net\u0026quot;) { 5. rewrite ^(.*) http://www.c1gstudio.com$1 permanent; 6. } 三级域名跳转\n1. if ($http_host ~* \u0026quot;^(.*)\\.i\\.c1gstudio\\.com$\u0026quot;) { 2. rewrite ^(.*) http://top.yingjiesheng.com$1; 3. break; 4. } 域名镜向\n1. server 2. { 3. listen 80; 4. server_name mirror.c1gstudio.com; 5. index index.html index.htm index.php; 6. root /opt/lampp/htdocs/www; 7. rewrite ^/(.*) http://www.c1gstudio.com/$1 last; 8. access_log off; 9. } ","date":"2018-06-02T22:35:47Z","permalink":"https://lxb.wiki/389c639/","title":"nginx 配置中的rewrite"},{"content":" 语法\nlocation [=|~|~*|^~] /uri/ {...}\n上下文: server\n此命令随URL 不同而接受不同的结构. 可以配置使用常规字符串和正则表达式. 若使用正则表达式, 则必须使用~*前缀(选择不区分大小写的匹配) 或~前缀(区分大小写的匹配)\n= 表示uri 以某个常规字符串开头, 理解为匹配url 路径即可. nginx 不对url 做编码, 因此请求为/static/%20%/aa 可以被规则^~ /static/ /aa (有空格) 匹配到. ~ 表示区分大小写的正则匹配 ~* 表示不区分大小写的正则匹配 !~ 和 !~* 分别为区分大小写不匹配 和 不区分大小写不匹配 的正则 / 通用匹配, 任何请求都会匹配到 多个location 配置的情况下, 匹配顺序为:\n先匹配=, 其次匹配^~, 再匹配按文件中顺序的正则匹配, 最后匹配/. 当有匹配成功的时候, 停止匹配, 按当前匹配规则处理请求.\n例1:\nlocation = / { # 规则A } location = /login { # 规则B } location ^~ /static { # 规则C } location ~ \\.(gif|jpg|png|js|css)$ { # 规则D } location ~* \\.png$ { # 规则E } location !~ \\.xhtml$ { # 规则F } location !~* \\.xhtml$ { # 规则G } location / { # 规则H } 产生效果如下:\n访问/ 根目录, 如http://localhost/ 将匹配规则A 访问http://localhost/login 将匹配规则B; http://localhost/register 将匹配规则H 访问http://localhost/static/a.html 将匹配规则C 访问http://localhost/a.png 讲匹配规则D 和规则E, 但规则D 顺序优先, 规则E 不起作用 访问http://localhost/static/c.png 优先匹配到规则C 访问http://localhost/a.PNG 将匹配规则E 访问http://localhost/a.xhtml 不会匹配到规则F 和规则G, http://localhost/a.XHTML 不会匹配到规则G 访问http://localhost/category/id/1111 匹配到规则H, 因为以上规则都不匹配, 这个时候应该是nginx 转发给后端应用服务器, 如FastCGI(php), tomcat(jsp), nginx 作为反向代理服务器存在. 所以实际使用中, 通常有至少三个匹配规则定义, 如下:\n# 第一个必选规则 直接匹配网站根, 通过域名访问网站首页比较频繁, 使用这个会加速处理; 这里直接转发给后端应用服务器了, 也可以是一个静态首页 location = / { proxy_pass http://tomcat:8080/index } # 第二个必选规则 处理静态文件请求, 这是nginx 作为http 服务器的强项. 有如下两种配置模式, 目录匹配或后缀匹配, 任选其一或搭配使用 location ^~ /static/ { root /webroot/static/; } location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ { root /webroot/res/; } # 第三个必选规则 通用规则, 用来转发动态请求到后端应用服务器. 非静态文件请求就默认是动态请求. location / { proxy_pass http://tomcat:8080/ } ","date":"2018-06-02T22:30:30Z","permalink":"https://lxb.wiki/a209000e/","title":"nginx配置中的location"},{"content":" 1. nginx 是怎么找index.php 文件的\n当nginx发现需要/web/echo/index.php 文件时, 就会向内核发起 IO 系统调用(因为要跟硬件打交道, 这里的硬件是指硬盘, 通常需要靠内核来操作, 而内核提供的这些功能是通过系统调用来实现的), 告诉内核, 我需要这个文件, 内核从/ 开始找到web 目录, 再在web 目录下找到echo 目录, 最后在echo 目录下找到index.php 文件, 于是把这个index.php 从硬盘上读取到内核自身的内存空间, 然后再把这个文件复制到nginx进程所在的内存空间, 于是 nginx就得到了自己想要的文件了\n2. 寻找文件在文件系统层面是怎么操作的\n如, nginx 需要得到/web/echo/index.php 这个文件 每个分区(像ext3 等文件系统, block块是文件存储的最小单元, 默认是4096字节) 都是包含元数据区和数据区, 每个文件在元数据区都有元数据条目(一般是128字节大小), 每个条目都有一个编号, 称之为 inode(index node), 这个inode 里包含 文件类型, 权限, 连接次数, 属主和数组的 ID\u0026amp;时间戳, 这个文件占据了哪些磁盘块也就是块的编号(block, 每个文件可以占用多个 block, 且 block 不一定是连续的, 每个 block 都有编号), 如下图:\n目录其实也是普通文件, 也需要占用磁盘块, 目录不是一个容器. 默认创建的目录大小为4096字节, 即只需要占用一个磁盘块, 但这是不确定的. 所以要找到目录也是需要到元数据区里找到对应的条目, 只要找到对应的inode就可以找到目录所占用的磁盘块. 目录里存着一张表(映射表), 里面放着 目录或文件的名称和对应的inode号, 如下:\n- - 文件名称(只是字符串) inode 号 test.txt 100 假如\n/ 在数据区占据1, 2号 block, `/` 其实也是一个目录, 里面有两个目录, web 和 111 web 占据5号 block, 是目录, 里面有2个目录 echo 和 data echo 占据11号 block, 是目录, 里面有一个文件 index.php index.php 占据15, 16号 block, 是文件 其在文件系统中分布如下图:\n那么内核究竟是怎么找到index.php 这个文件的呢? 内核拿到 nginx 的 IO 系统调用要获取/web/echo/index.php 这个文件请求之后,\n1. 内核读取元数据区 / 的inode, 从 inode 里读取 / 所对应的数据块的编号, 然后在数据区找到其对应的块(1, 2号块), 读取1号块上的映射表找到 web 这个名称在元数据区对应的 inode 号 2. 内核读取 web 对应的 inode(3号), 从中得到 web 在数据区对应的块是5号块, 于是到数据区找到5号块, 从中读取映射表, 知道 echo 对应的 inode 是5号, 于是到元数据区找到5号 inode 3. 内核读取5号 inode, 得到 echo 在数据区对应的事11号块, 于是到数据区读取11号块得到映射表, 得到index.php 对应的 inode 事9号 4. 内核到元数据区读取9号 inode, 得到 index.php 对应的事15号和16号数据块, 于是就到数据区域找到15 16号块, 读取其中的内容, 得到 index.php 的完整内容 ","date":"2018-06-01T22:32:04Z","permalink":"https://lxb.wiki/ab14d5fa/","title":"nginx 寻找index 原理"},{"content":"HTTP协议的特点: 1. 支持客户端/服务器模式 2. 简单快速: 客户端向服务器请求服务时, 只需传送请求方法和路径. 请求方法常用的有GET, HEAD, POST. 每种方法规定了客户端与服务器联系的类型. 由于HTTP协议简单, 使得HTTP服务器的程序规模小, 因而通信速度很快. 3. 灵活: HTTP 允许传输任意类型的数据对象. 正在传输的类型由Content-Type加以标记. 4. 无连接: 限制每次连接只处理一个请求. 服务器处理完客户端的请求, 并收到客户端的应答后, 即断开连接. 采用着用方式可以节省传输时间. 5. 无状态: 无状态是指协议对于事务处理没有记忆能力. 缺少状态意味着如果后续处理需要前面的信息, 则它必须重传, 这样可能导致每次传送的数据量增大. 另一方面, 在服务器不需要先前信息时, 它的应答就较快.\nURL HTTP是一种基于请求与响应模式的, 无状态的, 应用层的协议, 常基于TCP的连接方式, HTTP1.1版本中给出一种持续连接的机制, 绝大多数的web开发, 都是构建在HTTP协议之上的web应用.\nHTTP URL(URL是一种特殊类型的URI, 包含了用于查找某个资源的足够的信息)的格式如下: http://host[:port][abs_path]\nhttp 表示要通过HTTP协议来定位网络资源 host 表示合法的Internet主机域名或者IP地址 port 指定端口号, 缺省端口为80 abs_path 指定请求资源的URI 若URI 中没有给出abs_path, 那当它作为请求URI时, 必须以\u0026quot;/\u0026quot; 的形式给出, 通常这个工作浏览器会自动完成 请求 HTTP请求由三部分组成: 请求行, 消息报头, 请求正文\n请求行 以一个方法符号开头, 以空格分开, 后面跟请求的URI和协议的版本, 格式如下: Method Request-URI HTTP-Version CRLF\n请求方法有以下几种 - GET 请求获取Request-URI 所标识的资源 - POST 在Request-URI 表标识的资源后附加新的数据 - HEAD 请求获取由Request-URI 所标识的资源的响应消息报头 - PUT 请求服务器存储一个资源, 并用Request-URI 作为其标识 - DELETE 请求服务器删除Request-URI 所标识的资源 - TRACE 请求服务器会送收到的请求信息, 主要用于测试或诊断 - CONNECT 保留将来使用 - OPTIONS 请求查询服务器的性能, 或查询与资源相关的选项和需求\n响应 HTTP响应由三部分组成: 状态行, 消息报头, 响应正文\n状态行 格式: HTTP-Version Status-Code Reason-Phrase CRLF\n状态码由三位数字组成, 第一个数字定义了响应的类别: - 1xx: 指示信息 \u0026ndash; 表示请求已接受, 继续处理 - 2xx: 成功 \u0026ndash; 表示请求已被成功接收, 理解, 接受 - 3xx: 重定向 \u0026ndash; 要完成请求必须进行更进一步的操作 - 4xx: 客户端错误 \u0026ndash; 请求有语法错误或请求无法实现 - 5xx: 服务器端错误 \u0026ndash; 服务器未能实现合法的请求\n报头 HTTP 消息由客户端到服务器的请求和服务器到客户端的响应组成. 请求消息和相应消息都是由开始行(对于请求消息, 开始行就是请求行, 对于响应消息, 开始行就是状态行), 消息报头(可选), 空行(只有CRLF的行), 消息正文(可选) 组成\nHTTP 消息报头包括 普通报头, 请求报头, 响应报头, 实体报头 每一个报头域都是由名字 + \u0026quot;:\u0026quot; + 空格 + 值 组成, 消息报头域的名字是大小写无关的.\n普通报头 在普通报头中, 有少数报头域用于所有的请求和响应消息, 但并用于被传输的实体, 只用于传输的消息 例: Cache-Control 用于指定缓存指令, 缓存指令是单向的(响应中出现的缓存指令在请求中未必会出现), 且是独立的(一个消息的缓存指令不会影响另一个消息处理的缓存机制), HTTP1.0使用类似的报头域为Pragma. 请求时的缓存指令包括: no-cache(用于指示请求或相应消息不能缓存), no-store, max-age, max-stale, min-fresh, only-if-cached; 响应时的缓存指令包括: public, private, no-cache, no-store, no-transform, must-revalidate, proxy-revalidate, max-age, s-maxage eg: 为了指示IE浏览器(客户端)不要缓存页面, 服务器端的JSP程序可以编写如下: response.setHeader(\u0026quot;Cache-Control\u0026quot;, \u0026quot;no-cache\u0026quot;); 或 response.setHeader(\u0026quot;Pragma\u0026quot;, \u0026quot;no-cache\u0026quot;); 两者作用相同, 在发送的响应消息中设置普通报头域: Cache-Control: no-cache.\n请求报头 请求报头允许客户端向服务器端传递请求的附加信息以及客户端自身的信息.\n常用的请求报头域: Accept Accept 请求报头域用于指定客户端接收哪些类型的信息. 如: Accept:image/gif, 表明客户端希望接收GIF图像格式的资源; Accept:text/html, 表明客户端希望接受html 文本\nAccept-Charset 指定客户端接受的字符集. 如: Accept-Charset:iso-8859-1,GB2312. 如果请求消息中没有设置这个域, 缺省是任何字符集都可以接受.\nAccept-Encoding 指定可接受的内容编码. 如Accept-Encoding:gzip.deflate 缺省是任何内容编码都可以接受\nAccept-Language 指定一种自然语言. 如 Accept-Language:zh-cn 缺省是任何语言都可以接受\nAuthorization 用于证明客户端有权查看某个资源. 当浏览器访问一个页面时, 如果收到服务器的响应代码为401, 可以发送一个包含Authorization请求报头域的请求, 要求服务器对其进行验证\nHost(发送请求时, 该报头域是必需的) 指定被请求资源的Internet主机和端口号, 通常从HTTP URL中提取出来\nUser-Agent 允许客户端将它的操作系统, 浏览器和其他属性告诉服务器. 不过这个报头域不是必需的, 如果我们自己写一个浏览器, 不使用User-Agent 请求报头域, 那么服务器端就无法得知我们的信息了.\n请求报头示例\nGET /form.html HTTP/1.1 (CRLF) Accept:image/gif,image/x-xbigmap,image/jpeg,application/x-shockwave-flash,application/vnd.ms-excel,application/vnd.ms-powerpoint,application/msword,*/* (CRLF) Accept-Language:zh-cn (CRLF) Acdept-Encoding:gzip,deflate (CRLF) If-Modified-Since:Wed,05 Jan 2007 11:21:25 GMT (CRLF) If-None-Match:Mozilla/4.0(compatible;MSIE6.0,Windows NT 5.0) (CRLF) Host:www.guet.edu.cn (CRLF) Connection:Keep-Alive (CRLF) (CRLF) 响应报头 响应报头允许服务器传递不能放在状态行中的附加响应信息, 以及关于服务器的信息和对Request-URI所标识的资源进行下一步访问的信息\nLocation 重定向接受者到一个新的位置. Location响应报头域常用在更换域名的时候\nServer 包含了服务器用来处理请求的软件信息. 与User-Agent 请求报头域是相对应的 例: Server:Apache-Coyote/1.1\nWWW-Authenticate WWW-Authenticate 响应报头域必须包含在401响应消息中, 客户端收到401响应消息的时候, 并发送Authorization报头域请求服务器对其进行验证时, 服务端响应报头就包含该报头域 例: WWW-Authenticate:Basic realm=\u0026quot;Basic Auth Test!\n实体报头 请求和响应消息都可以传送一个实体. 一个实体由实体报头域和实体正文组成, 但并不是实体报头域和实体正文要在一起发送, 可以只发送实体报头域. 实体报头定义了关于实体正文(如: 有无实体正文) 和请求所标识的资源的元信息.\nContent-Encoding 被用作媒体类型的修饰符, 它的值指示了已经被应用到实体正文的附加内容的编码, 因而要获得Content-Type 报头域中所引用的媒体类型, 必须采用相应的解码机制.\nContent-Language 描述了资源所用的自然语言. 没有设置该域则认为实体内容将提供给所有的语言阅读\nContent-Length 指明实体正文的长度, 以字节方式存储的十进制数字来表示\nContent-Type 指明发送给接受者的实体正文的媒体类型 例: Content-Type:text/html;charset=ISO-8859-1 Content-Type:text/html;charset=GB2312\nLast-Modified 指示资源的最后修改日期和时间\nExpires 给出响应国企的日期和时间. 为了让代理服务器或浏览器在一段时间以后更新缓存中(再次访问曾访问过的页面时, 直接从缓存中加载, 缩短响应时间和降低服务器负载) 的页面, 我们可以使用Expires 实体报头域指定页面过期的时间. 例: Expires:Thu, 15 Sep 2006 16:23:12 GMT\nHTTP1.1 的客户端和缓存必须将其他非法的日期格式(包括0) 看作已经过期 为了让浏览器不要缓存页面, 我们也可以利用Expires 实体报头域设置为0, jsp中程序如下: response.setDateHeader(\u0026quot;Expires\u0026quot;, \u0026quot;0\u0026quot;);\n","date":"2018-05-30T23:11:26Z","permalink":"https://lxb.wiki/4e7c79/","title":"HTTP协议笔记"},{"content":"不成功的方式: 1. QNetworkReply的isFinished()函数, 通过while循环判断reply是否已经结束, 结束后再调用readAll()读取响应信息, 结果与判断isRunning() 方式结果一样, 都会进入死循环, 没有响应. 2. QNetworkReply继承自QIODevice, 尝试调用QIODevice的waitForReadyRead()方法, 结果不阻塞, 直接返回\n成功的方式: 使用QEventLoop来阻塞运行, 知道信号发出\nQNetworkReply *reply = _manager-\u0026gt;post(QNetworkRequest(QUrl(SERVER_URL)), data); QByteArray responseData; QEventLoop eventLoop; connect(_manager, SIGNAL(finished(QNetworkReply*)), \u0026amp;eventLoop, SLOT(quit())); eventLoop.exec(); //block until finish responseData = reply-\u0026gt;readAll(); ","date":"2018-05-22T11:12:38Z","permalink":"https://lxb.wiki/c57f4e3b/","title":"qt 同步方式发送post 请求"},{"content":"设置程序图标 把ico文件放到源文件目录下, 命名为\u0026quot;test.ico\u0026quot; 创建一个myico.rc 文件, 输入如下内容 IDI_ICON1 ICON DISCARDABLE \u0026quot;test.ico\u0026quot; 在pro文件写入 RC_FILE = myico.rc 执行qmake, 编译 编译, 打包 选择release编译运行 将生成的exe文件放到某个路径下, 如 Desktop/Test 在cmd里, 进入到exe存放路径, 使用wendeployqt工具拷贝exe运行需要的dll 使用Inno Setup Compiler生成安装文件 Inno Setup 工具使用注意事项 添加主执行文件外的其他应用程序文件夹下的文件时, 需要编辑一次, 重新指定目标子文件夹 编译脚本为*.iss 文件, 编译后默认在源exe的Base 目录下生成Output文件夹, 指定的setup.exe文件生成在Output 文件夹下 Inno Setup 工具基础版不支持中文. 如需显示中文, 需要找汉化版 ","date":"2018-05-03T23:03:09Z","permalink":"https://lxb.wiki/7e8574d1/","title":"qt 程序打包"},{"content":"使用gerrit自带的数据库h2, 验证方式为HTTP, SMTP 服务器未配置\ngit 安装 可直接从yum 源安装\ngerrit 安装 先添加gerrit 用户. gerrit 从2.10开始, 换成了新版界面. 几乎国内所有的镜像都会下载失败, 需要翻墙下载. 下载完成后, 初始化命令为: java -jar gerrrit-war init -d /home/gerrit/repository\n初始化启动时, \u0026ldquo;Authentication method\u0026rdquo; 设为\u0026quot;http\u0026quot; ,其他默认 \u0026ldquo;Listen on port [8080]\u0026rdquo; 可用默认, 如端口被占用, 初始化后也可在配置文件修改\napache 安装 直接从yum源安装 apache名字为httpd, 服务名也是httpd. 服务启动后, 默认以apache用户运行. 如需访问其他用户的文件, 如/home/gerrit/repository/htpasswd, 需要确保apache 用户有足够的权限\n配置 apache 修改 apache 的conf 文件, 一般路径为/etc/httpd/conf/httpd.conf windows 下的配置文件路径为 INSTALL_DIR/conf/httpd.conf\n去掉下面几行的注释\nLoadModule proxy_module modules/mod_proxy.so LoadModule proxy_connect_module modules/mod_proxy_connect.so LoadModule proxy_http_module modules/mod_proxy_http.so LoadModule proxy_ftp_module modules/mod_proxy_ftp.so LoadModule negotiation_module modules/mod_negotiation.so 在最后追加下面配置\n\u0026lt;VirtualHost *:8080\u0026gt; ServerName v3server ProxyRequests Off ProxyVia Off ProxyPreserveHost On \u0026lt;Proxy *:8080\u0026gt; Order deny,allow Allow from all \u0026lt;/Proxy\u0026gt; \u0026lt;Location /login/\u0026gt; AuthType Basic AuthName \u0026quot;Gerrit Code Review\u0026quot; Require valid-user AuthUserFile D:/git/htpasswd \u0026lt;/Location\u0026gt; ProxyPass / http://10.14.132.179:9080/ ProxyPassReverse / http://10.14.132.179:9080/ \u0026lt;/VirtualHost\u0026gt; 如端口被占用, 修改conf文件的\u0026quot;Listen 8080\u0026quot; 字段, 换成其他的端口 查看某个端口是否被占用 : netstat -lnp | grep 8080 ProxyPass 和 proxyPassReverse 的端口需与gerrit的conf文件里端口一致\n配置 gerrit 修改GERRIT_DIR/etc/gerrit.config 文件\n[gerrit] basePath = git canonicalWebUrl = http://10.14.132.179:9080/ [database] type = H2 database = db/ReviewDB [auth] type = HTTP logoutUrl = http://aa:aa@10.14.132.179:8080/ [sendemail] smtpServer = smtp.163.com smtpUser = useremail@163.com smtpPass = userpass from = useremail@163.com [container] user = admin javaHome = C:\\\\Program Files\\\\Java\\\\jdk1.6.0_27\\\\jre [sshd] listenAddress = *:29418 [httpd] listenUrl = http://10.14.132.179:9080/ [cache] directory = cache 需要修改的内容: - canonicalWebUrl - auth/type\n需要注意: canonicalWebUrl 和 listenAddress 不是8080. apache 的端口和 gerrit 的端口是不同的, 用户访问地址为 apache 的地址\n启动 gerrit GERRIT_DIR/bin/gerrit.sh start\n启动 apache service httpd start\n添加账号和密码 htpasswd -cm /home/gerrit/repository/htpasswd USER_NAME\nhtpasswd 为apache 的命令工具 参数c 意为新建文件, 即 /home/gerrit/repository/htpasswd 文件不存在时, 新建名为htpasswd的文件 参数m 为使用md5 加密 当htpasswd文件存在时, 可以使用htpasswd -m /PATH_TO_HTPASSWD USER_NAME 添加账号 保存账号密码信息的文件(htpasswd), 名字为自定义的, 但需要与apache 的conf 配置文件里 AuthUserFile 一致 ","date":"2018-05-02T23:56:55Z","permalink":"https://lxb.wiki/2eb2e06d/","title":"Gerrit + apache 安装"},{"content":"*.pro qmake的工程(project)文件 例子:\nTEMPLATE = app CONFIG += QT QT += core gui TARGET = somename SOURCES += main.cpp \\ widget.cpp HEADERS += widget.h FORMS += widget.ui 前三行是qmake的默认值, 都可以省略 TARGET 行指定工程名, 也可以省略 *.pri include 文件 接上面的例子, 我们可以将源文件的设置独立处理, 放到somename.pri文件内:\nSOURCES += main.cpp \\ widget.cpp HEADERS += widget.h FORMS += widget.ui 这时, pro 文件就可以简化为:\nTEMPLATE = app CONFIG += QT QT += core gui TARGET = somename include(somename.pri) *.prf 特性(feature) 文件 和pri文件类似, prf文件也是要被包含进pro文件. 只是它更隐蔽.\n在上面的例子中, 其实已经用到了prf, 就是 CONFIG += QT\n当在CONFIG 中指定一个值时, qmake就会尝试去加载相应的feature文件: - Qt安装目录下的mkspecs/features/qt.prf - features 文件的文件名必须小写\n例子:\nwin32:CONFIG += console // 为win32程序添加控制台 把该文件命名为a.prf, 放到前面提到的目录中, 然后在pro文件内添加 CONFIG += a\n也可以使用load命令来加载prf文件 load(a)\n","date":"2018-04-20T22:25:51Z","permalink":"https://lxb.wiki/924904f6/","title":"Qt 工程的几种文件"},{"content":"变量声明 每行只声明一个变量\n避免使用短的/无意义的命名\n当一个变量被用到时再声明\n// Wrong int a, b; char* c, * d; // Correct int height; int width; char* nameOfOne; char* nameOfOther; 变量命名 变量名/函数名采用驼峰命名法(lowerCaseCamel), 首字母缩写词出现的命名中, 缩写也用驼峰命名\n// Wrong short Cntr; char ITEM_DELIM = ''; void myXMLStreamReader(); // Correct short counter; char itemDelimiter = ''; void myXmlStreamReader(); 空行/空格 用一个且仅用一个空行在适当的地方划分代码块\n在关键词和小括号之间总是只用一个空格符\n// Wrong if(foo) { } // Correct if (foo) { } 指针/引用 在类型名和*或\u0026amp;之间没有空格, 在*或\u0026amp;与变量名之间有一个空格\nchar* someValue; const QString\u0026amp; myString; const char* const WOR = \u0026quot;hello\u0026quot;; 符号与空格 二元操作符左右两边都有一个空格 一元操作符与变量之间不留空格 逗号左右没有空格, 右边一个空格 分号左边没有空格; 分号作为语句的结束符, 右边一般不再有内容 #号右边没有空格 左引号的左边和右引号的各一个空格, 左引号的右边和右引号的左边没有空格 如果右引号右边是右括号, 它们之间没有空格 cast 避免C语言的cast, 尽量用C++的cast(static_cast, const_cast, reinterpret_cast). reinterpret_cast 和 C风格的cast用起来都是危险的，但至少 reinterpret_cast 不会把const修饰符去掉\n涉及到QObjects或重构自己的代码时，不要使用dynamic_cast,而是用qobject_cast，例如在引进一个类型的方法时\n用构造函数去cast简单类型,例如：用int(myFloat)代替(int)myFloat\n// Wrong char* blockOfMemory = (char* ) malloc(data.size()); // Correct char *blockOfMemory = reinterpret_cast\u0026lt;char *\u0026gt;(malloc(data.size())); 语句 不要在一行写多条语句 括号 每个大括号单独一行\n不论条件语句的执行部分有几行, 必须使用大括号\n小括号用来给语句分组\n// Wrong if (address.isEmpty()) { return false; }\nfor (int i = 0; i \u0026lt; 10; +\u0026lsquo;\u0026lsquo;i) { qDebug(\u0026quot;%i\u0026quot;, i); }\n// Correct if (address.isEmpty()) { return false; } else { return true; }\nfor (int i = 0; i \u0026lt; 10;i) { qDebug(\u0026quot;%i\u0026quot;, i); }\n// Wrong if (a \u0026amp;\u0026amp; b || c)\n// Correct if ((a \u0026amp;\u0026amp; b) || c)\n// Wrong a + b \u0026amp; c\n// Correct (a + b) \u0026amp; c\nswitch语句 case缩进\n除enum外, 每组case最后都要加default;\nswitch (myEnum) { case Value1: doSomething(); break; case Value2: case Value3: doSomethingElse(); // fall through break; default: defaultHandling(); break; }\ngoto 禁止使用goto 换行 每行代码不多于120字符\n逗号在行尾. 操作符在新行的开头位置\n换行时尽量避免行与行之间看起来参差不齐\n// Wrong if (longExpression + otherLongExpression + otherOtherLongExpression) { }\n// Correct if (longExpression + otherLongExpression + otherOtherLongExpression) { }\nC++特性 不要使用异常处理 不要使用运行时类型识别 理智地使用模板 Qt源码中的规范 所有代码都是ascii，使用者如果不确定的话，只可能是7字节 每一个QObject的子类都必须有Q_OBJECT宏，即使这个类没用到信号或槽。否则qobject_cast将不能使用 在connect语句中，使信号和槽的参数规范化（参看 QMetaObject::normalizedSignature），可以加快信号/槽的查找速度。可以使用qtrepotools/util/normalize规范已有代码 包含头文件顺序 源文件对应的头文件 \u0026lt;分隔\u0026gt; C系统文件 \u0026lt;分隔\u0026gt; C++系统文件 \u0026lt;分隔\u0026gt; Qt库文件 \u0026lt;分隔\u0026gt; 其他目录 每组文件按字母升序排列\n编译器/平台 使用三目运算符 ？时要特别小心，如果每次的返回值的类型可能不一样的话，一些编译器会在运行时生成冲突的代码（此时编译器甚至不会报错） QString s; return condition ? s : \u0026quot;nothing\u0026quot;; // crash at runtime - QString vs. const char *\n要特别小心对齐问题。无论何时，当一个指针被cast后的对齐数是增加的时候，它都可能会崩溃。例如一个const char 被cast成了cons int，当cast之后的数字不得不在2或4个字节之间对齐时，指针就会在机器上崩溃\n任何需要需要执行构造函数或相关代码进行初始化的实例，都不能用作库代码中的全局实例。因为当构造函数或代码将要运行的时候，该实例还没有被定义（在第一次调用该实例时，在加载库时，在执行main()之前） // global scope static const QString x; // Wrong - default constructor needs to be run to initialize x static const QString y = \u0026quot;Hello\u0026quot;; // Wrong - constructor that takes a const char * has to be run QString z; // super wrong static const int i = foo(); // wrong - call time of foo() undefined, might not be called at all 可以使用下面方法: // global scope static const char x[] = \u0026quot;someText\u0026quot;; // Works - no constructor must be run, x set at compile time static int y = 7; // Works - y will be set at compile time static MyStruct s = {1, 2, 3}; // Works - will be initialized statically, no code being run static QString *ptr = 0; // Pointers to objects are ok - no code needed to be run to initialize ptr\n用Q_GLOBAL_STATIC定义全局实例\nQ_GLOBAL_STATIC(QString, s) void foo() { s()-\u0026gt;append(\u0026quot;moo\u0026quot;); } char型变量是有符号的还是无符号的取决于它运行环境的架构。如果你明确地想使用一个signed或unsinged char，就使用signed char或unsigned char。以下代码运行在把char默认为无符号的平台上时，其条件判断恒为真 char c; // c can't be negative if it is unsigned /********/ /*******/ if (c \u0026gt; 0) { … } // WRONG - condition is always true on platforms where the default is unsigned\n避免64位的枚举值\n嵌入式应用系统二进制接口将所有的枚举类型的值硬编码成32位int值 微软的编译器不支持64位的枚举值 编程偏好 用枚举值定义常量而非用const int或defines 枚举值会在编译时被编译器用实际值替换掉，因而运行时得出结果的速度更快 defines不是命名空间安全的（并且看起来很丑） 当重新实现一个虚方法时，在Qt5中，用 Q_DECL_OVERRIDE宏在函数声明之后，分号之前注解它 不要把const-iterator和none-const iterator搞混 for (Container::const_iterator it = c.begin(); it != c.end(); ++it) // Wrong for (Container::const_iterator it = c.cbegin(); it != c.cend(); ++it) // Right 命名空间 除跟UI直接交互的类外, 其他类必须处在命名空间内 float值 用qFuzzyCompare去和delta比较其值 用qIsNull去判断float值是不是二进制0，而不是和0.0比较 [static] bool qFuzzyCompare(double p1, double p2) // Instead of comparing with 0.0 qFuzzyCompare(0.0,1.0e-200); // This will return false // Compare adding 1 to both values will fix the problem qFuzzyCompare(1 + 0.0, 1 + 1.0e-200); // This will return true 类的成员命名 成员变量一般为名词\n函数成员一般为动词/动词+名词，但是当动词为get时，get常常省略。当返回值为Bool型变量时，函数名一般以前缀’is’开头\npublic: void setColor(const QColor\u0026amp; c); QColor color() const; void setDirty(bool b); bool isDirty() const; private Q_SLOTS: void onParentChanged(); 构造函数 为了使构造函数被错误使用的可能性降到最小，每一个构造函数（除了拷贝构函数）都应该检查自己是否需要加上explicit 符号 注意代码陷阱 不要为了图方便少些一些代码。因为代码是一次书写，后期不止一次地要去理解。例如 QSlider *slider = new QSlider(12, 18, 3, 13, Qt::Vertical, 0, \u0026quot;volume\u0026quot;); 改成下面的方式会更容易理解 QSlider *slider = new QSlider(Qt::Vertical); slider-\u0026gt;setRange(12, 18); slider-\u0026gt;setPageStep(3); slider-\u0026gt;setValue(13); slider-\u0026gt;setObjectName(\u0026quot;volume\u0026quot;); 参考资料 https://wiki.qt.io/Qt_Contribution_Guidelines https://wiki.qt.io/Qt_Coding_Style https://wiki.qt.io/Coding_Conventions https://community.kde.org/Policies/Library_Code_Policy https://wiki.qt.io/UI_Text_Conventions https://wiki.qt.io/API_Design_Principles http://doc.qt.io/qt-5/qml-codingconventions.html https://google.github.io/styleguide/cppguide.html ","date":"2018-04-02T11:27:52Z","permalink":"https://lxb.wiki/9c64b54d/","title":"Qt UI 编码规范"},{"content":"升级后版本: gcc-5.4.0 gdb-7.11.1\n安装开发必备环境 yum groupinstall \u0026#34;Development Tools\u0026#34; yum install glibc-static libstdc++-static 编译安装gcc-5.4.0 gcc下载地址\ntar -xvf gcc-5.4.0.tar.bz2 cd gcc-5.4.0 ./contrib/download_prerequisits mkdir build cd build ../configure --enable-checking=release --enable-languages=c,c++ --disable-multilib make（建议不要使用make -j来编译，虽然可以缩短编译时间，但极大可能会编译失败） make install 其中执行./contrib/download_prerequisits将自动下载以下几个文件，这个几个文件在gcc编译时需要： - mpfr-2.4.2.tar.bz2 - gmp-4.3.2.tar.bz2 - mpc-0.8.1.tar.gz - isl-0.15.tar.bz2\nmake install 时, 自动安装到/usr/local/gcc-5.40\n解决运行程序时, gcc 报错\u0026rsquo;GLIBCXX_3.4.21\u0026rsquo; not found 这是因为升级gcc时，生成的动态库没有替换老版本gcc的动态库导致的，将gcc最新版本的动态库替换系统中老版本的动态库即可解决，运行以下命令检查动态库： strings /lib64/libstdc++.so.6 | grep GLIBC\n以下是输出结果：\nGLIBCXX_3.4 GLIBCXX_3.4.1 GLIBCXX_3.4.2 GLIBCXX_3.4.3 GLIBCXX_3.4.4 GLIBCXX_3.4.5 GLIBCXX_3.4.6 GLIBCXX_3.4.7 GLIBCXX_3.4.8 GLIBCXX_3.4.9 GLIBCXX_3.4.10 GLIBCXX_3.4.11 GLIBCXX_3.4.12 GLIBCXX_3.4.13 GLIBCXX_3.4.14 GLIBCXX_3.4.15 GLIBCXX_3.4.16 GLIBCXX_3.4.17 GLIBCXX_3.4.18 GLIBCXX_3.4.19 GLIBC_2.3 GLIBC_2.2.5 GLIBC_2.14 GLIBC_2.4 GLIBC_2.3.2 GLIBCXX_DEBUG_MESSAGE_LENGTH 从输出结果可以看到并没有GLIBCXX_3.4.21,所以可以断定我们的程序运行时动态加载的是老的动态库，解决这个问题需要将当前链接文件的链接指向改成最新的动态库地址：\ncp /usr/local/lib64/libstdc++.so.6.0.21 /lib64 cd /lib64 rm -rf libstdc++.so.6 ln -s libstdc++.so.6.0.21 libstdc++.so.6 然后你可以执行以下命令来查看GLIBCXX_3.4.21已经可以找到了:\nstrings /lib64/libstdc++.so.6 | grep GLIBC 解决了这个问题终于可以执行程序了，然后又测试了-g选项来编译程序，编译好程序调试程序时并不能够设置断点以及print变量的值，gdb调试中出现：\nMissing separate debuginfos, use: debuginfo-install glibc-2.17-106.e17\\_2.6.x86\\_4 libgcc-4.8.5-4.e17.x86_64 的问题，通过上网查阅资料，是因为gcc版本和gdb版本并不匹配，或者说gdb版本过低\n编译安装gdb-7.11.1 gdb下载地址\ntar -xvf gdb-7.11.1.tar.gz cd gdb-7.11.1 ./configure make make install 当执行 make install 时gdb安装出现了错误：\nWARNING: 'makeinfo' is missing on your sysem，\n则需安装相关依赖程序:\nyum install texinfo libncurses5-dev 如果调试程序时出现下面信息时：\nwarning: File \u0026#34;/usr/local/lib64/libstdc++.so.6.0.21-gdb.py\u0026#34; auto-loading has been declined by your `auto-load safe-path\u0026#39; set to \u0026#34;$debugdir:$datadir/auto-load\u0026#34;. To enable execution of this file add add-auto-load-safe-path /usr/local/lib64/libstdc++.so.6.0.21-gdb.py line to your configuration file \u0026#34;/root/.gdbinit\u0026#34;. To completely disable this security protection add set auto-load safe-path / line to your configuration file \u0026#34;/root/.gdbinit\u0026#34;. 解决方法: 将以下信息放入~/.gdbinit\nadd-auto-load-safe-path /usr/local/lib64/libstdc++.so.6.0.21-gdb.py set auto-load safe-path / 若想通过gdb来调试STL容器，则还需要做一些配置，可以通过GDB Python pretty printers来解决这个问题：\nsvn checkout svn://gcc.gnu.org/svn/gcc/trunk/libstdc++-v3/python stlPrettyPrinter mv stlPrettyPrinter /usr/local 然后将下面的配置信息放入~/.gdbinit\npython import sys sys.path.insert(0, \u0026#39;/usr/local/stlPrettyPrinter\u0026#39;) from libstdcxx.v6.printers import register_libstdcxx_printers register_libstdcxx_printers (None) end ","date":"2018-03-28T11:37:20Z","permalink":"https://lxb.wiki/ec9feff6/","title":"CentOS7升级gcc 和gdb"},{"content":"原文地址: https://blog.csdn.net/nonmarking/article/details/50522413\n对于直播流来说, 只考虑发送端的同步问题, 原理如下: 1. 解析视音频, 讲视频流和音频流的时间戳用同样的时间基准表示 2. 比较转换后的两个时间戳, 找出较小值, 对应发送偏慢的流 3. 读取, 转码, 发送相应的流, 同时, 若该流的转码时间很快, 超前于wall clock, 则还需要进行相应的延时 4. 重复以上过程\n下文包括两部分, 一是音频转码部分, 二是视音频同步\n音频转码基本流程 首先是一些音频输入输出的基本设置\n//Set own audio device's name if (avformat_open_input(\u0026amp;ifmt_ctx_a, device_name_a, ifmt, \u0026amp;device_param) != 0){ printf(\u0026quot;Couldn't open input audio stream.（无法打开输入流）\\n\u0026quot;); return -1; } …… //input audio initialize if (avformat_find_stream_info(ifmt_ctx_a, NULL) \u0026lt; 0) { printf(\u0026quot;Couldn't find audio stream information.（无法获取流信息）\\n\u0026quot;); return -1; } audioindex = -1; for (i = 0; i \u0026lt; ifmt_ctx_a-\u0026gt;nb_streams; i++) if (ifmt_ctx_a-\u0026gt;streams[i]-\u0026gt;codec-\u0026gt;codec_type == AVMEDIA_TYPE_AUDIO) { audioindex = i; break; } if (audioindex == -1) { printf(\u0026quot;Couldn't find a audio stream.（没有找到视频流）\\n\u0026quot;); return -1; } if (avcodec_open2(ifmt_ctx_a-\u0026gt;streams[audioindex]-\u0026gt;codec, avcodec_find_decoder(ifmt_ctx_a-\u0026gt;streams[audioindex]-\u0026gt;codec-\u0026gt;codec_id), NULL) \u0026lt; 0) { printf(\u0026quot;Could not open audio codec.（无法打开解码器）\\n\u0026quot;); return -1; } …… //output audio encoder initialize pCodec_a = avcodec_find_encoder(AV_CODEC_ID_AAC); if (!pCodec_a){ printf(\u0026quot;Can not find output audio encoder! (没有找到合适的编码器！)\\n\u0026quot;); return -1; } pCodecCtx_a = avcodec_alloc_context3(pCodec_a); pCodecCtx_a-\u0026gt;channels = 2; pCodecCtx_a-\u0026gt;channel_layout = av_get_default_channel_layout(2); pCodecCtx_a-\u0026gt;sample_rate = ifmt_ctx_a-\u0026gt;streams[audioindex]-\u0026gt;codec-\u0026gt;sample_rate; pCodecCtx_a-\u0026gt;sample_fmt = pCodec_a-\u0026gt;sample_fmts[0]; pCodecCtx_a-\u0026gt;bit_rate = 32000; pCodecCtx_a-\u0026gt;time_base.num = 1; pCodecCtx_a-\u0026gt;time_base.den = pCodecCtx_a-\u0026gt;sample_rate; /** Allow the use of the experimental AAC encoder */ pCodecCtx_a-\u0026gt;strict_std_compliance = FF_COMPLIANCE_EXPERIMENTAL; /* Some formats want stream headers to be separate. */ if (ofmt_ctx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_GLOBALHEADER) pCodecCtx_a-\u0026gt;flags |= CODEC_FLAG_GLOBAL_HEADER; if (avcodec_open2(pCodecCtx_a, pCodec_a, NULL) \u0026lt; 0){ printf(\u0026quot;Failed to open ouput audio encoder! (编码器打开失败！)\\n\u0026quot;); return -1; } //Add a new stream to output,should be called by the user before avformat_write_header() for muxing audio_st = avformat_new_stream(ofmt_ctx, pCodec_a); if (audio_st == NULL){ return -1; } audio_st-\u0026gt;time_base.num = 1; audio_st-\u0026gt;time_base.den = pCodecCtx_a-\u0026gt;sample_rate; audio_st-\u0026gt;codec = pCodecCtx_a; 接下来, 考虑到输入音频的sample format 可能需要进行转换, 需要用到swresample库的功能 先做好相应的初始化\n// Initialize the resampler to be able to convert audio sample formats aud_convert_ctx = swr_alloc_set_opts(NULL, av_get_default_channel_layout(pCodecCtx_a-\u0026gt;channels), pCodecCtx_a-\u0026gt;sample_fmt, pCodecCtx_a-\u0026gt;sample_rate, av_get_default_channel_layout(ifmt_ctx_a-\u0026gt;streams[audioindex]-\u0026gt;codec-\u0026gt;channels), ifmt_ctx_a-\u0026gt;streams[audioindex]-\u0026gt;codec-\u0026gt;sample_fmt, ifmt_ctx_a-\u0026gt;streams[audioindex]-\u0026gt;codec-\u0026gt;sample_rate, 0, NULL); swr_init(aud_convert_ctx); 此外, 参照transcode_aac.c的做法, 使用FIFO buffer存储从输入端解码得到的音频采样数据, 这些数据在后续将转换sample format并进行编码, 由此即完成了一个音频转码功.\n此外, 还需要另外的一个buffer来存储转换合适之后的音频数据\n//Initialize the FIFO buffer to store audio samples to be encoded. AVAudioFifo *fifo = NULL; fifo = av_audio_fifo_alloc(pCodecCtx_a-\u0026gt;sample_fmt, pCodecCtx_a-\u0026gt;channels, 1); //Initialize the buffer to store converted samples to be encoded. uint8_t **converted_input_samples = NULL; /** * Allocate as many pointers as there are audio channels. * Each pointer will later point to the audio samples of the corresponding * channels (although it may be NULL for interleaved formats). */ if (!(converted_input_samples = (uint8_t**)calloc(pCodecCtx_a-\u0026gt;channels, sizeof(**converted_input_samples)))) { printf(\u0026quot;Could not allocate converted input sample pointers\\n\u0026quot;); return AVERROR(ENOMEM); } 至此, 一些基本的初始化工作完成.\n音频计算pts的方法和视频类似. 即先通过sample rate算出每两个音频sample之间的时间间隔, 再通过计数当前已编码的音频sample总数(nb_samples变量的作用) 来算出当前编码音频帧的时间戳. 如果和视频的流程做类比, 大概为: framerate 相当于sample rate, framecnt相当于nb_samples.\n//audio trancoding here const int output_frame_size = pCodecCtx_a-\u0026gt;frame_size; /** * Make sure that there is one frame worth of samples in the FIFO * buffer so that the encoder can do its work. * Since the decoder's and the encoder's frame size may differ, we * need to FIFO buffer to store as many frames worth of input samples * that they make up at least one frame worth of output samples. */ while (av_audio_fifo_size(fifo) \u0026lt; output_frame_size) { /** * Decode one frame worth of audio samples, convert it to the * output sample format and put it into the FIFO buffer. */ AVFrame *input_frame = av_frame_alloc(); if (!input_frame) { ret = AVERROR(ENOMEM); return ret; } /** Decode one frame worth of audio samples. */ /** Packet used for temporary storage. */ AVPacket input_packet; av_init_packet(\u0026amp;input_packet); input_packet.data = NULL; input_packet.size = 0; /** Read one audio frame from the input file into a temporary packet. */ if ((ret = av_read_frame(ifmt_ctx_a, \u0026amp;input_packet)) \u0026lt; 0) { /** If we are at the end of the file, flush the decoder below. */ if (ret == AVERROR_EOF) { encode_audio = 0; } else { printf(\u0026quot;Could not read audio frame\\n\u0026quot;); return ret; } } /** * Decode the audio frame stored in the temporary packet. * The input audio stream decoder is used to do this. * If we are at the end of the file, pass an empty packet to the decoder * to flush it. */ if ((ret = avcodec_decode_audio4(ifmt_ctx_a-\u0026gt;streams[audioindex]-\u0026gt;codec, input_frame, \u0026amp;dec_got_frame_a, \u0026amp;input_packet)) \u0026lt; 0) { printf(\u0026quot;Could not decode audio frame\\n\u0026quot;); return ret; } av_packet_unref(\u0026amp;input_packet); /** If there is decoded data, convert and store it */ if (dec_got_frame_a) { /** * Allocate memory for the samples of all channels in one consecutive * block for convenience. */ if ((ret = av_samples_alloc(converted_input_samples, NULL, pCodecCtx_a-\u0026gt;channels, input_frame-\u0026gt;nb_samples, pCodecCtx_a-\u0026gt;sample_fmt, 0)) \u0026lt; 0) { printf(\u0026quot;Could not allocate converted input samples\\n\u0026quot;); av_freep(\u0026amp;(*converted_input_samples)[0]); free(*converted_input_samples); return ret; } /** * Convert the input samples to the desired output sample format. * This requires a temporary storage provided by converted_input_samples. */ /** Convert the samples using the resampler. */ if ((ret = swr_convert(aud_convert_ctx, converted_input_samples, input_frame-\u0026gt;nb_samples, (const uint8_t**)input_frame-\u0026gt;extended_data, input_frame-\u0026gt;nb_samples)) \u0026lt; 0) { printf(\u0026quot;Could not convert input samples\\n\u0026quot;); return ret; } /** Add the converted input samples to the FIFO buffer for later processing. */ /** * Make the FIFO as large as it needs to be to hold both, * the old and the new samples. */ if ((ret = av_audio_fifo_realloc(fifo, av_audio_fifo_size(fifo) + input_frame-\u0026gt;nb_samples)) \u0026lt; 0) { printf(\u0026quot;Could not reallocate FIFO\\n\u0026quot;); return ret; } /** Store the new samples in the FIFO buffer. */ if (av_audio_fifo_write(fifo, (void **)converted_input_samples, input_frame-\u0026gt;nb_samples) \u0026lt; input_frame-\u0026gt;nb_samples) { printf(\u0026quot;Could not write data to FIFO\\n\u0026quot;); return AVERROR_EXIT; } } } /** * If we have enough samples for the encoder, we encode them. * At the end of the file, we pass the remaining samples to * the encoder. */ if (av_audio_fifo_size(fifo) \u0026gt;= output_frame_size) /** * Take one frame worth of audio samples from the FIFO buffer, * encode it and write it to the output file. */ { /** Temporary storage of the output samples of the frame written to the file. */ AVFrame *output_frame=av_frame_alloc(); if (!output_frame) { ret = AVERROR(ENOMEM); return ret; } /** * Use the maximum number of possible samples per frame. * If there is less than the maximum possible frame size in the FIFO * buffer use this number. Otherwise, use the maximum possible frame size */ const int frame_size = FFMIN(av_audio_fifo_size(fifo), pCodecCtx_a-\u0026gt;frame_size); /** Initialize temporary storage for one output frame. */ /** * Set the frame's parameters, especially its size and format. * av_frame_get_buffer needs this to allocate memory for the * audio samples of the frame. * Default channel layouts based on the number of channels * are assumed for simplicity. */ output_frame-\u0026gt;nb_samples = frame_size; output_frame-\u0026gt;channel_layout = pCodecCtx_a-\u0026gt;channel_layout; output_frame-\u0026gt;format = pCodecCtx_a-\u0026gt;sample_fmt; output_frame-\u0026gt;sample_rate = pCodecCtx_a-\u0026gt;sample_rate; /** * Allocate the samples of the created frame. This call will make * sure that the audio frame can hold as many samples as specified. */ if ((ret = av_frame_get_buffer(output_frame, 0)) \u0026lt; 0) { printf(\u0026quot;Could not allocate output frame samples\\n\u0026quot;); av_frame_free(\u0026amp;output_frame); return ret; } /** * Read as many samples from the FIFO buffer as required to fill the frame. * The samples are stored in the frame temporarily. */ if (av_audio_fifo_read(fifo, (void **)output_frame-\u0026gt;data, frame_size) \u0026lt; frame_size) { printf(\u0026quot;Could not read data from FIFO\\n\u0026quot;); return AVERROR_EXIT; } /** Encode one frame worth of audio samples. */ /** Packet used for temporary storage. */ AVPacket output_packet; av_init_packet(\u0026amp;output_packet); output_packet.data = NULL; output_packet.size = 0; /** Set a timestamp based on the sample rate for the container. */ if (output_frame) { nb_samples += output_frame-\u0026gt;nb_samples; } /** * Encode the audio frame and store it in the temporary packet. * The output audio stream encoder is used to do this. */ if ((ret = avcodec_encode_audio2(pCodecCtx_a, \u0026amp;output_packet, output_frame, \u0026amp;enc_got_frame_a)) \u0026lt; 0) { printf(\u0026quot;Could not encode frame\\n\u0026quot;); av_packet_unref(\u0026amp;output_packet); return ret; } /** Write one audio frame from the temporary packet to the output file. */ if (enc_got_frame_a) { output_packet.stream_index = 1; AVRational time_base = ofmt_ctx-\u0026gt;streams[1]-\u0026gt;time_base; AVRational r_framerate1 = { ifmt_ctx_a-\u0026gt;streams[audioindex]-\u0026gt;codec-\u0026gt;sample_rate, 1 };// { 44100, 1}; int64_t calc_duration = (double)(AV_TIME_BASE)*(1 / av_q2d(r_framerate1)); //内部时间戳 output_packet.pts = av_rescale_q(nb_samples*calc_duration, time_base_q, time_base); output_packet.dts = output_packet.pts; output_packet.duration = output_frame-\u0026gt;nb_samples; //printf(\u0026quot;audio pts : %d\\n\u0026quot;, output_packet.pts); aud_next_pts = nb_samples*calc_duration; int64_t pts_time = av_rescale_q(output_packet.pts, time_base, time_base_q); int64_t now_time = av_gettime() - start_time; if ((pts_time \u0026gt; now_time) \u0026amp;\u0026amp; ((aud_next_pts + pts_time - now_time)\u0026lt;vid_next_pts)) av_usleep(pts_time - now_time); if ((ret = av_interleaved_write_frame(ofmt_ctx, \u0026amp;output_packet)) \u0026lt; 0) { printf(\u0026quot;Could not write frame\\n\u0026quot;); av_packet_unref(\u0026amp;output_packet); return ret; } av_packet_unref(\u0026amp;output_packet); } av_frame_free(\u0026amp;output_frame); } 视音频同步 首先定义几个变量\nint aud_next_pts = 0;//视频流目前的pts,可以理解为目前的进度 int vid_next_pts = 0;//音频流目前的pts int encode_video = 1, encode_audio = 1;//是否要编码视频、音频 则相应的视音频同步方法如下: 1. 确定视频, 音频二者中至少有一个是需要进行转码的 2. 比较两个流的进度, 使用av_compare_ts函数, 注意：此时的vid_next_pts和aud_next_pts的time base都是ffmpeg内部基准，即AVRational time_base_q = { 1, AV_TIME_BASE }; 3. 对进度落后的流进行转码, 并相应地对进度进行更新. 对于视频，有 vid_next_pts=framecnt_calc_duration;，对于音频，有 aud_next_pts = nb_samples_calc_duration;这里framecnt和nb_samples都相当于计数器，而calc_duration是对应流每两个frame或sample之间的时间间隔，也是以ffmpeg内部时间基准为单位的 4. 若转码进度很快完成, 则不能急于写入输出流, 而是需要先进行延时, 但是也要保证延时后的时间不会超过另一个流的进度\n综上, 流程如下:\n//start decode and encode int64_t start_time = av_gettime(); while (encode_video || encode_audio) { if (encode_video \u0026amp;\u0026amp; (!encode_audio || av_compare_ts(vid_next_pts, time_base_q, aud_next_pts, time_base_q) \u0026lt;= 0)) { 进行视频转码； 转码完成后； vid_next_pts=framecnt*calc_duration; //general timebase //Delay int64_t pts_time = av_rescale_q(enc_pkt.pts, time_base, time_base_q); int64_t now_time = av_gettime() - start_time; if ((pts_time \u0026gt; now_time) \u0026amp;\u0026amp; ((vid_next_pts + pts_time - now_time)\u0026lt;aud_next_pts)) av_usleep(pts_time - now_time); 写入流； } else { 进行音频转码； 转码完成后； aud_next_pts = nb_samples*calc_duration; int64_t pts_time = av_rescale_q(output_packet.pts, time_base, time_base_q); int64_t now_time = av_gettime() - start_time; if ((pts_time \u0026gt; now_time) \u0026amp;\u0026amp; ((aud_next_pts + pts_time - now_time)\u0026lt;vid_next_pts)) av_usleep(pts_time - now_time); 写入流； } 至此, 视音频同步完成. 最后再完成一些flush_encoder的工作即可.\n","date":"2018-03-27T14:41:52Z","permalink":"https://lxb.wiki/aeb01c06/","title":"ffmpeg 视音频同步"},{"content":"在使用dshow设备推流时，经常会报出real time buffer too full dropping frames的错误信息，其原因在这篇文章里有写到，可以通过添加rtbufsize参数来解决，码率越高对应的rtbufsize就需要越高，但过高的rtbufsize会带来视频的延时，若要保持同步，可能就需要对音频人为增加一定的延时。而根据我的测试，即使不添加rtbufszie参数，虽然会报出错误信息，但并不影响直播流的观看或录制，而且可以保持同步。这就是一个trade off的问题了。\n","date":"2018-03-27T14:39:47Z","permalink":"https://lxb.wiki/eaddfbfe/","title":"ffmpeg 推流报错"},{"content":"Developer Guide .proto 文件\nmessage Person { required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2; } message PhoneNumber { required string number = 1; optional PhoneType type = 2 [default = HOME]; } repeated PhoneNumber phone = 4; } Once you\u0026rsquo;ve defined your messages, you run the protocol buffer compiler for your application\u0026rsquo;s language on your .proto file to generate data access classes. These provide simple accessors for each field (like name() and set_name()) as well as methods to serialize/parse the whole structure to/from raw bytes\nYou can add new fields to your message formats without breaking backwards-compatibility; old binaries simply ignore the new field when parsing. So if you have a communications protocol that uses protocol buffers as its data format, you can extend your protocol without having to worry about breaking existing code.\nLanguage Guide Defining A Message Type syntax = \u0026#34;proto3\u0026#34;; // First non-empty; first non-comment line message SearchRequest { string query = 1; // unique numbered tag int32 page_number = 2; int32 result_per_page = 3; } Specifying Field Types Assigning Tags 1-15 one byte 16-2047 two bytes you should reserve the tags 1 through 15 for very frequently occurring message elements. Remember to leave some room for frequently occurring elements that might be added in the future.\nrange: 1 to 536,870,911 You also cannot use the numbers 19000 through 19999 (FieldDescriptor::kFirstReservedNumber through FieldDescriptor::kLastReservedNumber)\nSpecifying Field Rules singular zero or one of this field repeated any number of times Adding More Message Types Reserved Fields message Foo { reserved 2, 15, 9 to 11; reserved \u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;; } Note that you can\u0026rsquo;t mix field names and tag numbers in the same reserved statement.\nWhat\u0026rsquo;s Generated From Your .proto? Default Values sigular: - string - byte - bool - numeric type - enum - message field\nrepeated: - repeated filed\nEnumerations message SearchRequest { string query = 1; int32 page_number = 2; int32 result_per_page = 3; enum Corpus { UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; } Corpus corpus = 4; } You can define aliases by assigning the same value to different enum constants\nenum EnumAllowingAlias { option allow_alias = true; UNKNOWN = 0; STARTED = 1; RUNNING = 1; } enum EnumNotAllowingAlias { UNKNOWN = 0; STARTED = 1; // RUNNING = 1; // Uncommenting this line will cause a compile error inside Google and a warning message outside. } Reserved Values enum Foo { reserved 2, 15, 9 to 11, 40 to max; reserved \u0026#34;FOO\u0026#34;, \u0026#34;BAR\u0026#34;; } Note that you can\u0026rsquo;t mix field names and numeric values in the same reserved statement.\nUsing Other Message Types Define a message in the same .proto file.\nmessage SearchResponse { repeated Result results = 1; } message Result { string url = 1; string title = 2; repeated string snippets = 3; } Importing Definitions By default you can only use definitions from directly imported .proto files. import \u0026quot;myproject/other_protos.proto\u0026quot;;\n// new.proto // All definitions are moved here ====================================================== // old.proto // This is the proto that all clients are importing. import public \u0026#34;new.proto\u0026#34;; import \u0026#34;other.proto\u0026#34;; ====================================================== // client.proto import \u0026#34;old.proto\u0026#34;; // You use definitions from old.proto and new.proto, but not other.proto The protocol compiler searches for imported files in a set of directories specified on the protocol compiler command line using the -I/\u0026ndash;proto_path flag. If no flag was given, it looks in the directory in which the compiler was invoked. In general you should set the \u0026ndash;proto_path flag to the root of your project and use fully qualified names for all imports.\nUsing proto2 Message Types It\u0026rsquo;s possible to import proto2 message types and use them in your proto3 messages, and vice versa. However, proto2 enums cannot be used directly in proto3 syntax (it\u0026rsquo;s okay if an imported proto2 message uses them).\nNested Types message SearchResponse { message Result { string url = 1; string title = 2; repeated string snippets = 3; } repeated Result results = 1; } If you want to reuse this message type outside its parent message type, you refer to it as Parent.Type:\nmessage SomeOtherMessage { SearchResponse.Result result = 1; } You can nest messages as deeply as you like\nmessage Outer { // Level 0 message MiddleAA { // Level 1 message Inner { // Level 2 int64 ival = 1; bool booly = 2; } } message MiddleBB { // Level 1 message Inner { // Level 2 int32 ival = 1; bool booly = 2; } } } Updating A Message Type Don\u0026rsquo;t change the numeric tags for any existing fields If you add new fields, any messages serialized by code using your \u0026ldquo;old\u0026rdquo; message format can still be parsed by your new generated code Fields can be removed, as long as the tag number is not used again in your updated message type You may want to rename the field instead, perhaps adding the prefix \u0026ldquo;OBSOLETE_\u0026rdquo;, or make the tag reserved, so that future users of your .proto can\u0026rsquo;t accidentally reuse the number. Compatibility int32, uint32, int64, uint64, and bool are all compatible sint32 and sint64 are compatible with each other but are not compatible with the other integer types string and bytes are compatible as long as the bytes are valid UTF-8 Embedded messages are compatible with bytes if the bytes contain an encoded version of the message fixed32 is compatible with sfixed32, and fixed64 with sfixed64 enum is compatible with int32, uint32, int64, and uint64 in terms of wire format (note that values will be truncated if they don\u0026rsquo;t fit) Moving any fields into an existing oneof is not safe Any import \u0026#34;google/protobuf/any.proto\u0026#34;; message ErrorStatus { string message = 1; repeated google.protobuf.Any details = 2; } Oneof You can add fields of any type, but cannot use repeated fields\nFeatures: - Setting a oneof field will automatically clear all other members of the oneof - If the parser encounters multiple members of the same oneof on the wire, only the last member seen is used in the parsed message - If you\u0026rsquo;re using C++, make sure your code doesn\u0026rsquo;t cause memory crashes - Again in C++, if you Swap() two messages with oneofs, each message will end up with the other’s oneof case\nMaps map\u0026lt;key_type, value_type\u0026gt; map_field = N The key_type can be any integral or string type. The value_type can be any type except another map.\nMap fields cannot be repeated Wire format ordering and map iteration ordering of map values is undefined When generating text format for a .proto, maps are sorted by key When parsing from the wire or when merging, if there are duplicate map keys the last key seen is used. When parsing a map from text format, parsing may fail if there are duplicate keys backwords compatibility:\nmessage MapFieldEntry { key_type key = 1; value_type value = 2; } repeated MapFieldEntry map_field = N; Packages JSON Mapping ","date":"2018-03-21T17:47:31Z","permalink":"https://lxb.wiki/66065582/","title":"protocol buffer"},{"content":"注释 使用# 进行行注释\n模板 TEMPLATE = app 告诉qmake为这个应用程序生成哪种makefile. - app 默认值. 生成app的makefile - lib 生成一个库的makefile - vcapp 生成一个应用程序的VisualStudio项目文件 - vclib 生成一个库的VisualStudio 项目文件 - subdirs 生成makefile文件编译subdirs指定的子文件夹\n应用程序目录 指定生成的应用程序放置的目录 DESTDIR += ../bin\n配置信息 COFNIG 用来告诉qmake 关于应用程序的配置信息 CONFIG += qt warn_on release\nui目录 指定uic命令将.ui文件转化成的ui_*.h文件的存放目录 UI_DIR += forms\nrcc目录 指定rcc命令将.qrc文件转换成的qrc_*.h文件的存放目录 RCC_DIR += ../tmp\nmoc目录 指定moc命令将含Q_OBJECT的头文件转换成标准.h文件的存放目录 MOC_DIR += ../tmp\n目标文件目录 指定目标文件(obj)的存放目录 OBJECTS_DIR += ../tmp\n依赖相关路径 程序编译时依赖的相关路径 DEPENDPATH += . forms include qrc sources\n头文件包含路径 INCLUDEPATH += .\nqmake时产生的信息 message($$(PATH))\n源文件编码方式 CODECFORSRC = GBK\n工程中包含的头文件 HEADERS += include/aa.h\n工程中包含的.ui文件 FORMS += forms/aa.ui\n工程中包含的源文件 SOURCES += sources/main.cpp sources/aa.cpp\n工程中包含的资源文件 RESOURCES += qrc/aa.qrc LIBS += -LfolderPath Release: LIBS += -LfolderReleasePath Debug: LIBS += -LfolderDebugPath DEFINES += XX_XX_XXX // 定义编译选项, 在.h文件中就可以用 #ifdefine XX_XX_XXX RC_FIELS = xxx.icns 平台相关性处理 根据qmake所运行的平台来使用相应的作用域来进行处理.\n为Windows平台添加的依赖平台的文件示例:\nwin32{ SOURCES += hello_win.cpp } 生成Makefile qmake -oMakefile hello.pro\n对于VisualStudio用户, qmake也可以生成.dsp文件 qmake -tvcapp -o hello.dsp hello.pro\npro文件实例 TEMPLATE = app #模块配置 LANGUAGE = C++ #C++语言 CONFIG += qt warn_on debug release #引入的lib文件,用于引入动态链接库 LIBS += qaxcontainer.lib #头文件包含路径 INCLUDEPATH += ../../qtcompnent/qtchklisten/inc ../../qtcompnent/qtclearfile/inc ../../validator/inc/validerrcode ../../qtcompnent/qtdir/inc ../inc ../../utillib/inc/xmlapi ../../utillib/inc/util ../../xercesc ../../qtcompnent/qteditor/inc ../../qtcompnent/qtfunreview/inc ../../qtcompnent/qttable/inc ../../qtcompnent/qtversion/inc ../../qtcompnent/qtini/inc ../../icdtool/icdservices/inc ../../icdtool/dataset/inc ../../icdtool/doi/inc ../../icdtool/reportcontrol/inc ../../icdtool/GSEconctrol/inc ../../icdtool/inputs/inc ../../icdtool/SMVconctrol/inc ../../icdtool/logcontrol/inc ../../scdpreview/inc/scdpreviewtoollib ../../scdpreview/form ../../icdtool/sclcontrol/inc ../../icdtool/log/inc ../../icdtool/settingcontrol/inc ../../qtcompnent/qteditor/inc ../../qtcompnent/qttreeview/inc ../../qtcompnent/qttabwidget/inc ../../communication/inc ../../qtcompnent/qtabout/inc ../iedmanage/inc ../ldmanage/inc ../foriecrun/inc ../../qtcompnent/validset/inc #工程中包含的头文件 HEADERS += ../inc/exportstable.h / ../inc/maintabwidget.h / ../inc/outputtab.h / ../inc/strutil.h / ../inc/treeeditview.h / ../inc/MainForm.h / ../inc/recenfileini.h / ../inc/ExportCIDFunction.h #工程中包含的源文件 SOURCES += ../src/main.cpp / ../src/exportstable.cpp / ../src/maintabwidget.cpp / ../src/outputtab.cpp / ../src/treeeditview.cpp / ../src/MainForm.cpp / ../src/recenfileini.cpp / ../src/ExportCIDFunction.cpp #工程中包含的.ui设计文件 FORMS = ../form/scdmainform.ui / ../form/exportiedform.ui / ../form/Exportsedform.ui / ../form/Importsedform.ui / ../form/formiminputs.ui #图像文件 IMAGES = images/substation.png / images/communication.png / images/autocom.png / images/reportcfg.png / images/comcfg.png / images/filetrans.png / images/review.png / images/setting.png #工程中包含的资源文件 RESOURCES = Scintilla.qrc #CONFIG -= release CONFIG -= debug RC_FILE = scdtool.rc BINLIB = ../../bin ../../xercesc/lib UI_HEADERS_DIR = ../inc # .ui文件转会为**.h 存放的目录 UI_SOURCES_DIR = ../src # .ui文件转会为**.cpp 存放的目录 QMAKE_LIBDIR = $${BINLIB} release { TARGET = scdtool #指定生成的应用程序名 OBJECTS_DIR = ../../obj/scdtool/release #指定目标文件(obj)的存放目录 } debug { TARGET = scdtool_d #指定生成的应用程序名 OBJECTS_DIR = ../../obj/scdtool/debug #指定目标文件(obj)的存放目录 } MOC_DIR = $${OBJECTS_DIR} DESTDIR = ../../bin #指定生成的应用程序放置的目录 补充: cnblogs\n","date":"2018-03-21T09:49:25Z","permalink":"https://lxb.wiki/8304997e/","title":"qt 的 pro 文件"},{"content":"原文地址: http://blog.csdn.net/wh8_2011/article/details/73506154\n本文实现: 读取PC摄像头视频数据并以RTMP协议发送为直播流. 示例包含 1. FFmpeg的libavdevice的使用 2. 视频编码, 解码, 推流的基本流程\n要使用libavdevice的相关函数, 首先需要注册相关组件 avdevice_register_all()\n列出电脑中可用的DShow设备\nAVFormatContext *pFmtCtx = avformat_alloc_context(); AVDeviceInfoList *device_info = NULL; AVDictionary* options = NULL; av_dict_set(\u0026amp;options, \u0026quot;list_devices\u0026quot;, \u0026quot;true\u0026quot;, 0); AVInputFormat *iformat = av_find_input_format(\u0026quot;dshow\u0026quot;); printf(\u0026quot;Device Info=============\\n\u0026quot;); avformat_open_input(\u0026amp;pFmtCtx, \u0026quot;video=dummy\u0026quot;, iformat, \u0026amp;options); printf(\u0026quot;========================\\n\u0026quot;); 也可以直接使用FFmpeg的工具 ffmpeg -list_devices true -f dshow -i dummy\nPS: avdevice有一个avdevice_list_devices函数可以枚举系统的采集设备, 包括设备名和设备描述, 可以让用户选择要使用的设备, 但是不支持DShow设备.\n像打开普通文件一样将上面的具体设备名作为输入打开, 并进行相应的初始化设置\nav_register_all(); //Register Device avdevice_register_all(); avformat_network_init(); //Show Dshow Device show_dshow_device(); printf(\u0026quot;\\nChoose capture device: \u0026quot;); if (gets(capture_name) == 0) { printf(\u0026quot;Error in gets()\\n\u0026quot;); return -1; } sprintf(device_name, \u0026quot;video=%s\u0026quot;, capture_name); ifmt=av_find_input_format(\u0026quot;dshow\u0026quot;); //Set own video device's name if (avformat_open_input(\u0026amp;ifmt_ctx, device_name, ifmt, NULL) != 0){ printf(\u0026quot;Couldn't open input stream.（无法打开输入流）\\n\u0026quot;); return -1; } //input initialize if (avformat_find_stream_info(ifmt_ctx, NULL)\u0026lt;0) { printf(\u0026quot;Couldn't find stream information.（无法获取流信息）\\n\u0026quot;); return -1; } videoindex = -1; for (i = 0; i\u0026lt;ifmt_ctx-\u0026gt;nb_streams; i++) if (ifmt_ctx-\u0026gt;streams[i]-\u0026gt;codec-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO) { videoindex = i; break; } if (videoindex == -1) { printf(\u0026quot;Couldn't find a video stream.（没有找到视频流）\\n\u0026quot;); return -1; } if (avcodec_open2(ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;codec, avcodec_find_decoder(ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;codec-\u0026gt;codec_id), NULL)\u0026lt;0) { printf(\u0026quot;Could not open codec.（无法打开解码器）\\n\u0026quot;); return -1; } 输入设备初始化后, 需要对输出做相应的初始化. FFmpeg将网络协议和文件同等看待, 同时因为使用RTMP协议进行传输, 因此制定输出为flv格式, 编码器使用H.264\n//output initialize avformat_alloc_output_context2(\u0026amp;ofmt_ctx, NULL, \u0026quot;flv\u0026quot;, out_path); //output encoder initialize pCodec = avcodec_find_encoder(AV_CODEC_ID_H264); if (!pCodec){ printf(\u0026quot;Can not find encoder! (没有找到合适的编码器！)\\n\u0026quot;); return -1; } pCodecCtx=avcodec_alloc_context3(pCodec); pCodecCtx-\u0026gt;pix_fmt = PIX_FMT_YUV420P; pCodecCtx-\u0026gt;width = ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;codec-\u0026gt;width; pCodecCtx-\u0026gt;height = ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;codec-\u0026gt;height; pCodecCtx-\u0026gt;time_base.num = 1; pCodecCtx-\u0026gt;time_base.den = 25; pCodecCtx-\u0026gt;bit_rate = 400000; pCodecCtx-\u0026gt;gop_size = 250; /* Some formats,for example,flv, want stream headers to be separate. */ if (ofmt_ctx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_GLOBALHEADER) pCodecCtx-\u0026gt;flags |= CODEC_FLAG_GLOBAL_HEADER; //H264 codec param //pCodecCtx-\u0026gt;me_range = 16; //pCodecCtx-\u0026gt;max_qdiff = 4; //pCodecCtx-\u0026gt;qcompress = 0.6; pCodecCtx-\u0026gt;qmin = 10; pCodecCtx-\u0026gt;qmax = 51; //Optional Param pCodecCtx-\u0026gt;max_b_frames = 3; // Set H264 preset and tune AVDictionary *param = 0; av_dict_set(\u0026amp;param, \u0026quot;preset\u0026quot;, \u0026quot;fast\u0026quot;, 0); av_dict_set(\u0026amp;param, \u0026quot;tune\u0026quot;, \u0026quot;zerolatency\u0026quot;, 0); if (avcodec_open2(pCodecCtx, pCodec,\u0026amp;param) \u0026lt; 0){ printf(\u0026quot;Failed to open encoder! (编码器打开失败！)\\n\u0026quot;); return -1; } //Add a new stream to output,should be called by the user before avformat_write_header() for muxing video_st = avformat_new_stream(ofmt_ctx, pCodec); if (video_st == NULL){ return -1; } video_st-\u0026gt;time_base.num = 1; video_st-\u0026gt;time_base.den = 25; video_st-\u0026gt;codec = pCodecCtx; //Open output URL,set before avformat_write_header() for muxing if (avio_open(\u0026amp;ofmt_ctx-\u0026gt;pb,out_path, AVIO_FLAG_READ_WRITE) \u0026lt; 0){ printf(\u0026quot;Failed to open output file! (输出文件打开失败！)\\n\u0026quot;); return -1; } //Show some Information av_dump_format(ofmt_ctx, 0, out_path, 1); //Write File Header avformat_write_header(ofmt_ctx,NULL); 完成输入和输出的初始化后, 就可以正式开始解码和编码并推流的流程了. 需要注意的是, 摄像头数据往往是RGB格式的, 需要将其转换为YUV420P格式, 才能推流, 因此要先做如下的准备工作\n//prepare before decode and encode dec_pkt = (AVPacket *)av_malloc(sizeof(AVPacket)); //enc_pkt = (AVPacket *)av_malloc(sizeof(AVPacket)); //camera data has a pix fmt of RGB,convert it to YUV420 img_convert_ctx = sws_getContext(ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;codec-\u0026gt;width, ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;codec-\u0026gt;height, ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;codec-\u0026gt;pix_fmt, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL); pFrameYUV = avcodec_alloc_frame(); uint8_t *out_buffer = (uint8_t *)av_malloc(avpicture_get_size(PIX_FMT_YUV420P, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height)); avpicture_fill((AVPicture *)pFrameYUV, out_buffer, PIX_FMT_YUV420P, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height); 现在, 就可以正式开始解码, 编码 和推流了\n//start decode and encode int64_t start_time=av_gettime(); while (av_read_frame(ifmt_ctx, dec_pkt) \u0026gt;= 0){ if (exit_thread) break; av_log(NULL, AV_LOG_DEBUG, \u0026quot;Going to reencode the frame\\n\u0026quot;); pframe = av_frame_alloc(); if (!pframe) { ret = AVERROR(ENOMEM); return -1; } //av_packet_rescale_ts(dec_pkt, ifmt_ctx-\u0026gt;streams[dec_pkt-\u0026gt;stream_index]-\u0026gt;time_base, // ifmt_ctx-\u0026gt;streams[dec_pkt-\u0026gt;stream_index]-\u0026gt;codec-\u0026gt;time_base); ret = avcodec_decode_video2(ifmt_ctx-\u0026gt;streams[dec_pkt-\u0026gt;stream_index]-\u0026gt;codec, pframe, \u0026amp;dec_got_frame, dec_pkt); if (ret \u0026lt; 0) { av_frame_free(\u0026amp;pframe); av_log(NULL, AV_LOG_ERROR, \u0026quot;Decoding failed\\n\u0026quot;); break; } if (dec_got_frame){ sws_scale(img_convert_ctx, (const uint8_t* const*)pframe-\u0026gt;data, pframe-\u0026gt;linesize, 0, pCodecCtx-\u0026gt;height, pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize); enc_pkt.data = NULL; enc_pkt.size = 0; av_init_packet(\u0026amp;enc_pkt); ret = avcodec_encode_video2(pCodecCtx, \u0026amp;enc_pkt, pFrameYUV, \u0026amp;enc_got_frame); av_frame_free(\u0026amp;pframe); if (enc_got_frame == 1){ //printf(\u0026quot;Succeed to encode frame: %5d\\tsize:%5d\\n\u0026quot;, framecnt, enc_pkt.size); framecnt++; enc_pkt.stream_index = video_st-\u0026gt;index; //Write PTS AVRational time_base = ofmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;time_base;//{ 1, 1000 }; AVRational r_framerate1 = ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;r_frame_rate;// { 50, 2 }; AVRational time_base_q = { 1, AV_TIME_BASE }; //Duration between 2 frames (us) int64_t calc_duration = (double)(AV_TIME_BASE)*(1 / av_q2d(r_framerate1)); //内部时间戳 //Parameters //enc_pkt.pts = (double)(framecnt*calc_duration)*(double)(av_q2d(time_base_q)) / (double)(av_q2d(time_base)); enc_pkt.pts = av_rescale_q(framecnt*calc_duration, time_base_q, time_base); enc_pkt.dts = enc_pkt.pts; enc_pkt.duration = av_rescale_q(calc_duration, time_base_q, time_base); //(double)(calc_duration)*(double)(av_q2d(time_base_q)) / (double)(av_q2d(time_base)); enc_pkt.pos = -1; //Delay int64_t pts_time = av_rescale_q(enc_pkt.dts, time_base, time_base_q); int64_t now_time = av_gettime() - start_time; if (pts_time \u0026gt; now_time) av_usleep(pts_time - now_time); ret = av_interleaved_write_frame(ofmt_ctx, \u0026amp;enc_pkt); av_free_packet(\u0026amp;enc_pkt); } } else { av_frame_free(\u0026amp;pframe); } av_free_packet(dec_pkt); } 解码比较简单, 编码部分需要自己计算PTS, DTS, 比较复杂 这里通过帧率计算PTS和DTS, 首先通过帧率计算两帧之间的时间间隔, 但是要换算\n","date":"2018-01-13T20:50:43Z","permalink":"https://lxb.wiki/ae1aac27/","title":"基于FFmpeg的摄像头直播(推流)"},{"content":"原文地址: http://blog.csdn.net/leixiaohua1020/article/details/39803457\n将本地的MOV/AVI/MKV/MP4/FLV等格式的媒体文件， 通过流媒体协议(RTMP, HTTP, UDP, TCP, RTP等)以直播流的形式推送出去.\n在这个推流器的基础上, 可以进行以下几种方式的修改, 实现各式各样的推流器. 例如: * 将输入文件改为网络流URL, 可以显示转流器 * 将输入文件改为回调函数(内存读取)的形式, 可以推送内存中的视频数据 * 将输入文件改为系统设备(通过libavdevice), 同时加上编码的功能, 可以实现实时推流器(现场直播)\n需要注意的地方 封装格式 RTMP采用的封装格式FLV, 因此在指定输出流媒体的时候需要制定其封装格式为\u0026quot;flv\u0026quot;. 同理, 其他流媒体协议也需要指定其封装格式. 例如采用UDP推送流媒体的时候, 可以指定其封装格式为\u0026quot;mpegts\u0026quot;.\n延时 发送流媒体的数据的时候需要延时. 否则, FFmpeg处理数据速度很快, 瞬间就能把所有的数据发送出去, 流媒体服务器是承受不了的. 因此需要按照视频实际的帧率发送数据. 本文的推流器在视频帧与帧之间采用av_usleep()函数休眠的方式来延迟发送. 这样就可以按照视频的帧率发送数据了, 代码如下\n//… int64_t start_time=av_gettime(); while (1) { //… //Important:Delay if(pkt.stream_index==videoindex){ AVRational time_base=ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;time_base; AVRational time_base_q={1,AV_TIME_BASE}; int64_t pts_time = av_rescale_q(pkt.dts, time_base, time_base_q); int64_t now_time = av_gettime() - start_time; if (pts_time \u0026gt; now_time) av_usleep(pts_time - now_time); } //… } //… PTS/DTS问题 没有封装格式的裸流(例如H.264裸流)是不包含PTS, DTS这些参数的. 在发送这种数据的时候, 需要自己计算并写入AVPacket的PTS, DTS, duration等参数.\n//FIX：No PTS (Example: Raw H.264) //Simple Write PTS if(pkt.pts==AV_NOPTS_VALUE){ //Write PTS AVRational time_base1=ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;time_base; //Duration between 2 frames (us) int64_t calc_duration=(double)AV_TIME_BASE/av_q2d(ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;r_frame_rate); //Parameters pkt.pts=(double)(frame_index*calc_duration)/(double)(av_q2d(time_base1)*AV_TIME_BASE); pkt.dts=pkt.pts; pkt.duration=(double)calc_duration/(double)(av_q2d(time_base1)*AV_TIME_BASE); } sequence 代码\n/** * 最简单的基于FFmpeg的推流器（推送RTMP） * Simplest FFmpeg Streamer (Send RTMP) * * 雷霄骅 Lei Xiaohua * leixiaohua1020@126.com * 中国传媒大学/数字电视技术 * Communication University of China / Digital TV Technology * http://blog.csdn.net/leixiaohua1020 * * 本例子实现了推送本地视频至流媒体服务器（以RTMP为例）。 * 是使用FFmpeg进行流媒体推送最简单的教程。 * * This example stream local media files to streaming media * server (Use RTMP as example). * It's the simplest FFmpeg streamer. * */ #include \u0026lt;stdio.h\u0026gt; #define __STDC_CONSTANT_MACROS #ifdef _WIN32 //Windows extern \u0026quot;C\u0026quot; { #include \u0026quot;libavformat/avformat.h\u0026quot; #include \u0026quot;libavutil/mathematics.h\u0026quot; #include \u0026quot;libavutil/time.h\u0026quot; }; #else //Linux... #ifdef __cplusplus extern \u0026quot;C\u0026quot; { #endif #include \u0026lt;libavformat/avformat.h\u0026gt; #include \u0026lt;libavutil/mathematics.h\u0026gt; #include \u0026lt;libavutil/time.h\u0026gt; #ifdef __cplusplus }; #endif #endif int main(int argc, char* argv[]) { AVOutputFormat *ofmt = NULL; //输入对应一个AVFormatContext，输出对应一个AVFormatContext //（Input AVFormatContext and Output AVFormatContext） AVFormatContext *ifmt_ctx = NULL, *ofmt_ctx = NULL; AVPacket pkt; const char *in_filename, *out_filename; int ret, i; int videoindex=-1; int frame_index=0; int64_t start_time=0; //in_filename = \u0026quot;cuc_ieschool.mov\u0026quot;; //in_filename = \u0026quot;cuc_ieschool.mkv\u0026quot;; //in_filename = \u0026quot;cuc_ieschool.ts\u0026quot;; //in_filename = \u0026quot;cuc_ieschool.mp4\u0026quot;; //in_filename = \u0026quot;cuc_ieschool.h264\u0026quot;; in_filename = \u0026quot;cuc_ieschool.flv\u0026quot;;//输入URL（Input file URL） //in_filename = \u0026quot;shanghai03_p.h264\u0026quot;; out_filename = \u0026quot;rtmp://localhost/publishlive/livestream\u0026quot;;//输出 URL（Output URL）[RTMP] //out_filename = \u0026quot;rtp://233.233.233.233:6666\u0026quot;;//输出 URL（Output URL）[UDP] av_register_all(); //Network avformat_network_init(); //输入（Input） if ((ret = avformat_open_input(\u0026amp;ifmt_ctx, in_filename, 0, 0)) \u0026lt; 0) { printf( \u0026quot;Could not open input file.\u0026quot;); goto end; } if ((ret = avformat_find_stream_info(ifmt_ctx, 0)) \u0026lt; 0) { printf( \u0026quot;Failed to retrieve input stream information\u0026quot;); goto end; } for(i=0; i\u0026lt;ifmt_ctx-\u0026gt;nb_streams; i++) if(ifmt_ctx-\u0026gt;streams[i]-\u0026gt;codec-\u0026gt;codec_type==AVMEDIA_TYPE_VIDEO){ videoindex=i; break; } av_dump_format(ifmt_ctx, 0, in_filename, 0); //输出（Output） avformat_alloc_output_context2(\u0026amp;ofmt_ctx, NULL, \u0026quot;flv\u0026quot;, out_filename); //RTMP //avformat_alloc_output_context2(\u0026amp;ofmt_ctx, NULL, \u0026quot;mpegts\u0026quot;, out_filename);//UDP if (!ofmt_ctx) { printf( \u0026quot;Could not create output context\\n\u0026quot;); ret = AVERROR_UNKNOWN; goto end; } ofmt = ofmt_ctx-\u0026gt;oformat; for (i = 0; i \u0026lt; ifmt_ctx-\u0026gt;nb_streams; i++) { //根据输入流创建输出流（Create output AVStream according to input AVStream） AVStream *in_stream = ifmt_ctx-\u0026gt;streams[i]; AVStream *out_stream = avformat_new_stream(ofmt_ctx, in_stream-\u0026gt;codec-\u0026gt;codec); if (!out_stream) { printf( \u0026quot;Failed allocating output stream\\n\u0026quot;); ret = AVERROR_UNKNOWN; goto end; } //复制AVCodecContext的设置（Copy the settings of AVCodecContext） ret = avcodec_copy_context(out_stream-\u0026gt;codec, in_stream-\u0026gt;codec); if (ret \u0026lt; 0) { printf( \u0026quot;Failed to copy context from input to output stream codec context\\n\u0026quot;); goto end; } out_stream-\u0026gt;codec-\u0026gt;codec_tag = 0; if (ofmt_ctx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_GLOBALHEADER) out_stream-\u0026gt;codec-\u0026gt;flags |= CODEC_FLAG_GLOBAL_HEADER; } //Dump Format------------------ av_dump_format(ofmt_ctx, 0, out_filename, 1); //打开输出URL（Open output URL） if (!(ofmt-\u0026gt;flags \u0026amp; AVFMT_NOFILE)) { ret = avio_open(\u0026amp;ofmt_ctx-\u0026gt;pb, out_filename, AVIO_FLAG_WRITE); if (ret \u0026lt; 0) { printf( \u0026quot;Could not open output URL '%s'\u0026quot;, out_filename); goto end; } } //写文件头（Write file header） ret = avformat_write_header(ofmt_ctx, NULL); if (ret \u0026lt; 0) { printf( \u0026quot;Error occurred when opening output URL\\n\u0026quot;); goto end; } start_time=av_gettime(); while (1) { AVStream *in_stream, *out_stream; //获取一个AVPacket（Get an AVPacket） ret = av_read_frame(ifmt_ctx, \u0026amp;pkt); if (ret \u0026lt; 0) break; //FIX：No PTS (Example: Raw H.264) //Simple Write PTS if(pkt.pts==AV_NOPTS_VALUE){ //Write PTS AVRational time_base1=ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;time_base; //Duration between 2 frames (us) int64_t calc_duration=(double)AV_TIME_BASE/av_q2d(ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;r_frame_rate); //Parameters pkt.pts=(double)(frame_index*calc_duration)/(double)(av_q2d(time_base1)*AV_TIME_BASE); pkt.dts=pkt.pts; pkt.duration=(double)calc_duration/(double)(av_q2d(time_base1)*AV_TIME_BASE); } //Important:Delay if(pkt.stream_index==videoindex){ AVRational time_base=ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;time_base; AVRational time_base_q={1,AV_TIME_BASE}; int64_t pts_time = av_rescale_q(pkt.dts, time_base, time_base_q); int64_t now_time = av_gettime() - start_time; if (pts_time \u0026gt; now_time) av_usleep(pts_time - now_time); } in_stream = ifmt_ctx-\u0026gt;streams[pkt.stream_index]; out_stream = ofmt_ctx-\u0026gt;streams[pkt.stream_index]; /* copy packet */ //转换PTS/DTS（Convert PTS/DTS） pkt.pts = av_rescale_q_rnd(pkt.pts, in_stream-\u0026gt;time_base, out_stream-\u0026gt;time_base, (AVRounding)(AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX)); pkt.dts = av_rescale_q_rnd(pkt.dts, in_stream-\u0026gt;time_base, out_stream-\u0026gt;time_base, (AVRounding)(AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX)); pkt.duration = av_rescale_q(pkt.duration, in_stream-\u0026gt;time_base, out_stream-\u0026gt;time_base); pkt.pos = -1; //Print to Screen if(pkt.stream_index==videoindex){ printf(\u0026quot;Send %8d video frames to output URL\\n\u0026quot;,frame_index); frame_index++; } //ret = av_write_frame(ofmt_ctx, \u0026amp;pkt); ret = av_interleaved_write_frame(ofmt_ctx, \u0026amp;pkt); if (ret \u0026lt; 0) { printf( \u0026quot;Error muxing packet\\n\u0026quot;); break; } av_free_packet(\u0026amp;pkt); } //写文件尾（Write file trailer） av_write_trailer(ofmt_ctx); end: avformat_close_input(\u0026amp;ifmt_ctx); /* close output */ if (ofmt_ctx \u0026amp;\u0026amp; !(ofmt-\u0026gt;flags \u0026amp; AVFMT_NOFILE)) avio_close(ofmt_ctx-\u0026gt;pb); avformat_free_context(ofmt_ctx); if (ret \u0026lt; 0 \u0026amp;\u0026amp; ret != AVERROR_EOF) { printf( \u0026quot;Error occurred.\\n\u0026quot;); return -1; } return 0; } ","date":"2018-01-13T11:51:28Z","permalink":"https://lxb.wiki/5722b57a/","title":"基于FFmpeg的推送文件到RTMP服务器"},{"content":"SRR测试网址 http://www.ossrs.net/srs.release/trunk/research/players/srs_player.html 获取 git clone https://github.com/ossrs/srs.git\nconfigure make cd srs/trunk ./configure \u0026amp;\u0026amp; make\n开启服务器 ./objs/srs -c conf/srs.conf\n列出设备 ./ffmpeg.exe -list_devices true -f dshow -i dummy ffmpeg采集摄像头推流 ffmpeg.exe -f dshow -i video=\u0026quot;EasyCamera\u0026quot; -q 4 -s 640*480 -aspect 4:3 -r 10 -vcodec flv -ar 22050 -ab 64k -ac 1 -acodec libmp3lame -threads 4 -f flv rtmp://192.168.1.102/RTMP/RtmpVideo\nffmpeg采集摄像头和麦克风推流 ffmpeg -f dshow -i video=\u0026quot;USB2.0 PC CAMERA\u0026quot; -f dshow -i audio=\u0026quot;麦克风 (2- USB2.0 MIC)\u0026quot; -b:a 600k -ab 128k -f flv rtmp://192.168.1.102/RTMP/RtmpVideo\n","date":"2018-01-12T19:52:44Z","permalink":"https://lxb.wiki/b3ed22dc/","title":"ffmpeg 推流工具"},{"content":"命令组 和 代码块 () 命令组. 如 (a=hello,echo $a) 在()中的命令列表, 将作为一个子Shell来运行 在()中的变量, 由于是在子Shell总运行的, 因此对脚本剩下的部分是不可见的\n如\na=123 (a=321;) echo \u0026quot;a=$a\u0026quot; # a=123 # 在()中的a变量, 更像是一个局部变量 {} 代码块, 又称内部组. 这个结构创建了一个匿名的函数, 与函数不同的是, 在{}中声明的变量, 对于脚本剩余的代码是可见的, 如\n{ local a; a=123; } # bash中的local申请的变量只能用在函数中 a=123; {a=321;} echo \u0026quot;a=$a\u0026quot; # a=321 ()也可用作初始化数组 array=(element1,element2,element3)\n{xxx,yyy,zzz} 大括号扩展, 例\ncat {file1,file2,file3} \u0026gt; combined_file # 把file1 file2 file3连接在一起, 重定向到combined_file cp file1.{txt,bak} # 把file1.txt 复制到file1.bak 一个命令会对大括号中以逗号分隔的文件列表起作用, file globbing会对大括号中的文件名作扩展\n# 大括号中不允许有空白, 除非这个空白是有意义的 echo {file1,file2}\\ :{\\ A,\u0026quot; B\u0026quot;,' C'} # file1 : A file1 : B file1 : C file2 : A file2 : B file2 : C ","date":"2017-10-02T11:54:01Z","permalink":"https://lxb.wiki/8cb7d3c0/","title":"命令组和代码块"},{"content":"冒号(:) 是一个空命令. 作用与true相同. \u0026ldquo;:\u0026ldquo;是一个bash内建命令, 返回值为0, 即与true相同. 例:\n: echo $? # 0 死循环\nwhile : do list_1 list_2 done if/then 中的占位符\nif list then : # 什么都不做, 引出分支 else take-some-action fi 在一个2元命令中, 提供一个占位符, 表明后面的表达式, 不是一个命令, 如\n:$((n=$n+1) 如果没有:, bash会尝试把\u0026rdquo;$((n=$n+1))\u0026rdquo; 解释成一个命令\n使用\u0026quot;参数替换\u0026quot; 来评估字符串变量\n:${HOSTNAME?}${USER?}${MAIL?} # 如果一个或多个环境变量没有设置, 则打印错误信息 在和\u0026gt;(重定向符号)结合使用时, 把一个文件截断到0长度, 不修改它的权限. 如果文件不存在, 则创建它\n: \u0026gt; data.xxx # 文件\u0026quot;data.xxx\u0026quot; 被清空 # 与 cat /dev/null \u0026gt; data.xxx 作用相同, 但是不会产生一个新的进程, 因为:是一个内建命令. 只适用于普通文件, 不适用于管道, 符号链接, 和其他特殊文件.\n也可以用作注释, :与#不同的是, :不会关闭剩余行的错误检查.\n","date":"2017-09-07T17:55:50Z","permalink":"https://lxb.wiki/9aa135a6/","title":"Shell 中的冒号"},{"content":"select提供了一个构建交互式菜单程序的方式, 语法结构: select name [ in word ] ; do list ; done\n例:\n#!/bin/bash select i in a b c d do echo $i done 执行结果\n$ ./select.sh 1) a 2) b 3) c 4) d #? 选择索引\n$ ./select.sh 1) a 2) b 3) c 4) d #? 1 a #? 2 b #? 3 c #? 4 d #? 6 #? 1) a 2) b 3) c 4) d #? 1) a 2) b 3) c 4) d #? 如果输入的不是菜单描述的范围就会echo一个空行，如果直接输入回车，就会再显示一遍菜单本身。当然我们会发现这样一个菜单程序似乎没有什么意义，实际程序中，select大多数情况是跟case配合使用的。\n#!/bin/bash select i in a b c d do case $i in a) echo \u0026quot;Your choice is a\u0026quot; ;; b) echo \u0026quot;Your choice is b\u0026quot; ;; c) echo \u0026quot;Your choice is c\u0026quot; ;; d) echo \u0026quot;Your choice is d\u0026quot; ;; *) echo \u0026quot;Wrong choice! exit!\u0026quot; ;; esac done 执行结果\n$ ./select.sh 1) a 2) b 3) c 4) d #? 1 Your choice is a #? 2 Your choice is b #? 3 Your choice is c #? 4 Your choice is d #? 5 Wrong choice! exit! ","date":"2017-09-05T16:02:11Z","permalink":"https://lxb.wiki/53b3b0c1/","title":"Shell编程中select用法"},{"content":"请对比如下两个测试：\n$ for i in `ls /etc`;do echo $i;done adjtime adobe appstream.conf arch-release asound.conf avahi bash.bash_logout bash.bashrc bind.keys binfmt.d ...... $ for i in /etc/*;do echo $i;done /etc/adjtime /etc/adobe /etc/appstream.conf /etc/arch-release /etc/asound.conf /etc/avahi /etc/bash.bash_logout /etc/bash.bashrc /etc/bind.keys /etc/binfmt.d ...... 像ls这样的命令很多时候是设计给人用的，它的很多显示是有特殊设定的，可能并不是纯文本。 比如可能包含一些格式化字符，也可能包含可以让终端显示出颜色的标记字符等等。 当我们在程序里面使用类似这样的命令的时候要格外小心，说不定什么时候在什么不同环境配置的系统上， 你的程序就会有意想不到的异常出现，到时候排查起来非常麻烦。 所以这里我们应该尽量避免使用ls这样的命令来做类似的行为，用通配符可能更好。\n当然，如果你要操作的是多层目录文件的话，那么ls就更不能帮你的忙了，它遇到目录之后显示成这样：\n$ ls /etc/* /etc/adobe: mms.cfg /etc/avahi: avahi-autoipd.action avahi-daemon.conf avahi-dnsconfd.action hosts services /etc/binfmt.d: /etc/bluetooth: main.conf /etc/ca-certificates: extracted trust-source 所以遍历一个目录还是要用两个连续的**，如果不是bash 4.0之后的版本的话，可以使用find。 我推荐用find，因为它更通用。 有时候你会发现，使用find之后，绝大多数原来需要写脚本解决的问题可能都用不着了，一个find命令解决很多问题\n","date":"2017-09-05T15:03:02Z","permalink":"https://lxb.wiki/12994d1/","title":"在shell脚本中使用ls命令的注意事项"},{"content":"SMTP(Simple Mail Transfer Protocol)是电子邮件从客户机传输到服务器或从某一个服务器传输到另一个服务器使用的传输协议。SMTP 是请求/响应协议，命令和响应都是基于 ASCII 文本，并以 CR 和 LF 符结束。响应包括一个表示返回状态的三位数字代码。在 TCP 协议 25 端口监听连接请求。其命令如下：\nSMTP命令\n命令说明\nHELO ＜domain＞＜CRLF＞\n识别发送方到接收SMTP的一个HELO命令\nAUTH LOGIN\n登陆服务器的命令。在这条命令之后，要发送用Base64编码后的用户名与密码进行登陆\nMAIL FROM:＜reverse-path＞＜CRLF＞\n＜reverse-path＞为发送者地址。此命令告诉接收方一个新邮件发送的开始，并对所有的状态和缓冲区进行初始化。此命令开始一个邮件传输处理，最终完成将邮件数据传送到一个或多个邮箱中\nRCPT TO:＜forward-path＞＜CRLF＞\n＜forward-path＞标识各个邮件接收者的地址\nDATA ＜CRLF＞\n接收SMTP将把其后的行为看作邮件数据去处理，以＜CRLF＞.＜CRLF＞标识数据的结尾\nREST ＜CRLF＞\n退出/复位当前的邮件传输\nNOOP ＜CRLF＞\n要求接收SMTP仅做OK应答。（用于测试）\nQUIT ＜CRLF＞\n要求接收SMTP返回一个OK应答并关闭传输。\nVRFY ＜string＞ ＜CRLF＞\n验证指定的邮箱是否存在，由于安全因素，服务器多禁止此命令。\nEXPN ＜string＞ ＜CRLF＞\n验证给定的邮箱列表是否存在，扩充邮箱列表，也常禁止使用。\nHELP ＜CRLF＞\n查询服务器支持什么命令\n邮件交互图\nA-\u0026gt;B: 1. 建立TCP连接(host:port, 默认port为25) B-\u0026gt;A: 220. Anti-spam GT for Coremail System Note over A: A-\u0026gt;B: 2. 向服务器标识用户身份(HELO host\\r\\/n) B-\u0026gt;A: 250 OK Note over A: A-\u0026gt;B: 3. 登录服务器(AUTH LOGIN\\r\\/n) B-\u0026gt;A: 334. username: (这里是解密后的信息) A-\u0026gt;B: \u0026lt;my_username\u0026gt;(要用Base64加密) B-\u0026gt;A: 334. password: (这里是解密后的信息) A-\u0026gt;B: \u0026lt;my_password\u0026gt;(要用Base64加密) B-\u0026gt;A: 235. Authentication successful Note over A: A-\u0026gt;B: 4. 指定发信者(MAIL FROM: \u0026lt;my_sender@gmail.com\u0026gt;\\r\\/n) B-\u0026gt;A: 250. Mail OK Note over A: A-\u0026gt;B: 5. 指定收信者(RCPT TO: \u0026lt;my_receiver@gmail.com\u0026gt;\\r\\/n) B-\u0026gt;A: 250. Mail OK Note over A: A-\u0026gt;B: 6. 发送数据(DATA\\r\\/n) B-\u0026gt;A: 354. End data with \u0026lt;CR\u0026gt;\u0026lt;LF\u0026gt;.\u0026lt;CR\u0026gt;\u0026lt;LF\u0026gt; Note over A: A-\u0026gt;B: 7. to: \u0026lt;my_receiver@gmail.com\\r\\/nsubject:\u0026lt;my_subject\u0026gt;\\r\\/nSome Context\\r\\/n.\\r\\/n\u0026gt; B-\u0026gt;A: 250. Mail OK Note over A: A-\u0026gt;B: 8. QUIT\\r\\/n B-\u0026gt;A: 221. Bye 因markdown里不能打出\u0026quot;\\n\u0026quot;, 因此使用\u0026quot;\\/n\u0026quot; 代替\u0026quot;\\n\u0026quot;\nSMTP发信操作及返回码\n[crazywill@localhost crazywill]$ telnet smtp.163.com 25 #telnet登录25端口 Trying 202.108.5.81... Connected to smtp.163.com. Escape character is '^]'. 220 163.com Coremail SMTP(Anti Spam) System EHLO smtp.163.com # 握手 :) 250-mail 250-PIPELINING 250-AUTH LOGIN PLAIN 250-AUTH=LOGIN PLAIN 250 8BITMIME AUTH LOGIN # 开始认证登录 334 dXNlcm5hbWU6 crazywill 334 UGFzc3dvcmQ6 mypassword 535 Error: authentication failed # 直接用户名密码不能登录 AUTH LOGIN 334 dXNlcm5hbWU6 Y3Jhenl3aWxs 334 UGFzc3dvcmQ6 bXlwYXNzd29yZA== 235 Authentication successful # 使用Base64编码则成功登录 MAIL FROM:\u0026lt;test@163.com\u0026gt; # 邮件发送方 553 You are not authorized to send mail, authentication is required # 不可伪造发送邮件 MAIL FROM:\u0026lt;crazywill@163.com\u0026gt; # 邮件发送方 250 Mail OK RCPT TO:\u0026lt;crazywill@163.com\u0026gt; # 邮件的接收方，若有多个收件人，则重复这一语句多次。 250 Mail OK DATA # 邮件体内容 354 Please start mail input. TO: crazywill@163.com # 此处的TO，FROM，等内容，可以随便造假 :) 可以骗人但骗不了懂得查看邮件源码的。 FROM: cccc@163.com SUBJECT: test by telnet/smtp test, just a test. # 邮件正文内容，与Header部分空一行开始写 . # 邮件写完，以一个句点加回车结果。 250 Mail OK queued as smtp10,wKjADQ2ApxRnnqBE0CWaEw==.38326S3 # 返回250 表示发送成功。 NOOP # 空语句，不执行任何操作，一般用来保持和服务器连接，不要掉线 250 OK QUIT # 退出 221 Closing connection. Good bye. Connection closed by foreign host. [crazywill@localhost crazywill]$ 参考资料: 用c++发邮件 电子邮件发送的原理以及简易实现 邮件正文及其附件的发送的C++实现 C++通过SMTP发送邮件总结 C++实现向多人发送邮件\n","date":"2017-06-08T10:34:08Z","permalink":"https://lxb.wiki/b0248f59/","title":"邮件发送原理"},{"content":"这个问题是说, 怎么得到组成一句话的各个单词, 或者得到CSV中的各个数据片段. 这在C++中是个很简单的问题, 却有很多种答案.\n有3种方案, 每种有利有弊. 使用时请自己选择最佳方案. 这篇文章的目的是说明 迭代器的接口是如何优胜于简单的容器的, 并且阐明 design of the STL 是何等强大.\n方案1使用的标准组件(虽然方案1.2 做了微调). 方案2相对好点但使用了boost. 而方案3 更好但使用了ranges. 所以到底应该用哪个, 取决于你需要什么和你能使用什么.\nSolution 1: Iterating on a stream Stepping into the world of streams \u0026ldquo;流\u0026rdquo; 是一个 能生成 与源或希望连接的目标 的联系 的对象. 流可以从源中获取信息(std::istream), 或为目标提供信息(std::ostream), 或者两者皆可(std::iostream).\n源和目标可以是标准输入(std::cin), 标准输出(std::cout), 一个文件, 或者一个字符串, 前提是方式得当. 对流的主要操作包括: - 对于输入流: 使用操作符\u0026gt;\u0026gt; 从里面读取信息 - 对于输出流: 使用操作符\u0026lt;\u0026lt;, 向它推入信息\n一个指向字符串的输入流, std::istringstream, 有个有趣的特性: 它的操作符\u0026gt;\u0026gt; 在源字符串中制造出去向下一个空格的字符串.\nistream_iterator std::istream_iterator 是连接输入流的迭代器. 它代表了输入迭代器的普遍接口, 但它的操作符++ 更像是输入流.\nistream_iterator 以它从流里读取的类型为模板. 我们现在使用istream_iterator\u0026lt;std::string\u0026gt;, 它从流里读取字符串, 分离时为我们提供一个字符串.\n当到达流的终点时, 流向它的迭代器发送信号, 然后迭代器被标记为结束.\nSolution 1.1 现在, 我们可以借迭代器的接口使用算法, 这真切地证明了STL 设计的灵活性. 为了使用STL, 我们需要一个begin 和一个end (请参考Inserting several elements into an STL container efficiently). begin 是一个 还没开始着手分割的字符串的istreamstream 的迭代器: std::istream_iterator\u0026lt;std::string\u0026gt;(iss) . 按照惯例, end 的默认值也是个istream_iterator : std::istream_iterator\u0026lt;string\u0026gt;().\n代码如下:\nstd::string text = \u0026quot;Let me split this into words\u0026quot;; std::istringstream iss(text); std::vector\u0026lt;std::string\u0026gt; results((std::istream_iterator\u0026lt;std::string\u0026gt;(iss)), std::istream_iterator\u0026lt;std::string\u0026gt;()); 第一个参数的额外的括号是为了避免与一个函数调用的歧义\u0026ndash;请参考Scott Meyers的著作Effective STL 条目6 \u0026ldquo;most vexing parse\u0026rdquo;\n优: - 仅使用标准组件 - 除字符串外, 对所有流都适用 劣: - 只能以空格为分隔符进行分割, 而且这在解析CSV时会是个至关重要的问题 - 在性能方面有待优化(但如果这不是影响你整个程序的瓶颈, 这也不是个大问题) - 很多人认为仅为了分割一个字符串, 写了太多代码\nSolution1.2: Pimp my operator\u0026raquo; 导致上面两条劣势的原因是同一个: istream_iterator 从流里读取字符串时调用的操作符\u0026gt;\u0026gt;. 这个操作符做了很多事: 在下一个空格处停止(这是我们的最初的需求, 但这个不能自定义), 格式化, 读取然后设置一些标志位, 构造对象, 等等. 而以上这些, 大部分我们是不需要的. 所以我们希望自己实现下面的函数:\nstd::istream\u0026amp; operator\u0026gt;\u0026gt;(std::istream\u0026amp; is, std::string\u0026amp; output) { // ...does lots of things... } 实际上, 我们无法改变这些, 因为这是在标注库里的. 我们可以用另一个类型重载它, 但是这个类型需要是string 的一种.\n所以现在的需求就是, 用另一种类型伪装成string. 有两种方案: 继承std::string 和 用显式转换封装string. 这里我们选择继承.\n假如我们希望以逗号为分割符分割一个字符串:\nclass WordDelimitedByCommas: pulic std::string {}; 我必须承认这是有争议的. 有人会说:\u0026quot;std::string 没有虚析构函数, 所以你不应该继承它!\u0026quot; 这可能, 大概, 也许是有一点点点点武断. 这里我要说的是, 继承本身不会产生问题. 诚然, 当一个指向WordDelimitedByCommas 的指针以std::string 的形式被delete 掉时, 会产生问题. 继续读, 你会发现, 我们不会这么做. 现在我们可以阻止写代码的人借WordDelimitedByCommas 突发冷箭破坏程序吗? 我们不能. 但是这个险值得我们冒吗? 请继续读, 然后你自己判断.\n现在为了仅实现我们需要的功能, 我们可以重载操作符\u0026gt;\u0026gt; : 获取下一个逗号之前的所有字符. 这个可以借用getline 函数实现:\nstd::istream\u0026amp; operator\u0026gt;\u0026gt;(std::istream* is, std::WordDelimitedByCommas\u0026amp;) { std::getline(is, output, ','); return is; } 返回值is 保证了可以连续调用操作符\u0026gt;\u0026gt;\n现在我们可以写初级代码了:\nstd::string text = \u0026quot;Let,me,split,this,into,words\u0026quot;; std::istringstream iss(text); std::vector\u0026lt;std::string\u0026gt; results((std::istream_iterator\u0026lt;WordDelimitedByCommas\u0026gt;(iss)), std::istream_iterator\u0026lt;WordDelimitedByCommas\u0026gt;()); 我们可以通过模板化WordDelimitedByCommas 泛华所有的分隔符:\ntemplate\u0026lt;char delemiter\u0026gt; class WordDelimitedBy: pulic std::string {}; 现在以分号举例:\nstd::string text = \u0026quot;Let;me;split;this;into;words\u0026quot;; std::istringstream iss(text); std::vector\u0026lt;std::string\u0026gt; results((std::istream_iterator\u0026lt;WordDelimitedBy\u0026lt;';'\u0026gt;\u0026gt;(iss)), std::istream_iterator\u0026lt;WordDelimitedBy\u0026lt;';'\u0026gt;\u0026gt;()); 优: - 编译时允许任何分隔符 - 不仅是字符串, 对任何流都可以操作 - 比方案1更快(快20%到30%) 劣: - 虽然可以很方便的复用, 但仍不是标准 - 仅仅为了分割一个字符串, 这个方案仍然使用了大量代码\nSolution2: Using boost::split 这个方案比方案1高级, 除非你需要对所有的流都进行操作.\n#include \u0026lt;boost/algorithm/string.hpp\u0026gt; std::string text = \u0026quot;Let me split this into words\u0026quot;; std::vector\u0026lt;std::string\u0026gt; result; boost::split\u0026lt;results, text, [](char c){return ' ' == c;}); 传给boost::split 的第三个参数是一个函数或函数对象, 确定一个字符是不是分隔符. 上面的例子是使用lambda 表达式, 传入一个char, 返回这个char 是否是空格.\nboost::split 的实现很简单: 在到达字符串的结束位置之前, 重复地调用find_if .\n优: - 非常直观的接口 - 允许任何分隔符, 甚至是多个 - 高效: 比方案1.1 快 60% 劣: - 暂不是标准: 需要用到boost\nSolution 3(未来): Usingranges 虽然它们现在还没有像标准库甚至boost 里的组件一样被广泛使用, ranges 是future of the STL . 在未来几年, 会大量面世.\nEric Neiber 的 range-v3 库 提供了非常友好的接口. 为了生成一个字符串的分割view, 代码如下:\nstd::string text = \u0026quot;Let me split this into words\u0026quot;; auto splitText = text | view::split(' '); 它有很多有趣的特性, 诸如 使用一个子字符串作为分隔符. ranges 会被C++20 引入, 所以我们应该能在几年之内就可以使用这个功能了.\nSo, how do I split my string? 如果你能使用boost, 务必使用方案2. 或者你可以自己写算法, 像boost 那样基于find_if 分割字符串.\n如果你不想这么做, 你可以使用标准, 即方案1.1, 如果你需要自定义分隔符, 或者发现1.1是个瓶颈, 那么你可以选择方案1.2 .\n如果你可以使用ranges , 那么就应该选择方案3.\n翻译原文: http://www.fluentcpp.com/2017/04/21/how-to-split-a-string-in-c/\n","date":"2017-06-04T18:40:14Z","permalink":"https://lxb.wiki/9747854a/","title":"【译】How to split a string in C++"},{"content":"A strict weak ordering is a binary relation \u0026lt; on a set S that is a strict partial order (a transitive relation that is irreflexive, or equivalently, that is asymmetric) in which the relation neither a \u0026lt; b nor b \u0026lt; a is transitive. Therefore, a strict weak ordering has the following properties:\nFor all x in S, it is not the case that x \u0026lt; x (irreflexivity). For all x, y in S, if x \u0026lt; y then it is not the case that y \u0026lt; x (asymmetry). For all x, y, z in S, if x \u0026lt; y and y \u0026lt; z then x \u0026lt; z (transitivity). For all x, y, z in S, if x is incomparable with y (neither x \u0026lt; y nor y \u0026lt; x hold), and y is incomparable with z, then x is incomparable with z (transitivity of incomparability). This list of properties is somewhat redundant, as asymmetry follows readily from irreflexivity and transitivity.\n离散数学中的relation: Given a function f (which models a binary relation) over a domain D, and a, b ∈ D:\nReflexivity: f (a, a) is true. Asymmetry: For a ≠ b, if f(a, b) is true, f(b,a) is false Anti-symmetry: If f(a, b) and f(b, a) are both true iff a ≡ b Transitivity: If f(a, b) and f(b, c) are true, then f(a, c) is true Incomparability: Neither f(a, b) nor f(b, a) is true Transitivity of incomparability: If a and b are incomparable, and so are b and c, then a and c are incomparable. 摘自WikiPedia\n","date":"2017-05-27T14:42:41Z","permalink":"https://lxb.wiki/22f34ac7/","title":"strict weak ordering"},{"content":"一般情况下, 普通用户执行\u0026quot;su -\u0026ldquo;命令, 可以登录为root. 为了加强系统的安全性, 有必要建立一个管理员的组, 只允许这个组的用户执行\u0026quot;su -\u0026rdquo; 命令登录为root, 而让其他组的用户即使执行\u0026quot;su -\u0026quot; 输入了正确的密码, 也无法登录为root用户. 在Unix 和Linux 下, 这个组的名称通常为\u0026quot;wheel\u0026quot;.\n1 添加一个用户, 把这个用户加入wheel组 2 修改/etc/pam.d/su #auth required pam_wheel.so use_uid 这行注释打开 3 修改/etc/login.defs 在文件末添加一行 SU_WHEEL_ONLY yes\n","date":"2017-05-23T09:26:31Z","permalink":"https://lxb.wiki/e5131675/","title":"Linux 禁止普通用户su切换root"},{"content":"1 修改 /etc/ssh/sshd_config #PermitRootLogin yes 取消注释并改为 PermitRootLogin no\n2 重启ssh /etc/init.d/sshd restart\n","date":"2017-05-23T09:07:42Z","permalink":"https://lxb.wiki/d29ba5b9/","title":"禁止root用户ssh登录机器"},{"content":"RapidJSON 的设计有一个特性, 进行赋值操作时, 不是把源value复制(copy)到目的 value, 而是转移(move)到目的value. 例如\nValue a(123); Value b(456); b = a; // a becomes a Null value, b becomes number 123. 这样的设计的目的是 为了提高性能. 对于固定大小的JSON类型(Number, True, False, Null), 复制很简单快捷. 而对于可变大小的类型(String, Array, Object), 复制时会产生大量不容易被察觉的开销. 尤其是当我们需要创建一个临时的值, 把它复制给另一个变量, 然后析构它. 若使用正常的复制 语义:\nDocument d; Value o(kObjectType); { Value contacts(kArrayType); // Adding elements to contacts array. // ... o.AddMember(\u0026quot;contacts\u0026quot;, contacts, d.GetAllocator(); // deep clone contacts(may be with lots of allocations) // destruct contact } o 需要分配跟contacts 大小一样的缓冲区, 做深度复制, 然后析构contacts . 这样会产生大量不必要的内存分配/释放 和内存复制. 有一些方案可以避免实质的复制这些数据, 如引用计数, 垃圾回收等等. 为了使RapidJSON简单和快速, 我们选择使用转移语义来进行赋值. 这与std::auto_ptr类似, 都是在赋值时转移拥有权. 转移比复制简捷地多, 它只需 析构原来的值, 把源值memcpy() 到目的值, 最后再把源值 设为Null类型.\n使用转移语义, 上面的例子变成:\nDocument d; Value o(kObjectType); { Value contacts(kArraryType); // Adding elements to contacts array. o.AddMember(\u0026quot;contacts\u0026quot;, contacts, d.GetAllocator()); // Just memcpy() of contacts itself to the value of new member(16 bytes) // contacts became Null here. Its destructiong is trivial. } 转移语义和临时值 有时, 我们想直接构造一个临时变量传给\u0026quot;转移\u0026quot;函数, 如PushBack() , AddMember() . 由于临时对象不能直接转化成正常的值引用, 我们可以调用Move() 函数\nValue a(kArrayType); Document::AllocatorType\u0026amp; allocator = document.GetAllocator(); // a.PushBack(Value(42), allocator); // Compiling error a.PushBack(Value().SetInt(42), allocator); // fluent API a.PushBack(Value(42).Move(), allocator); // same as above 翻译原文: http://rapidjson.org/md_doc_tutorial.html#MoveSemantics\n","date":"2017-05-10T10:10:27Z","permalink":"https://lxb.wiki/e5a4892c/","title":"Move semantics of RapidJSON"},{"content":"如果你用C++编码， 需要对容器内的元素进行排序， 这个容器提供任意访问的迭代器， 比如std::vector， 那么简单快捷的方法是使用里的std::sort 函数.\nBasic sorting std::sort 函数需要两个参数, 这两个参数分别指向你要排序的序列容器的开始(initial)和终点(final). 这个序列容易内除final指向的那个元素外 所有元素都会被排序. 下面是一个简单的排序例子:\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt;\u0026lt;/vector\u0026gt;\u0026lt;/algorithm\u0026gt; const int array[] {10, 20, 5, 15, 0}; std::vector\u0026lt;int\u0026gt; vec(array, array + 5);\u0026lt;/int\u0026gt; std::sort(vec.begin(), vec.end()); 输出: 0 5 10 15 20\nMore complex sorting 在某些时候, 根据数值升序排序已经足够解决问题了, 但是当我们需要按某个特定的参数进行排序, 或者降序排列时, 就需要一些其他的东西了. 对于这种需求, std::sort 需要引入第三个参数: 比较函数. 这个比较函数有两个参数, 分别是序列容器的两个元素, 返回值可以隐式地转为bool. 如果第一个参数应该排在第二个参数前面, 则返回true.\n例:\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt;\u0026lt;/vector\u0026gt;\u0026lt;/algorithm\u0026gt; bool DescOrderInt(int a, int b); ... const int array[] = {10, 20, 5, 15, 0}; std::vector\u0026lt;int\u0026gt; vec(array, array + 5);\u0026lt;/int\u0026gt; std::sort(vec.begin(), vec.end(), DescOrderInt); DescOrderInt的实现:\nbool DescOrderInt(int a, int b) { return a \u0026amp;gt; b; } 输出: 20 15 10 5 0\nC++11 sort using function objects 网上很多例子说, 为了排列元素, 可以使用std::binary_function 定义比较函数, 但不幸的是, std::binary_function 在C++11 中已经被标为 \u0026ldquo;将被弃用的\u0026rdquo;, 在C++17中会被完全移除, 所以写新的C++代码时, 最好不要用这个.\n我们可以使用C++11中引入的std::function 来定义这个函数指针. 例:\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;function\u0026gt; #include \u0026lt;vector\u0026gt;\u0026lt;/vector\u0026gt;\u0026lt;/function\u0026gt;\u0026lt;/algorithm\u0026gt; struct StrDescOrderInt { bool operator()(int a, int b) const { return a \u0026amp;gt; b; } }; ... const int array[] = {10, 20, 5, 15, 0}; std::vector\u0026lt;int\u0026gt; vec(array, array + 5);\u0026lt;/int\u0026gt; std::function\u0026lt;bool(int, int)=\u0026#34;\u0026#34;\u0026gt; sorter = StrDescOrderInt();\u0026lt;/bool(int,\u0026gt; std::sort(vec.begin(), vec.end(), sorter); 输出: 20 15 10 5 0\nA real-life example: providing multiple sorting options 我们假设有一队足球运动员, 我们想让用户按他们自己的意愿去排列这些运动员. 有一个图表的UI, 上面有几个按钮, 每个按钮对应不用的排序规则.\nPlaer 类的代码:\n// -- Player.h -- #include \u0026lt;string\u0026gt;\u0026lt;/string\u0026gt; class Player { public: Player(const char * name, int caps, int goals); const std::string \u0026amp;amp; GetName() const; int GetCaps() const; int GetGoals() const; private: std::string mName; int mCaps; int mGoals; }; ​\n现在我们新写一个类或结构体来列出所有的比较函数. 比较函数是一个结构体并实现操作符(), 操作符() 带有两个参数, 分别为两个指向Player的指针, 返回bool值.\nclass Player; struct PlayerSorting { // name struct SortPlayerByNameAsc (bool operator()(Player* p1, Player* p2) const;); struct SortPlayerByNameDes (bool operator()(Player* p1, Player* p2) const;); // caps struct SortPlayerByCapsAsc (bool operator()(Player* p1, Player* p2) const;); struct SortPlayerByCapsDes (bool operator()(Player* p1, Player* p2) const;); // goals struct SortPlayerByGoalsAsc (bool operator()(Player* p1, Player* p2) const;); struct SortPlayerByGoalsDes (bool operator()(Player* p1, Player* p2) const;); } 然后, 在调用它的地方, 我们可以先把所有的std::function 存在一个std::vector 里, 使用的时候, 用索引访问vector的元素.\nstd::vector\u0026lt; std::function\u0026lt;bool(player *,=\u0026#34;\u0026#34; player=\u0026#34;\u0026#34; *)=\u0026#34;\u0026#34;\u0026gt; \u0026gt; sorters; sorters.push_back(PlayerSorting::SortPlayerByNameAsc()); sorters.push_back(PlayerSorting::SortPlayerByCapsAsc()); sorters.push_back(PlayerSorting::SortPlayerByGoalsAsc()); sorters.push_back(PlayerSorting::SortPlayerByNameDes()); sorters.push_back(PlayerSorting::SortPlayerByCapsDes()); sorters.push_back(PlayerSorting::SortPlayerByGoalsDes());\u0026lt;/bool(player\u0026gt; ​\n例如, 根据得分降序排列:\nstd::vector\u0026lt;player *=\u0026#34;\u0026#34;\u0026gt; players;\u0026lt;/player\u0026gt; // ...init players... std::sort(players.begin(), players.end(), sorters[5]); 输出:\nNAME CAPS GOALS Lionel Messi 21 20 David Villa 13 16 Asamoah Gyan 22 15 Arjen Robben 11 12 Mesut Oezil 19 10 Diego Forlan 20 10 Andres Iniesta 15 9 Wesley Sneijder 24 6 Xavi 17 5 Bastian Schweinsteiger 23 4 假如需要实现一种新的排序方式, 我们只需要在PlayerSorting类中添加一个新的仿函数即可.\n原文地址: http://blog.davidecoppola.com/2015/01/cpp11-sort-using-function-objects/\n","date":"2017-04-19T21:58:53Z","permalink":"https://lxb.wiki/e754bcbe/","title":"【译】C++11 sort using function objects"},{"content":"现象 通过gdb打开core，但看不到core的内容，信息如下：\n$ gdb XXX core.XXX GNU gdb (GDB) Red Hat Enterprise Linux ( 7.0.1-32.el5) Copyright (C) 2009 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \u0026#34;show copying\u0026#34; and \u0026#34;show warranty\u0026#34; for details. This GDB was configured as \u0026#34;x86_64-redhat-linux-gnu\u0026#34;. For bug reporting instructions, please see: \u0026lt;http://www.gnu.org/software/gdb/bugs/\u0026gt;... Reading symbols from /home/XXX/XXX...done. BFD: Warning: /home/XXX/core.XXX is truncated: expected core file size \u0026gt;= 747175936, found: 1236992. warning: core file may not match specified executable file. Cannot access memory at address 0x344201cc88 调查 ulimit -a的结果如下：\ncore file size (blocks, -c) 1000 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 40960 max locked memory (kbytes, -l) 32 max memory size (kbytes, -m) unlimited open files (-n) 65000 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 536870912 real-time priority (-r) 0 stack size (kbytes, -s) 1024000 cpu time (seconds, -t) unlimited max user processes (-u) 40960 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 经别人指点，说是“core file size”的值太小了。\n修改core file size的方法 1 使用root用户登录，在/etc/security/limits.conf文件中，添加了“* hard core unlimited”行，添加后此文件的内容大致如下：\n# /etc/security/limits.conf # # Each line describes a limit for a user in the form: # # \u0026lt;domain\u0026gt; \u0026lt;type\u0026gt; \u0026lt;item\u0026gt; \u0026lt;value\u0026gt; # * - msgqueue 536870912 * soft nofile 65000 * hard nofile 65000 * soft core unlimited * hard core unlimited 2 修改这个文件后，退出root用户 3 退出自己的账户的全部登录的终端，然后关闭telnet工具，重新使用自己的账户登录系统，键入下面的命令，都会返回unlimited\n$ ulimit -S -c unlimited $ ulimit -H -c unlimited 此时core文件就不会被截断了。\n参考资料 How do I enable core dumps for everybody http://www.akadia.com/services/ora_enable_core.html\n原文地址: http://blog.sina.com.cn/s/blog_537f4d9b0100wi88.html\n","date":"2017-04-10T21:09:35Z","permalink":"https://lxb.wiki/d12416f0/","title":"core文件被截断问题的解决办法"},{"content":"考虑以下代码:\nbool fun(const string\u0026amp;amp; code) { assert(code.length() \u0026amp;gt;= 2); if (code.substr(0, 2) == string(\u0026quot;XX\u0026quot;)) { // ... } // ... } 有没有发现什么问题? 不要纠结于assert(), 它只是为了保证 string \u0026ldquo;code\u0026rdquo; 长度大于2而已.\n很显然, 这段代码用来检查string是否以\u0026quot;XX\u0026quot;开头. 基于它长度大于2 的前提, 这段代码能正常运行. 我们的关心的问题是, 表达式能否达到正确的结果.\n绝大多数情况下, 我们之所以使用C++, 是希望能使我们的程序达到最优的性能. 基于这个目标, 上面的代码看起来就不是很正确了. 为了检查\u0026quot;code\u0026quot;是否以\u0026quot;XX\u0026quot;开头, 我们生成了两个临时的string, 每个string都可能潜在地申请堆上的内存. 有人可能会为此辩解: std::string应该能为一个 2字母的序列实现 短字符串最优化(SSO). 就算这个辩解是正确的, 这段代码也已经 耗费了 一些不能被优化掉的开销, 更何况, 并不是所有的都会实现SSO. 例如, 我使用的GCC 4.4.7 就不会为string实现SSO.\n类模板std::basic_string 的接口很复杂. 它提供了大量的成员函数, 似乎不用它们显得不领情, 同时开发者也不会有自己一遍遍重新解析的冲动.\n因为开发者模糊地记得应用于NTBS(null-terminated byte strings)(可以被隐式地转为const char* )的 操作符 == 会使结果出错, 所以他通过 确保参与比较的两个值都是std::string 类型来避开这个错误. 他可能在想, 在运行操作符== 前文本\u0026quot;XX\u0026quot; 已经被显式地转成了std::string, 那么这么做也没有坏处. 但是, 这是错误的, 因为对于操作符==, 标准提供了两种版本:\nbool operator==(const std::string\u0026amp;amp; lhs, const char* rhs); bool operator==(const char* lhs, const std::string\u0026amp;amp; rhs); 当然实际上他们是带有多个参数的函数模板, 远比这个复杂. std::string 可以直接跟NTBS比较, 没有必要生成临时的std::string. 我们开头的例子, 可以通过去除显式生成的临时副本 进行优化: if (code.substr(0, 2) == \u0026quot;XX\u0026quot;)\n更进一步, 不可否认, 在有些地方使用操作符== 看起来很高雅, 但是仅仅为了检查一个string 本身的一部分而去新申请一部分资源(生成一个新的string) 这种做法是错误的. 开发者的初衷, 并不是要是程序看起来高雅. 实际上, 如果我们深入研究std::basic_string 的官方文档, 就会发现, std::basic_string提供了一种比较它的子字符串和NTBS的方法: if(code.compare(0, 2, \u0026quot;XX\u0026quot;) == 0) 这个比较是三方比较, 结果等于0表示相等. 它可以达到目的, 并且不需要生成任何临时的string.\n尽管这个compare() 使性能达到了很大的优化, 但我并不满足于此. 虽然它做了正确的事情, 但如果我们是第一次遇到他, 很难抓住他的精髓. 如果你可以使用boost库, 我的建议性的解决方案是使用Boost String Algorithms Library 中的算法:\n#include \u0026lt;boost algorithm=\u0026quot;\u0026quot; string=\u0026quot;\u0026quot; predicate.hpp=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/boost\u0026gt; bool func(const string\u0026amp;amp; code) { if (boost::algorithm::starts_with(code, \u0026quot;XX\u0026quot;)) } 这段代码很好地体现了我想说的意思, 没有任何多余的开销.\n原文地址: https://akrzemi1.wordpress.com/2015/04/15/strings-interface/\n","date":"2017-04-09T22:00:41Z","permalink":"https://lxb.wiki/4c3249cd/","title":"【译】String\u0026#039;s interface"},{"content":"在我们用C/C++开发的过程中，总是有一个问题会给我们带来苦恼。这个问题就是函数内和函数外代码需要通过一块内存来交互（比如，函数返回字符串），这个问题困扰和很多开发人员。如果你的内存是在函数内栈上分配的，那么这个内存会随着函数的返回而被弹栈释放，所以，你一定要返回一块函数外部还有效的内存。\n这是一个让无数人困扰的问题。如果你一不小心，你就很有可能在这个上面犯错误。当然目前有很多解决方法，如果你熟悉一些标准库的话，你可以看到许多各式各样的解决方法。大体来说有下面几种：\n1）在函数内部通过malloc或new在堆上分配内存，然后把这块内存返回（因为在堆上分配的内存是全局可见的）。这样带来的问题就是潜在的内存问题。因为，如果返回出去的内存不释放，那么就是memory Leak。或者是被多次释放，从而造成程序的crash。这两个问题都相当的严重，所以这种设计方法并不推荐。（在一些Windows API中，当你调用了一些API后，你必需也要调用他的某些API来释放这块内存）\n2）让用户传入一块他自己的内存地址，而在函数中把要返回的内存放到这块内存中。这是一个目前普遍使用的方式。很多Windows API函数或是标准C函数都需要你传入一个buffer和这个buffer的长度。这种方式对我们来说应该是屡见不鲜了。这种方式的好处就是由函数外部的程序来维护这块内存，比较简显直观。但问题就是在使用上稍许有些麻烦。不过这种方式把犯错误的机率减到了最低。\n3）第三种方式显得比较另类，他利用了static的特性，static的栈内存一旦分配，那这块内存不会随着函数的返回而释放，而且，它是全局可见的（只要你有这块内存的地址）。所以，有一些函数使用了static的这个特性，即不用使用堆上的内存，也不需要用户传入一个buffer和其长度。从而，使用得自己的函数长得很漂亮，也很容易使用。\n这里，我想对第三个方法进行一些讨论。使用static内存这个方法看似不错，但是它有让你想象不到的陷阱。让我们来用一个实际发生的案例来举一个例子吧。\n示例\n有过socket编程经验的人一定知道一个函数叫：inet_ntoa，这个函数主要的功能是把一个数字型的IP地址转成字符串，这个函数的定义是这样的（注意它的返回值）：\nchar *inet_ntoa(struct in_addr in);\n显然，这个函数不会分配堆上的内存，而他又没有让你传一下字符串的buffer进入，那么他一定使用“返回static char[]”这种方法。在我们继续我们的讨论之前，让我们先了解一下IP地址相关的知识，下面是inet_ntoa这个函数需要传入的参数：（也许你会很奇怪，只有一个member的struct还要放在struct中干什么？这应该是为了程序日后的扩展性的考虑）\nstruct in_addr { unsigned long int s_addr; } 对于IPV4来说，一个IP地址由四个8位的bit组成，其放在s_addr中，高位在后，这是为了方便网络传输。如果你得到的一个s_addr的整型值是：3776385196。那么，打开你的Windows计算器吧，看看它的二进制是什么？让我们从右到左，8位为一组（如下所示）。\n11100001 00010111 00010000 10101100\n再把每一组转成十进制，于是我们就得到：225 23 16 172， 于是IP地址就是 172.16.23.225。\n好了，言归正传。我们有这样一个程序，想记录网络包的源地址和目地地址，于是，我们有如下的代码：\nstruct in_addr src, des; ........ ........ fprintf(fp, \u0026#34;源IP地址\u0026lt;%s\u0026gt;/t目的IP地址\u0026lt;%s\u0026gt;/n\u0026#34;, inet_ntoa(src), inet_ntoa(des)); 会发生什么样的结果呢？你会发现记录到文件中的源IP地址和目的IP地址完全一样。这是什么问题呢？于是你开始调试你的程序，你发现src.s_addr和des.s_addr根本不一样（如下所示）。可为什么输出到文件的源和目的都是一样的？难道说是inet_ntoa的bug？\nsrc.s_addr = 3776385196; //对应于172.16.23.225 des.s_addr = 1678184620; //对应于172.16.7.100 原因就是inet_ntoa()“自作聪明”地把内部的static char[]返回了，而我们的程序正是踩中了这个陷阱。让我们来分析一下fprintf代码。在我们fprintf时，编译器先计算inet_ntoa(des)，于是其返回一个字符串的地址，然后程序再去求inet_ntoa(src)表达式，又得到一个字符串的地址。这两个字符串的地址都是inet_ntoa()中那个static char[]，显然是同一个地址，而第二次求src的IP时，这个值的des的IP地址内容必将被src的IP覆盖。所以，这两个表达式的字符串内存都是一样的了，此时，程序会调用fprintf把这两个字符串（其实是一个）输出到文件。所以，得到相同的结果也就不奇怪。\n仔细看一下inet_ntoa的man，我们可以看到这句话：The string is returned in a statically allocated buffer, which subsequent calls will overwrite. 证实了我们的分析。\n小结\n让我们大家都扪心自问一下，我们在写程序的过程当中是否使用了这种方法？这是一个比较危险，容易出错的方法。这种陷阱让人防不胜防。想想，如果你有这样的程序：\nif ( strcmp( inet_ntoa(ip1), inet_ntoa(ip2) )==0 ) { …. …. } 本想判断一下两个IP地址是否一样，却不料掉入了那个陷阱——让这个条件表达式永真。\n这个事情告诉我们下面几个道理：\n1）慎用这种方式的设计。返回函数内部的static内存有很大的陷阱。\n2）如果一定要使用这种方式的话。你就必须严肃地告诉所有使用这个函数的人，千万不要在一个表达式中多次使用这个函数。而且，还要告诉他们，不copy函数返回的内存的内容，而只是保存返回的内存地址或是引用是没用的。不然的话，后果概不负责。\n3）C/C++是很危险的世界，如果你不清楚他的话。还是回火星去吧。\n附：看过Efftive C++的朋友一定知道其中有一个条款（item 23）：不要试图返回对象的引用。这个条款中也对是否返回函数内部的static变量进行了讨论。结果也是持否定态度的。\n原文地址: http://www.tuicool.com/articles/JNZZfiZ\n","date":"2017-04-02T23:43:17Z","permalink":"https://lxb.wiki/d66df6b4/","title":"C/C++返回内部静态成员的陷阱"},{"content":"从一段代码引用开始:\nstd::vector\u0026amp;lt; std::pair\u0026lt;int, std::string=\u0026quot;\u0026quot;\u0026gt; \u0026amp;gt; v1 = ... // v1 is filled with data std::vector\u0026amp;lt; std::pair\u0026lt;int, std::string=\u0026quot;\u0026quot;\u0026gt; \u0026amp;gt; v2 = ... // v2 is filled with data std::vector\u0026amp;lt; std::pair\u0026lt;int, std::string=\u0026quot;\u0026quot;\u0026gt; \u0026amp;gt; results;\u0026lt;/int,\u0026gt;\u0026lt;/int,\u0026gt;\u0026lt;/int,\u0026gt; std::sort(v1.begin(), v1.end()); std::sort(v2.begin(), v2.end()); std::set_difference(v1.begin(), v1.end(), v2.begin(), v2.end(), std::back_inserter(result), compareFirst); 我们在两个排好序的vector v1 和 v2上调用std::set_difference. std::set_difference 把结果写入 result, std::back_inserter 确保输出的结果从result 的后面添入. 自定义的compareFirst 作为比较函数提供给std::set_difference\n默认地, std::set_difference 通过 std::pair 默认的比较函数来比较里面的元素(比较pair的first和second), 我们自定义了compareFirst, 希望只比较pair的first. compareFirst不是STL的函数, 需要我们自己实现.\nstd::set_difference 使用的前提是input已经排好序, 倘若我们自定义比较函数C, 而通过C我们能把元素排好序, 那么我们使用这个C代替sort的默认排序也是可以的.\n在此例中, 我们使用std::set_difference 只对pair的first进行排序, 尽管它们已经通过\u0026quot;first + second\u0026quot;的方式排序完了.\n下面来实现compareFirst. 初版:\nbool compareFirst(const std::pair\u0026lt;int, std::string=\u0026quot;\u0026quot;\u0026gt;\u0026amp;amp; p1, const std::pair\u0026lt;int, std::string=\u0026quot;\u0026quot;\u0026gt;\u0026amp;amp; p2) { return p1.first == p2.first; // not final code, bug lurking here! } 实际上, 上面的代码不会得到我们预期的结果. 为什么? 毕竟std::set_difference 会检查元素跟另一个容器的元素是否相等(equal), 不是吗?\u0026lt;/int,\u0026gt;\u0026lt;/int,\u0026gt;\n为了理解上面的内容, 我们把STL大概地分为两类: 操作排序元素的 和操作乱序元素的.\nComparing elements\nC++中描述\u0026quot;a is the same as b\u0026quot; 有两种方法\n- the natural way: a == b. This is called equality. Equality is based on operator==. - the other way: a is not smaller than b and b is not smaller than a, so !(a\u0026lt;b) \u0026amp;\u0026amp;=\u0026quot;\u0026quot; !(b\u0026lt;a).=\u0026quot;\u0026quot; this=\u0026quot;\u0026quot; is=\u0026quot;\u0026quot; called=\u0026quot;\u0026quot; equivalence.=\u0026quot;\u0026quot; equivalence=\u0026quot;\u0026quot; based=\u0026quot;\u0026quot; on=\u0026quot;\u0026quot; operator\u0026lt;.=\u0026quot;\u0026quot; ```=\u0026quot;\u0026quot; 这两个问题涉及到另一个名词:=\u0026quot;\u0026quot; `equivalence`=\u0026quot;\u0026quot; \u0026lt;u=\u0026quot;\u0026quot;\u0026gt;How is it different from equality?\u0026lt;/b)\u0026gt; 对于基本类型如int, 甚至实践中大多数类型, `equivalence` 和`quality` 是相通的. 但是正如*Scott Meyers* 在\u0026amp;lt;\u0026amp;lt; Effective STL\u0026amp;gt;\u0026amp;gt; 一书条目19中指出的, 对于有一些类型, 即使\u0026quot;并非罕见\u0026quot;, `equivalence` 和 `equality` 是不同的, 如 大小写不敏感的string类型. \u0026lt;u\u0026gt;Why such a far-fetched way to express a simple thing?\u0026lt;/u\u0026gt; 当我们使用算法对容器内元素进行排序时, 很容易理解必须有独一无二的排序方法(如有多种排序方法, 会很笨重, 并可能产生不一致的结果). 所以对于一个特定的容器, 排序时, \u0026quot;==\u0026quot; 和\u0026quot;\u0026amp;lt;\u0026quot; 只能选一个. 对于STL中排序的部分, 我们别无选择: 排序时必须使用\u0026quot;\u0026amp;lt;\u0026quot;; 而乱序部分, 则没有这个约束, 我们可以使用\u0026quot;==\u0026quot;. **Implementing the comparator** STL的乱序部分使用\u0026quot;==\u0026quot;, 而排序部分使用\u0026quot;\u0026amp;lt;\u0026quot;. 我们自定义的比较函数也必须遵循这种逻辑. 现在我们可以理解怎么自定义实现`std::set_difference` 的比较函数`compareFirst` 了. ​\nbool compareFirst(const std::pair\u0026lt;int, std::string=\u0026quot;\u0026quot;\u0026gt;\u0026amp; p1, const std::pair\u0026lt;int, std::string=\u0026quot;\u0026quot;\u0026gt;\u0026amp; p2) { return p1.first \u0026lt; p2.first; // correct, STL-compatible code. } ```\n原文地址: http://www.fluentcpp.com/2017/02/16/custom-comparison-equality-equivalence-stl/ \u0026lt;/int,\u0026gt;\u0026lt;/int,\u0026gt;\n","date":"2017-03-29T19:01:51Z","permalink":"https://lxb.wiki/55f488ad/","title":"【译】Custom comparison, equality and equivalence with the STL"},{"content":"本文分3部分: 1. 怎么使用STL进行高效的查找: 借用传统STL算法对元素进行范围搜索 2. 搜索STL容器: 当你有直接读取STL容器里元素的权限时, 怎么进行高效准确的搜索(与简单的范围搜索相比较) 3. STL搜索算法的秘密: 向公众展示不为人知的算法, 这些算法在已经学习过的人眼里确实是很有用的\nSTL根据查看方式的不同, 一共分为两种: 排序的和不排序的. * 排序集合的遍历, 通常需要对数时长, 而乱序集合的遍历, 需要线性时长 * 排序容器中比较元素大小的函数根据equivalence(comparing with \u0026lt;), 而乱序容器中的函数根据equality(comparing with ==).\n本文将展示对于在一个范围内搜索一个给定的值, C++怎么样去阐述下面3个问题: * 它存在否 * 它在哪 * 它应该在什么位置(排序容器)\nIs it there? 乱序容器的元素 这个问题可以用std::find来表达(需要和与范围的终点值的比较相结合):\nvector\u0026lt;int\u0026gt; v = ... // v filled with values if (std::find(v.begin(), v.end(), 42) != v.end()) { ... \u0026ldquo;Is it there\u0026quot;这个问题也可以用std::count来表达:\nvector\u0026lt;int\u0026gt; v = ... // v filled with values if (std::count(v.begin(), v.end(), 42)) { ... std::count()的返回值会被隐式地转换成if条件里的bool值: 如果该范围里有至少一个值为42, 则返回true.\n与std::find相比, std::count的优劣: 优势:\nstd::count避免了与范围的end值相比较 弊端:\nstd::count遍历整个集合, 而std::find在第一个与要查找的值相等的位置停下 可以证明, 对于\u0026quot;想要查找某个值\u0026quot;这件事, std::find 表达得更明确 基于以上, std::find用得更多. Note 若要确认某个值存在而非是与要搜索的值相等, 请使用std::count_if, std::find_if, std::find_if_not\n排序容器的元素 使用的算法是std::binary_search, 此函数返回一个bool值, 此bool值表示在集合中是否存在与搜索的值相等的元素.\nstd::set\u0026lt;int\u0026gt; numbers = // sorted elements bool is42InThere = std::binary_search(numbers.begin(), numbers.end(), 42); ```\u0026lt;/int\u0026gt; ### Where is it? (当确定了要搜索的值存在后,) 我们想更进一步, 得到指向那个元素的迭代器. #### 乱序容器的元素 使用std::find. 返回指向第一个与搜索的值相等的元素的迭代器, 如果找不到, 则返回集合的终点. ​\nstd::vector numbers = \u0026hellip; auto searchResult = std::find(numbers.begin(), numbers.end(), 42);\nif (searchResult != numbers.end()) { \u0026hellip;\n#### 排序容器的元素 对于排序集合, STL并没有像std::find一样直接的算法. std::find并不是为排序容器设计的, 因为它依据的是\u0026quot;==\u0026quot;而不是\u0026quot;\u0026amp;lt;\u0026quot;, 消耗的时间为线性时长而不是对数时长. 对于一个给定的容器, 如果容器内元素的\u0026quot;equality\u0026quot;和\u0026quot;equivalence\u0026quot;是相同的, 且你能接受消耗的线性时长, 那么std::find会为你返回正确的结果, 你也能从它简单直接的接口中获益. **但是,** 不能忘记, std::find并不是为排序容器设计的. 这里推荐使用`std::equal_range`. (并非`std::lower_bound`) 函数原型: ​\ntemplate\u0026lt; class ForwardIt, class T \u0026gt; std::pair\u0026lt;forwardit,forwardit\u0026gt; equal_range( ForwardIt first, ForwardIt last, const T\u0026amp; value );\n`std::equal_range` 返回与搜索值相等的元素的范围, 这个范围用一对集合内的迭代器表示. 这两个迭代器分别指向 与搜索值相等的范围里第一个元素和最后一个元素的下一个位置.\u0026lt;/forwardit,forwardit\u0026gt; 然而, 它的接口有些笨重: 例A: std::vector v = {3, 7, 3, 11, 3, 3, 2}; sort(v.begin(), v.end());\n// equal_range, attempt 1: natively clumsy std::pair\u0026lt;std::vector::iterator, std::vector::iterator\u0026gt; range1 = equal_range(v.begin(), v.end(), 3); std::for_each(range1.first, range1.second, doSomething);\n用一个`typedef` 或者`using`让它更简洁: 例B: std::vector v = {3, 7, 3, 11, 3, 3, 2}; sort(v.begin(), v.end());\u0026lt;/std::vector\nusing IteratorPair = std::pair\u0026lt;std::vector::iterator, std::vector::iterator\u0026gt;;\u0026lt;/std::vector\n// equal_range, attempt 2: with the classical typedef IteratorPair range2 = equal_range(v.begin(), v.end(), 3); std::for_each(range2.first, range2.second, doSomething);\n例B确实简洁了很多, 但是仍有一个根本问题: 没有考虑 抽象等级. 尽管返回的是一个范围, 但这对迭代器强迫我们在操作返回的范围时必须按照\u0026quot;第一\u0026quot;\u0026quot;第二\u0026quot;这种方式来写代码. 范围就应该用\u0026quot;首\u0026quot;\u0026quot;尾\u0026quot;这种方式来表达. 这不仅给我们在其他地方使用这个返回值时造成很大的麻烦, 而且使代码很别扭. 为了解决这个问题, 我么可以把`std::equal_range` 返回的迭代器对封装进一个有\u0026quot;范围\u0026quot;这种语义的`object` ​\ntemplate\nclass Range\n{\npublic:\nRange(std::pair range)\nm_begin(range.first), m_end(range.second) {} typename Container::iterator begin() { return m_begin; } typename Container::iterator end() { return m_end; }\nprivate: typename Container::iterator m_begin; typename Container::iterator m_end; };\n注意: 尽管`std::equal_range` 返回的结果是一个\u0026quot;范围\u0026quot;, 但是`std::begin` 和 `std::end` 不能用在这个结果上. 而上面的封装解决了这个问题. 可以像下面这样使用: ​\nstd::vector v = {3, 7, 3, 11, 3, 3, 2}; sort(v.begin(), v.end());\n// equal_range, attempt 3: natural al last Rangestd::vector\\ range3 = equal_range(v.begin(), v.end(), 3); std::for_each(range3.begin(), range3.end(), doSomething);\n不管你使用上面的哪种方式, `std::equal_range` 都会返回一个范围, 要确定它是否为空, 可以通过检查那两个迭代器(是否相等)或者使用`std::distance` 检查它的大小. \u0026lt;/std::vector\u0026lt;int\u0026gt; ​\nbool noElementFound = range3.begin() == range3.end(); size_t numberOfElementFound = std::distance(range3.begin(), range3.end()) ```\nWhere should it be? 这个问题仅仅针对排序的范围, 因为对于乱序的范围, 某个元素可能会存在任何位置.\n对于排序的范围, 这个问题可以简化为: 如果它存在, 那么它在哪儿? 如果它不存在, 那么它应该在哪儿?\n这个问题可以用算法std::lower_bound 和std::upper_bound 来解释.\n当你理解了std::equal_range 后, 上面这句话就很容易理解了: std::lower_bound 和std::upper_bound 都会返回 std::equal_range 返回的那个迭代器对的第一个和第二个迭代器.\n要插入某个值x, 使用std::lower_bound 得到指向 在范围里与x相等的元素之前的位置的迭代器, 使用std::upper_bound 得到指向 在范围里与x相等的元素之后的位置的迭代器.\n注意: 如果仅仅是搜索某个元素, 永远不要使用std::lower_bound\n与std::find 相反, 你不能根据 判断std::lower_bound 返回的迭代器是否与终点的迭代器相等 来判断要搜索的值是否存在于这个集合. 事实上, 如果这个值在集合里不存在, 则std::lower_bound 返回它应该在的位置, 而不是终点的迭代器. 所以, 你不仅需要确认返回的迭代器不是终点的迭代器, 还要确认它指向的元素跟要搜索的值是相等的.\n总结 Question to express in C++\nNOT SORTED\nSORTED\nIs it there?\nstd::find != end\nstd::binary_search\nWhere is it?\nstd::find\nstd::equal_range\nWhere should it be?\nstd::lower_bound / std::upper_bound\n原文地址: http://www.fluentcpp.com/2017/01/16/how-to-stdfind-something-efficiently-with-the-stl/?hmsr=toutiao.io\u0026utm_medium=toutiao.io\u0026amp;utm_source=toutiao.io\n","date":"2017-03-16T22:07:59Z","permalink":"https://lxb.wiki/56dc57bb/","title":"【译】How to (std::)find something efficiently with the STL"},{"content":"条款9：在删除选项中仔细选择 假定你有一个标准STL容器，c，容纳int， Container\u0026lt;int\u0026gt; c; 而你想把c中所有值为1963的对象都去掉。令人吃惊的是，完成这项任务的方法因不同的容 器类型而不同：没有一种方法是通用的。\n如果你有一个连续内存容器（vector、deque或string——参见条款1），最好的方法是erase-remove惯用法（参见条款32）：\nc.erase(remove(c.begin(), c.end(), 1963), // 当c是vector、string c.end()); // 或deque时， // erase-remove惯用法 // 是去除特定值的元素 // 的最佳方法 这方法也适合于list，但是，正如条款44解释的，list的成员函数remove更高效：\nc.remove(1963); // 当c是list时， // remove成员函数是去除 // 特定值的元素的最佳方法 当c是标准关联容器（即，set、multiset、map或multimap）时，使用任何叫做remove的东 西都是完全错误的。这样的容器没有叫做remove的成员函数，而且使用remove算法可能覆 盖容器值（参见条款32），潜在地破坏容器。（关于这样的破坏的细节，参考条款22，那 个条款也解释了为什么试图在map和multimap上使用remove肯定不能编译，而试图在set和 multiset上使用可能不能编译。）\n不，对于关联容器，解决问题的适当方法是调用erase：\nc.erase(1963); // 当c是标准关联容器时 // erase成员函数是去除 // 特定值的元素的最佳方法 这不仅是正确的，而且很高效，只花费对数时间。（序列容器的基于删除的技术需要线性 时间。）并且，关联容器的erase成员函数有基于等价而不是相等的优势，条款19解释了这 一区别的重要性。\n让我们现在稍微修改一下这个问题。不是从c中除去每个有特定值的物体，让我们消除下面 判断式（参见条款39）返回真的每个对象：\nbool badValue(int x); // 返回x是否是“bad” 对于序列容器（vector、string、deque和list），我们要做的只是把每个remove()替换为remove_if()，然后就完成了： c.erase(remove_if(c.begin(), c.end(), badValue), // 当c是vector、string c.end()); // 或deque时这是去掉 // badValue返回真 // 的对象的最佳方法 c.remove_if(badValue); // 当c是list时这是去掉 // badValue返回真 // 的对象的最佳方法 对于标准关联容器，它不是很直截了当。有两种方法处理该问题，一个更容易编码，另一 个更高效。“更容易但效率较低”的解决方案用remove_copy_if()把我们需要的值拷贝到一 个新容器中，然后把原容器的内容和新的交换：\nAssocContainer\u0026lt;int\u0026gt; c; // c现在是一种 ... // 标准关联容器 AssocContainer\u0026lt;int\u0026gt; goodValues; // 用于容纳不删除 // 的值的临时容器 remove_copy_if(c.begin(), c.end(), // 从c拷贝不删除 inserter(goodValues, // 的值到 goodValues.end()), // goodValues badValue); c.swap(goodValues); // 交换c和goodValues // 的内容 这种方法的缺点是它拷贝了所有不删除的元素，而这样的拷贝开销可能大于我们期望的底线。\n我们可以通过直接从原容器删除元素来避开拷贝的开销。不过，因为关联容器没有提供类似remove_if()的成员函数，所以我们必须写一个循环来迭代c中的元素，和原来一样删除元素.\n看起来，这个任务很简单，而且实际上，代码也很简单。不幸的是，那些正确工作的代码 很少是跃出脑海的代码。例如，这是很多程序员首先想到的：\nAssocContainer\u0026lt;int\u0026gt; c; ... for (AssocContainer\u0026lt;int\u0026gt;::iterator i = c.begin(); // 清晰，直截了当 i!= c.end(); // 而漏洞百出的用于 ++i) { // 删除c中badValue返回真 if (badValue(*i)) c.erase(i); // 的每个元素的代码 } // 不要这么做！\u0026lt;/int\u0026gt;\u0026lt;/int\u0026gt; ​\n唉，这有未定义的行为。当容器的一个元素被删时，指向那个元素的所有迭代器都失效了 。当c.erase(i)返回时，i已经失效。那对于这个循环是个坏消息，因为在erase()返回后， i通过for循环的++i部分自增。\n为了避免这个问题，我们必须保证在调用erase之前就得到了c中下一元素的迭代器。最容 易的方法是当我们调用时在i上使用后置递增：\nAssocContainer\u0026lt;int\u0026gt; c; ... for (AssocContainer\u0026lt;int\u0026gt;::iterator i = c.begin(); // for循环的第三部分 i != c.end(); // 是空的；i现在在下面 /*nothing*/ ){ // 自增 if (badValue(*i)) c.erase(i++); // 对于坏的值，把当前的 else ++i; // i传给erase，然后 } // 作为副作用增加i； // 对于好的值， // 只增加i 这种调用erase()的解决方法可以工作，因为表达式i++的值是i的旧值，但作为副作用，i增 加了。因此，我们把i的旧值（没增加的）传给erase，但在erase开始执行前i已经自增了 。那正好是我们想要的。正如我所说的，代码很简单，只不过不是大多数程序员在第一次 尝试时想到的。\n现在让我们进一步修改该问题。不仅删除badValue返回真的每个元素，而且每当一个元素 被删掉时，我们也想把一条消息写到日志文件中。\n对于关联容器，这说多容易就有多容易，因为只需要对我们刚才开发的循环做一个微不足 道的修改就行了：\nofstream logFile; // 要写入的日志文件 AssocContainer\u0026lt;int\u0026gt; c; ... for (AssocContainer\u0026lt;int\u0026gt;::iterator i = c.begin(); // 循环条件和前面一样 i !=c.end();){ if (badValue(*i)){ logFile \u0026amp;lt;\u0026amp;lt; \u0026#34;Erasing \u0026#34; \u0026amp;lt;\u0026amp;lt; *i \u0026amp;lt;\u0026amp;lt;\u0026#39;\\n\u0026#39;; // 写日志文件 c.erase(i++); // 删除元素 } else ++i; } 现在是vector、string和deque给我们带来麻烦。我们不能再使用erase-remove惯用法，因为没有办法让erase()或remove()写日志文件。而且，我们不能使用刚刚为关联容器开发的循环, 因为它为vector、string和deque产生未定义的行为！要记得对于那样的容器，调用erase不仅使所有指向被删元素的迭代器失效，也使被删元素之后的所有迭代器失效。在我们的情况里，那包括所有i之后的迭代器。我们写i++，++i或你能想起的其它任何东西都没有用，因为没有能导致迭代器有效的。\n我们必须对vector、string和deque采用不同的战略。特别是，我们必须利用erase()的返回值。那个返回值正是我们需要的：一旦删除完成，它就是指向紧接在被删元素之后的元素的有效迭代器。换句话说，我们这么写：\nfor (SeqContainer\u0026lt;int\u0026gt;::iterator i = c.begin(); i != c.end();){ if (badValue(*i)){ logFile \u0026amp;lt;\u0026amp;lt; \u0026#34;Erasing \u0026#34; \u0026amp;lt;\u0026amp;lt; *i \u0026amp;lt;\u0026amp;lt; \u0026#39;\\n\u0026#39;; i = c.erase(i); // 通过把erase的返回值 } // 赋给i来保持i有效 else ++i; } 这可以很好地工作，但只用于标准序列容器。由于论证一个可能的问题（条款5做了），标准关联容器的erase()的返回类型是void[1]。对于那些容器，你必须使用“后置递增你要传给erase()的迭代器”技术。（顺便说说，在为序列容器编码和为关联容器编码之间的这种差别是为什么写容器无关代码一般缺乏考虑的一个例子——参见条款2。)\n为了避免你奇怪list的适当方法是什么，事实表明对于迭代和删除，你可以像vector/str ing/deque一样或像关联容器一样对待list；两种方法都可以为list工作。\n如果我们观察在本条款中提到的所有东西，我们得出下列结论：\n去除一个容器中有特定值的所有对象： 如果容器是vector、string或deque，使用erase-remove惯用法。\n如果容器是list，使用list::remove。\n如果容器是标准关联容器，使用它的erase成员函数。\n去除一个容器中满足一个特定判定式的所有对象： 如果容器是vector、string或deque，使用erase-remove_if惯用法。\n如果容器是list，使用list::remove_if。\n如果容器是标准关联容器，使用remove_copy_if和swap，或写一个循环来遍历容器元素， 当你把迭代器传给erase时记得后置递增它。\n在循环内做某些事情（除了删除对象之外）： 如果容器是标准序列容器，写一个循环来遍历容器元素，每当调用erase时记得都用它的返回值更新你的迭代器。 如果容器是标准关联容器，写一个循环来遍历容器元素，当你把迭代器传给erase时记得后置递增它。\n如你所见，与仅仅调用erase相比，有效地删除容器元素有更多的东西。解决问题的最好方法取决于你是怎样鉴别出哪个对象是要被去掉的，储存它们的容器的类型，和当你删除它们的时候你还想要做什么（如果有的话）。只要你小心而且注意了本条款的建议，你将毫不费力。如果你不小心，你将冒着产生不必要低效的代码或未定义行为的危险。\n------------------------------------------------------------------------------ [1] 这仅对带有迭代器实参的erase()形式是正确的。关联容器也提供一个带有一个值的实参 的erase()形式，而那种形式返回被删掉的元素个数。但这里，我们只关心通过迭代器删除东 西。\n参考地址\n","date":"2017-03-09T21:09:09Z","permalink":"https://lxb.wiki/978f4b48/","title":"【译】Effective STL 9"},{"content":"STL中的容器按存储方式分为两类，一类是按以数组形式存储的容器（如：vector 、deque)；另一类是以不连续的节点形式存储的容器（如：list、set、map）。在使用erase方法来删除元素时，需要注意一些问题。\n1.list,set,map容器 在使用 list、set 或 map遍历删除某些元素时可以这样使用：\n1.1 正确写法 1\nstd::list\u0026lt;int\u0026gt; list; std::list\u0026lt;int\u0026gt;::iterator it_list; for (it_list = list.begin(); it_list != list.end();) { if (willDelete(*it_list)) { it_list = list.erase(it_list); } else { ++it_list; } } Note: 以上方法仅适用于standard sequence container, 因为对于standard associative container, erase()的返回类型为void. (查阅Effective STL Item 9)以下为原文:\nThis works wonderfully, but only for the standard sequence containers. Due to reasoning one might question, erase()'s return type for the standard associative containers is void. For those containers, you have to use the postincrement-the-iterator-you-pass-to-erase technique. 1.2 正确写法2 查阅原版Effctive STL Item 9, 证实, 下面这种写法不能用于标准序列容器, 而适用于标准关联容器, 而List也可以使用这种方法.\nstd::list\u0026lt;int\u0026gt; list; std::list\u0026lt;int\u0026gt;::iterator it_list; for (it_list = list.begin(); it_list != list.end();) { if (willDelete(*it_list)) { list.erase(it_list++); // 必须使用后缀自增, 不能使用前缀自增 } else { ++it_list; } } ```\u0026lt;/int\u0026gt;\u0026lt;/int\u0026gt; **1.3 错误写法 1** std::list\u0026lt; int\u0026gt; List; std::list\u0026lt; int\u0026gt;::iterator itList; for( itList = List.begin(); itList != List.end(); itList++) { if( WillDelete( *itList) ) { List.erase( itList); } }\n**1.4 错误写法 2** std::list\u0026lt; int\u0026gt; List; std::list\u0026lt; int\u0026gt;::iterator itList; for( itList = List.begin(); itList != List.end(); ) { if( WillDelete( *itList) ) { itList = List.erase( ++itList); } else itList++; }\n**1.5 分析** 正确方法1: 通过erase()方法的返回值来获取下一个元素的位置; 正确方法2: 在调用erase()方法之前先使用\u0026quot;++\u0026quot; 来获取下一个元素的位置; 错误使用方法1: 在调用erase()方法之后使用\u0026quot;++\u0026quot; 来获取下一个元素的位置, 由于在调用erase()方法之后, 该元素的位置已经被删除, 如果再根据这个旧的位置来获取下一个位置, 则会出现异常; 错误使用方法2: 同上 ####**2. vector,deque 容器** 在使用 vector、deque遍历删除元素时，也可以通过erase的返回值来获取下一个元素的位置： **2.1 正确写法:** std::vector vec; std::vector::iterator it_vec; for (it_vec = vec.begin(); it_vec != vec.end();) { if (willDelete(*it_vec)) { it_vec = vec.erase(it_vec); } else { ++it_vec; } } ```\n2.2 注意\nvector, deque 不能像上面的\u0026quot;正确方法2\u0026quot; 的办法来遍历删除. 原因请参考Effective STL条款9。摘录到下面： 1) 对于关联容器(如map, set, multimap, multiset)，删除当前的iterator，仅仅会使当前的iterator失效，只要在erase时，递增当前iterator即可。这是因为map之类的容器，使用了红黑树来实现，插入、删除一个结点不会对其他结点造成影响。\nfor (iter = cont.begin(); it != cont.end();) { (*iter)-\u0026amp;gt;doSomething(); if (shouldDelete(*iter)) cont.erase(iter++); else ++iter; } 因为iter传给erase方法的是一个副本，iter++会指向下一个元素。\n对于序列式容器(如vector, deque)，删除当前的iterator会使后面所有元素的iterator都失效。这是因为vetor, deque使用了连续分配的内存，删除一个元素导致后面所有的元素会向前移动一个位置。还好erase()方法可以返回下一个有效的iterator。\nfor (iter = cont.begin(); iter != cont.end();) { (*it)-\u0026gt;doSomething(); if (shouldDelete(*iter)) iter = cont.erase(iter); else ++iter; }\n3)对于list来说，它使用了不连续分配的内存，并且它的erase()方法也会返回下一个有效的iterator，因此上面两种方法都可以使用。\n3. 其他 set 键和值相等。 键唯一。 元素默认按升序排列。 如果迭代器所指向的元素被删除，则该迭代器失效。其它任何增加、删除元素的操作都不会使迭代器失效\nmap 键唯一。 元素默认按键的升序排列。 如果迭代器所指向的元素被删除，则该迭代器失效。其它任何增加、删除元素的操作都不会使迭代器失效。\n作成参考地址\n","date":"2017-03-02T23:10:19Z","permalink":"https://lxb.wiki/b12cd95a/","title":"STL 的 erase( ) 陷阱-迭代器失效总结"},{"content":"使用GDB 一般来说GDB主要调试的是C/C++的程序。要调试C/C++的程序，首先在编译时，我们必须要把调试信息加到可执行文件中。使用编译器（cc/gcc/g++）的 -g 参数可以做到这一点。如：\n$gcc -g -Wall hello.c -o hello $g++ -g -Wall hello.cpp -o hello 如果没有-g，你将看不见程序的函数名、变量名，所代替的全是运行时的内存地址。当你用-g把调试信息加入之后，并成功编译目标代码以后，让我们来看看如何用gdb来调试他。 启动GDB的方法有以下几种： gdb \u0026lt;program\u0026gt; program也就是你的执行文件，一般在当前目录下。 gdb \u0026lt;program\u0026gt; core 用gdb同时调试一个运行程序和core文件，core是程序非法执行后core dump后产生的文件。 gdb \u0026lt;program\u0026gt; \u0026lt;pid\u0026gt; 如果你的程序是一个服务程序，那么你可以指定这个服务程序运行时的进程ID。gdb会自动attach上去，并调试他。program应该在PATH环境变量中搜索得到。 以上三种都是进入gdb环境和加载被调试程序同时进行的。也可以先进入gdb环境，在加载被调试程序，方法如下：\n*在终端输入：gdb *在gdb环境中：file \u0026lt;program\u0026gt; 这两步等价于：gdb \u0026lt;program\u0026gt; GDB启动时，可以加上一些GDB的启动开关，详细的开关可以用gdb -help查看。我在下面只例举一些比较常用的参数：\n-symbols \u0026lt;file\u0026gt; -s \u0026lt;file\u0026gt; 从指定文件中读取符号表。 -se file 从指定文件中读取符号表信息，并把他用在可执行文件中。 -core \u0026lt;file\u0026gt; -c \u0026lt;file\u0026gt; 调试时core dump的core文件。 -directory \u0026lt;directory\u0026gt; -d \u0026lt;directory\u0026gt; 加入一个源文件的搜索路径。默认搜索路径是环境变量中PATH所定义的路径。 ```\u0026lt;/directory\u0026gt;\u0026lt;/directory\u0026gt;\u0026lt;/file\u0026gt;\u0026lt;/file\u0026gt;\u0026lt;/file\u0026gt;\u0026lt;/file\u0026gt;\u0026lt;/program\u0026gt;\u0026lt;/program\u0026gt;\u0026lt;/pid\u0026gt;\u0026lt;/program\u0026gt;\u0026lt;/program\u0026gt;\u0026lt;/program\u0026gt; ###GDB的命令概貌 启动gdb后，你就被带入gdb的调试环境中，就可以使用gdb的命令开始调试程序了，gdb的命令可以使用help命令来查看，如下所示： ```bash $ gdb GNU gdb 6.7.1-debian Copyright (C) 2007 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;http: gnu.org=\u0026#34;\u0026#34; licenses=\u0026#34;\u0026#34; gpl.html=\u0026#34;\u0026#34;\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \u0026#34;show copying\u0026#34; and \u0026#34;show warranty\u0026#34; for details. This GDB was configured as \u0026#34;i486-linux-gnu\u0026#34;. (gdb) help List of classes of commands:\u0026lt;/http:\u0026gt; aliases -- Aliases of other commands breakpoints -- Making program stop at certain points data -- Examining data files -- Specifying and examining files internals -- Maintenance commands obscure -- Obscure features running -- Running the program stack -- Examining the stack status -- Status inquiries support -- Support facilities tracepoints -- Tracing of program execution without stopping the program user-defined -- User-defined commands Type \u0026#34;help\u0026#34; followed by a class name for a list of commands in that class. Type \u0026#34;help all\u0026#34; for the list of all commands. Type \u0026#34;help\u0026#34; followed by command name for full documentation. Type \u0026#34;apropos word\u0026#34; to search for commands related to \u0026#34;word\u0026#34;. Command name abbreviations are allowed if unambiguous. (gdb) gdb 的命令很多，gdb把之分成许多个种类。help命令只是例出gdb的命令种类，如果要看种类中的命令，可以使用help \u0026lt;class\u0026gt;命令，如：help breakpoints，查看设置断点的所有命令。也可以直接help \u0026lt;command\u0026gt;\u0026lt;/command\u0026gt;来查看命令的帮助。 gdb中，输入命令时，可以不用打全命令，只用打命令的前几个字符就可以了，当然，命令的前几个字符应该要标志着一个唯一的命令，在Linux下，你可以敲击两次TAB键来补齐命令的全称，如果有重复的，那么gdb会把其列出来。\n示例一：在进入函数func时，设置一个断点。可以敲入break func，或是直接就是b func\n(gdb) b func Breakpoint 1 at 0x804837a: file tst.c, line 5. 示例二：敲入b按两次TAB键，你会看到所有b打头的命令：\n(gdb) b backtrace break bt (gdb) 示例三：只记得函数的前缀，可以这样：\n(gdb) b make_ \u0026amp;lt;按TAB键\u0026amp;gt; （再按下一次TAB键，你会看到:） make_a_section_from_file make_environ make_abs_section make_function_type make_blockvector make_pointer_type make_cleanup make_reference_type make_command make_symbol_completion_list (gdb) b make_ GDB把所有make开头的函数全部列出来给你查看。 示例四：调试C++的程序时，有可以函数名一样。如：\n(gdb) b \u0026#39;bubble( M-? bubble(double,double) bubble(int,int) (gdb) b \u0026#39;bubble( 你可以查看到C++中的所有的重载函数及参数。（注：M-?和“按两次TAB键”是一个意思） 要退出gdb时，只用发quit或命令简称q就行了\nGDB中运行UNIX的shell程序 在gdb环境中，你可以执行UNIX的shell的命令，使用gdb的shell命令来完成： shell \u0026lt;command string=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/command\u0026gt; 调用UNIX的shell来执行\u0026lt;command string=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/command\u0026gt;，环境变量SHELL中定义的UNIX的shell将会被用来执行\u0026lt;command string=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/command\u0026gt;，如果SHELL没有定义，那就使用UNIX的标准shell：/bin/sh。（在Windows中使用Command.com或cmd.exe） 还有一个gdb命令是make： make \u0026lt;make-args\u0026gt; 可以在gdb中执行make命令来重新build自己的程序。这个命令等价于shell make \u0026lt;make-args\u0026gt;。\n在GDB中运行程序 当以gdb \u0026lt;program\u0026gt;方式启动gdb后，gdb会在PATH路径和当前目录中搜索\u0026lt;program\u0026gt;的源文件。如要确认gdb是否读到源文件，可使用l或list命令，看看gdb是否能列出源代码。 在gdb中，运行程序使用r或是run命令。程序的运行，你有可能需要设置下面四方面的事。 1、程序运行参数。 set args 可指定运行时参数。（如：set args 10 20 30 40 50） show args 命令可以查看设置好的运行参数。 2、运行环境。 `path\n可设定程序的运行路径。 show paths 查看程序的运行路径。 set environment varname [=value] 设置环境变量。如：set env USER=hchen show environment [varname] 查看环境变量。 **3、工作目录。**cd\n` 相当于shell的cd命令。 pwd 显示当前的所在目录。 4、程序的输入输出。 info terminal 显示你程序用到的终端的模式。 使用重定向控制程序输出。如：run \u0026gt; outfile tty命令可以指写输入输出的终端设备。如：tty /dev/ttyb\n调试已运行的程序 两种方法： 1. 在UNIX下用ps查看正在运行的程序的PID（进程ID），然后用gdb \u0026lt;program\u0026gt; PID格式挂接正在运行的程序。 2. 先用gdb \u0026lt;program\u0026gt;关联上源代码，并进行gdb，在gdb中用attach命令来挂接进程的PID。并用detach来取消挂接的进程。\n暂停/恢复程序运行 调试程序中，暂停程序运行是必须的，GDB可以方便地暂停程序的运行。你可以设置程序的在哪行停住，在什么条件下停住，在收到什么信号时停往等等。以便于你查看运行时的变量，以及运行时的流程。 当进程被gdb停住时，你可以使用info program 来查看程序的是否在运行，进程号，被暂停的原因。 在gdb中，我们可以有以下几种暂停方式：断点（BreakPoint）、观察点（Watch Point）、捕捉点（Catch Point）、信号（Signals）、线程停止（Thread Stops）。如果要恢复程序运行，可以使用c或是 continue命令。\n下面为重要的使用步骤, 只摘抄了部分必要的信息, 如设置断点, 查看栈信息, 其余操作, 可以在wiki.ubuntu查看\n设置断点（Break Points） 我们用break命令来设置断点。下面有几点设置断点的方法： break \u0026lt;function\u0026gt; 在进入指定函数时停住。C++中可以使用class::function或function(type,type)格式来指定函数名。 break \u0026lt;linenum\u0026gt; 在指定行号停住。 break +offset break -offset 在当前行号的前面或后面的offset行停住。offiset为自然数。 break filename：linenum 在源文件filename的linenum行处停住。 break filename：function 在源文件filename的function函数的入口处停住。 break *address 在程序运行的内存地址处停住。 break break命令没有参数时，表示在下一条指令处停住。 break ... if \u0026lt;condition\u0026gt; \u0026hellip;可以是上述的参数，condition表示条件，在条件成立时停住。比如在循环体中，可以设置break if i==100，表示当i为100时停住程序。 查看断点时，可使用info命令，如下所示：（注：n表示断点号） info breakpoints [n] info break [n]\n维护停止点 上面说了如何设置程序的停止点，GDB中的停止点也就是上述的三类。在GDB中，如果你觉得已定义好的停止点没有用了，你可以使用delete、clear、disable、enable这几个命令来进行维护。 clear 清除所有的已定义的停止点。 clear \u0026lt;function\u0026gt; clear \u0026lt;filename：function\u0026gt; 清除所有设置在函数上的停止点。 clear \u0026lt;linenum\u0026gt; clear \u0026lt;filename：linenum\u0026gt; 清除所有设置在指定行上的停止点。 delete [breakpoints] [range...] 删除指定的断点，breakpoints为断点号。如果不指定断点号，则表示删除所有的断点。range 表示断点号的范围（如：3-7）。其简写命令为d。\u0026lt;/filename：linenum\u0026gt;\u0026lt;/filename：function\u0026gt;\n比删除更好的一种方法是disable停止点，disable了的停止点，GDB不会删除，当你还需要时，enable即可，就好像回收站一样。 disable [breakpoints] [range...] disable所指定的停止点，breakpoints为停止点号。如果什么都不指定，表示disable所有的停止点。简写命令是dis. enable [breakpoints] [range...] enable所指定的停止点，breakpoints为停止点号。 enable [breakpoints] once range... enable所指定的停止点一次，当程序停止后，该停止点马上被GDB自动disable。 enable [breakpoints] delete range... enable所指定的停止点一次，当程序停止后，该停止点马上被GDB自动删除。\n恢复程序运行和单步调试 当程序被停住了，你可以用continue命令恢复程序的运行直到程序结束，或下一个断点到来。也可以使用step或next命令单步跟踪程序。 continue [ignore-count] c [ignore-count] fg [ignore-count] 恢复程序运行，直到程序结束，或是下一个断点到来。ignore-count表示忽略其后的断点次数。continue，c，fg三个命令都是一样的意思。 step \u0026lt;count\u0026gt; 单步跟踪，如果有函数调用，他会进入该函数。进入函数的前提是，此函数被编译有debug信息。很像VC等工具中的step in。后面可以加count也可以不加，不加表示一条条地执行，加表示执行后面的count条指令，然后再停住。 next \u0026lt;count\u0026gt; 同样单步跟踪，如果有函数调用，他不会进入该函数。很像VC等工具中的step over。后面可以加count也可以不加，不加表示一条条地执行，加表示执行后面的count条指令，然后再停住。 set step-mode set step-mode on 打开step-mode模式，于是，在进行单步跟踪时，程序不会因为没有debug信息而不停住。这个参数很有利于查看机器码。 set step-mode off 关闭step-mode模式。 finish 运行程序，直到当前函数完成返回。并打印函数返回时的堆栈地址和返回值及参数值等信息。 until 或 u 当你厌倦了在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环体。 stepi 或 si nexti 或 ni 单步跟踪一条机器指令！一条程序代码有可能由数条机器指令完成，stepi和nexti可以单步执行机器指令。与之一样有相同功能的命令是“display/i $pc” ，当运行完这个命令后，单步跟踪会在打出程序代码的同时打出机器指令（也就是汇编代码）\n查看栈信息 当程序被停住了，你需要做的第一件事就是查看程序是在哪里停住的。当你的程序调用了一个函数，函数的地址，函数参数，函数内的局部变量都会被压入“栈”（Stack）中。你可以用GDB命令来查看当前的栈中的信息。 下面是一些查看函数调用栈信息的GDB命令： backtrace bt 打印当前的函数调用栈的所有信息。如：\n(gdb) bt #0 func (n=250) at tst.c:6 #1 0x08048524 in main (argc=1, argv=0xbffff674) at tst.c:30 #2 0x400409ed in __libc_start_main () from /lib/libc.so.6 从上可以看出函数的调用栈信息：__libc_start_main --\u0026amp;gt; main() --\u0026amp;gt; func()\nbacktrace \u0026lt;n\u0026gt; bt \u0026lt;n\u0026gt; n是一个正整数，表示只打印栈顶上n层的栈信息。 backtrace \u0026amp;lt;-n\u0026amp;gt; bt \u0026amp;lt;-n\u0026amp;gt; -n表一个负整数，表示只打印栈底下n层的栈信息。 如果你要查看某一层的信息，你需要切换当前栈，一般来说，程序停止时，最顶层的栈就是当前栈，如果你要查看栈下面层的详细信息，首先要做的是切换当前栈。 frame \u0026lt;n\u0026gt; f \u0026lt;n\u0026gt; n是一个从0开始的整数，是栈中的层编号。比如：frame 0，表示栈顶，frame 1，表示栈的第二层。 up \u0026lt;n\u0026gt; 表示向栈的上面移动n层，可以不打n，表示向上移动一层。 down \u0026lt;n\u0026gt; 表示向栈的下面移动n层，可以不打n，表示向下移动一层。\n上面的命令，都会打印出移动到的栈层的信息。如果你不想让其打出信息。你可以使用这三个命令： select-frame \u0026lt;n\u0026gt; 对应于 frame 命令。 up-silently \u0026lt;n\u0026gt;对应于 up 命令。 down-silently \u0026lt;n\u0026gt; 对应于 down 命令。 查看当前栈层的信息，你可以用以下GDB命令： frame 或 f 会打印出这些信息：栈的层编号，当前的函数名，函数参数值，函数所在文件及行号，函数执行到的语句。 info frame info f 这个命令会打印出更为详细的当前栈层的信息，只不过，大多数都是运行时的内存地址。比如：函数地址，调用函数的地址，被调用函数的地址，目前的函数是由什么样的程序语言写成的、函数参数地址及值、局部变量的地址等等。如： bash (gdb) info f Stack level 0, frame at 0xbffff5d4: eip = 0x804845d in func (tst.c:6); saved eip 0x8048524 called by frame at 0xbffff60c source language c. Arglist at 0xbffff5d4, args: n=250 Locals at 0xbffff5d4, Previous frame's sp is 0x0 Saved registers: ebp at 0xbffff5d4, eip at 0xbffff5d8\ninfo args 打印出当前函数的参数名及其值。 info locals 打印出当前函数中所有局部变量及其值。 info catch 打印出当前的函数中的异常处理信息。\n","date":"2017-02-23T19:12:02Z","permalink":"https://lxb.wiki/13b68d49/","title":"用GDB调试程序"},{"content":"代码要运行，必须先转成二进制的机器码。这是编译器的任务。\n比如，下面这段源码（假定文件名叫做test.c）。\n#include \u0026lt;stdio.h\u0026gt; int main(void) { fputs(\u0026quot;Hello, world!\\n\u0026quot;, stdout); return 0; } ```\u0026lt;/stdio.h\u0026gt; 要先用编译器处理一下，才能运行。 ```bash $ gcc test.c $ ./a.out Hello, world! 对于复杂的项目，编译过程还必须分成三步。\n$ ./configure $ make $ make install 这些命令到底在干什么？大多数的书籍和资料，都语焉不详，只说这样就可以编译了，没有进一步的解释。\n本文将介绍编译器的工作过程，也就是上面这三个命令各自的任务。我主要参考了Alex Smith的文章《Building C Projects》。需要声明的是，本文主要针对gcc编译器，也就是针对C和C++，不一定适用于其他语言的编译。\n第一步 配置（configure） 编译器在开始工作之前，需要知道当前的系统环境，比如标准库在哪里、软件的安装位置在哪里、需要安装哪些组件等等。这是因为不同计算机的系统环境不一样，通过指定编译参数，编译器就可以灵活适应环境，编译出各种环境都能运行的机器码。这个确定编译参数的步骤，就叫做”配置”（configure）。\n这些配置信息保存在一个配置文件之中，约定俗成是一个叫做configure的脚本文件。通常它是由autoconf工具生成的。编译器通过运行这个脚本，获知编译参数。\nconfigure脚本已经尽量考虑到不同系统的差异，并且对各种编译参数给出了默认值。如果用户的系统环境比较特别，或者有一些特定的需求，就需要手动向configure脚本提供编译参数。\n$ ./configure --prefix=/www --with-mysql\n上面代码是php源码的一种编译配置，用户指定安装后的文件保存在www目录，并且编译时加入mysql模块的支持。\n第二步 确定标准库和头文件的位置 源码肯定会用到标准库函数（standard library）和头文件（header）。它们可以存放在系统的任意目录中，编译器实际上没办法自动检测它们的位置，只有通过配置文件才能知道。\n编译的第二步，就是从配置文件中知道标准库和头文件的位置。一般来说，配置文件会给出一个清单，列出几个具体的目录。等到编译时，编译器就按顺序到这几个目录中，寻找目标。\n第三步 确定依赖关系 对于大型项目来说，源码文件之间往往存在依赖关系，编译器需要确定编译的先后顺序。假定A文件依赖于B文件，编译器应该保证做到下面两点。\n（1）只有在B文件编译完成后，才开始编译A文件。 （2）当B文件发生变化时，A文件会被重新编译。\n编译顺序保存在一个叫做makefile的文件中，里面列出哪个文件先编译，哪个文件后编译。而makefile文件由configure脚本运行生成，这就是为什么编译时configure必须首先运行的原因。\n在确定依赖关系的同时，编译器也确定了，编译时会用到哪些头文件。\n第四步 头文件的预编译（precompilation） 不同的源码文件，可能引用同一个头文件（比如stdio.h）。编译的时候，头文件也必须一起编译。为了节省时间，编译器会在编译源码之前，先编译头文件。这保证了头文件只需编译一次，不必每次用到的时候，都重新编译了。\n不过，并不是头文件的所有内容，都会被预编译。用来声明宏的#define命令，就不会被预编译。\n第五步 预处理（Preprocessing） 预编译完成后，编译器就开始替换掉源码中bash的头文件和宏。以本文开头的那段源码为例，它包含头文件stdio.h，替换后的样子如下。\nextern int fputs(const char *, FILE *); extern FILE *stdout; int main(void) { fputs(\u0026quot;Hello, world!\\n\u0026quot;, stdout); return 0; } 为了便于阅读，上面代码只截取了头文件中与源码相关的那部分，即fputs和FILE的声明，省略了stdio.h的其他部分（因为它们非常长）。另外，上面代码的头文件没有经过预编译，而实际上，插入源码的是预编译后的结果。编译器在这一步还会移除注释。\n这一步称为”预处理”（Preprocessing），因为完成之后，就要开始真正的处理了。\n第六步 编译（Compilation） 预处理之后，编译器就开始生成机器码。对于某些编译器来说，还存在一个中间步骤，会先把源码转为汇编码（assembly），然后再把汇编码转为机器码。\n下面是本文开头的那段源码转成的汇编码。\n```` .file \u0026ldquo;test.c\u0026rdquo; .section .rodata .LC0: .string \u0026ldquo;Hello, world!\\n\u0026rdquo; .text .globl main .type main, @function main: .LFB0: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 movq stdout(%rip), %rax movq %rax, %rcx movl $14, %edx movl $1, %esi movl $.LC0, %edi call fwrite movl $0, %eax popq %rbp .cfi_def_cfa 7, 8 ret .cfi_endproc .LFE0: .size main, .-main .ident \u0026ldquo;GCC: (Debian 4.9.1-19) 4.9.1\u0026rdquo; .section .note.GNU-stack,\u0026quot;\u0026quot;,@progbits ```\n这种转码后的文件称为对象文件（object file）。\n第七步 连接（Linking） 对象文件还不能运行，必须进一步转成可执行文件。如果你仔细看上一步的转码结果，会发现其中引用了stdout函数和fwrite函数。也就是说，程序要正常运行，除了上面的代码以外，还必须有stdout和fwrite这两个函数的代码，它们是由C语言的标准库提供的。\n编译器的下一步工作，就是把外部函数的代码（通常是后缀名为.lib和.a的文件），添加到可执行文件中。这就叫做连接（linking）。这种通过拷贝，将外部函数库添加到可执行文件的方式，叫做静态连接（static linking），后文会提到还有动态连接（dynamic linking）。\nmake命令的作用，就是从第四步头文件预编译开始，一直到做完这一步。\n第八步 安装（Installation） 上一步的连接是在内存中进行的，即编译器在内存中生成了可执行文件。下一步，必须将可执行文件保存到用户事先指定的安装目录。\n表面上，这一步很简单，就是将可执行文件（连带相关的数据文件）拷贝过去就行了。但是实际上，这一步还必须完成创建目录、保存文件、设置权限等步骤。这整个的保存过程就称为”安装”（Installation）。\n第九步 操作系统连接 可执行文件安装后，必须以某种方式通知操作系统，让其知道可以使用这个程序了。比如，我们安装了一个文本阅读程序，往往希望双击txt文件，该程序就会自动运行。\n这就要求在操作系统中，登记这个程序的元数据：文件名、文件描述、关联后缀名等等。Linux系统中，这些信息通常保存在/usr/share/applications目录下的.desktop文件中。另外，在Windows操作系统中，还需要在Start启动菜单中，建立一个快捷方式。\n这些事情就叫做”操作系统连接”。make install命令，就用来完成”安装”和”操作系统连接”这两步。\n第十步 生成安装包 写到这里，源码编译的整个过程就基本完成了。但是只有很少一部分用户，愿意耐着性子，从头到尾做一遍这个过程。事实上，如果你只有源码可以交给用户，他们会认定你是一个不友好的家伙。大部分用户要的是一个二进制的可执行程序，立刻就能运行。这就要求开发者，将上一步生成的可执行文件，做成可以分发的安装包。\n所以，编译器还必须有生成安装包的功能。通常是将可执行文件（连带相关的数据文件），以某种目录结构，保存成压缩文件包，交给用户。\n第十一步 动态连接（Dynamic linking） 正常情况下，到这一步，程序已经可以运行了。至于运行期间（runtime）发生的事情，与编译器一概无关。但是，开发者可以在编译阶段选择可执行文件连接外部函数库的方式，到底是静态连接（编译时连接），还是动态连接（运行时连接）。所以，最后还要提一下，什么叫做动态连接。\n前面已经说过，静态连接就是把外部函数库，拷贝到可执行文件中。这样做的好处是，适用范围比较广，不用担心用户机器缺少某个库文件；缺点是安装包会比较大，而且多个应用程序之间，无法共享库文件。动态连接的做法正好相反，外部函数库不进入安装包，只在运行时动态引用。好处是安装包会比较小，多个应用程序可以共享库文件；缺点是用户必须事先安装好库文件，而且版本和安装位置都必须符合要求，否则就不能正常运行。\n现实中，大部分软件采用动态连接，共享库文件。这种动态共享的库文件，Linux平台是后缀名为.so的文件，Windows平台是.dll文件，Mac平台是.dylib文件。\n","date":"2017-02-09T22:13:33Z","permalink":"https://lxb.wiki/49fab9fa/","title":"编译器工作过程"},{"content":" unordered_map与map的区别 boost::unordered_map， 它与 stl::map的区别就是，stl::map是按照operator\u0026lt;比较判断元素是否相同，以及比较元素的大小，然后选择合适的位置插入到树中。所以，如果对map进行遍历（中序遍历）的话，输出的结果是有序的。顺序就是按照operator\u0026lt; 定义的大小排序。 而boost::unordered_map是计算元素的Hash值，根据Hash值判断元素是否相同。所以，对unordered_map进行遍历，结果是无序的。 用法的区别就是，stl::map 的key需要定义operator\u0026lt; 。 而boost::unordered_map需要定义hash_value函数并且重载operator==。对于内置类型，如string，这些都不用操心。对于自定义的类型做key，就需要自己重载operator== 或者hash_value()了。 最后，说，当不需要结果排好序时，最好用unordered_map。\nlinux下使用 普通的key就不说了和map一样 看一下用sockaddr_in 作为key的方法\n#ifndef CSESSION_H #define CSESSION_H #include \u0026lt;netinet in.h=\u0026quot;\u0026quot;\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;/time.h\u0026gt;\u0026lt;/netinet\u0026gt; \u0026lt;map\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;tr1 unordered_map=\u0026quot;\u0026quot;\u0026gt; //头文件 #include \u0026lt;iostream\u0026gt; using namespace std; using namespace std::tr1; struct Terminal { int nid ; //id the key for terminal sockaddr_in addr; //ip the key for Client time_t tm; //last alive time enTerminalStat enStat;//status Terminal(); ~Terminal(); Terminal \u0026amp;amp;operator =(const Terminal\u0026amp;amp; term); }; struct hash_func //hash 函数 { size_t operator()(const sockaddr_in \u0026amp;amp;addr) const { return addr.sin_port*9999 + addr.sin_addr.s_addr; } }; struct cmp_fun //比较函数 == { bool operator()(const sockaddr_in \u0026amp;amp;addr1, const sockaddr_in \u0026amp;amp;addr2) const { return memcmp(\u0026amp;amp;addr1, \u0026amp;amp;addr2, sizeof(sockaddr_in)) == 0 ? true:false; } }; //typedef unordered_map\u0026lt;int,terminal*\u0026gt; MapTerminal; // Terminal socket 作为key //typedef unordered_map\u0026lt;int,terminal*\u0026gt;::iterator MapTerminal_It; // \u0026lt;/int,terminal*\u0026gt;\u0026lt;/int,terminal*\u0026gt; typedef unordered_map\u0026lt;sockaddr_in, terminal*,hash_func,=\u0026quot;\u0026quot; cmp_fun=\u0026quot;\u0026quot;\u0026gt; MapClientSession; // sockaddr_in作为key typedef unordered_map\u0026lt;sockaddr_in, terminal*,hash_func,=\u0026quot;\u0026quot; cmp_fun=\u0026quot;\u0026quot;\u0026gt;::iterator MapClientSession_It; // \u0026lt;/sockaddr_in,\u0026gt;\u0026lt;/sockaddr_in,\u0026gt; #endif // CSESSION_H operator==有两种方式 一种是\nstruct st { bool operator==(const st \u0026amp;amp;s) const ... }； 另一种就是自定义函数体，代码中\nstruct cmp_fun { bool operator()(...) ... } 必须要自定义operator==和hash_value。 重载operator==是因为，如果两个元素的hash_value的值相同，并不能断定这两个元素就相同，必须再调用operator==。 当然，如果hash_value的值不同，就不需要调用operator==了。\n","date":"2017-01-12T20:05:01Z","permalink":"https://lxb.wiki/d97ca7/","title":"unordered_map笔记"},{"content":"http://www.cplusplus.com/reference/unordered_set/unordered_set/\nunordered_set 模板原型:\ntemplate \u0026lt; class Key, class Hash = hash\u0026lt;key\u0026gt;, class Pred = equal_to\u0026lt;key\u0026gt;, class Alloc = allocator\u0026lt;key\u0026gt; \u0026gt; class unordered_set; 当比较unordered_set中某两个元素时, 先调用hash\u0026lt;key\u0026gt;, 如果hash\u0026lt;key\u0026gt; 不相等, 说明两个元素不同, 如果hash\u0026lt;key\u0026gt; 值相等, 则调用equal_to\u0026lt;key\u0026gt;, 判断两个元素是否完全相等. (Hash函数和Compare函数都可以自定义)\nC++ 11中对unordered_set描述大体如下：无序集合容器（unordered_set）是一个存储唯一(unique，即无重复）的关联容器（Associative container），容器中的元素无特别的秩序关系，该容器允许基于值的快速元素检索，同时也支持正向迭代。 在一个unordered_set内部，元素不会按任何顺序排序，而是通过元素值的hash值将元素分组放置到各个槽(Bucker，也可以译为“桶”），这样就能通过元素值快速访问各个对应的元素（均摊耗时为O（1））。 原型中的Key代表要存储的类型，而hash也就是你的hash函数，equal_to用来判断两个元素是否相等，allocator是内存的分配策略。一般情况下，我们只关心hash和equal_to参数，下面将介绍这两部分。\nhash\u0026lt;key\u0026gt; hash\u0026lt;key\u0026gt;通过相应的hash函数，将传入的参数转换为一个size_t类型值，然后用该值对当前hashtable的bucket取模算得其对应的hash值。而C++标准库，为我们提供了基本数据类型的hash函数：\n/// Primary class template hash. template struct hash; /// Partial specializations for pointer types. template struct hash\u0026lt;\\_Tp*\u0026gt; : public \\_\\_hash\\_base\u0026lt;size\\_t, \\_tp*=\u0026#34;\u0026#34;\u0026gt; { size\\_t operator()(\\_Tp* \\_\\_p) const noexcept { return reinterpret_cast(__p); } }; \u0026lt;/size_t,\u0026gt; // Explicit specializations for integer types. define \\_Cxx\\_hashtable\\_define\\_trivial\\_hash(\\_Tp) \\ ====================================================== template\u0026lt;\u0026gt; \\ struct hash\u0026lt;\\_Tp\u0026gt; : public \\_\\_hash\\_base\u0026lt;size\\_t, \\_tp=\u0026#34;\u0026#34;\u0026gt; \\ { \\ size\\_t \\ operator()(\\_Tp \\_\\_val) const noexcept \\ { return static_cast(__val); } \\ }; \u0026lt;/size_t,\u0026gt; /// Explicit specialization for bool. \\_Cxx\\_hashtable\\_define\\_trivial_hash(bool) /// Explicit specialization for char. \\_Cxx\\_hashtable\\_define\\_trivial_hash(char) /// Explicit specialization for signed char. \\_Cxx\\_hashtable\\_define\\_trivial_hash(signed char) /// Explicit specialization for unsigned char. \\_Cxx\\_hashtable\\_define\\_trivial_hash(unsigned char) /// Explicit specialization for wchar\\_t. \\_Cxx\\_hashtable\\_define\\_trivial\\_hash(wchar_t) /// Explicit specialization for char16\\_t. \\_Cxx\\_hashtable\\_define\\_trivial\\_hash(char16_t) /// Explicit specialization for char32\\_t. \\_Cxx\\_hashtable\\_define\\_trivial\\_hash(char32_t) /// Explicit specialization for short. \\_Cxx\\_hashtable\\_define\\_trivial_hash(short) /// Explicit specialization for int. \\_Cxx\\_hashtable\\_define\\_trivial_hash(int) /// Explicit specialization for long. \\_Cxx\\_hashtable\\_define\\_trivial_hash(long) /// Explicit specialization for long long. \\_Cxx\\_hashtable\\_define\\_trivial_hash(long long) /// Explicit specialization for unsigned short. \\_Cxx\\_hashtable\\_define\\_trivial_hash(unsigned short) /// Explicit specialization for unsigned int. \\_Cxx\\_hashtable\\_define\\_trivial_hash(unsigned int) /// Explicit specialization for unsigned long. \\_Cxx\\_hashtable\\_define\\_trivial_hash(unsigned long) /// Explicit specialization for unsigned long long. \\_Cxx\\_hashtable\\_define\\_trivial_hash(unsigned long long) 对于指针类型，标准库只是单一将地址转换为一个size_t值作为hash值，这里特别需要注意的是char *类型的指针，其标准库提供的hash函数只是将指针所指地址转换为一个sieze_t值，如果，你需要用char *所指的内容做hash，那么，你需要自己写hash函数或者调用系统提供的hash\u0026lt;string\u0026gt;。 标准库为string类型对象提供了一个hash函数，即：Murmur hash，。对于float、double、long double标准库也有相应的hash函数，这里，不做过多的解释，相应的可以参看functional_hash.h头文件。 上述只是介绍了基本数据类型，而在实际应用中，有时，我们需要使用自己写的hash函数，那怎么自定义hash函数？参考标准库基本数据类型的hash函数，我们会发现这些hash函数有个共同的特点：通过定义函数对象，实现相应的hash函数，这也就意味我们可以通过自定义相应的函数对象，来实现自定义hash函数。比如：已知平面上有N，每个点的x轴、y轴范围为[0，100]，现在需要统计有多少个不同点？hash函数设计为：将每个点的x、y值看成是101进制，如下所示:\n#include\u0026lt;bits\\stdc++.h\u0026gt; using namespace std; struct myHash { size_t operator()(pair\u0026lt;int, int\u0026gt; __val) const { return static_cast\u0026lt;size_t\u0026gt;(__val.first * 101 + __val.second); } }; int main() { unordered_set\u0026lt;pair\u0026lt;int, int\u0026gt;, myHash\u0026gt; S; int x, y; while (cin \u0026gt;\u0026gt; x \u0026gt;\u0026gt; y) S.insert(make_pair(x, y)); for (auto it = S.begin(); it != S.end(); ++it) cout \u0026lt;\u0026lt; it-\u0026gt;first \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;second \u0026lt;\u0026lt; endl; return 0; } equal_to\u0026lt;key\u0026gt; 该参数用于实现比较两个关键字是否相等，至于为什么需要这个参数？这里做点解释，前面我们说过，当不同关键字，通过hash函数，可能会得到相同的关键字值，每当我们在unordered_set里面做数据插入、删除时，由于unordered_set关键字唯一性，所以我们得确保唯一性。标准库定义了基本类型的比较函数，而对于自定义的数据类型，我们需要自定义比较函数。这里有两种方法:重载==操作符和使用函数对象，下面是STL中实现equal_to\u0026lt;key\u0026gt;的源代码：\ntemplate\u0026lt;typename _Arg, typename _Result\u0026gt; struct unary_function { /// @c argument_type is the type of the argument typedef _Arg argument_type; /// @c result_type is the return type typedef _Result result_type; }; template\u0026lt;typename _Tp\u0026gt; struct equal_to : public binary_function\u0026lt;_Tp, _Tp, bool\u0026gt; { bool operator()(const _Tp\u0026amp; __x, const _Tp\u0026amp; __y) const { return __x == __y; } }; 扩容与缩容\n在vector中，每当我们插入一个新元素时，如果当前的容量（capacity)已不足，需要向系统申请一个更大的空间，然后将原始数据拷贝到新空间中。这种现象在unordered_set中也存在，比如当前的表长为100，而真实存在表中的数据已经大于1000个元素，此时，每个bucker均摊有10个元素，这样就会影响到unordered_set的存取效率，而标准库通过采用某种策略来对当前空间进行扩容，以此来提高存取效率。当然，这里也存在缩容，原理和扩容类似，不过，需要注意的是，每当unordered_set内部进行一次扩容或者缩容，都需要对表中的数据重新计算，也就是说，扩容或者缩容的时间复杂度至少为。\ncode：\n// unordered_set::find #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;unordered_set\u0026gt; \u0026lt;/unordered_set\u0026gt;\u0026lt;/string\u0026gt;\u0026lt;/iostream\u0026gt; int main () { std::unordered_set\u0026lt;std::string\u0026gt; myset = { \u0026quot;red\u0026quot;,\u0026quot;green\u0026quot;,\u0026quot;blue\u0026quot; }; \u0026lt;/std::string\u0026gt; std::string input; std::cout \u0026amp;lt;\u0026amp;lt; \u0026quot;color? \u0026quot;; getline (std::cin,input); std::unordered_set\u0026lt;std::string\u0026gt;::const_iterator got = myset.find (input); \u0026lt;/std::string\u0026gt; if ( got == myset.end() ) std::cout \u0026amp;lt;\u0026amp;lt; \u0026quot;not found in myset\u0026quot;; else std::cout \u0026amp;lt;\u0026amp;lt; *got \u0026amp;lt;\u0026amp;lt; \u0026quot; is in myset\u0026quot;; std::cout \u0026amp;lt;\u0026amp;lt; std::endl; return 0; } ","date":"2017-01-05T23:14:47Z","permalink":"https://lxb.wiki/14decfad/","title":"unordered_set笔记"},{"content":" 记住阿姆达尔定律： Ahmdal\u0026rsquo;s rule $$Speedup =\\dfrac{ time_{old}}{time_{new}} = \\dfrac{1}{(1-func_{cost})+func_{cost}/func_{speedup}}$$ func_cost是函数func运行时间百分比，func_speedup是你优化函数的运行的系数。 所以，如果你优化了函数TriangleIntersect执行40%的运行时间，使它运行快了近两倍，而你的程序会运行快25%。 这意味着不经常使用的代码不需要做较多优化考虑（或者完全不优化）。 这里有句俗语：让经常执行的路径运行更加高效，而运行稀少的路径正确运行。 代码先保证正确，然后再考虑优化 这并不意味着用8周时间写一个全功能的射线追踪算法，然后用8周时间去优化它。 分多步来做性能优化。 先写正确的代码，当你意识到这个函数可能会被经常调用，进行明显的优化。 然后再寻找算法的瓶颈，并解决（通过优化或者改进算法）。通常，改进算法能显著地改进瓶颈——也许是采用一个你还没有预想到的方法。所有频繁调用的函数，都需要优化。\n我所了解的那些写出非常高效代码的人说，他们优化代码的时间，是写代码时间的两倍。\n跳转和分支执行代价高，如果可能，尽量少用。\n函数调用需要两次跳转，外加栈内存操作。 优先使用迭代而不是递归。 使用内联函数处理短小的函数来消除函数调用开销。 将循环内的函数调用移动到循环外(例如，将for(i=0;i\u0026lt;100;i++) DoSomething();改为DoSomething() { for(i=0;i\u0026lt;100;i++) { … }})。 if…else if…else if…else if…很长的分支链执行到最后的分支需要很多的跳转。如果可能，将其转换为一个switch声明语句，编译器有时候会将其转换为一个表查询单次跳转。如果switch声明不可行，将最常见的场景放在if分支链的最前面。 5. 仔细思考函数下标的顺序。\n两阶或更高阶的数组在内存中还是以一维的方式在存储在内存中，这意味着（对于C/C++数组）array[i][j] 和 array[i][j+1]是相邻的，但是array[i][j] 和array[i+1][j]可能相距很远。 以适当的方式访问存储实际内存中的数据，可以显著地提升你代码的执行效率（有时候可以提升一个数量级甚至更多）。 现代处理器从主内存中加载数据到处理器cache，会加载比单个值更多的数据。该操作会获取请求数据和相邻数据（一个cache行大小）的整块数据。这意味着，一旦array[i][j]已经在处理器cache中，array[i][j+1]很大可能也已经在cache中了，而array[i+1][j]可能还在内存中。 6. 使用指令层的并行机制\n尽管许多程序还是依赖单线程的执行，现代处理器在单核中也提供了不少的并行性。例如：单个CPU可以同时执行4个浮点数乘，等待4个内存请求并执行一个分支预判。 为了最大化利用这种并行性，代码块（在跳转之间的）需要足够的独立指令来允许处理器被充分利用。 考虑展开循环来改进这一点。 这也是使用内联函数的一个好理由。 7. 避免或减少使用本地变量。\n本地变量通常都存储在栈上。不过如果数量比较少，它们可以存储在CPU寄存器中。在这种情况下，函数不但得到了更快访问存储在寄存器中的数据的好处，也避免了初始化一个栈帧的开销。 不要将大量数据转换为全局变量。 8. 减少函数参数的个数。\n和减少使用本地变量的理由一样——它们也是存放在栈上。 9. 通过引用传递结构体而不是传值\n我在射线追踪中还找不到一个场景需要将结构体使用传值方式（包括一些简单结构如：Vector，Point和Color）。 10. 如果你的函数不需要返回值，不要定义。\n尽量避免数据转换。\n整数和浮点数指令通常操作不同的寄存器，所以转换需要进行一次拷贝操作。 短整型（char和short）仍然使用一整个寄存器，并且它们需要被填充为32/64位，然后在存储回内存时需要再次转换为小字节（不过，这个开销一定比一个更大的数据类型的内存开销要多一点）。\n定义C++对象时需要注意。\n使用类初始化而不是使用赋值（Color c(black); 比Color c; c = black;更快）\n使类构造函数尽可能轻量。 尤其是常用的简单类型（比如，color，vector，point等等），这些类经常被复制。 这些默认构造函数通常都是在隐式执行的，这或许不是你所期望的。 使用类初始化列表(Use Color::Color() : r(0), g(0), b(0) {}，而不是初始化函数Color::Color() { r= g = b = 0; } .)\n如果可以的话，使用位移操作\u0026raquo;和\u0026laquo;来代替整数乘除法\n小心使用表查找函数\n许多人都鼓励将复杂的函数（比如：三角函数）转化为使用预编译的查找表。对于射线追踪功能来说，这通常导致了不必要的内存查找，这很昂贵（并不断增长），并且这和计算一个三角函数并从内存中获取值一样快（尤其你考虑到三角查找打乱了cpu的cache存取）。 在其他情况下，查找表会很有用。对于GPU编程通常优先使用表查找而不是复杂函数。\n对大多数类，优先使用+= 、 -= 、 *= 和 /=，而不是使用+ 、 – 、 * 、 和?/\n这些简单操作需要创建一个匿名临时中间变量。 例如：Vector v = Vector(1,0,0) + Vector(0,1,0) + Vector(0,0,1);?创建了五个匿名临时Vector: Vector(1,0,0), Vector(0,1,0), Vector(0,0,1), Vector(1,0,0) + Vector(0,1,0), 和 Vector(1,0,0) + Vector(0,1,0) + Vector(0,0,1). 对上述代码进行简单转换：Vector v(1,0,0); v+= Vector(0,1,0); v+= Vector(0,0,1);仅仅创建了两个临时Vector: Vector(0,1,0) 和 Vector(0,0,1)。这节约了6次函数调用（3次构造函数和3次析构函数）。\n对于基本数据类型，优先使用+?、?-?、??、?和?/，而不是+=?、?-=?、?= 和 /=\n推迟定义本地变量\n定义一个对象变量通常需要调用一次函数（构造函数）。 如果一个变量只在某些情况下需要（例如在一个if声明语句内），仅在其需要的时候定义，这样，构造函数仅在其被使用的时候调用。\n对于对象，使用前缀操作符（++obj），而不是后缀操作符（obj++）\n这在你的射线追踪算法中可能不是一个问题 使用后缀操作符需要执行一次对象拷贝（这也导致了额外的构造和析构函数调用），而前缀的构造函数不需要一个临时的拷贝。\n小心使用模板\n对不同的是实例实现进行不同的优化。 标准模板库已经经过良好的优化，不过我建议你在实现一个交互式射线追踪算法时避免使用它。 使用自己的实现，你知道它如何使用算法，所以你知道如何最有效的实现它。 最重要的是，我的经历告诉我：调试STL库非常低效。通常这也不是一个问题，除非你使用debug版本做性能分析。你会发现STL的构造函数，迭代器和其他一些操作，占用了你15%的运行时间，这会导致你分析性能输出更加费劲。 避免在计算时进行动态内存分配 动态内存对于存储场景和运行期间其他数据都很有用。 但是，在许多（大多数）的系统动态内存分配需要获取控制访问分配器的锁。对于多线程应用程序，现实中使用动态内存由于额外的处理器导致了性能下降，因为需要等待分配器锁和释放内存。 即便对于单线程应用，在堆上分配内存也比在栈上分配内存开销大得多。操作系统还需要执行一些操作来计算并找到适合尺寸的内存块。 找到你系统内存cache的信息并利用它们 如果一个是数据结构正好适合一个cache行，处理整个类从内存中只需要做一次获取操作。 确保所有的数据结构都是cache行大小对齐（如果你的数据结构和一个cache行大小都是128字节，仍有可能因为你的结构体中的一个字节在一个cache行中，而其他127字节在另外一个cahce行中）。 避免不需要的数据初始化 如果你需要初始化一大段的内存，考虑使用memset。 尽早结束循环和尽早返回函数调用 考虑一个射线和三角形交叉，通常的情况是射线会越过三角，所以这里可以优化。 如果你决定将射线和三角面板交叉。如果射线和面板交叉t值是负数，你可以立即返回。这允许你跳过射线三角交叉一大半的质心坐标计算。这是一个大的节约，一旦你知道这个交叉不存在，你就应该立即返回交叉计算函数。 同样的，一些循环也应该尽早结束。例如，当设置阴影射线，对于近处的交叉通常都是不必须的，一旦有类似的的交叉，交叉计算就应该尽早返回。（这里的交叉含义不太明白，可能是专业词汇，译者注） 在稿纸上简化你的方程式 许多方程式中，通常都可以或者在某些条件中取消计算。 编译器不能发现这些简化，但是你可以。取消一个内部循环的一些昂贵操作可以抵消你在其他地方的好几天的优化工作。 整数、定点数、32位浮点数和64位双精度数字的数学运算差异，没有你想象的那么大 在现代CPU，浮点数运算和整数运算差不多拥有同样的效率。在计算密集型应用（比如射线追踪），这意味这可以忽略整数和浮点数计算的开销差异。这也就是说，你不必要对算数进行整数处理优化。 双精度浮点数运算也不比单精度浮点数运算更慢，尤其是在64位机器上。我在同一台机器测试射线追踪算法全部使用double比全部使用floats运行有时候更快，反过来测试也看到了一样的现象（这里的原文是：I have seen ray tracers run faster using all doubles than all floats on the same machine. I have also seen the reverse）。 不断改进你的数学计算，以消除昂贵的操作 sqrt()经常可以被优化掉，尤其是在比较两个值的平方根是否一致时。 如果你重复地需要处理 除x 操作，考虑计算1/x的值，乘以它。这在向量规范化（3次除法）运算中赢得了大的改进，不过我最近发现也有点难以确定的。不过，这仍然有所改进，如果你要进行三次或更多除法运算。 如果你在执行一个循环，那些在循环中执行不发生变化的部分，确保提取到循环外部。 考虑看看你的计算值是否可以在循环中修改得到（而不每次都重新开始循环计算）。 ","date":"2016-12-17T22:02:36Z","permalink":"https://lxb.wiki/8e72ff9a/","title":"c++代码优化建议"},{"content":"C的表达式 x == x，何时为假呢？即下面的代码：\nif (x == x) { printf(\u0026quot;Equal\\n\u0026quot;); } else { printf(\u0026quot;Not equal\\n\u0026quot;); } 什么时候输出为\u0026quot;Not equal\u0026quot;呢？\n#include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt;\u0026lt;/string.h\u0026gt;\u0026lt;/stdio.h\u0026gt;\u0026lt;/stdlib.h\u0026gt; int main(void) { float x = 0xffffffff; if (x == x) { printf(\u0026quot;Equal\\n\u0026quot;); } else { printf(\u0026quot;Not equal\\n\u0026quot;); } if (x \u0026amp;gt;= 0) { printf(\u0026quot;x(%f) \u0026amp;gt;= 0\\n\u0026quot;, x); } else if (x \u0026amp;lt; 0) { printf(\u0026quot;x(%f) \u0026amp;lt; 0\\n\u0026quot;, x); } int a = 0xffffffff; memcpy(\u0026amp;amp;x, \u0026amp;amp;a, sizeof(x)); if (x == x) { printf(\u0026quot;Equal\\n\u0026quot;); } else { printf(\u0026quot;Not equal\\n\u0026quot;); } if (x \u0026amp;gt;= 0) { printf(\u0026quot;x(%f) \u0026amp;gt;= 0\\n\u0026quot;, x); } else if (x \u0026amp;lt; 0) { printf(\u0026quot;x(%f) \u0026amp;lt; 0\\n\u0026quot;, x); } else { printf(\u0026quot;Surprise x(%f)!!!\\n\u0026quot;, x); } return 0; } 编译gcc -g -Wall test.c，看执行结果：\n$ ./a.out Equal x(4294967296.000000) \u0026amp;gt;= 0 Not equal Surprise x(-nan)!!! 最后两行输出是不是有点surprise啊。\n下面先简单解释一下： 1. 当float x = 0xffffffff：这时将整数赋给一个浮点数，由于float和int的size都是4，而浮点数的存储格式与整数不同，其需要将某些位作为小数位，所以float的范围要小于int的范围。因此这里涉及到了整数转换浮点的规定。因为这个转换其实很少用到，我也就不查了。但是总之，这个转换是合法的。但是最终的值很可能不是你想要的结果——尤其是当浮点的范围小于整数的范围时。 2. 即使整数转换成浮点，数值再不是期望值，但它也一定是一个合法的浮点数值。所以第一个x == x，一定为true，且x不是大于0，就是小于0。这时x存的并不是0xffffffff。 3. 当使用memcpy将0xff填充到x的地址时，这时x存的保证为0xffffffff。但是这个不是一个合法的float的值。因此奇怪的现象发生了，x并不等于x。原因则是与cpu的浮点指令相关. 4. 作为一个非法的float值，当它与其它任何数值比较时，都会返回false。这也就造成了，后面惊奇的结果，x既不大于等于0，也不小于0。\n总结一下：一般来说，浮点类型很少被使用，也不应该在程序中鼓励使用。不仅其效率比整数低，且由于浮点类型特殊的存储格式，很容易造成一些意想不到的错误。如果真的无法避免时，一定要小心小心再小心。特别要注意今天的主题，这种非法的浮点值，会导致任何比较判断都失败。而判断这种浮点值的方法也很简单，如果x != x，那么该浮点即为非法浮点值。\n","date":"2016-11-19T20:40:58Z","permalink":"https://lxb.wiki/72da8a18/","title":"x == x"},{"content":"原文地址 https://segmentfault.com/a/1190000004467381\n最近被一个语法问题缠了半天，终于找到了原因。不仔细思考一下写的时候真的很容易忽略。先看代码：\ntemplate class A { public: const T t = 0;\ntemplate A\u0026amp; operator=(const A\u0026amp; a) { return *this; } };\nint main() { A a, b;\nb = a; // error } 这会带来一个编译错误，然而横睇掂睇都看不出问题。于是我就试了一下这样的代码：A c; b = c;居然通过了编译。F**k，这个模板居然胳膊肘往外拐。\n其实我在写这个代码的时候忽略了一点，就是default assignment operator，它是你在定义类的时候编译器默认给你加上去的，行为是对所有成员变量赋值。它的声明是A\u0026amp; operator=(const A\u0026amp; a);，跟我们自己定义的放在一起：\ntemplate A\u0026amp; operator=(const A\u0026amp; a) { return *this; }\nA\u0026amp; operator=(const A\u0026amp; a) /= delete/; 恰好构成了模板特化，这就糟了。一旦构成了特化，OtherT可以匹配的类型就会除去int，用A赋值时只能调用系统给我们定义的那个。然而它也不起作用，因为成员里面有常量（这样它就会被标记为= delete，留意delete并不会令OtherT可以匹配到int，反而令它匹配不到）。\n知道了原因之后，解决就很方便了，只要重新定义这个默认赋值运算符就好：\nA\u0026amp; operator=(const A\u0026amp; a) { /\u0026hellip;/ }\n","date":"2016-10-29T20:20:32Z","permalink":"https://lxb.wiki/a25c4e07/","title":"C++在重载operator=为带模板的函数的时候的陷阱"},{"content":"关于Makefile怎么写,参考http://blog.csdn.net/haoel/article/details/2886\n一 关于编译和链接\n一般来说，无论是C、C++、还是pas，首先要把源文件编译成中间代码文件，在Windows下是 .obj 文件，UNIX下是 .o 文件，即 Object File，这个动作叫做编译（compile）。然后再把大量的Object File合成执行文件，这个动作叫作链接（link）。\n编译时，编译器需要的是语法的正确，函数与变量的声明的正确。对于后者，通常是你需要告诉编译器头文件的所在位置（头文件中应该只是声明，而定义应该放在C/C++文件中），只要所有的语法正确，编译器就可以编译出中间目标文件。一般来说，每个源文件都应该对应于一个中间目标文件（O文件或是OBJ文件）。\n链接时，主要是链接函数和全局变量，所以，我们可以使用这些中间目标文件（O文件或是OBJ文件）来链接我们的应用程序。链接器并不管函数所在的源文件，只管函数的中间目标文件（Object File），在大多数时候，由于源文件太多，编译生成的中间目标文件太多，而在链接时需要明显地指出中间目标文件名，这对于编译很不方便，所以，我们要给中间目标文件打个包，在Windows下这种包叫“库文件”（Library File)，也就是 .lib 文件，在UNIX下，是Archive File，也就是 .a 文件。\n总结一下，源文件首先会生成中间目标文件，再由中间目标文件生成执行文件。在编译时，编译器只检测程序语法，和函数、变量是否被声明。如果函数未被声明，编译器会给出一个警告，但可以生成Object File。而在链接程序时，链接器会在所有的Object File中找寻函数的实现，如果找不到，那到就会报链接错误码（Linker Error），在VC下，这种错误一般是：Link 2001错误，意思说是说，链接器未能找到函数的实现。你需要指定函数的Object File.\n二 Makefile的规则\n三条:\n1）如果这个工程没有编译过，那么我们的所有C文件都要编译并被链接。 2）如果这个工程的某几个C文件被修改，那么我们只编译被修改的C文件，并链接目标程序。 3）如果这个工程的头文件被改变了，那么我们需要编译引用了这几个头文件的C文件，并链接目标程序。\ntarget \u0026hellip; : prerequisites \u0026hellip; command \u0026hellip; \u0026hellip;\ntarget也就是一个目标文件，可以是Object File，也可以是执行文件,还可以是一个标签（Label）.\nprerequisites就是，要生成那个target所需要的东西(文件或是目标)。\ncommand也就是make需要执行的命令。（任意的Shell命令）\n这是一个文件的依赖关系，也就是说，target这一个或多个的目标文件依赖于prerequisites中的文件，其生成规则定义在command中。说白一点就是说，prerequisites中如果有一个以上的文件比target文件要新的话，command所定义的命令就会被执行。这就是Makefile的规则。也就是Makefile中最核心的内容。\nFor example:\nedit : main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.o cc -o edit main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.o\nmain.o : main.c defs.h cc -c main.c kbd.o : kbd.c defs.h command.h cc -c kbd.c command.o : command.c defs.h command.h cc -c command.c display.o : display.c defs.h buffer.h cc -c display.c insert.o : insert.c defs.h buffer.h cc -c insert.c search.o : search.c defs.h buffer.h cc -c search.c files.o : files.c defs.h buffer.h command.h cc -c files.c utils.o : utils.c defs.h cc -c utils.c clean : rm edit main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.o\n在定义好依赖关系后，后续的那一行定义了如何生成目标文件的操作系统命令，一定要以一个[Tab]键作为开头(在Makefile中的命令，必须要以[Tab]键开始)。make并不管命令是怎么工作的，它只管执行所定义的命令。make会比较targets文件和prerequisites文件的修改日期，如果prerequisites文件的日期要比targets文件的日期要新，或者target不存在的话，make就会执行后续定义的命令。\nclean不是一个文件，它只不过是一个动作名字，有点像C语言中的lable一样，如果其冒号后什么也没有，那么make就不会自动去找文件的依赖性，也就不会自动执行其后所定义的命令。要执行其后的命令，就要在make命令后明显得指出这个lable的名字。这样的方法非常有用，我们可以在一个makefile中定义不用的编译或是和编译无关的命令，比如程序的打包，程序的备份，等等。\n三 Makefile里有什么\n1 显示规则\n2 隐晦规则\n3 变量的定义\n4 文件指示: 其包括了三个部分，一个是在一个Makefile中引用另一个Makefile，就像C语言中的include一样；另一个是指根据某些情况指定Makefile中的有效部分，就像C语言中的预编译#if一样；还有就是定义一个多行的命令。\n5 注释: Makefile中只有行注释，和UNIX的Shell脚本一样，其注释是用“#”字符，这个就像C/C++中的“//”一样。如果你要在你的Makefile中使用“#”字符，可以用反斜框进行转义，如：“#”。\n四 Makefile的文件名\n默认情况下，make命令会在当前目录下按顺序找寻文件名为“GNUmakefile”、“makefile”、“Makefile”的文件，找到了就解释这个文件。在这三个文件名中，最好使用“Makefile”这个文件名，因为这个文件名第一个字符为大写，这样有一种显目的感觉。最好不要用“GNUmakefile”，这个文件是GNU的make识别的。有另外一些make只对全小写的“makefile”文件名敏感，但是基本上来说，大多数的make都支持“makefile”和“Makefile”这两种默认文件名。\n当然，也可以使用别的文件名来书写Makefile，比如：“Make.Linux”，“Make.Solaris”，“Make.AIX”等，如果要指定特定的Makefile，可以使用make的“-f”和“\u0026ndash;file”参数，如：make -f Make.Linux或make \u0026ndash;file Make.AIX。\n五 引用其它的Makefile\ninclude的语法是：\ninclude\nfilename可以是当前操作系统Shell的文件模式（可以保含路径和通配符）\n在include前面可以有一些空字符，但是绝不能是[Tab]键开始。include和可以用一个或多个空格隔开。例如,有这样几个Makefile：a.mk、b.mk、c.mk，还有一个文件叫foo.make，以及一个变量$(bar)，其包含了e.mk和f.mk，那么，下面的语句：\ninclude foo.make *.mk $(bar)\n等价于：\ninclude foo.make a.mk b.mk c.mk e.mk f.mk\nmake命令开始时，会把找寻include所指出的其它Makefile，并把其内容安置在当前的位置。就好像C/C++的#include指令一样。如果文件都没有指定绝对路径或是相对路径的话，make会在当前目录下首先寻找，如果当前目录下没有找到，那么，make还会在下面的几个目录下找：\n1、如果make执行时，有“-I”或“\u0026ndash;include-dir”参数，那么make就会在这个参数所指定的目录下去寻找。 2、如果目录/include（一般是：/usr/local/bin或/usr/include）存在的话，make也会去找。\n如果有文件没有找到的话，make会生成一条警告信息，但不会马上出现致命错误。它会继续载入其它的文件，一旦完成makefile的读取，make会再重试这些没有找到，或是不能读取的文件，如果还是不行，make才会出现一条致命信息。如果你想让make不理那些无法读取的文件，而继续执行，你可以在include前加一个减号“-”。如：\n-include 其表示，无论include过程中出现什么错误，都不要报错继续执行。和其它版本make兼容的相关命令是sinclude，其作用和这一个是一样的。\n六 环境变量 MAKEFILES\n如果当前环境中定义了环境变量MAKEFILES，那么，make会把这个变量中的值做一个类似于include的动作。这个变量中的值是其它的Makefile，用空格分隔。只是，它和include不同的是，从这个环境变量中引入的Makefile的“目标”不会起作用，如果环境变量中定义的文件发现错误，make也会不理。\n但是在这里还是建议不要使用这个环境变量，因为只要这个变量一被定义，那么当使用make时，所有的Makefile都会受到它的影响，这绝不是想看到的。在这里提这个事，只是为了告诉大家，也许有时候你的Makefile出现了怪事，那么你可以看看当前环境中有没有定义这个变量。\n当make嵌套调用时（参见前面的“嵌套调用”章节），上层Makefile中定义的变量会以系统环境变量的方式传递到下层的Makefile中。当然，默认情况下，只有通过命令行设置的变量会被传递。而定义在文件中的变量，如果要向下层Makefile传递，则需要使用exprot关键字来声明.\n七 关于命令\n通常，make会把其要执行的命令行在命令执行前输出到屏幕上。当我们用“@”字符在命令行前，那么，这个命令将不被make显示出来，最具代表性的例子是，我们用这个功能来像屏幕显示一些信息。如：\n@echo 正在编译XXX模块\u0026hellip;\u0026hellip;\n当make执行时，会输出“正在编译XXX模块\u0026hellip;\u0026hellip;”字串，但不会输出命令，如果没有“@”，那么，make将输出：\necho 正在编译XXX模块\u0026hellip;\u0026hellip; 正在编译XXX模块\u0026hellip;\u0026hellip;\n如果make执行时，带入make参数“-n”或“\u0026ndash;just-print”，那么其只是显示命令，但不会执行命令，这个功能很有利于调试Makefile，看看书写的命令执行起来是什么样子的或是什么顺序的,而make参数“-s”或“\u0026ndash;slient”则是全面禁止命令的显示。\n如果要让上一条命令的结果应用在下一条命令时，应该使用分号分隔这两条命令。比如第一条命令是cd，希望第二条命令在cd之后的基础上运行，那么就不能把这两条命令写在两行上，而应该把这两条命令写在一行上，用分号分隔。如：\n示例一： exec: cd /home/hchen pwd\n示例二： exec: cd /home/hchen; pwd\n当执行“make exec”时，第一个例子中的cd没有作用，pwd会打印出当前的Makefile目录，而第二个例子中，cd就起作用了，pwd会打印出“/home/hchen”。\n每当命令运行完后，make会检测每个命令的返回码，如果命令返回成功，那么make会执行下一条命令，当规则中所有的命令成功返回后，这个规则就算是成功完成了。如果一个规则中的某个命令出错了（命令退出码非零），那么make就会终止执行当前规则，这将有可能终止所有规则的执行。\n有些时候，命令的出错并不表示就是错误的。例如mkdir，如果目录不存在，那么mkdir就成功执行，万事大吉，如果目录存在，那么就出错了。之所以使用mkdir的意思就是一定要有这样的一个目录，只要这个目录存在了,就不希望mkdir出错而终止规则的运行。为了做到这一点，忽略命令的出错，可以在Makefile的命令行前加一个减号“-”（在Tab键之后），标记为不管命令出不出错都认为是成功的。如：\nclean: -rm -f *.o\n还有一个全局的办法是，给make加上“-i”或是“\u0026ndash;ignore-errors”参数，那么，Makefile中所有命令都会忽略错误。而如果一个规则是以“.IGNORE”作为目标的，那么这个规则中的所有命令将会忽略错误。还有一个要提一下的make的参数的是“-k”或是“\u0026ndash;keep-going”，这个参数的意思是，如果某规则中的命令出错了，那么就终止该规则的执行，但继续执行其它规则。\n在一些大的工程中，会把不同模块或是不同功能的源文件放在不同的目录中，这种情况可以在每个目录中都书写一个该目录的Makefile，例如，有一个子目录叫subdir，这个目录下有个Makefile文件，来指明了这个目录下文件的编译规则。那么总控的Makefile可以这样书写：\nsubsystem: cd subdir \u0026amp;\u0026amp; $(MAKE)\n其等价于：\nsubsystem: $(MAKE) -C subdir\n这两个例子的意思都是先进入“subdir”目录，然后执行make命令。总控Makefile的变量可以传递到下级的Makefile中，但是不会覆盖下层的Makefile中所定义的变量，除非指定了“-e”参数。\n如果要传递变量到下级Makefile中，那么可以使用这样的声明：\nexport\n如果不想让某些变量传递到下级Makefile中，那么可以这样声明：\nunexport\n如：\n示例一：\nexport variable = value\n其等价于：\nvariable = value export variable\n其等价于：\nexport variable := value\n其等价于：\nvariable := value export variable\n示例二：\nexport variable += value\n其等价于：\nvariable += value export variable\n如果要传递所有的变量，那么，只要一个export就行了,后面什么也不用跟，表示传递所有的变量。\n八 变量\n两种高级用法:\n我们可以替换变量中的共有的部分，其格式是“$(var:a=b)”或是“${var:a=b}”，其意思是，把变量“var”中所有以“a”字串“结尾”的“a”替换成“b”字串。这里的“结尾”意思是“空格”或是“结束符”。\n示例：\nfoo := a.o b.o c.o bar := $(foo:.o=.c)\n这个示例中，我们先定义了一个“$(foo)”变量，而第二行的意思是把“$(foo)”中所有的“.o”字串“结尾”全部替换成“.c”，所以“$(bar)”的值就是“a.c b.c c.c”。\n第二种高级用法是——“把变量的值再当成变量”。先看一个例子：\nx = y y = z a := $($(x))\n在这个例子中，$(x)的值是“y”，所以$($(x))就是$(y)，于是$(a)的值就是“z”。（注意，是“x=y”，而不是“x=$(y)”）\n我们还可以使用更多的层次：\nx = y y = z z = u a := $($($(x)))\n这里的$(a)的值是“u”.\n还有一种设置变量值的方法是使用define关键字。使用define关键字设置变量的值可以有换行，这有利于定义一系列的命令.定义是以endef关键字结束,其工作方式和“=”操作符一样。变量的值可以包含函数、命令、文字，或是其它变量。命令需要以[Tab]键开头，define定义的命令也不例外.\n下面的这个示例展示了define的用法：\ndefine two-lines echo foo echo $(bar) endef\n九 目标变量\n前面所有的在Makefile中定义的变量都是“全局变量”，在整个文件，都可以访问这些变量。当然，“自动化变量”除外，如“$\u0026lt;”等这种类量的自动化变量就属于“规则型变量”，这种变量的值依赖于规则的目标和依赖目标的定义。\n当然，我们同样可以为某个目标设置局部变量，这种变量被称为“Target-specific Variable”，它可以和“全局变量”同名，因为它的作用范围只在这条规则以及连带规则中，所以其值也只在作用范围内有效,而不会影响规则链以外的全局变量的值。\n其语法是：\n:\n: overide\n可以是各种赋值表达式，如“=”、“:=”、“+=”或是“？=”。第二个语法是针对于make命令行带入的变量，或是系统环境变量。\n这个特性非常的有用，当我们设置了这样一个变量，这个变量会作用到由这个目标所引发的所有的规则中去。如：\nprog : CFLAGS = -g prog : prog.o foo.o bar.o $(CC) $(CFLAGS) prog.o foo.o bar.o\nprog.o : prog.c $(CC) $(CFLAGS) prog.c\nfoo.o : foo.c $(CC) $(CFLAGS) foo.c\nbar.o : bar.c $(CC) $(CFLAGS) bar.c\n在这个示例中，不管全局的$(CFLAGS)的值是什么，在prog目标，以及其所引发的所有规则中（prog.o foo.o bar.o的规则），$(CFLAGS)的值都是“-g”.\n十 条件判断语法\n条件表达式的语法为：\nelse endif\n其中表示条件关键字，如“ifeq”。这个关键字有四个。\n第一个是我们前面所见过的“ifeq”\nifeq (, ) ifeq \u0026rsquo;\u0026rsquo; \u0026rsquo;\u0026rsquo; ifeq \u0026quot;\u0026quot; \u0026quot;\u0026quot; ifeq \u0026quot;\u0026quot; \u0026rsquo;\u0026rsquo; ifeq \u0026rsquo;\u0026rsquo; \u0026quot;\u0026quot;\n比较参数“arg1”和“arg2”的值是否相同。当然，参数中我们还可以使用make的函数。如：\nifeq ($(strip $(foo)),) endif\n这个示例中使用了“strip”函数，如果这个函数的返回值是空（Empty），那么就生效。\n第二个条件关键字是“ifneq”。\n第三个条件关键字是“ifdef”。语法是：\nifdef\n如果变量的值非空，那到表达式为真。否则，表达式为假。当然，同样可以是一个函数的返回值。注意，ifdef只是测试一个变量是否有值，其并不会把变量扩展到当前位置。还是来看两个例子：\n示例一： bar = foo = $(bar) ifdef foo frobozz = yes else frobozz = no endif\n示例二： foo = ifdef foo frobozz = yes else frobozz = no endif\n第一个例子中，“$(frobozz)”值是“yes”，第二个则是“no”。\n第四个条件关键字是“ifndef”。\n在这一行上，多余的空格是被允许的，但是不能以[Tab]键做为开始（不然就被认为是命令）。而注释符“#”同样也是安全的。“else”和“endif”也一样，只要不是以[Tab]键开始就行了。\n特别注意的是，make是在读取Makefile时就计算条件表达式的值，并根据条件表达式的值来选择语句，所以，最好不要把自动化变量（如“$@”等）放入条件表达式中，因为自动化变量是在运行时才有的。\n十一 foreach 函数 foreach函数和别的函数非常的不一样。因为这个函数是用来做循环用的，它的语法是：\n$(foreach ,\n\u0026lt;list\u0026gt;,\u0026lt;text\u0026gt;)这个函数的意思是，把参数 \u0026lt;list\u0026gt;中的单词逐一取出放到参数\u0026lt;var\u0026gt;所指定的变量中，然后再执行\u0026lt;text\u0026gt;所包含的表达式。每一次\u0026lt;text\u0026gt;会返回一个字符串，循环过程中，\u0026lt;text\u0026gt;的所返回的每个字符串会以空格分隔，最后当整个循环结束时，\u0026lt;text\u0026gt;所返回的每个字符串所组成的整个字符串（以空格分隔）将会是foreach函数的返回值。\u0026amp;nbsp; \u0026amp;nbsp;所以，\u0026lt;var\u0026gt;最好是一个变量名，\u0026lt;/var\u0026gt; \u0026lt;list\u0026gt;可以是一个表达式，而\u0026lt;text\u0026gt;中一般会使用\u0026lt;var\u0026gt;这个参数来依次枚举 \u0026lt;list\u0026gt;中的单词。举个例子：\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;names := a b c d files := $(foreach n,$(names),$(n).o) $(name)中的单词会被挨个取出，并存到变量“n”中，“$(n).o”每次根据“$(n)”计算出一个值，这些值以空格分隔，最后作为foreach函数的返回，所以，$(files)的值是“a.o b.o c.o d.o”。 十二 检查规则\n有时候，我们不想让我们的makefile中的规则执行起来，只想检查一下命令，或是执行的序列。可以使用make命令的下述参数：\n“-n” “\u0026ndash;just-print” “\u0026ndash;dry-run”\n------------------ “-t” “\u0026ndash;touch” 这个参数的意思就是把目标文件的时间更新，但不更改目标文件。也就是说，make假装编译目标，但不是真正的编译目标，只是把目标变成已编译过的状态。\n“-W ” 这个参数需要指定一个文件。一般是是源文件（或依赖文件），make会根据规则推导来运行依赖于这个文件的命令，一般来说，可以和“-n”参数一同使用，来查看这个依赖文件所发生的规则命令。假定目标需要更新，如果和“-n”选项使用，那么这个参数会输出该目标更新时的运行动作。\n十三 make的其他参数\n“-B” “\u0026ndash;always-make” 认为所有的目标都需要更新（重编译）。\n“-C\n” “\u0026ndash;directory=\n” 指定读取makefile的目录。如果有多个“-C”参数，make的解释是后面的路径以前面的作为相对路径，并以最后的目录作为被指定目录。如：“make –C ~hchen/test –C prog”等价于“make –C ~hchen/test/prog”。\n“-i” “\u0026ndash;ignore-errors” 在执行时忽略所有的错误。\n“-k” “\u0026ndash;keep-going” 出错也不停止运行。如果生成一个目标失败了，那么依赖于其上的目标就不会被执行了。 十四 隐含规则\n在使用Makefile时，有一些会经常使用，而且使用频率非常高的东西，比如，编译C/C++的源程序为中间目标文件（Unix下是[.o]文件，Windows下是[.obj]文件）,这些就是早先约定了的，不需要我们再写出来的规则。\n“隐含规则”也就是一种惯例，make会按照这种“惯例”心照不喧地来运行，即使Makefile中没有书写这样的规则。例如，把[.c]文件编译成[.o]文件这一规则，根本就不用写出来，make会自动推导出这种规则，并生成需要的[.o]文件。\n“隐含规则”会使用一些系统变量，我们可以改变这些系统变量的值来定制隐含规则的运行时的参数。如系统变量“CFLAGS”可以控制编译时的编译器参数。\n1 使用隐含规则\n如果要使用隐含规则生成你需要的目标，你所需要做的就是不要写出这个目标的规则。那么，make会试图去自动推导产生这个目标的规则和命令，如果make可以自动推导生成这个目标的规则和命令，那么这个行为就是隐含规则的自动推导。当然，隐含规则是make事先约定好的一些东西。例如，我们有下面的一个Makefile：\nfoo : foo.o bar.o cc –o foo foo.o bar.o $(CFLAGS) $(LDFLAGS)\n这个Makefile中并没有写下如何生成foo.o和bar.o这两目标的规则和命令。因为make的“隐含规则”功能会自动为我们自动去推导这两个目标的依赖目标和生成命令。\nmake会在自己的“隐含规则”库中寻找可以用的规则，如果找到，那么就会使用。如果找不到，那么就会报错。在上面的那个例子中，make调用的隐含规则是，把[.o]的目标的依赖文件置成[.c]，并使用C的编译命令“cc –c $(CFLAGS) [.c]”来生成[.o]的目标。也就是说，我们完全没有必要写下下面的两条规则：\nfoo.o : foo.c cc –c foo.c $(CFLAGS) bar.o : bar.c cc –c bar.c $(CFLAGS)\n因为，这已经是“约定”好了的事了，make和我们约定好了用C编译器“cc”生成[.o]文件的规则，这就是隐含规则。\n当然，如果我们为[.o]文件书写了自己的规则，那么make就不会自动推导并调用隐含规则，它会按照我们写好的规则忠实地执行。\n还有，在make的“隐含规则库”中，每一条隐含规则都在库中有其顺序，越靠前的则是越被经常使用的，所以，这会导致我们有些时候即使我们显示地指定了目标依赖，make也不会管。如下面这条规则（没有命令）：\nfoo.o : foo.p\n依赖文件“foo.p”（Pascal程序的源文件）有可能变得没有意义。如果目录下存在了“foo.c”文件，那么我们的隐含规则一样会生效，并会通过“foo.c”调用C的编译器生成foo.o文件。因为，在隐含规则中，Pascal的规则出现在C的规则之后，所以，make找到可以生成foo.o的C的规则就不再寻找下一条规则了。如果你确实不希望任何隐含规则推导，那么，你就不要只写出“依赖规则”，而不写命令。当然，我们也可以使用make的参数“-r”或“\u0026ndash;no-builtin-rules”选项来取消所有的预设置的隐含规则。\n1 编译C程序的隐含规则 “.o”的目标的依赖目标会自动推导为“.c”，并且其生成命令是“$(CC) –c $(CPPFLAGS) $(CFLAGS)”\n2 编译C++程序的隐含规则 “.o”的目标的依赖目标会自动推导为“.cc”或是“.C”，并且其生成命令是“$(CXX) –c $(CPPFLAGS) $(CFLAGS)”。（建议使用“.cc”作为C++源文件的后缀，而不是“.C”）\n3 链接Object文件的隐含规则 “”目标依赖于“.o”，通过运行C的编译器来运行链接程序生成（一般是“ld”），其生成命令是：“$(CC) $(LDFLAGS) .o $(LOADLIBES) $(LDLIBS)”。这个规则对于只有一个源文件的工程有效，同时也对多个Object文件（由不同的源文件生成）的也有效。例如如下规则：\nx : y.o z.o\n并且“x.c”、“y.c”和“z.c”都存在时，隐含规则将执行如下命令：\ncc -c x.c -o x.o cc -c y.c -o y.o cc -c z.c -o z.o cc x.o y.o z.o -o x rm -f x.o rm -f y.o rm -f z.o\n如果没有一个源文件（如上例中的x.c）和你的目标名字（如上例中的x）相关联，那么，你最好写出自己的生成规则，不然，隐含规则会报错的。\n","date":"2016-10-09T22:21:25Z","permalink":"https://lxb.wiki/31dc5dc1/","title":"Makefile学习笔记"},{"content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start Create a new post $ hexo new \u0026#34;My New Post\u0026#34; More info: Writing\nRun server $ hexo server More info: Server\nGenerate static files $ hexo generate More info: Generating\nDeploy to remote sites $ hexo deploy More info: Deployment\n","date":"0001-01-01T00:00:00Z","permalink":"https://lxb.wiki/a1751c09/","title":"Hello Hexo"}]