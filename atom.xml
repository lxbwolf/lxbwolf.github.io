<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Gate</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://lxbwolf.github.io/"/>
  <updated>2019-10-04T11:25:07.539Z</updated>
  <id>https://lxbwolf.github.io/</id>
  
  <author>
    <name>Brooke Lau</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Go闭包技术</title>
    <link href="https://lxbwolf.github.io/eb01d7dc/"/>
    <id>https://lxbwolf.github.io/eb01d7dc/</id>
    <published>2019-10-04T11:25:07.000Z</published>
    <updated>2019-10-04T11:25:07.539Z</updated>
    
    <content type="html"><![CDATA[<p>斐波那契数列(Fibonacci sequence),又称黄金分割数列 .因数学家列昂纳多·斐波那契(Leonardoda Fibonacci)以兔子繁殖为例子而引入,故又称为“兔子数列”,指的是这样一个数列: 1、1、2、3、5、8、13、21、34、……在数学上,斐波那契数列以如下被以递推的方法定义: F(1)=1，F(2)=1, F(n)=F(n-1)+F(n-2)（n&gt;=3，n∈N*）<br><img src="https://note.youdao.com/yws/public/resource/723251c4553dc65b7ea84b37b0d5788d/xmlnote/B536914CD0194338915F9A7B18A754D7/1139" alt="fibonacci.png"></p><p>斐波那契数列就是形如 1 1 2 3 5 8 13 21 34 55 的递增数列,从第三项开始起,当前项是前两项之和.<br>为了计算方便,定义两个变量 a,b 表示前两项,初始值分别设置成 0,1 ,示例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 0 1 1 2 3 5 8 13 21 34 55</span><br><span class="line">// a b</span><br><span class="line">// a b</span><br><span class="line">a, b := 0, 1</span><br></pre></td></tr></table></figure><p>初始化后下一轮移动,a, b = b, a+b 结果是 a , b = 1 , 1,刚好能够表示斐波那契数列的开头.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">func fibonacciByNormal() &#123;</span><br><span class="line">    a, b := 0, 1</span><br><span class="line">    a, b = b, a+b</span><br><span class="line">    fmt.Print(a, &quot; &quot;)</span><br><span class="line">    fmt.Println()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是上述示例只能生成斐波那契数列中的第一个数字,假如我们需要前十个数列,又该如何?</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">func fibonacciByNormal() &#123;</span><br><span class="line">    a, b := 0, 1</span><br><span class="line">    for i := 0; i &lt; 10; i++ &#123;</span><br><span class="line">        a, b = b, a+b</span><br><span class="line">        fmt.Print(a, &quot; &quot;)</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过指定循环次数再稍加修改上述单数列代码,现在就可以生成前十位数列:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 1 1 2 3 5 8 13 21 34 55</span><br><span class="line">func TestFibonacciByNormal(t *testing.T) &#123;</span><br><span class="line">    fibonacciByNormal()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种做法是接触闭包概念前我们一直在采用的解决方案,相信稍微有一定编程经验的开发者都能实现,但是闭包却提供了另一种思路!</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 1 1 2 3 5 8 13 21 34 55</span><br><span class="line">func fibonacci() func() int &#123;</span><br><span class="line">    a, b := 0, 1</span><br><span class="line">    return func() int &#123;</span><br><span class="line">        a, b = b, a+b</span><br><span class="line">        return a</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不论是普通函数还是闭包函数,实现斐波那契数列生成器函数的逻辑不变,只是实现不同,闭包返回的是内部函数,留给使用者继续调用而普通函数是直接生成斐波那契数列.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 1 1 2 3 5 8 13 21 34 55</span><br><span class="line">func TestFibonacci(t *testing.T) &#123;</span><br><span class="line">    f := fibonacci()</span><br><span class="line">    for i := 0; i &lt; 10; i++ &#123;</span><br><span class="line">        fmt.Print(f(), &quot; &quot;)</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于这种函数内部嵌套另一个函数并且内部函数引用了外部变量的这种实现方式,称之为”闭包”!</p><p>闭包自带独立的运行环境,每一次运行闭包的环境都是相互独立的,正如面向对象中类和对象实例化的关系那样,闭包是类,闭包的引用是实例化对象.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">func autoIncrease() func() int &#123;</span><br><span class="line">    i := 0</span><br><span class="line">    return func() int &#123;</span><br><span class="line">        i = i + 1</span><br><span class="line">        return i</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述示例是闭包实现的计算器自增,每一次引用 autoIncrease 函数获得的闭包环境都是彼此独立的,直接上单元测试用例.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">func TestAutoIncrease(t *testing.T) &#123;</span><br><span class="line">    a := autoIncrease()</span><br><span class="line">    // 1 2 3</span><br><span class="line">    t.Log(a(), a(), a())</span><br><span class="line">    b := autoIncrease()</span><br><span class="line">    // 1 2 3</span><br><span class="line">    t.Log(b(), b(), b())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>函数引用 a 和 b 的环境是独立的,相当于另一个一模一样计数器重新开始计数,并不会影响原来的计数器的运行结果.</p><p>普通函数内部定义的变量寿命有限,函数运行结束后也就被系统销毁了,结束了自己短暂而又光荣的一生.</p><p>但是,闭包所引用的变量却不一样,只要一直处于使用中状态,那么变量就会”长生不老”,并不会因为出身于函数内就和普通变量拥有一样的短暂人生.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">func fightWithHorse() func() int &#123;</span><br><span class="line">    horseShowTime := 0</span><br><span class="line">    return func() int &#123;</span><br><span class="line">        horseShowTime++</span><br><span class="line">        fmt.Printf(&quot;(%d)祖国需要我,我就提枪上马立即战斗!\n&quot;,horseShowTime)</span><br><span class="line">        return horseShowTime</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func TestFightWithHorse(t *testing.T) &#123;</span><br><span class="line">    f := fightWithHorse()</span><br><span class="line">    // 1 2 3</span><br><span class="line">    t.Log(f(), f(), f())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>凡事有利必有弊,闭包不死则引用变量不灭,如果不理解变量长生不老的特性,编写闭包函数时可能一不小心就掉进作用域陷阱了,千万要小心!<br>下面以绑定循环变量为例讲解闭包作用域的陷阱,示例如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">func countByClosureButWrong() []func() int &#123;</span><br><span class="line">    var arr []func() int</span><br><span class="line"> for i := 1; i &lt;= 3; i++ &#123;</span><br><span class="line">        arr = append(arr, func() int &#123;</span><br><span class="line">            return i</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    return arr</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>countByClosureButWrong 闭包函数引用的自由变量不仅有 arr 数组还有循环变量 i ,函数的整体逻辑是: 闭包函数内部维护一个函数数组,保存的函数主要返回了循环变量.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">func TestCountByClosure(t *testing.T) &#123;</span><br><span class="line">    // 4 4 4</span><br><span class="line">    for _, c := range countByClosureButWrong() &#123;</span><br><span class="line">        t.Log(c())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当我们运行 countByClosureButWrong 函数获得闭包返回的函数数组 arr,然后通过 range 关键字进行遍历数组,得到正在遍历的函数项 c.</p><p>当我们运行 c() 时,期望输出的 1,2,3 循环变量的值,但是实际结果却是 4,4,4.<br><img src="https://note.youdao.com/yws/public/resource/723251c4553dc65b7ea84b37b0d5788d/xmlnote/7BB3368DAC6A4AEB847EAB127682D486/1144" alt></p><p>原因仍然是变量长生不老的特性:遍历循环时绑定的变量值肯定是 1,2,3,但是循环变量 i 却没有像普通函数那样消亡而是一直长生不老,所以变量的引用发生变化了!<br><img src="https://note.youdao.com/yws/public/resource/723251c4553dc65b7ea84b37b0d5788d/xmlnote/C4B872B0C6354133B321806B9AF02F85/1145" alt></p><p>长生不老的循环变量的值刚好是当初循环的终止条件 i=4,只要运行闭包函数,不论是数组中的哪一项函数引用的都是相同的变量 i,所以全部都是 4,4,4.</p><p>既然是变量引用出现问题,那么解决起来就很简单了,不用变量引用就好了嘛!</p><p>最简单的做法就是使用短暂的临时变量 n 暂存起来正在遍历的值,闭包内引用的变量不再是 i 而是临时变量 n.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">func countByClosureButWrong() []func() int &#123;</span><br><span class="line">    var arr []func() int</span><br><span class="line"> for i := 1; i &lt;= 3; i++ &#123;</span><br><span class="line">        n := i</span><br><span class="line">        fmt.Printf(&quot;for i=%d n=%d \n&quot;, i,n)</span><br><span class="line">        arr = append(arr, func() int &#123;</span><br><span class="line">            fmt.Printf(&quot;append i=%d n=%d\n&quot;, i, n)</span><br><span class="line">            return n</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    return arr</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://note.youdao.com/yws/public/resource/723251c4553dc65b7ea84b37b0d5788d/xmlnote/957A722165B94E7785E0AB1DAE3B5B0C/1146" alt></p><p>上述解决办法很简单就是采用临时变量绑定循环变量的值,而不是原来的长生不老的变量引用,但是这种做法不够优雅,还可以继续简化进行版本升级.</p><p>既然是采用变量赋值的做法,是不是和参数传递中的值传递很相像?那我们就可以用值传递的方式重新复制一份变量的值传递给闭包函数.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">func countByClosureWithOk() []func() int &#123;</span><br><span class="line">    var arr []func() int</span><br><span class="line"> for i := 1; i &lt;= 3; i++ &#123;</span><br><span class="line">        fmt.Printf(&quot;for i=%d \n&quot;, i)</span><br><span class="line">        func(n int) &#123;</span><br><span class="line">            arr = append(arr, func() int &#123;</span><br><span class="line">                fmt.Printf(&quot;append n=%d \n&quot;, n)</span><br><span class="line">                return n</span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;(i)</span><br><span class="line">    &#125;</span><br><span class="line">    return arr</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>采用匿名函数进行值传递进行改造后,我们再次运行测试用例验证一下改造结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">func TestCountByClosureWithOk(t *testing.T) &#123;</span><br><span class="line">    // 1 2 3</span><br><span class="line">    for _, c := range countByClosureWithOk() &#123;</span><br><span class="line">        t.Log(c())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>模拟类和对象的关系,也可以实现封装,具备一定面向对象能力<ul><li>每次调用闭包函数所处的环境都是相互独立的,这种特性类似于面向对象中类和实例化对象的关系.</li></ul></li><li>缓存复杂逻辑,常驻内存,避免滥用全局变量徒增维护成本.<ul><li>长生不老的特性使得闭包引用变量可以常驻内存,用于缓存一些复杂逻辑代码非常合适,避免了原来的全局变量的滥用.</li></ul></li><li>实现闭包成本较高,同时也增加了理解难度.<ul><li>普通函数转变成闭包函数不仅实现起来有一定难度,而且理解起来也不容易,不仅要求多测试几遍还要理解闭包的特性.</li></ul></li><li>滥用容易占用过多内存,可能造成内存泄漏.<ul><li>过多使用闭包势必造成引用变量一直常驻内存,如果出现循环引用或者垃圾回收不及时有可能造成内存泄漏问题.</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;斐波那契数列(Fibonacci sequence),又称黄金分割数列 .因数学家列昂纳多·斐波那契(Leonardoda Fibonacci)以兔子繁殖为例子而引入,故又称为“兔子数列”,指的是这样一个数列: 1、1、2、3、5、8、13、21、34、……在数学上,斐波那
      
    
    </summary>
    
    
      <category term="Golang" scheme="https://lxbwolf.github.io/categories/Golang/"/>
    
    
  </entry>
  
  <entry>
    <title>github 博客绑定域名</title>
    <link href="https://lxbwolf.github.io/e9fbcad9/"/>
    <id>https://lxbwolf.github.io/e9fbcad9/</id>
    <published>2019-09-26T16:54:15.000Z</published>
    <updated>2019-10-03T16:52:39.427Z</updated>
    
    <content type="html"><![CDATA[<p>某篇文章说, CNAME 解析只支持 www 不支持@<br>所以@ 只能 解析到一个一个的 IP</p><h4 id="1-source-添加-CNAME-文件"><a href="#1-source-添加-CNAME-文件" class="headerlink" title="1. source 添加 CNAME 文件"></a>1. source 添加 CNAME 文件</h4><p>在源码的<code>source</code> 目录下, 添加一个<code>CNAME</code>文件<br>文件内容为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lxb.wiki</span><br></pre></td></tr></table></figure><h4 id="2-DNS-设置"><a href="#2-DNS-设置" class="headerlink" title="2. DNS 设置"></a>2. DNS 设置</h4><table><thead><tr><th>记录类型</th><th>主机记录</th><th>解析路线(isp)</th><th>记录值</th><th>MX优先级</th><th>TTL</th><th>状态</th><th>操作</th></tr></thead><tbody><tr><td>CNAME</td><td>www</td><td>默认</td><td>lxbwolf.github.io</td><td>–</td><td>10 分钟</td><td>正常</td><td>修改暂停删除备注</td></tr><tr><td>A</td><td>@</td><td>默认</td><td>185.199.108.153</td><td>–</td><td>10 分钟</td><td>正常</td><td>修改暂停删除备注</td></tr><tr><td>A</td><td>@</td><td>默认</td><td>185.199.111.153</td><td>–</td><td>10 分钟</td><td>正常</td><td>修改暂停删除备注</td></tr><tr><td>A</td><td>@</td><td>默认</td><td>185.199.110.153</td><td>–</td><td>10 分钟</td><td>正常</td><td>修改暂停删除备注</td></tr><tr><td>A</td><td>@</td><td>默认</td><td>185.199.109.153</td><td>–</td><td>10 分钟</td><td>正常</td><td>修改暂停删除备注</td></tr></tbody></table><h4 id="3-hexo-部署"><a href="#3-hexo-部署" class="headerlink" title="3. hexo 部署"></a>3. hexo 部署</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;某篇文章说, CNAME 解析只支持 www 不支持@&lt;br&gt;所以@ 只能 解析到一个一个的 IP&lt;/p&gt;
&lt;h4 id=&quot;1-source-添加-CNAME-文件&quot;&gt;&lt;a href=&quot;#1-source-添加-CNAME-文件&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
    
      <category term="Web" scheme="https://lxbwolf.github.io/categories/Web/"/>
    
    
      <category term="博客" scheme="https://lxbwolf.github.io/tags/%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>Hello Hexo</title>
    <link href="https://lxbwolf.github.io/a1751c09/"/>
    <id>https://lxbwolf.github.io/a1751c09/</id>
    <published>2019-09-26T16:14:22.211Z</published>
    <updated>2019-10-03T07:57:15.349Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>xargs</title>
    <link href="https://lxbwolf.github.io/38dfadad/"/>
    <id>https://lxbwolf.github.io/38dfadad/</id>
    <published>2019-08-19T17:14:58.000Z</published>
    <updated>2019-10-03T07:57:15.416Z</updated>
    
    <content type="html"><![CDATA[<p>xargs 是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。</p><p>xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。</p><p>xargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。</p><p>xargs 默认的命令是 echo，这意味着通过管道传递给 xargs 的输入将会包含换行和空白，不过通过 xargs 的处理，换行和空白将被空格取代。</p><p>xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。</p><p>之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了 xargs 命令</p><p>例如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find /sbin -perm 700 |ls -l       #这个命令是错误的</span><br><span class="line">find /sbin -perm 700 |xargs ls -l   #这样才是正确的</span><br></pre></td></tr></table></figure><p><strong>命令格式</strong><br><code>somecommand |xargs -item command</code></p><p><strong>重要参数:</strong></p><ul><li>-i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。</li></ul><p><strong>其他参数:</strong></p><ul><li>-a file 从文件中读入作为sdtin</li><li>-e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。</li><li>-p 当每次执行一个argument的时候询问一次用户。</li><li>-n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。</li><li>-t 表示先打印命令，然后再执行。</li><li>-r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。</li><li>-s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。</li><li>-L num 从标准输入一次读取 num 行送给 command 命令。</li><li>-l 同 -L。</li><li>-d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。</li><li>-x exit的意思，主要是配合-s使用。。</li><li>-P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧。</li></ul><h4 id="实例"><a href="#实例" class="headerlink" title="实例:"></a>实例:</h4><h5 id="1-多行变成单行"><a href="#1-多行变成单行" class="headerlink" title="1. 多行变成单行"></a>1. 多行变成单行</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># cat test.txt</span><br><span class="line"></span><br><span class="line">a b c d e f g</span><br><span class="line">h i j k l m n</span><br><span class="line">o p q</span><br><span class="line">r s t</span><br><span class="line">u v w x y z</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># cat test.txt | xargs</span><br><span class="line">a b c d e f g h i j k l m n o p q r s t u v w x y z</span><br></pre></td></tr></table></figure><h5 id="2-一次使用n个参数"><a href="#2-一次使用n个参数" class="headerlink" title="2. 一次使用n个参数"></a>2. 一次使用n个参数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># cat test.txt | xargs -n3</span><br><span class="line"></span><br><span class="line">a b c</span><br><span class="line">d e f</span><br><span class="line">g h i</span><br><span class="line">j k l</span><br><span class="line">m n o</span><br><span class="line">p q r</span><br><span class="line">s t u</span><br><span class="line">v w x</span><br><span class="line">y z</span><br></pre></td></tr></table></figure><h5 id="3-d选项指定分隔符"><a href="#3-d选项指定分隔符" class="headerlink" title="3. d选项指定分隔符"></a>3. d选项指定分隔符</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># echo &quot;nameXnameXnameXname&quot; | xargs -dX</span><br><span class="line"></span><br><span class="line">name name name name</span><br></pre></td></tr></table></figure><p>结合<code>-n</code> 选项使用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># echo &quot;nameXnameXnameXname&quot; | xargs -dX -n2</span><br><span class="line"></span><br><span class="line">name name</span><br><span class="line">name name</span><br></pre></td></tr></table></figure><h5 id="4-I选项的使用"><a href="#4-I选项的使用" class="headerlink" title="4. I选项的使用"></a>4. I选项的使用</h5><h6 id="4-1-获取参数并替换"><a href="#4-1-获取参数并替换" class="headerlink" title="4.1 获取参数并替换{}"></a>4.1 获取参数并替换<code>{}</code></h6><p>假设一个命令为 <a href="http://sk.sh/" target="_blank" rel="noopener">sk.sh</a> 和一个保存参数的文件 arg.txt：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">#sk.sh命令内容，打印出所有参数。</span><br><span class="line"></span><br><span class="line">echo $*</span><br></pre></td></tr></table></figure><p>arg.txt.文件内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># cat arg.txt</span><br><span class="line"></span><br><span class="line">aaa</span><br><span class="line">bbb</span><br><span class="line">ccc</span><br></pre></td></tr></table></figure><p><code>xargs</code> 的一个选项 <code>-I</code>，使用 <code>-I</code> 指定一个替换字符串 <code>{}</code>，这个字符串在 <code>xargs</code> 扩展时会被替换掉，当 <code>-I</code> 与 <code>xargs</code> 结合使用，每一个参数命令都会被执行一次：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># cat arg.txt | xargs -I &#123;&#125; ./sk.sh sombefore &#123;&#125; someafter</span><br><span class="line"></span><br><span class="line">sombefore aaa someafter</span><br><span class="line">sombefore bbb someafter</span><br><span class="line">sombefore ccc someafter</span><br></pre></td></tr></table></figure><h6 id="4-2-复制文件实例"><a href="#4-2-复制文件实例" class="headerlink" title="4.2 复制文件实例"></a>4.2 复制文件实例</h6><p>复制所有图片文件到 /data/images 目录下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls *.jpg | xargs -n1 -I &#123;&#125; cp &#123;&#125; /data/images/</span><br></pre></td></tr></table></figure><h6 id="4-3-xargs-结合find-使用"><a href="#4-3-xargs-结合find-使用" class="headerlink" title="4.3 xargs 结合find 使用"></a>4.3 xargs 结合find 使用</h6><p>用 rm 删除太多的文件时候，可能得到一个错误信息：<code>/bin/rm Argument list too long.</code> 用 xargs 去避免这个问题：</p><p><code>find . -type f -name &quot;*.log&quot; -print0 | xargs -0 rm -f</code> xargs -0 将 \0 作为定界符。</p><p>统计一个源代码目录中所有 php 文件的行数： <code>find . -type f -name &quot;*.php&quot; -print0 | xargs -0 wc -l</code></p><p>查找所有的 jpg 文件，并且压缩它们： <code>find . -type f -name &quot;*.jpg&quot; -print | xargs tar -czvf images.tar.gz</code></p><h6 id="4-4-下载多个文件"><a href="#4-4-下载多个文件" class="headerlink" title="4.4 下载多个文件"></a>4.4 下载多个文件</h6><p>假如你有一个文件包含了很多你希望下载的 URL，你能够使用 xargs下载所有链接： <code># cat url-list.txt | xargs wget -c</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;xargs 是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。&lt;/p&gt;
&lt;p&gt;xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。&lt;/p&gt;
&lt;p&gt;xargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行
      
    
    </summary>
    
    
      <category term="Shell" scheme="https://lxbwolf.github.io/categories/Shell/"/>
    
    
  </entry>
  
  <entry>
    <title>升级https</title>
    <link href="https://lxbwolf.github.io/ddf7de45/"/>
    <id>https://lxbwolf.github.io/ddf7de45/</id>
    <published>2019-08-07T18:53:34.000Z</published>
    <updated>2019-10-03T16:44:30.044Z</updated>
    
    <content type="html"><![CDATA[<p><em>环境</em></p><pre><code>CentOSnginx</code></pre><h3 id="获取证书"><a href="#获取证书" class="headerlink" title="获取证书"></a>获取证书</h3><p>HTTPS 证书分三类：1. DV 域名验证证书 2. OV 组织机构验证证书 3. EV 增强的组织机构验证证书。每类证书的审核要求不同，在浏览器地址栏也会有区分，对于个人网站而言，使用免费的 DV 证书就足够了。 我使用了大名鼎鼎的 Let’s Encrypt 来生成证书。</p><h4 id="1-安装-certbot"><a href="#1-安装-certbot" class="headerlink" title="1. 安装 certbot"></a>1. 安装 certbot</h4><p>certbot 是 Let’s Encrypt 提供的一套自动化工具。</p><pre><code>yum install epel-releaseyum install certbot</code></pre><h4 id="2-生成证书"><a href="#2-生成证书" class="headerlink" title="2. 生成证书"></a>2. 生成证书</h4><p>这里采用 webroot 作为 Let’s Encrypt 的认证方式。</p><pre><code>certbot certonly -a webroot --webroot-path=/your/project/path -d example.com -d www.example.com</code></pre><p>webroot-path就是项目根路径，使用 -d 可以添加多个域名。这时证书就已经生成成功了，默认保存在 /etc/letsencrypt/live/example.com/ 下。证书文件包括：</p><ul><li>cert.pem: 服务端证书</li><li>chain.pem: 浏览器需要的所有证书但不包括服务端证书，比如根证书和中间证书</li><li>fullchain.pem: 包括了cert.pem和chain.pem的内容</li><li>privkey.pem: 证书私钥</li></ul><h4 id="3-生成迪菲-赫尔曼密钥交换组（-Strong-Diffie-Hellman-Group）"><a href="#3-生成迪菲-赫尔曼密钥交换组（-Strong-Diffie-Hellman-Group）" class="headerlink" title="3. 生成迪菲-赫尔曼密钥交换组（ Strong Diffie-Hellman Group）"></a>3. 生成迪菲-赫尔曼密钥交换组（ Strong Diffie-Hellman Group）</h4><p>为了进一步提高安全性，也可以生成一个 Strong Diffie-Hellman Group。</p><pre><code>openssl dhparam -out /etc/ssl/certs/dhparam.pem 2048</code></pre><h3 id="配置nginx"><a href="#配置nginx" class="headerlink" title="配置nginx"></a>配置nginx</h3><p>编辑 Nginx 配置文件，如果你不知道配置文件在哪，可以用 locate /nginx.conf 命令查找。添加以下内容，具体参数以你的实际情况为准。</p><pre><code>server {        listen 443 ssl;        # 启用http2        # 需要安装 Nginx Http2 Module        # listen 443 http2 ssl;        server_name my_server_name;        #证书文件        ssl_certificate /etc/letsencrypt/live/my_server_name/fullchain.pem;        #私钥文件        ssl_certificate_key /etc/letsencrypt/live/my_server_name/privkey.pem;        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;        # 优先采取服务器算法        ssl_prefer_server_ciphers on;        # 定义算法        ssl_ciphers &amp;quot;EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH&amp;quot;;        ssl_ecdh_curve secp384r1;        ssl_session_cache shared:SSL:10m;        ssl_session_tickets off;        ssl_stapling on;        ssl_stapling_verify on;        resolver 8.8.8.8 8.8.4.4 valid=300s;        resolver_timeout 5s;        add_header Strict-Transport-Security &amp;quot;max-age=63072000; includeSubdomains&amp;quot;;        add_header X-Frame-Options DENY;        add_header X-Content-Type-Options nosniff;        # 使用DH文件        ssl_dhparam /etc/ssl/certs/dhparam.pem;        location ~ /.well-known {            allow all;        }        location ~ \.php$ {            root           my_root;            fastcgi_pass   my_host:my_port;            fastcgi_index  index.php;            fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;            include        fastcgi_params;        }        root my_root;        index index.html index.php;        location / {            root my_root;            autoindex on;            index index.html index.php;            client_max_body_size 1024m;        }}</code></pre><p>其中的几项配置: <code>ssl_stapling on;</code> 开启 OCSP Stapling，使服务端主动获取 OCSP 查询结果并随着证书一起发送给客户端，从而让客户端跳过自己去验证的过程，提高 TLS 握手效率。 <code>add_header Strict-Transport-Security &amp;quot;max-age=63072000; includeSubdomains&amp;quot;;</code> 启用 HSTS 策略，强制浏览器使用 HTTPS 连接，max-age设置单位时间内強制使用 HTTPS 连接；includeSubDomains 可选，设置所有子域同时生效。浏览器在获取该响应头后，在 max-age 的时间内，如果遇到 HTTP 连接，就会通过 307 跳转強制使用 HTTPS 进行连接 <code>add_header X-Frame-Options DENY;</code> 添加 X-Frame-Options 响应头，可以禁止网站被嵌入到 iframe 中，减少点击劫持 (clickjacking)攻击。 <code>add_header X-Content-Type-Options nosniff;</code> 添加 X-Content-Type-Options 响应头，防止 MIME 类型嗅探攻击 测试nginx.conf 是否有语法错误 <code>nginx -t</code> 重启nginx <code>nginx -s reload</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;em&gt;环境&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CentOS
nginx&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;获取证书&quot;&gt;&lt;a href=&quot;#获取证书&quot; class=&quot;headerlink&quot; title=&quot;获取证书&quot;&gt;&lt;/a&gt;获取证书&lt;/h3&gt;&lt;p&gt;HTTPS 证
      
    
    </summary>
    
    
      <category term="Web" scheme="https://lxbwolf.github.io/categories/Web/"/>
    
    
      <category term="https" scheme="https://lxbwolf.github.io/tags/https/"/>
    
  </entry>
  
  <entry>
    <title>docker挂载目录失败/权限拒绝</title>
    <link href="https://lxbwolf.github.io/498654c2/"/>
    <id>https://lxbwolf.github.io/498654c2/</id>
    <published>2019-07-23T09:32:38.000Z</published>
    <updated>2019-10-03T07:57:15.287Z</updated>
    
    <content type="html"><![CDATA[<p>把宿主机的一个目录挂载到容器中的一个目录，当访问容器中的这个目录时，出现如下问题：<br> <code>ls: cannot open directory .: Permission denied</code><br>无法访问目录，权限拒绝。<br>该问题通常在centos7下出现。或者一个容器启动成功后，里面的服务无法成功访问，这是因为centos7中的安全模块selinux把权限禁掉了，一般的解决方案有以下两种：<br>（1）临时关闭selinux<br>直接在centos服务器上执行以下命令即可。执行完成以后建议重新<code>docker run</code>。 <code>setenforce 0</code><br>（2）给容器加权限<br>在<code>docker run</code>时给该容器加权限，加上以下参数即可：<br> <code>--privileged=true</code><br> 一般都推荐使用这种方式。<br> 按上述方法修改后, 如果执行下面命令失败<br> <code>docker run --name rookie-nginx-test -d -p 8082:80 -v ~/nginx/www:/usr/share/nginx/html -v ~/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v ~/nginx/logs:/var/log/nginx -v ~/nginx/conf/conf.d:/etc/nginx/conf.d --link php7-fpm:php nginx</code><br>则是因为<code>~/nginx/www/</code> 目录下没有index 文件导致. 手动创建<code>index.php</code> 文件解决</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;把宿主机的一个目录挂载到容器中的一个目录，当访问容器中的这个目录时，出现如下问题：&lt;br&gt; &lt;code&gt;ls: cannot open directory .: Permission denied&lt;/code&gt;&lt;br&gt;无法访问目录，权限拒绝。&lt;br&gt;该问题通常在centos
      
    
    </summary>
    
    
      <category term="Docker" scheme="https://lxbwolf.github.io/categories/Docker/"/>
    
    
  </entry>
  
  <entry>
    <title>Mac iTerm2登陆CentOS提示warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory</title>
    <link href="https://lxbwolf.github.io/784beb8f/"/>
    <id>https://lxbwolf.github.io/784beb8f/</id>
    <published>2019-07-02T03:48:53.000Z</published>
    <updated>2019-10-03T16:55:28.088Z</updated>
    
    <content type="html"><![CDATA[<p>【报错原因】：没有utf-8这个语系（没添加语言_国名前缀），LC_ALL又没设定值。 <strong>服务端解决方法：</strong> 在远程系统上， <code>/etc/environment</code>加入以下两行，重新登陆即可。</p><pre><code>LANG=en_US.utf-8LC_ALL=en_US.utf-8</code></pre><p><strong>Mac终端解决方法：</strong> 编辑<code>~/.bashrc</code>或者<code>~/.zshrc</code>文件，添加</p><pre><code>export LC_ALL=en_US.UTF-8  export LANG=en_US.UTF-8</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;【报错原因】：没有utf-8这个语系（没添加语言_国名前缀），LC_ALL又没设定值。 &lt;strong&gt;服务端解决方法：&lt;/strong&gt; 在远程系统上， &lt;code&gt;/etc/environment&lt;/code&gt;加入以下两行，重新登陆即可。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
      
    
    </summary>
    
    
      <category term="Tools" scheme="https://lxbwolf.github.io/categories/Tools/"/>
    
    
      <category term="iTerm2" scheme="https://lxbwolf.github.io/tags/iTerm2/"/>
    
  </entry>
  
  <entry>
    <title>升级到php7.1之后wordpress 网站出现Error establishing a database connection的解决方法</title>
    <link href="https://lxbwolf.github.io/b6b408b2/"/>
    <id>https://lxbwolf.github.io/b6b408b2/</id>
    <published>2019-06-12T15:37:00.000Z</published>
    <updated>2019-10-03T16:44:16.932Z</updated>
    
    <content type="html"><![CDATA[<p>现在很多WordPress的插件都推荐将php版本升级到7.0或者7.1以上，于是就折腾了一下把几个blog升级到了7.1.5，升级的过程不难，无非就是额外安装一个php，然后启动自带的配套php-fpm7，然后nginx里location转发到新的php socket文件，这里就不表了。 升级完了，phpinfo()发现一切都正常，但是访问WordPress，却意外提示Error establishing a database connection，但是db的连接信息明明没有问题，经过反复搜索尝试，发现只要将 <code>/usr/share/nginx/html/wp-config.php</code> 文件里的 <code>define(&#39;DB_HOST&#39;, &#39;localhost&#39;);</code> 修改为 <code>define(&#39;DB_HOST&#39;, &#39;127.0.0.1&#39;);</code> 即可解决，猜测原因可能是php7.1中对域的resolve问题 另外, 为了 Debug, 可以把 <code>/usr/share/nginx/html/wp-config.php</code> 的 debug 改为 true <code>define(&#39;WP_DEBUG&#39;, true);</code> 改好了, 再改成 false.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;现在很多WordPress的插件都推荐将php版本升级到7.0或者7.1以上，于是就折腾了一下把几个blog升级到了7.1.5，升级的过程不难，无非就是额外安装一个php，然后启动自带的配套php-fpm7，然后nginx里location转发到新的php socket文件
      
    
    </summary>
    
    
      <category term="Web" scheme="https://lxbwolf.github.io/categories/Web/"/>
    
    
      <category term="wordpress" scheme="https://lxbwolf.github.io/tags/wordpress/"/>
    
  </entry>
  
  <entry>
    <title>date 命令转换时间戳</title>
    <link href="https://lxbwolf.github.io/7b4019ad/"/>
    <id>https://lxbwolf.github.io/7b4019ad/</id>
    <published>2019-06-10T08:59:14.000Z</published>
    <updated>2019-10-03T07:57:15.285Z</updated>
    
    <content type="html"><![CDATA[<p>给定时间戳, 转换成日期<br>网上所有的命令都是<br><code>date -d @$stamp &quot;+%Y-%m-%d&quot;</code><br> 但是一直提示<br> <code>date: invalid date</code>@stamp’<code>带上&quot;@&quot; 符号, 就参数错误 正确使用方法:</code>date -d “1970-01-01 UTC 1287331200 seconds” +%F<code>或者使用awk</code>awk ‘{print strftime(“%Y%m”, 1287331200)}’<code>调用外部命令耗时比较长, 更高效的方法:</code>printf “%(%Y%m)T\n” “$str” &gt;&gt; file<code>如果bash 版本低于4, printf 不支持打印日期格式, 因此使用 下面这个bash</code>/opt/compiler/gcc-4.8.2/bin/bash`</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;给定时间戳, 转换成日期&lt;br&gt;网上所有的命令都是&lt;br&gt;&lt;code&gt;date -d @$stamp &amp;quot;+%Y-%m-%d&amp;quot;&lt;/code&gt;&lt;br&gt; 但是一直提示&lt;br&gt; &lt;code&gt;date: invalid date&lt;/code&gt;@stamp’&lt;cod
      
    
    </summary>
    
    
      <category term="Shell" scheme="https://lxbwolf.github.io/categories/Shell/"/>
    
    
  </entry>
  
  <entry>
    <title>大小端</title>
    <link href="https://lxbwolf.github.io/7ee0edaa/"/>
    <id>https://lxbwolf.github.io/7ee0edaa/</id>
    <published>2019-05-24T10:37:53.000Z</published>
    <updated>2019-10-03T16:46:23.023Z</updated>
    
    <content type="html"><![CDATA[<p>计算机系统中内存是以字节为单位进行编址的，每个地址单元都唯一的对应着1个字节（8 bit）。这可以应对char类型数据的存储要求，因为char类型长度刚好是1个字节，但是有些类型的长度是超过1个字节的（字符串虽然是多字节的，但它本质是由一个个char类型组成的类似数组的结构而已），比如C/C++中，short类型一般是2个字节，int类型一般4个字节等。因此这里就存在着一个如何安排多个字节数据中各字节存放顺序的问题。正是因为不同的安排顺序导致了大端存储模式和小端存储模式的存在。</p><h4 id="1-解释"><a href="#1-解释" class="headerlink" title="1. 解释"></a>1. 解释</h4><p>假如有一个4字节的数据为 0x12 34 56 78（十进制：305419896，0x12为高字节，0x78为低字节），若将其存放于地址 0x4000 8000中，则有：</p><p>内存地址</p><p>0x4000 8000（低地址）</p><p>0x4000 8001</p><p>0x4000 8002</p><p>0x4000 8003（高地址）</p><p>大端模式</p><p>0x12（高字节）</p><p>0x34</p><p>0x56</p><p>0x78（低字节）</p><p>小端模式</p><p>0x78（低字节）</p><p>0x56</p><p>0x34</p><p>0x12（高字节）</p><ul><li>大端模式：是指数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中</li><li>小端模式，是指数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中</li></ul><p>为什么截然相反的大小端存储模式能够并存至今？在标准化备受推崇的今天，为什么大小端谁都没有被另外一个所同化？我想这除了历史的惯性使然，还与它们各自的优缺点有关。 大端模式优点：符号位在所表示的数据的内存的第一个字节中，便于快速判断数据的正负和大小 小端模式优点：1. 内存的低地址处存放低字节，所以在强制转换数据时不需要调整字节的内容（注解：比如把int的4字节强制转换成short的2字节时，就直接把int数据存储的前两个字节给short就行，因为其前两个字节刚好就是最低的两个字节，符合转换逻辑）； 2. CPU做数值运算时从内存中依顺序依次从低位到高位取数据进行运算，直到最后刷新最高位的符号位，这样的运算方式会更高效 其各自的优点就是对方的缺点，正因为两者彼此不分伯仲，再加上一些硬件厂商的坚持（见1.3节），因此在多字节存储顺序上始终没有一个统一的标准</p><ul><li>Intel的80×86系列芯片使用小端存储模式</li><li>ARM芯片默认采用小端，但可以切换为大端</li><li>MIPS芯片采用大端，但可以在大小端之间切换</li><li>在网络上传输的数据普遍采用的都是大端</li></ul><h4 id="2-判断"><a href="#2-判断" class="headerlink" title="2. 判断"></a>2. 判断</h4><p>方法一：通过将多字节数据强制类型转换成单字节数据，再通过判断起始存储位置是数据高字节还是低字节进行检测</p><pre><code>// @Ret: 大端，返回true; 小端，返回falsebool IsBigEndian_1(){    int nNum = 0x12345678;    char cLowAddressValue = *(char*)&amp;nNum;    // 低地址处是高字节，则为大端    if ( cLowAddressValue == 0x12 )    return true;    return false; }</code></pre><p>方法二：利用联合体union的存放顺序是所有成员都从低地址开始存放这一特性进行检测</p><pre><code>// @Ret: 大端，返回true; 小端，返回falsebool isBigEndian_2(){    union uendian    {       int nNum;       char cLowAddressValue;    };    uendian u;    u.nNum = 0x12345678;    if ( u.cLowAddressValue == 0x12 )     return true;    return false;}</code></pre><h4 id="3-转换"><a href="#3-转换" class="headerlink" title="3. 转换"></a>3. 转换</h4><p>大小端转换</p><pre><code>// 实现16bit的数据之间的大小端转换#define BLSWITCH16(A)   (  ( ( (uint16)(A) &amp; 0xff00 ) &gt;&gt; 8  )    | \                             ( ( (uint16)(A) &amp; 0x00ff ) &lt;&lt; 8  )     )  // 实现32bit的数据之间的大小端转换#define BLSWITCH32(A)   (  ( ( (uint32)(A) &amp; 0xff000000) &gt;&gt; 24) |\         (((uint32)(A) &amp; 0x00ff0000) &gt;&gt; 8) | \         (((unit32)(A) &amp; 0x0000ff00) &lt;&lt; 8) | \         (((uint32)(A) &amp; 0x000000ff) &lt;&lt; 32)  )</code></pre><p>由于网络字节序一律为大端，而目前个人PC大部分都是X86的小端模式，因此网络编程中不可避免得要进行网络字节序和主机字节序之间的相互转换</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;计算机系统中内存是以字节为单位进行编址的，每个地址单元都唯一的对应着1个字节（8 bit）。这可以应对char类型数据的存储要求，因为char类型长度刚好是1个字节，但是有些类型的长度是超过1个字节的（字符串虽然是多字节的，但它本质是由一个个char类型组成的类似数组的结构
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://lxbwolf.github.io/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>分布式发号器架构设计</title>
    <link href="https://lxbwolf.github.io/3d5a1f1d/"/>
    <id>https://lxbwolf.github.io/3d5a1f1d/</id>
    <published>2019-05-10T06:04:04.000Z</published>
    <updated>2019-10-03T16:41:41.095Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一-需求设计"><a href="#一-需求设计" class="headerlink" title="一 需求设计"></a>一 需求设计</h3><ol><li><p>分布式环境下，保证每个序列号（sequence）是全系统唯一的；</p></li><li><p>序列号可排序，满足单调递增的规律；</p></li><li><p>特定场景下，能生成无规则（或者看不出规则）的序列号；</p></li><li><p>生成的序列号尽量短；</p></li><li><p>序列号可进行二次混淆，提供可扩展的interface，业务方自定义实现。</p></li></ol><h3 id="二-方案设计"><a href="#二-方案设计" class="headerlink" title="二 方案设计"></a>二 方案设计</h3><p>为了满足上述需求，发号器必须能够支持不同的生成策略，最好是还能支持自定义的生成策略，这就对系统本身的可扩展性提出了要求。 目前，发号器设计了两种比较通用的基础策略，各有优缺点，但结合起来，能达到优势互补的目的。</p><h4 id="1-segment"><a href="#1-segment" class="headerlink" title="1. segment"></a>1. segment</h4><p>第一种策略称之为『分段』（segment），下文将对其进行详细阐述： 整个segment发号器有两个重要的角色：Redis和MongoDB，理论上MongoDB是可以被MySQL或其他DB产品所替代的。 segment发号器所产生的号码满足单调递增的规律，短时间内产生的号码不会有过长的问题（可根据实际需要，设置初始值，比如 100）。</p><h5 id="Redis数据结构（Hash类型）"><a href="#Redis数据结构（Hash类型）" class="headerlink" title="Redis数据结构（Hash类型）"></a>Redis数据结构（Hash类型）</h5><pre><code>key: &lt;string&gt;，表示业务主键/名称value: {  cur: &lt;long&gt;，表示当前序列号  max: &lt;long&gt;，表示这个号段最大的可用序列号}</code></pre><p>取号的大部分操作都集中在Redis，为了保证序列号递增的原子性，取号的功能可以用Lua脚本实现。</p><pre><code>--[[  由于RedisTemplate设置的HashValueSerializer是GenericToStringSerializer，故此处的HASH结构中的  VALUE都是string类型，需要使用tonumber函数转换成数字类型。]]local max = redis.pcall(&quot;HGET&quot;, KEYS[1], &quot;max&quot;)  --获取一段序列号的maxlocal cur = redis.pcall(&quot;HGET&quot;, KEYS[1], &quot;cur&quot;)  --获取当前发号位置if tonumber(cur) &gt;= tonumber(max) then  --没有超过这段序列号的上限    local step = ARGV[1]    if (step == nil) then  --没有传入step参数        step = redis.pcall(&quot;HGET&quot;, KEYS[1], &quot;step&quot;)  --获取这段序列号的step配置参数值    end    redis.pcall(&quot;HSET&quot;, KEYS[1], &quot;max&quot;, tonumber(max) + tonumber(step))  --调整max参数值，扩展上限endreturn redis.pcall(&quot;HINCRBY&quot;, KEYS[1], &quot;cur&quot;, 1)  --触发HINCRBY操作，对cur自增，并返回自增后的值</code></pre><p>注意：在redis执行lua script期间，redis处于BUSY状态，这个时候对redis的任何形式的访问都会抛出JedisBusyException异常，所以lua script中的处理逻辑不得太复杂。 值得一提的是，即使切换到一个新的database，或者开启新线程执行lua script，都将会遇到同样的问题，毕竟redis是单进程单线程的。 如果不幸遇到上述问题，需要使用redis-cli客户端连上redis-server，向其发送SCRIPT KILL命令，即可终止脚本执行， 如果想避免上述问题，也可以直接使用Springboot提供的RedisTemplate，能支持绝大部分redis command。</p><h5 id="MongoDB-数据结构"><a href="#MongoDB-数据结构" class="headerlink" title="MongoDB 数据结构"></a>MongoDB 数据结构</h5><pre><code>{ bizTag: &lt;string&gt;,  表示业务主键/名称 max: &lt;long&gt;,  表示这个号段最大的可用序列号 step: &lt;int&gt;, 每次分段的步长 timestamp: &lt;long&gt;,  更新数据的时间戳（毫秒）}</code></pre><p>MongoDB部分主要是对号段的分配进行管理，一个号段不能多发，也可以根据发号情况，适当放缩号段步长（step）。 到此为止，segment发号器的雏形已经形成了。 一个比较突出的问题是在两个号段衔接的时间点，当一个segment派发完了后，会对MongoDB和Redis中的数据中的max扩容，I/O消耗比正常发号要稍多，会遇到“尖刺” 为了消除“尖刺”，可以使用双Buffer模型 <img src="http://lxb.wiki/wp-content/uploads/2019/06/9135a2df270662dedd513fa4258fc5ab.png" alt> 这个模型的核心思想就是“<strong>预分配</strong>”。可以设置一个阈值（threshold），比如20%，当Buffer-1里面的号段已经消耗了20%，那么立刻根据Buffer-1的max和step，开辟Buffer-2。 当Buffer-1完全消耗了，可以无缝衔接Buffer-2,。如果Buffer-2的消耗也达到阈值了，又可以开辟Buffer-1，如此往复。 接下来，我们来讨论一下<strong>异常/故障</strong>情况。 ① Redis宕机。因为大部分发号工作都是依靠Redis完成的，所以发生了这种情况是非常糟糕的。如果想有效降低此风险，最行之有效的办法是对Redis进行集群化，通常是1主2从，这样可以挺住非常高的QPS了。 当然也有退而求其次的办法，就是利用上述提到的双Buffer模型。不依赖Redis取号，直接通过程序控制，利用机器内存。所以当需要重启发号服务之前，要确保依赖的组件是运行良好的，不然号段就丢失了。 ② 要不要持久化的问题。这个问题主要是针对Redis，如果没有记录下当前的取号进度，那么随着Redis的宕机，取号现场就变得难以恢复了；如果每次都记录取号进度，那么这种I/O高密度型的作业会对服务性能 造成一定影响，并且随着取号的时间延长，恢复取号现场就变得越来越慢了，甚至到最后是无法忍受的。除了对Redis做高可用之外，引入MongoDB也是出于对Redis持久化功能辅助的考虑。 个人建议：如果Redis已经集群化了，而且还开启了双Buffer的策略，以及MongoDB的加持，可以不用再开启Redis的持久化了。 如果考虑到极端情况下，Redis还是宕机了，我们可以使用MongoDB里面存下来的max，就max+1赋值给cur（避免上个号段取完，正好宕机了）。 ③ MongoDB宕机。这个问题不是很严重，只要将step适当拉长一些（至少取号能支撑20分钟），利用Redis还在正常取号的时间来抢救MongoDB。不过，考虑到实际可能没这么快恢复mongo服务，可以在程序中采取 一些容错措施，比如号段用完了，mongo服务无法到达，直接关闭取号通道，直到MongoDB能正常使用；或者程序给一个默认的step，让MongoDB中的max延长到max+step*n（可能取了N个号段MongoDB才恢复过来）， 这样取号服务也可以继续。依靠程序本身继续服务，那么需要有相关的log，这样才有利于恢复MongoDB中的数据。 ④ 取号服务宕机。这个没什么好说的，只能尽快恢复服务运行了。 ⑤ Redis，MongoDB都宕机了。这种情况已经很极端了，只能利用双Buffer策略，以及程序默认的设置进行工作了，同样要有相关的log，以便恢复Redis和MongoDB。 ⑥ 都宕机了。我有一句mmp不知当讲不当讲……</p><h4 id="2、snowflake"><a href="#2、snowflake" class="headerlink" title="2、snowflake"></a>2、snowflake</h4><p>第二种策略是Twitter出品，算法思想比较巧妙，实现的难度也不大。 <img src="http://lxb.wiki/wp-content/uploads/2019/06/91c86f2e2861b86d041ea16e874728a6.png" alt> 以上示意图描述了一个序列号的二进制组成结构。 第一位不用，恒为0，即表示正整数； 接下来的41位表示时间戳，精确到毫秒。为了节约空间，可以将此时间戳定义为距离某个时间点所经历的毫秒数（Java默认是1970-01-01 00:00:00）； 再后来的10位用来标识工作机器，如果出现了跨IDC的情况，可以将这10位一分为二，一部分用于标识IDC，一部分用于标识服务器； 最后12位是序列号，自增长。 snowflake的核心思想是64bit的合理分配，但不必要严格按照上图所示的分法。 如果在机器较少的情况下，可以适当缩短机器id的长度，留出来给序列号。 当然，snowflake的算法将会面临两个挑战： ① 机器id的指定。这个问题在分布式的环境下会比较突出，通常的解决方案是利用Redis或者Zookeeper进行机器注册，确保注册上去的机器id是唯一的。为了解决 强依赖Redis或者Zookeeper的问题，可以将机器id写入本地文件系统。 ② 机器id的生成规则。这个问题会有一些纠结，因为机器id的生成大致要满足三个条件：a. int类型(10bit)纯数字，b. 相对稳定，c. 与其他机器要有所区别。至于优雅美观，都是其次了。对于机器id的存储，可以使用HASH结构，KEY的规则是“application-name.port.ip”，其中ip是通过算法转换成了一段长整型的纯数字，VALUE则是机器id， 服务id，机房id，其中，可以通过服务id和机房id反推出机器id。 假设服务id(workerId)占8bit，机房id(rackId)占2bit，从1开始，workerId=00000001，rackId=01，machineId=00000000101 如果用Redis存储，其表现形式如下： <img src="http://lxb.wiki/wp-content/uploads/2019/06/f4da350756f1116434e6636a38888282.png" alt> 如果存储在文件中（建议properties文件），则文件名是sequence-client:8112:3232235742.properties，文件内容如下： <img src="http://lxb.wiki/wp-content/uploads/2019/06/3b1e3b6b90aaa663bb3a578bd98c1db1.png" alt> 如果发号服务上线，直接按照“application-name.port.ip”的规则取其内容。 ③ 时钟回拨。因为snowflake对系统时间是很依赖的，所以对于时钟的波动是很敏感的，尤其是时钟回拨，很有可能就会出现重复发号的情况。时钟回拨问题解决策略通常是直接拒绝发号，直到时钟正常，必要时进行告警。</p><h3 id="三-程序设计"><a href="#三-程序设计" class="headerlink" title="三 程序设计"></a>三 程序设计</h3><p>整个发号过程可以分成三个层次： 1、策略层(strategy layer)：这个层面决定的是发号方法/算法，涵盖了上述所讲的segment和snowflake两种方式，当然，用户也可以自己扩展实现其他发号策略。 <img src="http://lxb.wiki/wp-content/uploads/2019/06/377252c9da3f792b50732cb650d42d8d.png" alt> 最顶上定义Sequence实际上就是发号的结果。bizType是对发号业务场景的定义，比如订单号，用户ID，邀请好友的分享码。 发号策略的init接口是发号前的初始化工作，而generate接口就是调用发号器的主入口了。 当然，考虑到各种异常情况，加入了拒绝发号的处理器（SequenceRejectedHandler），默认实现只是记录日志，用户可根据需求去实现该处理器，然后用set方法设置发号策略的拒绝处理器。 2、插件层(plugin layer)：此处的插件可以理解是一种拦截器，贯穿SequenceStrategy的发号全周期。引入插件后，无疑是丰富了整个发号的操作过程，用户可以从中干预到发号的整个流程，以便达到其他的目的，比如：记录发号历史，统计发号速率，发号二次混淆等。 <img src="http://lxb.wiki/wp-content/uploads/2019/06/56fe2b69f67a1fc9cce3179163d76278.png" alt> 可以看出，插件被设计成『注册式』的，发号策略只有注册了相关插件之后，插件才能生效， 当然，一个插件能被多个发号策略所注册，一个发号策略也能同时注册多个插件，所以两者是多对多的关系，PluginManager的出现就是解决插件的注册管理问题。 从SequencePlugin的定义中可以发现，插件是有优先级（Order）的，通过getOrder()可以获得，在这套发号系统里，Order值越小，表示该插件越优先执行。此外，插件有三个重要的操作： before，表示发号之前的处理。若返回了false，那么该插件后面的操作都失效了，否则继续执行发号流程。 after，表示发号之后的处理。 doException，表示插件发生异常的处理方法。 3、持久层(persistence layer)：这个层面指代的是上述所提的MongoDB部分，如果不需要持久化的支持，可以不实现此接口，那么整个发号器就变成纯内存管理的了。 <img src="http://lxb.wiki/wp-content/uploads/2019/06/f65af0475f67e95a778a92d6ef681f62.png" alt> PersistRepository定义了基本的CRUD方法，其中persistId可以理解成上述提到的BizType。 一切的持久化对象都是从PersistModel开始的，上图中的Segment、PersistDocument都是为了实现分段发号器而定义的。</p><h3 id="四-总结"><a href="#四-总结" class="headerlink" title="四 总结"></a>四 总结</h3><p>这篇文章详细阐述了分布式发号器系统的设计，旨在能做出一个可扩展，易维护的发号系统。业界比较知名的发号算法似乎也不多，整个发号系统不一定就按照笔者所做的设计，还是要立足于具体的业务需求。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一-需求设计&quot;&gt;&lt;a href=&quot;#一-需求设计&quot; class=&quot;headerlink&quot; title=&quot;一 需求设计&quot;&gt;&lt;/a&gt;一 需求设计&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;分布式环境下，保证每个序列号（sequence）是全系统唯一的；&lt;/p&gt;
&lt;/li&gt;
&lt;l
      
    
    </summary>
    
    
      <category term="DB" scheme="https://lxbwolf.github.io/categories/DB/"/>
    
    
      <category term="idalloc" scheme="https://lxbwolf.github.io/tags/idalloc/"/>
    
  </entry>
  
  <entry>
    <title>mysqldump: Got error: 1044: Access denied for user</title>
    <link href="https://lxbwolf.github.io/a333bc04/"/>
    <id>https://lxbwolf.github.io/a333bc04/</id>
    <published>2019-04-27T03:24:27.000Z</published>
    <updated>2019-10-03T16:57:23.397Z</updated>
    
    <content type="html"><![CDATA[<p><code>mysqldump -u username -p dbname &gt; dbname.sql</code> mysqldump: Got error: 1044: Access denied for user XXX to database XXX when using LOCK TABLES 解决方法: <code>mysqldump -u dbuser -ppass db --skip-lock-tables &gt; db.sql</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;code&gt;mysqldump -u username -p dbname &amp;gt; dbname.sql&lt;/code&gt; mysqldump: Got error: 1044: Access denied for user XXX to database XXX when 
      
    
    </summary>
    
    
      <category term="DB" scheme="https://lxbwolf.github.io/categories/DB/"/>
    
    
      <category term="mysql" scheme="https://lxbwolf.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>DDBS</title>
    <link href="https://lxbwolf.github.io/728c18a3/"/>
    <id>https://lxbwolf.github.io/728c18a3/</id>
    <published>2019-04-10T06:00:41.000Z</published>
    <updated>2019-10-03T16:41:23.262Z</updated>
    
    <content type="html"><![CDATA[<p>业务规模较小时，使用单机mysql作存储。但伴随业务发展，存储容量和并发能力会有瓶颈。</p><pre><code>首先，假设单机的硬盘为1.8T，也可以挂更大容量硬盘，但仍有限。其次，单机的读写并发能力有限，假设峰值写入qps1000，峰值读取qps3000，网卡对读取时流量也有要求，单次访问的读取量不应过大。单机的链接数也有限。那么，当使用单机mysql的业务发展，受到以上瓶颈时，一般的思路会是什么呢？一台机器不行，用两台呢，再不行，扩展更多台。一台扩展为两台，磁盘容量扩大了，通过分表，将表打散在不同机器上，共同承担写入任务，并发也提高了，感觉这个思路是对的。那么在这个过程中，我们需要做什么？业务发展到单机无法承受，即使在单机上，很多表应该也做过分表了。一般会根据业务选择分表键。单个表的大小mysql也有一定要求，一般存储量不大于1G，单条记录小一些，一般不超过1k，条数一般不超过1000万条，最多不超过5000万条，否则表的使用和维护效率都很低。假设业务已经做了足够多的分表，满足三年的数据增长需要，第一年过后，每个分表的条数达到200万条，整机存储容量使用了一半，此时我们想拆分为两台机器。此时我们可以将原机器上部分表数据同步到新机器上，并在model层抽象一个路由层，将对数据库的操作发到不同的机器上，上层业务仍可以认为在使用单机。此时可以将原机器上不归属自己管理范围的表删除，腾出空间。一台变成了两台，向分布式走了一步。此时存储容量和并发都提高了，由路由层管理两台机器。如果两台或今后的多台机器，并发数高于路由层处理能力怎么办？那还要把路由层机器也扩一下，把路由规则都写进去，大家按一个格则办事。经过上面的一番折腾，数据库机器水平扩展，解决了单机存在的一些问题。在这个扩展的过程中，是否会对业务产生中断影响呢？会有一点影响。至少在路由层改路由表时，会中断数据库的写入，读取此时可以不中断。ddbs中，使用到的多台机器，都叫做分片。分片提高了系统存储容量和并发能力，引入分片，也是系统的复杂度提高了，需要引入路由层机器，路由机器也可能需要扩展，复杂操作，还需要添加更多逻辑功能。但至少可以可业务逻辑区分开，业务可以把ddbs当做单机在使用。那么ddbs有哪些不足呢？ddbs还是要基于分表、分片实现的。那么对数据库的任何操作，首要条件是需要指明操作的分表键。没有这个维度的准确值，就不能对数据库操作，当然除非是备用库，那你随便扫表，因为备用库可以转为冗余安全，不走线上流量，可以做统计任务。单指明分表键还不行，还要注意操作的数据可能会分布在不同分表、不同分片中，这样的操作会引发ddbs产生大量并发操作，业务的一个请求就会占用多个机器多个链接，使ddbs得并发能力大打折扣。比如‘where 分表键 in （）’操作，这种操作要慎重，in中个数不可太多。 分表键最好选用整形，字符串型，可能hash后分配不均，表大小不均衡。事物操作在ddbs中的实现，非常耗费系统性能。事务类操作需要路由控制层控制整个操作过程，期中可能涉及多个分片，多个不同的表的操作，对系统整体可用性要求高</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;业务规模较小时，使用单机mysql作存储。但伴随业务发展，存储容量和并发能力会有瓶颈。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;首先，假设单机的硬盘为1.8T，也可以挂更大容量硬盘，但仍有限。

其次，单机的读写并发能力有限，假设峰值写入qps1000，峰值读取qps3000，网卡对
      
    
    </summary>
    
    
      <category term="DB" scheme="https://lxbwolf.github.io/categories/DB/"/>
    
    
      <category term="mysql" scheme="https://lxbwolf.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>跑道问题</title>
    <link href="https://lxbwolf.github.io/81be14b5/"/>
    <id>https://lxbwolf.github.io/81be14b5/</id>
    <published>2019-03-12T15:20:56.000Z</published>
    <updated>2019-10-03T07:57:15.303Z</updated>
    
    <content type="html"><![CDATA[<p>25个人，每5个人一个跑道，最少经过几次比赛，得到前三名</p><p><strong>初步思路</strong>: 第一步, 每5人一组, 全跑完后, 每组的后两名一定不在最终要的”前三名” 结果内, 所以每组可以排除2人, 剩下25-2_5=15人. 共经过5次比赛 第二步, 剩下的15人, 每5人一组, 跑完后, 每组淘汰2人, 剩下 15-2_3=9人. 经过3次比赛 第三步, 剩下的9个人分两组, A组5人B组4人, 跑完后, A组淘汰2人, B组淘汰1人, 剩下 9-2-1=6人. 经过2次比赛 第四步, 剩下的6人分两组, C组5人D组1人, A组跑完后, 淘汰2人, B组1人不需要跑, 剩下 6-2=4人. 经过1次比赛 第五步, 剩下的4个人, 跑一次, 得出前三名. 经过1次比赛 共经过 5+3+2+1+1=12次</p><p>在第一步中, 5组全跑完后, 每组的第一名再跑一次, 按速度快慢分别标为A1 B1 C1 D1 E1. 则A1 为25人中的第一名. 经过5+1=6次比赛 在第6次比赛中, 落后的两名D1 和E1, 可以被排除, 进而整个D组和E组都可以排除. C1不可能是第二名. 第二名可能的人员有A2 B1, 第三名可能的人员有 B1 A3 B2 A2 C1. 第二名的集合是第三名集合的子集. 第三名所有可能的5个人跑一次, 得出第二名和第三名.经过1次比赛 共经过7次比赛</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;25个人，每5个人一个跑道，最少经过几次比赛，得到前三名&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;初步思路&lt;/strong&gt;: 第一步, 每5人一组, 全跑完后, 每组的后两名一定不在最终要的”前三名” 结果内, 所以每组可以排除2人, 剩下25-2_5=15人. 共经过5次比赛 第
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="https://lxbwolf.github.io/categories/Algorithm/"/>
    
    
  </entry>
  
  <entry>
    <title>架构设计原则</title>
    <link href="https://lxbwolf.github.io/88049151/"/>
    <id>https://lxbwolf.github.io/88049151/</id>
    <published>2019-03-01T14:52:22.000Z</published>
    <updated>2019-10-03T07:57:15.440Z</updated>
    
    <content type="html"><![CDATA[<h4 id="GRASP-通用职责分配软件模式"><a href="#GRASP-通用职责分配软件模式" class="headerlink" title="GRASP 通用职责分配软件模式"></a>GRASP 通用职责分配软件模式</h4><p>来自 Craig Larman 的软件设计书《UML 和模式应用》[附录 1]，Larman 在书中提出软件设计的关键任务是职责分配，并提炼总结出 9 种 (5 种核心 +4 种扩展) 软件职责分配模式，这些模式是比 GoF 设计模式更抽象的元模式。</p><p><strong>1. 信息专家 (Information Expert)</strong></p><p>为对象分配职责的通用原则 – 把职责分配给拥有足够信息可以履行职责的专家</p><p><strong>2. 创建者 (Creator)</strong></p><p>将创建 A 的职责赋给 B，如果至少下面一种情况为真：</p><ul><li>B“包含”或者聚合 A</li><li>B 记录 A 的实例</li><li>B 密切地使用 A</li><li>B 拥有 A 的初始化数据</li></ul><p><strong>3. 低耦合 (Low Coupling)</strong></p><p>赋予职责使得对象间的耦合度尽可能低，最小化对象间的依赖和变更影响，最大化重用。</p><p><strong>4. 高内聚 (High Cohesion)</strong></p><p>赋予职责使得每个对象的职责尽可能保持聚焦和单一，易于管理和理解。</p><p><strong>5. 控制器 (Controller)</strong></p><p>把职责赋予系统、设备或者子系统的表示类 (门面控制器)，或者某个用例的表示类 (用例控制器)，让控制器接收事件并协调整个系统的运作。</p><p><strong>6. 多态 (Polymorphism)</strong></p><p>将职责分配给多个具有同名方法的多态子类，运行时根据需要动态切换子类，让系统行为变得可插拔。</p><p><strong>7. 纯虚构 (Pure Fabrication)</strong></p><p>针对真实问题域中不存在，但是设计建模中有用的概念，设计虚构类并赋予职责。</p><p><strong>8. 间接 (Indirection)</strong></p><p>在两个或者多个对象间有交互的情况下，为避免直接耦合，提高重用性，创建中间类并赋予职责，对象的交互交由中间类协调。</p><p><strong>9. 受保护的变化 (Protected Variation)</strong></p><p>简单讲就是封装变化。识别系统中可能的不稳定或者变化，在不稳定组件上创建稳定的抽象接口，将可能的变化封装在接口之后，使得系统内部的不稳定或者变化不会对系统的其它部分产生不良影响。</p><h4 id="SOLID-面向对象设计原则"><a href="#SOLID-面向对象设计原则" class="headerlink" title="SOLID 面向对象设计原则"></a>SOLID 面向对象设计原则</h4><p>S.O.L.I.D 是面向对象设计和编程 (OOD&amp;OOP) 中几个重要原则的首字母缩写，受 Robert Martin 推崇。</p><p><strong>1. 单一职责原则 (The Single Responsibility Principle)</strong></p><p>修改某个类的理由应该只有一个，如果超过一个，说明类承担不止一个职责，要视情况拆分。</p><p><strong>2. 开放封闭原则 (The Open Closed Principle)</strong></p><p>软件实体应该对扩展开放，对修改封闭。一般不要直接修改类库源码（即使你有源代码），通过继承等方式扩展。</p><p><strong>3. 里氏替代原则 (The Liskov Substitution Principle)</strong></p><p>当一个子类的实例能够被替换成任何超类的实例时，它们之间才是真正的 is-a 关系。</p><p><strong>4. 依赖倒置原则 (The Dependency Inversion Principle)</strong></p><p>高层模块不应该依赖于底层模块，二者都应该依赖于抽象。换句话说，依赖于抽象，不要依赖于具体实现。比方说，你不会把电器电源线焊死在室内电源接口处，而是用标准的插头插在标准的插座 (抽象) 上。</p><p><strong>5. 接口分离原则 (The Interface Segregation Principle)</strong></p><p>不要强迫用户去依赖它们不使用的接口。换句话说，使用多个专门的接口比使用单一的大而全接口要好。</p><p><strong>备注</strong></p><ol><li>高内聚 + 低耦合，就像道中的一阴一阳，是所有其它 OO 设计原则的原则 (元原则)，其它设计原则都是在这两个基础上泛化衍生出来的。</li><li>上述原则虽然是针对 OO 设计和编程提出，但是对于大规模系统架构仍然适用。比如，微服务架构就体现了：</li><li><ul><li>单一职责：一个微服务尽可能要职责单一，提供的接口也尽可能单一 (接口分离原则)，安全 / 路由 / 限流等跨横切面的关注点 (Cross-Cutting Concerns) 由独立网关负责，体现关注分离 (Separation of Concerns)。</li></ul></li></ol><ul><li>信息专家：当不确定哪个团队应该负责某个微服务时，一般原则也是谁拥有数据谁负责，基于有界上下文 Bounded Context（一般是边界比较清晰的领域数据源）构建微服务。</li><li>松散耦合：服务之间通过 HTTP/JSON 等轻量机制通信，服务之间不强耦合。</li><li>受保护的变化和依赖倒置：服务之间只依赖抽象接口，实现可能随时变化。</li><li>间接：网关在外面的客户端和内部的服务之间增加了一层间接，使两者不强耦合，可以相互独立演化。</li></ul><ol><li>作为架构师或者设计师，有两个设计能力是需要重点培养的，也是最难和最能体现架构设计水平的：</li><li><ul><li>合理的职责分配能力，也就是每个类 / 组件 / 子系统应该承担什么职责，如何保证职责单一，它们之间如何协作；</li></ul></li></ol><ul><li>系统抽象和核心领域建模能力，需要深入一线业务域。</li></ul><h3 id="分布式系统架构设计原则和理论"><a href="#分布式系统架构设计原则和理论" class="headerlink" title="分布式系统架构设计原则和理论"></a>分布式系统架构设计原则和理论</h3><h4 id="AKF-架构原则"><a href="#AKF-架构原则" class="headerlink" title="AKF 架构原则"></a>AKF 架构原则</h4><p>这 15 个架构原则来自《架构即未来 (The Art of Scalability)》[附录 2] 一书，作者马丁 L. 阿伯特和迈克尔 T. 费舍尔分别是 eBay 和 PayPal 的前 CTO，他们经历过 eBay 和 PayPal 大规模分布式电商平台的架构演进，在一线实战经验的基础上总结并提炼出 15 条架构原则：</p><p><strong>1.N + 1 设计</strong></p><p>永远不要少于两个，通常为三个。比方说无状态的 Web/API 一般部署至少&gt;=2 个。</p><p><strong>2. 回滚设计</strong></p><p>确保系统可以回滚到以前发布过的任何版本。可以通过发布系统保留历史版本，或者代码中引入动态开关切换机制 (Feature Switch)。</p><p><strong>3. 禁用设计</strong></p><p>能够关闭任何发布的功能。新功能隐藏在动态开关机制 (Feature Switch) 后面，可以按需一键打开，如发现问题随时关闭禁用。</p><p><strong>4. 监控设计</strong></p><p>在设计阶段就必须考虑监控，而不是在实施完毕之后补充。例如在需求阶段就要考虑关键指标监控项，这就是度量驱动开发 (Metrics Driven Development) 的理念。</p><p><strong>5. 设计多活数据中心</strong></p><p>不要被一个数据中心的解决方案把自己限制住。当然也要考虑成本和公司规模发展阶段。</p><p><strong>6. 使用成熟的技术</strong></p><p>只用确实好用的技术。商业组织毕竟不是研究机构，技术要落地实用，成熟的技术一般坑都被踩平了，新技术在完全成熟前一般需要踩坑躺坑。</p><p><strong>7. 异步设计</strong></p><p>能异步尽量用异步，只有当绝对必要或者无法异步时，才使用同步调用。</p><p><strong>8. 无状态系统</strong></p><p>尽可能无状态，只有当业务确实需要，才使用状态。无状态系统易于扩展，有状态系统不易扩展且状态复杂时更易出错。</p><p><strong>9. 水平扩展而非垂直升级</strong></p><p>永远不要依赖更大、更快的系统。一般公司成长到一定阶段普遍经历过买更大、更快系统的阶段，即使淘宝当年也买小型机扛流量，后来扛不住才体会这样做不 scalable，所以才有后来的去 IOE 行动。</p><p><strong>10. 设计时至少要有两步前瞻性</strong></p><p>在扩展性问题发生前考虑好下一步的行动计划。架构师的价值就体现在这里，架构设计对于流量的增长要有提前量。</p><p><strong>11. 非核心则购买</strong></p><p>如果不是你最擅长，也提供不了差异化的竞争优势则直接购买。避免 Not Invented Here 症状，避免凡事都要重造轮子，毕竟达成业务目标才是重点。</p><p><strong>12. 使用商品化硬件</strong></p><p>在大多数情况下，便宜的就是最好的。这点和第 9 点是一致的，通过商品化硬件水平扩展，而不是买更大、更快的系统。</p><p><strong>13. 小构建、小发布和快试错</strong></p><p>全部研发要小构建，不断迭代，让系统不断成长。这个和微服务理念一致。</p><p><strong>14. 隔离故障</strong></p><p>实现故障隔离设计，通过断路保护避免故障传播和交叉影响。通过舱壁泳道等机制隔离失败单元 (Failure Unit)，一个单元的失败不至影响其它单元的正常工作。</p><p><strong>15. 自动化</strong></p><p>设计和构建自动化的过程。如果机器可以做，就不要依赖于人。自动化是 DevOps 的基础。</p><p><strong>备注</strong></p><ol><li>这 15 条架构原则基本上是 eBay 在发展，经历过流量数量级增长冲击过程中，通过不断踩坑踩出来的，是干货中的干货。消化吸收这 15 条原则，基本可保系统架构不会有原则性问题。</li><li>这 15 条原则同样适用于现在的微服务架构。eBay 发展较早，它内部其实很早 (差不多 2010 年前) 就已形成完善的微服务生态，只是没有提出微服务这个概念。</li><li>这 15 条原则可根据 TTM(Time To Market)，可用性 / 可扩展性 / 质量，成本 / 效率分布在三个环内，如下图所示。</li></ol><h4 id="12-要素应用"><a href="#12-要素应用" class="headerlink" title="12 要素应用"></a>12 要素应用</h4><p>基于上百万应用的托管和运营经验，创始人 Adam Wiggins 提出了 12 要素应用宣言 。简单讲，满足这 12 个要素的应用是比较容易云化并居住在 Heroku 平台上的。</p><p><strong>1. 基准代码</strong></p><p>一份基准代码，多份部署。如果用镜像部署方式，则一个镜像可以部署到多个环境 (测试，预发，生产)，而不是给每个环境制作一个不同镜像。</p><p><strong>2. 依赖</strong></p><p>显式声明依赖。如果用镜像部署，则一般依赖被直接打在镜像中，或者声明在 docker file 中。</p><p><strong>3. 配置</strong></p><p>在环境中存储配置。在 Heroku 或者类似的 PaaS 平台上，配置一般是推荐注入到环境变量中的。现在采用集中式配置中心也是一种流行方式。</p><p><strong>4. 后端服务</strong></p><p>把后端服务 (例如缓存，数据库，MQ 等) 当作附加资源，相关配置和连接字符串通过环境变量注入，或者采用配置中心。</p><p><strong>5. 构建、发布和运行</strong></p><p>严格分离构建和运行。如果使用镜像部署，则构建、发布 / 运行是通过镜像这种中间格式严格分离的。</p><p><strong>6. 进程</strong></p><p>一个或者多个无状态的进程运行应用。容器运行时相当于进程，适用于无状态 Web/API。</p><p><strong>7. 端口绑定</strong></p><p>通过端口绑定提供服务。容器也是通过端口绑定对外提供服务。</p><p><strong>8. 并发</strong></p><p>通过进程模型进行扩展。容器运行时相当于进程，通过起多个容器可以任意扩展并发数量。</p><p><strong>9. 易处理</strong></p><p>快速启动和优雅终止可最大化健壮性。docker 容器支持秒级启动和关闭。</p><p><strong>10. 开发环境和线上环境等价</strong></p><p>尽可能保持开发、测试、预发和线上环境相同。容器可以保证容器内运行时环境的一致性，还需要保证不同环境的一致性，例如不同环境内的操作系统，负载均衡，服务发现，后台服务，监控告警等要尽可能一致。</p><p><strong>11. 日志</strong></p><p>把日志当作数据流。Heroku 不支持本地文件，所以必须以流方式把日志输送到后台日志服务。除了日志以外还要补充考虑 metrics 流的采集和输送。</p><p><strong>12. 管理进程</strong></p><p>后台管理任务当作一次性的进程。其实相当于在 Heroku 上以独立进程方式运行任务 Job。</p><p><strong>备注</strong></p><ol><li>12 要素应用也是当前云原生应用 (Cloud Native App) 的参考标准，也称为云应用迁移原则。满足这 12 个要素的应用，可以比较顺利迁移到各种云平台 (Kubernetes, Marathon, Cloud Foundry 等) 上。</li><li>对于面临企业遗留应用改造和云化迁移的架构师，可以重点参考这 12 条迁移原则。</li><li>Docker 容器技术可以认为是为云迁移量身定制的技术。容器化是后续云迁移的捷径，所以遗留应用改造可以先想办法做到容器化。</li></ol><h4 id="CAP-定理"><a href="#CAP-定理" class="headerlink" title="CAP 定理"></a>CAP 定理</h4><p>2000 年 7 月，加州大学伯克利分校的 Eric Brewer 教授在 ACM PODC 会议上提出 CAP 猜想。2 年后，麻省理工学院的 Seth Gilbert 和 Nancy Lynch 从理论上证明了 CAP。之后，CAP 理论正式成为分布式计算领域的公认定理。</p><p>CAP 认为：一个分布式系统最多同时满足一致性 (Consistency)，可用性 (Availability) 和分区容忍性 (Partition Tolerance) 这三项中的两项。</p><p><strong>1.一致性 (Consistency)</strong></p><p>一致性指“all nodes see the same data at the same time”，即更新操作成功，所有节点在同一时间的数据完全一致。</p><p><strong>2.可用性 (Availability)</strong></p><p>可用性指“Reads and writes always succeed”，即服务一直可用，而且响应时间正常。</p><p><strong>3.分区容忍性 (Partition tolerance)</strong></p><p>分区容忍性指“the system continue to operate despite arbitrary message loss or failure of part of the system.”，即分布式系统在遇到某节点或网络分区故障时，仍然能够对外提供满足一致性和可用性的服务。</p><h4 id="BASE-理论"><a href="#BASE-理论" class="headerlink" title="BASE 理论"></a>BASE 理论</h4><p>eBay 架构师 Dan Pritchett 基于对大规模分布式系统的实践总结，在 ACM 上发表文章提出了 BASE 理论，BASE 理论是对于 CAP 理论的延伸，核心思想是即使无法做到强一致性 (Strong Consistency，CAP 中的一致性指强一致性)，但是可以采用适当的方式达到最终一致性 (Eventual Consistency)。</p><p>BASE 指基本可用 (Basically Available)、软状态 (Soft State) 和最终一致性 (Eventual Consistency)。</p><p><strong>1.基本可用 (Basically Available)</strong></p><p>基本可用是指分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。比如服务降级。</p><p><strong>2.软状态 (Soft State)</strong></p><p>软状态是指允许系统存在中间状态，而该中间状态不会影响系统的整体可用性。分布式存储中一般一份数据至少存三个副本，允许不同节点间副本同步的延迟就是软状态的体现。</p><p><strong>3.最终一致性 (Eventual Consistency)</strong></p><p>最终一致性是指系统中的所有数据副本经过一段时间后，最终能够达成一致状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。</p><p><strong>备注</strong></p><ol><li>CAP 和 BASE 理论可以抠得很深，背后甚至有很复杂的数学证明。我理解得相对简单浅显：性能、高可用、不丢数据和数据一致性对分布式系统来说一般是强需求，随着流量的增长，复制和分区在所难免：</li><li><ul><li>复制 (replication)：数据在多个节点上存多份保证不丢和高可用；</li></ul></li></ol><ul><li>分区 (partition)：数据按某个纬度切分分布在不同节点上分摊流量压力保证高性能，同时也是为了降低每个节点的复杂性。例如数据库的分库分表，系统拆分微服务化也是一种分区。这两者都会带来一致性问题，一致性在时间上有一点妥协的余地 - 即是最终一致性；时间上要求强一致的话，只有可用性可以适当折中。系统架构的游戏很大部分是和状态一致性作斗争的游戏。</li></ul><ol><li>选择使用分布式产品时，比如 NoSQL 数据库，你需要了解它在 CAP 环中所在的位置，确保它满足你的场景需要。</li></ol><h3 id="组织和系统改进原则"><a href="#组织和系统改进原则" class="headerlink" title="组织和系统改进原则"></a>组织和系统改进原则</h3><h4 id="康威法则"><a href="#康威法则" class="headerlink" title="康威法则"></a>康威法则</h4><p>Melvin Conway 在 1967 年提出所谓康威法则 ，指出组织架构和系统架构之间有一种隐含的映射关系：</p><p>Organization which design system […] are constrained to produce designs which are copies of the communication structures of these organization. 设计系统的组织其产生的设计等价于组织间的沟通结构。</p><p>康威法则也可以倒过来阐述：</p><p>Conway’s law reversed：You won’t be able to successfully establish an efficient organization structure that is not supported by your system design(architecture)。 如果系统架构不支持，你无法建立一个高效的组织；同样，如果你的组织架构不支持，你也无法建立一个高效的系统架构。</p><h4 id="系统改进三原则"><a href="#系统改进三原则" class="headerlink" title="系统改进三原则"></a>系统改进三原则</h4><p>IT 运维管理畅销书《凤凰项目》[附录 8] 的作者 Gene Kim 在调研了众多高效能 IT 组织后总结出支撑 DevOps 运作的三个原理 (The Three Ways: The Principles Underpinning DevOps)[附录 9]，我认为也是系统改进提升的一般性原理 [附录 7]，见下图：</p><p><strong>原理一：系统思考 (System Thinking)</strong></p><p>开发驱动的组织，其能力不是制作软件，而是持续的交付客户价值。价值从业务需求开始，经过研发测试，到部署运维，依次流动，并最终以服务形式交付到客户手中。整个价值链流速并不依赖单个部分 (团队或个人) 的杰出工作，而是受整个价值链最薄弱环节 (瓶颈) 的限制。所以局部优化通常无效，反而招致全局受损。</p><p>Gene Kim 特别指出：Any improvements made anywhere besides the bottleneck are an illusion. 在瓶颈之外的任何优化提升都只是幻象。</p><p><strong>原理二：强化反馈环 (Amplify Feedback Loops)</strong></p><p>过程改进常常通过加强反馈环来达成。原理二强调企业和客户之间、组织团队间、流程上和系统内的反馈环。没有测量就没有提升，反馈要以测量数据为准，通过反馈数据优化改进系统。</p><p><strong>原理三：持续试验和学习的文化 (Culture of Continual Experimentation And Learning)</strong></p><p>在企业管理文化层面强调勇于试错和持续试验、学习和改进的文化。</p><p><strong>备注</strong></p><ol><li>康威法则给我们的启示：系统架构和组织架构之间有隐含的映射关系，你不能单方面改变一方的结构，调整时必须两边联动。系统架构如果是耦合的，就很难组织分散式的团队结构，两边映射不起来，团队之间容易摩擦导致生产率下降。所以一般先按业务边界对单块应用进行解耦拆分，同时做相应的团队拆分，使两边可以映射，每个团队可以独立开发、测试和部署各自的微服务，进而提升生产率。这就是近年流行的微服务架构背后的组织原则。详见我之前发表的文章《企业的组织架构是如何影响技术架构的》[附录 6]。</li><li>系统思考要求我们加强团队合作，培养流式思维和瓶颈约束思维，找出瓶颈并针对性地优化。在研发型组织中，常见的系统瓶颈如运维机器资源提供 (Provisioning) 缓慢，发布流程繁琐容易出错，开发 / 测试／UAT 环境缺失或不完善，遗留系统耦合历史负担重，基础研发平台薄弱等等。这些瓶颈点特别需要关注优化。</li><li>反馈原理要求我们关注基于数据的反馈，技术上的手段包括大数据分析和系统各个层次的测量监控。没有测量就没有反馈，没有反馈就没有提升。</li><li>在管理文化层面：</li><li><ul><li>管理层要承认企业内部近 50% 的创新或流程改进项目是有可能失败的，即使失败，员工不会受到责罚，鼓励持续的试验和从中学习；</li></ul></li></ol><ul><li>管理层要有技术偿债意识，勿追求 100% 员工利用率，要预留 20%~30% 的时间给员工做创新和系统改进提升项目</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;GRASP-通用职责分配软件模式&quot;&gt;&lt;a href=&quot;#GRASP-通用职责分配软件模式&quot; class=&quot;headerlink&quot; title=&quot;GRASP 通用职责分配软件模式&quot;&gt;&lt;/a&gt;GRASP 通用职责分配软件模式&lt;/h4&gt;&lt;p&gt;来自 Craig Larma
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxbwolf.github.io/categories/Design/"/>
    
    
  </entry>
  
  <entry>
    <title>秒杀系统优化思路</title>
    <link href="https://lxbwolf.github.io/bcca3074/"/>
    <id>https://lxbwolf.github.io/bcca3074/</id>
    <published>2019-02-26T14:13:12.000Z</published>
    <updated>2019-10-03T07:57:15.299Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、秒杀业务为什么难做"><a href="#一、秒杀业务为什么难做" class="headerlink" title="一、秒杀业务为什么难做"></a>一、秒杀业务为什么难做</h3><p>1）im系统，例如qq或者微博，每个人都读自己的数据（好友列表、群列表、个人信息）； 2）微博系统，每个人读你关注的人的数据，一个人读多个人的数据； 3）秒杀系统，库存只有一份，所有人会在集中的时间读和写这些数据，多个人读一个数据。</p><p>例如：小米手机每周二的秒杀，可能手机只有1万部，但瞬时进入的流量可能是几百几千万。 又例如：12306抢票，票是有限的，库存一份，瞬时流量非常多，都读相同的库存。读写冲突，锁非常严重，这是秒杀业务难的地方。那我们怎么优化秒杀业务的架构呢？</p><h3 id="二、优化方向"><a href="#二、优化方向" class="headerlink" title="二、优化方向"></a>二、优化方向</h3><p>优化方向有两个（今天就讲这两个点）： （1）将请求尽量拦截在系统上游（不要让锁冲突落到数据库上去）。传统秒杀系统之所以挂，请求都压倒了后端数据层，数据读写锁冲突严重，并发高响应慢，几乎所有请求都超时，流量虽大，下单成功的有效流量甚小。以12306为例，一趟火车其实只有2000张票，200w个人来买，基本没有人能买成功，请求有效率为0。</p><p>（2）充分利用缓存，秒杀买票，这是一个典型的读多写少的应用场景，大部分请求是车次查询，票查询，下单和支付才是写请求。一趟火车其实只有2000张票，200w个人来买，最多2000个人下单成功，其他人都是查询库存，写比例只有0.1%，读比例占99.9%，非常适合使用缓存来优化。好，后续讲讲怎么个“将请求尽量拦截在系统上游”法，以及怎么个“缓存”法，讲讲细节。</p><h3 id="三、常见秒杀架构"><a href="#三、常见秒杀架构" class="headerlink" title="三、常见秒杀架构"></a>三、常见秒杀架构</h3><p>（1）浏览器端，最上层，会执行到一些JS代码 （2）站点层，这一层会访问后端数据，拼html页面返回给浏览器 （3）服务层，向上游屏蔽底层数据细节，提供数据访问 （4）数据层，最终的库存是存在这里的，mysql是一个典型（当然还有会缓存）</p><h3 id="四、各层次优化细节"><a href="#四、各层次优化细节" class="headerlink" title="四、各层次优化细节"></a>四、各层次优化细节</h3><h4 id="第一层，客户端怎么优化（浏览器层，APP层）"><a href="#第一层，客户端怎么优化（浏览器层，APP层）" class="headerlink" title="第一层，客户端怎么优化（浏览器层，APP层）"></a>第一层，客户端怎么优化（浏览器层，APP层）</h4><p>微信的摇一摇抢红包，每次摇一摇，就会往后端发送请求么？下单抢票的场景，点击了“查询”按钮之后，系统那个卡呀，进度条涨的慢呀，作为用户，我会不自觉的再去点击“查询”，对么？继续点，继续点，点点点。。。有用么？平白无故的增加了系统负载，一个用户点5次，80%的请求是这么多出来的，怎么整？</p><p>（a）产品层面，用户点击“查询”或者“购票”后，按钮置灰，禁止用户重复提交请求； （b）JS层面，限制用户在x秒之内只能提交一次请求；</p><p>APP层面，可以做类似的事情，虽然你疯狂的在摇微信，其实x秒才向后端发起一次请求。这就是所谓的“将请求尽量拦截在系统上游”，越上游越好，浏览器层，APP层就给拦住，这样就能挡住80%+的请求，这种办法只能拦住普通用户（但99%的用户是普通用户）对于群内的高端程序员是拦不住的。firebug一抓包，http长啥样都知道，js是万万拦不住程序员写for循环，调用http接口的，这部分请求怎么处理？</p><h4 id="第二层，站点层面的请求拦截"><a href="#第二层，站点层面的请求拦截" class="headerlink" title="第二层，站点层面的请求拦截"></a>第二层，站点层面的请求拦截</h4><p>怎么拦截？怎么防止程序员写for循环调用，有去重依据么？ip？cookie-id？…想复杂了，这类业务都需要登录，用uid即可。在站点层面，对uid进行请求计数和去重，甚至不需要统一存储计数，直接站点层内存存储（这样计数会不准，但最简单）。一个uid，5秒只准透过1个请求，这样又能拦住99%的for循环请求。</p><p>5s只透过一个请求，其余的请求怎么办？缓存，页面缓存，同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面。同一个item的查询，例如车次，做页面缓存，x秒内到达站点层的请求，均返回同一页面。如此限流，既能保证用户有良好的用户体验（没有返回404）又能保证系统的健壮性（利用页面缓存，把请求拦截在站点层了）。</p><p>页面缓存不一定要保证所有站点返回一致的页面，直接放在每个站点的内存也是可以的。优点是简单，坏处是http请求落到不同的站点，返回的车票数据可能不一样，这是站点层的请求拦截与缓存优化。</p><p>好，这个方式拦住了写for循环发http请求的程序员，有些高端程序员（黑客）控制了10w个肉鸡，手里有10w个uid，同时发请求（先不考虑实名制的问题，小米抢手机不需要实名制），这下怎么办，站点层按照uid限流拦不住了。</p><h4 id="第三层-服务层来拦截（反正就是不要让请求落到数据库上去）"><a href="#第三层-服务层来拦截（反正就是不要让请求落到数据库上去）" class="headerlink" title="第三层 服务层来拦截（反正就是不要让请求落到数据库上去）"></a>第三层 服务层来拦截（反正就是不要让请求落到数据库上去）</h4><p>服务层怎么拦截？大哥，我是服务层，我清楚的知道小米只有1万部手机，我清楚的知道一列火车只有2000张车票，我透10w个请求去数据库有什么意义呢？没错，请求队列！</p><p>对于写请求，做请求队列，每次只透有限的写请求去数据层（下订单，支付这样的写业务）</p><p>1w部手机，只透1w个下单请求去db</p><p>3k张火车票，只透3k个下单请求去db</p><p>如果均成功再放下一批，如果库存不够则队列里的写请求全部返回“已售完”。</p><p>对于读请求，怎么优化？cache抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的。如此限流，只有非常少的写请求，和非常少的读缓存mis的请求会透到数据层去，又有99.9%的请求被拦住了。</p><p>当然，还有业务规则上的一些优化。回想12306所做的，分时分段售票，原来统一10点卖票，现在8点，8点半，9点，…每隔半个小时放出一批：将流量摊匀。</p><p>其次，数据粒度的优化：你去购票，对于余票查询这个业务，票剩了58张，还是26张，你真的关注么，其实我们只关心有票和无票？流量大的时候，做一个粗粒度的“有票”“无票”缓存即可。</p><p>第三，一些业务逻辑的异步：例如下单业务与 支付业务的分离。这些优化都是结合 业务 来的，我之前分享过一个观点“一切脱离业务的架构设计都是耍流氓”架构的优化也要针对业务。</p><h4 id="第四层-最后是数据库层"><a href="#第四层-最后是数据库层" class="headerlink" title="第四层 最后是数据库层"></a>第四层 最后是数据库层</h4><p>浏览器拦截了80%，站点层拦截了99.9%并做了页面缓存，服务层又做了写请求队列与数据缓存，每次透到数据库层的请求都是可控的。db基本就没什么压力了，闲庭信步，单机也能扛得住，还是那句话，库存是有限的，小米的产能有限，透这么多请求来数据库没有意义。</p><p>全部透到数据库，100w个下单，0个成功，请求有效率0%。透3k个到数据，全部成功，请求有效率100%。</p><h3 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h3><p>上文应该描述的非常清楚了，没什么总结了，对于秒杀系统，再次重复下我个人经验的两个架构优化思路： （1）尽量将请求拦截在系统上游（越上游越好）； （2）读多写少的常用多使用缓存（缓存抗读压力）；</p><p>浏览器和APP：做限速</p><p>站点层：按照uid做限速，做页面缓存</p><p>服务层：按照业务做写请求队列控制流量，做数据缓存</p><p>数据层：闲庭信步</p><p>并且：结合业务做优化</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一、秒杀业务为什么难做&quot;&gt;&lt;a href=&quot;#一、秒杀业务为什么难做&quot; class=&quot;headerlink&quot; title=&quot;一、秒杀业务为什么难做&quot;&gt;&lt;/a&gt;一、秒杀业务为什么难做&lt;/h3&gt;&lt;p&gt;1）im系统，例如qq或者微博，每个人都读自己的数据（好友列表、群列
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxbwolf.github.io/categories/Design/"/>
    
    
      <category term="架构" scheme="https://lxbwolf.github.io/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>制作种子</title>
    <link href="https://lxbwolf.github.io/7592d71b/"/>
    <id>https://lxbwolf.github.io/7592d71b/</id>
    <published>2018-11-01T13:20:18.000Z</published>
    <updated>2019-10-03T16:43:59.940Z</updated>
    
    <content type="html"><![CDATA[<p>1.下载mktorrent<br><code>git clone https://github.com/lxbwolf/mktorrent.git</code><br>2.下载完成后进入到文件夹里面<br>例如：<code>cd mktorrent</code>（如果是根目录的话）<br>3. <code>make</code><br>4. <code>make install</code><br>5. 默认安装目录位于<code>/usr/local/bin</code>，使用cd命令，从默认的/root路径切换到要制作成种子的文件上一级。<br> 例如<code>cd /Downloads</code><br>6. 制作种子命令为： <code>mktorrent -v -p -l 22 -a tracker_address -o name.torrent file_name</code><br>参数说明： tracker_address为你要发布的网站的tracker。 name.torrent为对生成torrent种子文件的命名，规则为：xxx.torrent。 file_name为你要做种的文件或文件夹。避免含有空格。<br>7. 等待一会儿会提示做种完成，在当前目录下即可找到。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.下载mktorrent&lt;br&gt;&lt;code&gt;git clone https://github.com/lxbwolf/mktorrent.git&lt;/code&gt;&lt;br&gt;2.下载完成后进入到文件夹里面&lt;br&gt;例如：&lt;code&gt;cd mktorrent&lt;/code&gt;（如果是根目
      
    
    </summary>
    
    
      <category term="Rasp" scheme="https://lxbwolf.github.io/categories/Rasp/"/>
    
    
      <category term="torrent" scheme="https://lxbwolf.github.io/tags/torrent/"/>
    
  </entry>
  
  <entry>
    <title>树莓派搭建迅雷远程下载服务器</title>
    <link href="https://lxbwolf.github.io/1846a864/"/>
    <id>https://lxbwolf.github.io/1846a864/</id>
    <published>2018-11-01T12:09:55.000Z</published>
    <updated>2019-10-03T16:47:21.617Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-下载路由器固件"><a href="#1-下载路由器固件" class="headerlink" title="1. 下载路由器固件"></a>1. 下载路由器固件</h3><p>从 <a href="http://luyou.xunlei.com/forum-51-1.html" target="_blank" rel="noopener">官网</a> 或者 百度网盘</p><p>解压到指定目录如 <code>/root/xunlei</code> 进入目录 执行<code>./portal</code> 稍等片刻，会在最后输出一个激活码</p><h3 id="2-在迅雷远程下载页面绑定树莓派"><a href="#2-在迅雷远程下载页面绑定树莓派" class="headerlink" title="2. 在迅雷远程下载页面绑定树莓派"></a>2. 在迅雷远程下载页面绑定树莓派</h3><p>登录<a href="http://yuancheng.xunlei.com/login.html" target="_blank" rel="noopener">迅雷远程下载</a>主页,登录之后，左侧会有一个添加按钮，点击添加按钮</p><p>不需要选择绑定设备类型, 直接将树莓派上获得的激活码填入框中，点击绑定后左侧就会出现树莓派对应的设备列表了，但是，如果我们此时就在右侧点击新建之后会发现,弹出的新建页面中会提示找不到挂载磁盘</p><h3 id="3-自定义迅雷的下载目录"><a href="#3-自定义迅雷的下载目录" class="headerlink" title="3. 自定义迅雷的下载目录"></a>3. 自定义迅雷的下载目录</h3><p>进入/mnt目录，创建目录TDDOWNLOAD(名字随意) 执行<code>mount --bind /data/TDDOWNLOAD /mnt/TDDOWNLOAD</code></p><p>其中/data/TDDOWNLOAD就是自定义的下载目录，你可以指定为其他任何目录。</p><p>然后再刚刚迅雷固件的解压目录下创建目录etc,同时在etc下创建文件thunder_mounts.cfg,编辑此文件, 写入内容</p><pre><code>avaliable_mount_path_pattern{/mnt/TDDOWNLOAD}</code></pre><p>重启路由器固件 <code>./root/xunlei/portal</code> 再进入远程下载界面新建下载就没有了没挂载磁盘的提示了</p><h3 id="4-迅雷路由器固件开机启动"><a href="#4-迅雷路由器固件开机启动" class="headerlink" title="4. 迅雷路由器固件开机启动"></a>4. 迅雷路由器固件开机启动</h3><p>在/etc/init.d/下新建xunlei脚本，写入:</p><pre><code>#!/bin/sh## Xunlei initscript#### BEGIN INIT INFO# Provides:          xunlei# Required-Start:    $network $local_fs $remote_fs# Required-Stop::    $network $local_fs $remote_fs# Should-Start:      $all# Should-Stop:       $all# Default-Start:     2 3 4 5# Default-Stop:      0 1 6# Short-Description: Start xunlei at boot time# Description:       A downloader### END INIT INFOdo_start(){./root/xunlei/portal}do_stop(){./root/xunlei/portal -s}case &quot;$1&quot; instart)do_start;;stop)do_stop;;esac</code></pre><p>然后将该脚本加入默认自启动中 <code>update-rc.d xunlei defaults</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-下载路由器固件&quot;&gt;&lt;a href=&quot;#1-下载路由器固件&quot; class=&quot;headerlink&quot; title=&quot;1. 下载路由器固件&quot;&gt;&lt;/a&gt;1. 下载路由器固件&lt;/h3&gt;&lt;p&gt;从 &lt;a href=&quot;http://luyou.xunlei.com/forum
      
    
    </summary>
    
    
      <category term="Rasp" scheme="https://lxbwolf.github.io/categories/Rasp/"/>
    
    
      <category term="thunder" scheme="https://lxbwolf.github.io/tags/thunder/"/>
    
  </entry>
  
  <entry>
    <title>树莓派基础环境</title>
    <link href="https://lxbwolf.github.io/5976aace/"/>
    <id>https://lxbwolf.github.io/5976aace/</id>
    <published>2018-10-18T14:24:19.000Z</published>
    <updated>2019-10-03T07:57:15.293Z</updated>
    
    <content type="html"><![CDATA[<h3 id="修改软件源"><a href="#修改软件源" class="headerlink" title="修改软件源"></a>修改软件源</h3><pre><code>sudo -secho -e &quot;deb http://mirrors.ustc.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi \n deb-src http://mirrors.ustc.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi&quot; &amp;gt; /etc/apt/sources.listecho -e &quot;deb http://mirrors.ustc.edu.cn/archive.raspberrypi.org/ stretch main ui&quot; &amp;gt; /etc/apt/sources.list.d/raspi.listexitsudo apt update &amp;amp;&amp;amp; sudo apt -y upgrade</code></pre><h3 id="中文输入法"><a href="#中文输入法" class="headerlink" title="中文输入法"></a>中文输入法</h3><pre><code>sudo apt-get install -y ttf-wqy-zenheisudo apt-get install -y scim-pinyin</code></pre><h3 id="看门狗-防止树莓派死机的监控"><a href="#看门狗-防止树莓派死机的监控" class="headerlink" title="看门狗(防止树莓派死机的监控)"></a>看门狗(防止树莓派死机的监控)</h3><p>当利用树莓派来做一些需要长期待机的应用时，如下载机、云储存、家庭影院等应用，我们往往会遇到的一个问题就是树莓派会因为过热而死机，需要我们重新启动树莓派，然后再次开启树莓派上的应用。这会给我们的日常操作带来许多麻烦。 Watchdog（看门狗）就能让树莓派永不死机。</p><pre><code>//树莓派自带看门狗模块，我们需要添加进去就好。sudo modprobe bcm2708_wdogecho -e &quot;\nbcm2708_wdog&quot; &amp;gt; sudo tee -a /etc/modules// 安装看门狗软件sudo apt-get install -y chkconfig watchdog// 配置sudo vim /etc/watchdog.conf// 去掉&quot;watchdog-device=/dev/watchdog&quot;这一行的#注释// 其它配置参考如下:# 用于设定CPU温度重启条件temperature-device = /sys/class/thermal/thermal_zone0/temp# 最大温度为100度，超过立即重启max-temperature = 100000# 1分钟最多进程为24个，超过即重启max-load-15=12# 5分钟最多进程为18个，超过即重启max-load-15=12# 15分钟最多进程为12个，超过即重启max-load-15=12// 完成配置后，启动看门狗sudo /etc/init.d/watchdog start// 设置为开机自启chkconfig watchdog on</code></pre><h3 id="Screen-让树莓派永不失联"><a href="#Screen-让树莓派永不失联" class="headerlink" title="Screen(让树莓派永不失联)"></a>Screen(让树莓派永不失联)</h3><p>利用SSH（Serare Shell，安全外壳协议）来远程控制树莓派应该是我们最常用的 操作树莓派的方式，但在用SSH连接时，我们常常会遇到连接突然断开的问题。连 接一旦断开，原米我们进行的操作也就中断了，若再使用，就得从头再来了。相信你肯定因为电脑待机而中断树莓派的任务而苦恼过。 Screen来让树莓派永不失联的方法。此方法下，就算连接断开了，当我们重新连接后依旧进行原来的操作，而不需要从头再来。</p><pre><code>// 直接安装Screensudo apt-get install -y screen// 开启一个后台view（后台的终端，不会因为断开连接而终止）screen -S 终端名// 然后就可以继续你的操作了</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;修改软件源&quot;&gt;&lt;a href=&quot;#修改软件源&quot; class=&quot;headerlink&quot; title=&quot;修改软件源&quot;&gt;&lt;/a&gt;修改软件源&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;sudo -s
echo -e &amp;quot;deb http://mirrors.ustc.edu.
      
    
    </summary>
    
    
      <category term="Rasp" scheme="https://lxbwolf.github.io/categories/Rasp/"/>
    
    
  </entry>
  
  <entry>
    <title>树莓派3B+ 安装系统</title>
    <link href="https://lxbwolf.github.io/cfbe6b0a/"/>
    <id>https://lxbwolf.github.io/cfbe6b0a/</id>
    <published>2018-10-17T14:11:38.000Z</published>
    <updated>2019-10-03T07:57:15.296Z</updated>
    
    <content type="html"><![CDATA[<p>安装步骤: <code>官网下载系统 -- 刷入TF卡 -- 设置开启显示器和SSH -- 通电 -- 进入系统</code></p><h3 id="1-进入官方网站下载系统镜像"><a href="#1-进入官方网站下载系统镜像" class="headerlink" title="1. 进入官方网站下载系统镜像"></a>1. 进入官方网站下载系统镜像</h3><p>官方系统 raspbian地址 <a href="https://www.raspberrypi.org/downloads/" target="_blank" rel="noopener">https://www.raspberrypi.org/downloads/</a></p><h3 id="2-Windows系统下的安装"><a href="#2-Windows系统下的安装" class="headerlink" title="2. Windows系统下的安装"></a>2. Windows系统下的安装</h3><h4 id="2-1-下载SD格式化工具"><a href="#2-1-下载SD格式化工具" class="headerlink" title="2.1 下载SD格式化工具"></a>2.1 下载SD格式化工具</h4><p>SDFormatter 地址 <a href="https://www.sdcard.org/downloads/formatter\_4/eula\_windows/" target="_blank" rel="noopener">https://www.sdcard.org/downloads/formatter\_4/eula\_windows/</a></p><p>安装后直接用默认选项 格式化SD卡</p><h4 id="2-2-下载写镜像工具"><a href="#2-2-下载写镜像工具" class="headerlink" title="2.2 下载写镜像工具"></a>2.2 下载写镜像工具</h4><p>Win32 DiskImager 地址 <a href="http://sourceforge.net/projects/win32diskimager/" target="_blank" rel="noopener">http://sourceforge.net/projects/win32diskimager/</a></p><h3 id="3-MAC系统下的安装"><a href="#3-MAC系统下的安装" class="headerlink" title="3. MAC系统下的安装"></a>3. MAC系统下的安装</h3><h4 id="3-1-查看当前已挂载的卷"><a href="#3-1-查看当前已挂载的卷" class="headerlink" title="3.1 查看当前已挂载的卷"></a>3.1 查看当前已挂载的卷</h4><pre><code>[liuxb@liuxb-mac]$ df -hFilesystem      Size   Used  Avail Capacity iused      ifree %iused  Mounted on/dev/disk1     112Gi   81Gi   30Gi    73% 1014786 4293952493    0%   /devfs          188Ki  188Ki    0Bi   100%     654          0  100%   /devmap -hosts       0Bi    0Bi    0Bi   100%       0          0  100%   /netmap auto_home    0Bi    0Bi    0Bi   100%       0          0  100%   /home/dev/disk2s3    92Gi   51Gi   41Gi    56%  336662   42525054    1%   /Volumes/系统/dev/disk2s4    20Gi   15Gi  4.4Gi    78%   92859    4579733    2%   /Volumes/数据/dev/disk3s1    29Gi  2.3Mi   29Gi     1%  107876    8373436    2%   /Volumes/未命名</code></pre><p><code>对比Size和Name可以找到SD卡的分区在系统里对应的设备文件（这里是/dev/disk3s1），如果你有多个分区，可能还会有disk3s2之类的</code></p><h4 id="3-2-使用diskutil-unmount将分区卸载"><a href="#3-2-使用diskutil-unmount将分区卸载" class="headerlink" title="3.2 使用diskutil unmount将分区卸载"></a>3.2 使用diskutil unmount将分区卸载</h4><pre><code>[liuxb@liuxb-mac]$ diskutil unmount /dev/disk3s1Volume 未命名 on disk3s1 unmounted</code></pre><h4 id="3-3-先对下载的zip压缩包进行解压，然后使用dd命令将系统镜像写入，需要特别特别注意disk后的数字，不能搞错"><a href="#3-3-先对下载的zip压缩包进行解压，然后使用dd命令将系统镜像写入，需要特别特别注意disk后的数字，不能搞错" class="headerlink" title="3.3 先对下载的zip压缩包进行解压，然后使用dd命令将系统镜像写入，需要特别特别注意disk后的数字，不能搞错"></a>3.3 先对下载的zip压缩包进行解压，然后使用dd命令将系统镜像写入，需要特别特别注意disk后的数字，不能搞错</h4><p>说明：/dev/disk3s1是分区，/dev/disk3是块设备，/dev/rdisk3是原始字符设备</p><pre><code>[liuxb@liuxb-mac]$ unzip 2017-09-07-raspbian-stretch.zip[liuxb@liuxb-mac]$ sudo dd bs=16m if=2017-09-07-raspbian-stretch.img of=/dev/rdisk3_输入用户密码</code></pre><p>经过几分钟的等待，出现下面的提示，说明TF卡刷好了：</p><pre><code>1172+1 records in1172+1 records out4916019200 bytes transferred in 127.253638 secs (9691442 bytes/sec)</code></pre><h3 id="4-开启SSH"><a href="#4-开启SSH" class="headerlink" title="4. 开启SSH"></a>4. 开启SSH</h3><p>在TF卡分区里创建一个名为”ssh”的不带后缀的空文件</p><h3 id="5-开启强制HDMI输出"><a href="#5-开启强制HDMI输出" class="headerlink" title="5. 开启强制HDMI输出"></a>5. 开启强制HDMI输出</h3><p>在TF卡分区，打开config.txt文件(开机后位置： /boot/config.txt)，修改如下：</p><pre><code>hdmi_safe=1config_hdmi_boost=4hdmi_ignore_edid=0xa5000080hdmi_group=2hdmi_mode=82</code></pre><p>参数介绍:</p><p>项</p><p>解释</p><p>hdmi_safe=1</p><p>安全启动HDMI</p><p>config_hdmi_boost=4</p><p>开启热插拔</p><p>hdmi_group=1</p><p>CEA电视显示器</p><p>hdmi_group=2</p><p>DMT电脑显示器</p><p>hdmi_ignore_edid=0xa5000080</p><p>忽略自动探测的分辨率</p><p>输出分辨率：</p><p>hdmi_mode=4</p><p>640x480 60Hz</p><p>hdmi_mode=9</p><p>800x600 60Hz</p><p>hdmi_mode=16</p><p>1024x768 60Hz</p><p>hdmi_mode=82</p><p>1080p 60Hz</p><h3 id="6-设置无线WI-FI连接：（假设没有网线，而且没能连接显示器）"><a href="#6-设置无线WI-FI连接：（假设没有网线，而且没能连接显示器）" class="headerlink" title="6.设置无线WI-FI连接：（假设没有网线，而且没能连接显示器）"></a>6.设置无线WI-FI连接：（假设没有网线，而且没能连接显示器）</h3><p>在TF卡的boot分区，创建wpa_supplicant.conf文件，加入如下内容：</p><pre><code>country=CNctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdevupdate_config=1network={ssid=&quot;lxb-wifi&quot;psk=&quot;123456789&quot;priority=1}</code></pre><p>在树莓派通电后会自动添加到<code>/etc/wpa_supplicant/wpa_supplicant.conf</code>文件里面，进行自动连接。</p><pre><code>// 详细介绍：#ssid:网络的ssid#psk:密码#priority:连接优先级，数字越大优先级越高（不可以是负数）#scan_ssid:连接隐藏WiFi时需要指定该值为1// 如果WiFi 没有密码network={ssid=&quot;无线网络名称（ssid）&quot;key_mgmt=NONE}// 如果WiFi 使用WEP加密network={ssid=&quot;无线网络名称（ssid）&quot;key_mgmt=NONEwep_key0=&quot;wifi密码&quot;}// 如果你的 WiFi 使用WPA/WPA2加密network={ssid=&quot;无线网络名称（ssid）&quot;key_mgmt=WPA-PSKpsk=&quot;wifi密码&quot;}</code></pre><p>以上设置完成后, TF卡可以插入树莓派了, 通电. 默认登录账号:<code>pi</code> 密码: <code>raspberry</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;安装步骤: &lt;code&gt;官网下载系统 -- 刷入TF卡 -- 设置开启显示器和SSH -- 通电 -- 进入系统&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;1-进入官方网站下载系统镜像&quot;&gt;&lt;a href=&quot;#1-进入官方网站下载系统镜像&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
    
      <category term="Rasp" scheme="https://lxbwolf.github.io/categories/Rasp/"/>
    
    
  </entry>
  
</feed>
