<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xiaobin&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://lxb.wiki/"/>
  <updated>2022-03-01T08:41:25.953Z</updated>
  <id>https://lxb.wiki/</id>
  
  <author>
    <name>Xiaobin.Liu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>hexo支持mermaid</title>
    <link href="https://lxb.wiki/6541b31d/"/>
    <id>https://lxb.wiki/6541b31d/</id>
    <published>2021-09-15T13:34:12.000Z</published>
    <updated>2022-03-01T08:41:25.953Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#前言">前言</a></li><li><a href="#安装插件">安装插件</a></li><li><a href="#编辑配置文件">编辑配置文件</a></li><li><a href="#在-ejs-中引入-mermaidjs">在 ejs 中引入 mermaid.js</a></li><li><a href="#qa">Q&amp;A</a></li></ul><!-- tocstop --><h2 id="前言"><span id="前言">前言</span></h2><p>一定要参考[官网](<a href="https://mermaid-js.github.io/mermaid/#/" target="_blank" rel="noopener">mermaid - Markdownish syntax for generating flowcharts, sequence diagrams, class diagrams, gantt charts and git graphs. (mermaid-js.github.io)</a>)</p><p>不要相信垃圾 CSDN</p><h2 id="安装插件"><span id="安装插件">安装插件</span></h2><p>npm 安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-filter-mermaid-diagrams</span><br></pre></td></tr></table></figure><p>项目 [GitHub 主页]<a href="https://github.com/webappdevelp/hexo-filter-mermaid-diagrams" target="_blank" rel="noopener">webappdevelp/hexo-filter-mermaid-diagrams: mermaid diagrams for hexo (github.com)</a></p><h2 id="编辑配置文件"><span id="编辑配置文件">编辑配置文件</span></h2><p>修改文件 <code>themes/pure/_config.yml</code></p><p>文件最好添加以下内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mermaid chart</span></span><br><span class="line"><span class="attr">mermaid:</span> <span class="comment">## mermaid url https://github.com/knsv/mermaid</span></span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span>  <span class="comment"># default true</span></span><br><span class="line"><span class="attr">  version:</span> <span class="string">"7.1.2"</span> <span class="comment"># default v7.1.2</span></span><br><span class="line"><span class="attr">  options:</span>  <span class="comment"># find more api options from https://github.com/knsv/mermaid/blob/master/src/mermaidAPI.js</span></span><br><span class="line">    <span class="comment">#startOnload: true  // default true</span></span><br></pre></td></tr></table></figure><h2 id="在-ejs-中引入-mermaidjs"><span id="在-ejs-中引入-mermaidjs">在 ejs 中引入 mermaid.js</span></h2><p>修改 <code>themes/pure/layout/_common/footer.ejs</code></p><p>添加以下内容</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;% <span class="keyword">if</span> (theme.mermaid.enable) &#123; %&gt;</span><br><span class="line">  &lt;script src=<span class="string">'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js'</span>&gt;<span class="xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line">  &lt;script&gt;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">window</span>.mermaid) &#123;</span><br><span class="line">      mermaid.initialize(&#123;<span class="attr">theme</span>: <span class="string">'forest'</span>&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &lt;<span class="regexp">/script&gt;</span></span><br><span class="line"><span class="regexp">&lt;% &#125; %&gt;</span></span><br></pre></td></tr></table></figure><h2 id="qampa"><span id="qampa">Q&amp;A</span></h2><p>如果加载完后，显示的图不正确，那么很有可能是因为引入 <code>mermaid.min.js</code> 的链接不正确</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#安装插件&quot;&gt;安装插件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#编辑配置文件&quot;&gt;编辑配置文件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#在-ejs
      
    
    </summary>
    
    
      <category term="Tools" scheme="https://lxb.wiki/categories/Tools/"/>
    
    
      <category term="工具" scheme="https://lxb.wiki/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="mermaid" scheme="https://lxb.wiki/tags/mermaid/"/>
    
      <category term="hexo" scheme="https://lxb.wiki/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统的CAP理论</title>
    <link href="https://lxb.wiki/3bdd21ca/"/>
    <id>https://lxb.wiki/3bdd21ca/</id>
    <published>2021-09-10T13:54:27.000Z</published>
    <updated>2022-02-26T07:50:30.182Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#cap理论概述">CAP理论概述</a></li><li><a href="#cap的定义">CAP的定义</a><ul><li><a href="#consistency-一致性">Consistency 一致性</a></li><li><a href="#availability-可用性">Availability 可用性</a></li><li><a href="#partition-tolerance分区容错性">Partition Tolerance分区容错性</a></li></ul></li><li><a href="#cap的证明">CAP的证明</a></li><li><a href="#cap权衡">CAP权衡</a><ul><li><a href="#ca-without-p">CA without P</a></li><li><a href="#cp-without-a">CP without A</a></li><li><a href="#ap-wihtout-c">AP wihtout C</a></li></ul></li></ul><!-- tocstop --><h2 id="cap理论概述"><span id="cap理论概述">CAP理论概述</span></h2><p>CAP理论：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226145516.png" alt></p><blockquote><p>CAP理论中的CA和数据库事务中ACID的CA并不是同一回事儿。两者之中的C都是都是一致性(Consistency)。CAP中的A指的是可用性（Availability），而ACID中的A指的是原子性（Atomicity)，切勿混为一谈。</p></blockquote><h2 id="cap的定义"><span id="cap的定义">CAP的定义</span></h2><h3 id="consistency-一致性"><span id="consistency-一致性">Consistency 一致性</span></h3><p>一致性指“<code>all nodes see the same data at the same time</code>”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，所以，一致性，说的就是数据一致性。<a href="http://www.hollischuang.com/archives/663" target="_blank" rel="noopener">分布式的一致性</a></p><p>对于一致性，可以分为从客户端和服务端两个不同的视角。从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。</p><p>一致性是因为有并发读写才有的问题，因此在理解一致性的问题时，一定要注意结合考虑并发读写的场景。</p><p>从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。</p><p><strong>三种一致性策略</strong></p><p>对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。</p><p>如果能容忍后续的部分或者全部访问不到，则是弱一致性。</p><p>如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。</p><p>CAP中说，不可能同时满足的这个一致性指的是强一致性。</p><h3 id="availability-可用性"><span id="availability-可用性">Availability 可用性</span></h3><p>可用性指“<code>Reads and writes always succeed</code>”，即服务一直可用，而且是正常响应时间。</p><p>对于一个可用性的分布式系统，每一个非故障的节点必须对每一个请求作出响应。所以，一般我们在衡量一个系统的可用性的时候，都是通过停机时间来计算的。</p><table><thead><tr><th align="center">可用性分类</th><th align="center">可用水平（%）</th><th align="center">年可容忍停机时间</th></tr></thead><tbody><tr><td align="center">容错可用性</td><td align="center">99.9999</td><td align="center">&lt;1 min</td></tr><tr><td align="center">极高可用性</td><td align="center">99.999</td><td align="center">&lt;5 min</td></tr><tr><td align="center">具有故障自动恢复能力的可用性</td><td align="center">99.99</td><td align="center">&lt;53 min</td></tr><tr><td align="center">高可用性</td><td align="center">99.9</td><td align="center">&lt;8.8h</td></tr><tr><td align="center">商品可用性</td><td align="center">99</td><td align="center">&lt;43.8 min</td></tr></tbody></table><p>通常我们描述一个系统的可用性时，我们说淘宝的系统可用性可以达到5个9，意思就是说他的可用水平是99.999%，即全年停机时间不超过 <code>(1-0.99999)*365*24*60 = 5.256 min</code>，这是一个极高的要求。</p><p>好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。一个分布式系统，上下游设计很多系统如负载均衡、WEB服务器、应用代码、数据库服务器等，任何一个节点的不稳定都可以影响可用性。</p><h3 id="partition-tolerance分区容错性"><span id="partition-tolerance分区容错性">Partition Tolerance分区容错性</span></h3><p>分区容错性指“<code>the system continues to operate despite arbitrary message loss or failure of part of the system</code>”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。</p><p>分区容错性和扩展性紧密相关。在分布式应用中，可能因为一些分布式的原因导致系统无法正常运转。好的分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，或者是机器之间有网络异常，将分布式系统分隔未独立的几个部分，各个部分还能维持分布式系统的运作，这样就具有好的分区容错性。</p><p>简单点说，就是在网络中断，消息丢失的情况下，系统如果还能正常工作，就是有比较好的分区容错性。</p><h2 id="cap的证明"><span id="cap的证明">CAP的证明</span></h2><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226154057.png" alt></p><p>如上图，是我们证明CAP的基本场景，网络中有两个节点N1和N2，可以简单的理解N1和N2分别是两台计算机，他们之间网络可以连通，N1中有一个应用程序A，和一个数据库V，N2也有一个应用程序B2和一个数据库V。现在，A和B是分布式系统的两个部分，V是分布式系统的数据存储的两个子数据库。</p><p>在满足一致性的时候，N1和N2中的数据是一样的，V0=V0。在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226154153.png" alt></p><p>如上图，是分布式系统正常运转的流程，用户向N1机器请求数据更新，程序A更新数据库Vo为V1，分布式系统将数据进行同步操作M，将V1同步的N2中V0，使得N2中的数据V0也更新为V1，N2中的数据再响应N2的请求。</p><p>这里，可以定义N1和N2的数据库V之间的数据是否一样为一致性；外部对N1和N2的请求响应为可用行；N1和N2之间的网络环境为分区容错性。这是正常运作的场景，也是理想的场景，然而现实是残酷的，当错误发生的时候，一致性和可用性还有分区容错性，是否能同时满足，还是说要进行取舍呢？</p><p>作为一个分布式系统，它和单机系统的最大区别，就在于网络，现在假设一种极端情况，N1和N2之间的网络断开了，我们要支持这种网络异常，相当于要满足分区容错性，能不能同时满足一致性和响应性呢？还是说要对他们进行取舍。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226154349.png" alt></p><p>假设在N1和N2之间网络断开的时候，有用户向N1发送数据更新请求，那N1中的数据V0将被更新为V1，由于网络是断开的，所以分布式系统同步操作M，所以N2中的数据依旧是V0；这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据V1，怎么办呢？</p><p>有二种选择，第一，牺牲数据一致性，保证可用性。响应旧的数据V0给用户；</p><p>第二，牺牲可用性，保证数据一致性。阻塞等待，直到网络连接恢复，数据更新操作M完成之后，再给用户响应最新的数据V1。</p><p>这个过程，证明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。</p><h2 id="cap权衡"><span id="cap权衡">CAP权衡</span></h2><p>通过CAP理论及前面的证明，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？</p><p>我们分三种情况来阐述一下。</p><h3 id="ca-without-p"><span id="ca-without-p">CA without P</span></h3><p>这种情况在分布式系统中几乎是不存在的。首先在分布式环境下，网络分区是一个自然的事实。因为分区是必然的，所以如果舍弃P，意味着要舍弃分布式系统。那也就没有必要再讨论CAP理论了。这也是为什么在前面的CAP证明中，我们以系统满足P为前提论述了无法同时满足C和A。</p><p>比如我们熟知的关系型数据库，如My Sql和Oracle就是保证了可用性和数据一致性，但是他并不是个分布式系统。一旦关系型数据库要考虑主备同步、集群部署等就必须要把P也考虑进来。</p><p>其实，在CAP理论中。C，A，P三者并不是平等的，CAP之父在《Spanner，真时，CAP理论》一文中写到：</p><blockquote><p>如果说Spanner真有什么特别之处，那就是谷歌的广域网。Google通过建立私有网络以及强大的网络工程能力来保证P，在多年运营改进的基础上，在生产环境中可以最大程度的减少分区发生，从而实现高可用性。</p></blockquote><p>从Google的经验中可以得到的结论是，无法通过降低CA来提升P。要想提升系统的分区容错性，需要通过提升基础设施的稳定性来保障。</p><p>所以，对于一个分布式系统来说。P是一个基本要求，CAP三者中，只能在CA两者之间做权衡，并且要想尽办法提升P。</p><h3 id="cp-without-a"><span id="cp-without-a">CP without A</span></h3><p>如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在CAP三者中保障CP而舍弃A。</p><p>一个保证了CP而一个舍弃了A的分布式系统，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。</p><p>设计成CP的系统其实也不少，其中最典型的就是很多分布式数据库，他们都是设计成CP的。在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的。</p><p>无论是像Redis、HBase这种分布式存储系统，还是像Zookeeper这种分布式协调组件。数据的一致性是他们最最基本的要求。一个连数据一致性都保证不了的分布式存储要他有何用？</p><p>ZooKeeper是个CP（一致性+分区容错性）的，即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性。但是它不能保证每次服务请求的可用性，也就是在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。ZooKeeper是分布式协调服务，它的职责是保证数据在其管辖下的所有服务之间保持同步、一致。所以就不难理解为什么ZooKeeper被设计成CP而不是AP特性的了。</p><h3 id="ap-wihtout-c"><span id="ap-wihtout-c">AP wihtout C</span></h3><p>要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。</p><p>这种舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性可以达到N个9，所以，对于很多业务系统来说，比如淘宝的购物，12306的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性。</p><p>你在12306买票的时候肯定遇到过这种场景，当你购买的时候提示你是有票的（但是可能实际已经没票了），你也正常的去输入验证码，下单了。但是过了一会系统提示你下单失败，余票不足。这其实就是先在可用性方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，会影响一些用户体验，但是也不至于造成用户流程的严重阻塞。</p><p>但是，我们说很多网站牺牲了一致性，选择了可用性，这其实也不准确的。就比如上面的买票的例子，其实舍弃的只是强一致性。退而求其次保证了最终一致性。也就是说，虽然下单的瞬间，关于车票的库存可能存在数据不一致的情况，但是过了一段时间，还是要保证最终一致性的。</p><p>对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#cap理论概述&quot;&gt;CAP理论概述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#cap的定义&quot;&gt;CAP的定义&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#consistency-一致性&quot;&gt;Consistency 一
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxb.wiki/categories/Design/"/>
    
    
      <category term="分布式" scheme="https://lxb.wiki/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>go map数据结构</title>
    <link href="https://lxb.wiki/aaf3975f/"/>
    <id>https://lxb.wiki/aaf3975f/</id>
    <published>2021-08-28T14:30:18.000Z</published>
    <updated>2022-02-26T06:46:51.919Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-前言">1. 前言</a></li><li><a href="#2-go-map的数据结构">2. go map的数据结构</a><ul><li><a href="#21-核心结体体">2.1 核心结体体</a></li><li><a href="#22-数据结构图">2.2 数据结构图</a></li></ul></li><li><a href="#3-go-map的常用操作">3. go map的常用操作</a><ul><li><a href="#31-创建">3.1 创建</a></li><li><a href="#32-插入或更新">3.2 插入或更新</a></li><li><a href="#33-删除">3.3 删除</a></li><li><a href="#34-查找">3.4 查找</a></li><li><a href="#35-range迭代">3.5 range迭代</a><ul><li><a href="#351-初始化迭代器mapiterinit">3.5.1 初始化迭代器mapiterinit()</a></li><li><a href="#352-迭代过程mapiternext">3.5.2 迭代过程mapiternext()</a></li></ul></li></ul></li><li><a href="#4-go-map的扩容缩容">4. go map的扩容缩容</a><ul><li><a href="#41-扩容缩容的基本原理">4.1 扩容缩容的基本原理</a></li><li><a href="#42-为什么叫伪缩容如何实现真缩容">4.2 为什么叫“伪缩容”？如何实现“真缩容”？</a></li></ul></li><li><a href="#5-qa关键知识点">5 Q&amp;A关键知识点</a><ul><li><a href="#51-基本原理">5.1 基本原理</a></li><li><a href="#52-时间复杂度和空间复杂度分析">5.2 时间复杂度和空间复杂度分析</a></li></ul></li></ul><!-- tocstop --><h1 id="1-前言"><span id="1-前言">1. 前言</span></h1><p>go的map底层实现方式是hash表（C++的map是红黑树实现，而C++ 11新增的unordered_map则与go的map类似，都是hash实现）。go map的数据被置入一个由桶组成的有序数组中，每个桶最多可以存放8个key/value对。key的hash值(32位)的低阶位用于在该数组中定位到桶，而高8位则用于在桶中区分key/value对。<br>go map的hash表中的基本单位是桶，每个桶最多存8个键值对，超了，则会链接到额外的溢出桶。所以go map是基本数据结构是hash数组+桶内的key-value数组+溢出的桶链表<br>当hash表超过阈值需要扩容增长时，会分配一个新的数组，新数组的大小一般是旧数组的2倍。这里从旧数组将数据迁移到新数组，不会一次全量拷贝，go会在每次读写Map时以桶为单位做动态搬迁疏散。</p><h1 id="2-go-map的数据结构"><span id="2-go-map的数据结构">2. go map的数据结构</span></h1><h2 id="21-核心结体体"><span id="21-核心结体体">2.1 核心结体体</span></h2><p>map主要由两个核心的结构，即基础结构和桶实现：</p><ul><li>hmap：map的基础结构</li><li>bmap：严格来说hmap.buckets指向桶组成的数组，每个桶的头部是bmap，之后是8个key，再是8个value，最后是1个溢出指针。溢出指针指向额外的桶链表，用于存储溢出的数据</li></ul><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> ( <span class="comment">// 关键的变量</span></span><br><span class="line">    bucketCntBits = <span class="number">3</span></span><br><span class="line">bucketCnt     = <span class="number">1</span> &lt;&lt; bucketCntBits  <span class="comment">// 一个桶最多存储8个key-value对</span></span><br><span class="line">loadFactorNum = <span class="number">13</span> <span class="comment">// 扩散因子：loadFactorNum / loadFactorDen = 6.5。</span></span><br><span class="line">loadFactorDen = <span class="number">2</span>  <span class="comment">// 即元素数量 &gt;= (hash桶数量(2^hmp.B) * 6.5 / 8) 时，触发扩容</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">// map的基础数据结构</span></span><br><span class="line"><span class="keyword">type</span> hmap <span class="keyword">struct</span> &#123;</span><br><span class="line">count     <span class="keyword">int</span> <span class="comment">// map存储的元素对计数，len()函数返回此值，所以map的len()时间复杂度是O(1)</span></span><br><span class="line">flags     <span class="keyword">uint8</span>  <span class="comment">// 记录几个特殊的位标记，如当前是否有别的线程正在写map、当前是否为相同大小的增长（扩容/缩容？）</span></span><br><span class="line">B         <span class="keyword">uint8</span>  <span class="comment">// hash桶buckets的数量为2^B个</span></span><br><span class="line">noverflow <span class="keyword">uint16</span> <span class="comment">// 溢出的桶的数量的近似值</span></span><br><span class="line">hash0     <span class="keyword">uint32</span> <span class="comment">// hash种子</span></span><br><span class="line"></span><br><span class="line">buckets    unsafe.Pointer <span class="comment">// 指向2^B个桶组成的数组的指针，数据存在这里</span></span><br><span class="line">oldbuckets unsafe.Pointer <span class="comment">// 指向扩容前的旧buckets数组，只在map增长时有效</span></span><br><span class="line">nevacuate  <span class="keyword">uintptr</span>        <span class="comment">// 计数器，标示扩容后搬迁的进度</span></span><br><span class="line"></span><br><span class="line">extra *mapextra <span class="comment">// 保存溢出桶的链表和未使用的溢出桶数组的首地址</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 桶的实现结构</span></span><br><span class="line"><span class="keyword">type</span> bmap <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// tophash存储桶内每个key的hash值的高字节</span></span><br><span class="line"><span class="comment">// tophash[0] &lt; minTopHash表示桶的疏散状态</span></span><br><span class="line"><span class="comment">// 当前版本bucketCnt的值是8，一个桶最多存储8个key-value对</span></span><br><span class="line">tophash [bucketCnt]<span class="keyword">uint8</span></span><br><span class="line"><span class="comment">// 特别注意：</span></span><br><span class="line"><span class="comment">// 实际分配内存时会申请一个更大的内存空间A，A的前8字节为bmap</span></span><br><span class="line"><span class="comment">// 后面依次跟8个key、8个value、1个溢出指针</span></span><br><span class="line"><span class="comment">// map的桶结构实际指的是内存空间A</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// map.go里很多函数的第1个入参是这个结构，从成员来看很明显，此结构标示了键值对和桶的大小等必要信息</span></span><br><span class="line"><span class="comment">// 有了这个结构的信息，map.go的代码就可以与键值对的具体数据类型解耦</span></span><br><span class="line"><span class="comment">// 所以map.go用内存偏移量和unsafe.Pointer指针来直接对内存进行存取，而无需关心key或value的具体类型</span></span><br><span class="line"><span class="keyword">type</span> maptype <span class="keyword">struct</span> &#123;</span><br><span class="line">typ        _type</span><br><span class="line">key        *_type</span><br><span class="line">elem       *_type</span><br><span class="line">bucket     *_type <span class="comment">// internal type representing a hash bucket</span></span><br><span class="line">keysize    <span class="keyword">uint8</span>  <span class="comment">// size of key slot</span></span><br><span class="line">valuesize  <span class="keyword">uint8</span>  <span class="comment">// size of value slot</span></span><br><span class="line">bucketsize <span class="keyword">uint16</span> <span class="comment">// size of bucket</span></span><br><span class="line">flags      <span class="keyword">uint32</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>C++使用模板可以根据不同的类型生成map的代码。<br>golang则通过上述maptype结构体传递键值对的类型大小等信息，从而map.go直接用指针操作对应大小的内存来实现全局一份map代码同时适用于不同类型的键值对。这点上可以认为相比C++用模板实现map的方式，go map的目标文件的代码量会更小。</p><h2 id="22-数据结构图"><span id="22-数据结构图">2.2 数据结构图</span></h2><p>map底层创建时，会初始化一个hmap结构体，同时分配一个足够大的内存空间A。其中A的前段用于hash数组，A的后段预留给溢出的桶。于是hmap.buckets指向hash数组，即A的首地址；hmap.extra.nextOverflow初始时指向内存A中的后段，即hash数组结尾的下一个桶，也即第1个预留的溢出桶。所以当hash冲突需要使用到新的溢出桶时，会优先使用上述预留的溢出桶，hmap.extra.nextOverflow依次往后偏移直到用完所有的溢出桶，才有可能会申请新的溢出桶空间。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226143452.png" alt></p><p>上图中，当需要分配一个溢出桶时，会优先从预留的溢出桶数组里取一个出来链接到链表后面，这时不需要再次申请内存。但当预留的桶被用完了，则需要申请新的内存给溢出桶。</p><h1 id="3-go-map的常用操作"><span id="3-go-map的常用操作">3. go map的常用操作</span></h1><h2 id="31-创建"><span id="31-创建">3.1 创建</span></h2><p>使用make(map[k]v, hint)创建map时会调用makemap()函数，代码逻辑比较简单。<br>值得注意的是，makemap()创建的hash数组，数组的前面是hash表的空间，当hint &gt;= 4时后面会追加2^(hint-4)个桶，之后再内存页帧对齐又追加了若干个桶（参见2.2章节结构图的hash数组部分）<br>所以创建map时一次内存分配既分配了用户预期大小的hash数组，又追加了一定量的预留的溢出桶，还做了内存对齐，一举多得。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// make(map[k]v, hint), hint即预分配大小</span></span><br><span class="line"><span class="comment">// 不传hint时，如用new创建个预设容量为0的map时，makemap只初始化hmap结构，不分配hash数组</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">makemap</span><span class="params">(t *maptype, hint <span class="keyword">int</span>, h *hmap)</span> *<span class="title">hmap</span></span> &#123;</span><br><span class="line"><span class="comment">// 省略部分代码</span></span><br><span class="line"><span class="comment">// 随机hash种子</span></span><br><span class="line">h.hash0 = fastrand()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2^h.B 为大于hint*6.5(扩容因子)的最小的2的幂</span></span><br><span class="line">B := <span class="keyword">uint8</span>(<span class="number">0</span>)</span><br><span class="line"><span class="comment">// overLoadFactor(hint, B)只有一行代码：return hint &gt; bucketCnt &amp;&amp; uintptr(hint) &gt; loadFactorNum*(bucketShift(B)/loadFactorDen)</span></span><br><span class="line"><span class="comment">// 即B的大小应满足 hint &lt;= (2^B) * 6.5</span></span><br><span class="line"><span class="comment">// 一个桶能存8对key-value，所以这就表示B的初始值是保证这个map不需要扩容即可存下hint个元素对的最小的B值</span></span><br><span class="line"><span class="keyword">for</span> overLoadFactor(hint, B) &#123;</span><br><span class="line">B++</span><br><span class="line">&#125;</span><br><span class="line">h.B = B</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里分配hash数组</span></span><br><span class="line"><span class="keyword">if</span> h.B != <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">var</span> nextOverflow *bmap</span><br><span class="line">h.buckets, nextOverflow = makeBucketArray(t, h.B, <span class="literal">nil</span>)</span><br><span class="line"><span class="comment">// makeBucketArray()会在hash数组后面预分配一些溢出桶，</span></span><br><span class="line"><span class="comment">// h.extra.nextOverflow用来保存上述溢出桶的首地址</span></span><br><span class="line"><span class="keyword">if</span> nextOverflow != <span class="literal">nil</span> &#123;</span><br><span class="line">h.extra = <span class="built_in">new</span>(mapextra)</span><br><span class="line">h.extra.nextOverflow = nextOverflow</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> h</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 分配hash数组</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">makeBucketArray</span><span class="params">(t *maptype, b <span class="keyword">uint8</span>, dirtyalloc unsafe.Pointer)</span> <span class="params">(buckets unsafe.Pointer, nextOverflow *bmap)</span></span> &#123;</span><br><span class="line">base := bucketShift(b) <span class="comment">// base代表用户预期的桶的数量，即hash数组的真实大小</span></span><br><span class="line">nbuckets := base <span class="comment">// nbuckets表示实际分配的桶的数量，&gt;= base，这就可能会追加一些溢出桶作为溢出的预留</span></span><br><span class="line"><span class="keyword">if</span> b &gt;= <span class="number">4</span> &#123;</span><br><span class="line"><span class="comment">// 这里追加一定数量的桶，并做内存对齐</span></span><br><span class="line">nbuckets += bucketShift(b - <span class="number">4</span>)</span><br><span class="line">sz := t.bucket.size * nbuckets</span><br><span class="line">up := roundupsize(sz)</span><br><span class="line"><span class="keyword">if</span> up != sz &#123;</span><br><span class="line">nbuckets = up / t.bucket.size</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 后面的代码就是申请内存空间了，此处省略</span></span><br><span class="line"><span class="comment">// 这里大家可以思考下这个数组空间要怎么分配，其实就是n*sizeof(桶)，所以：</span></span><br><span class="line"><span class="comment">// 每个桶前面是8字节的tophash数组，然后是8个key，再是8个value，最后放一个溢出指针</span></span><br><span class="line"><span class="comment">// sizeof(桶) = 8 + 8*sizeof(key) + 8*sizeof(value) + 8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> buckets, nextOverflow</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="32-插入或更新"><span id="32-插入或更新">3.2 插入或更新</span></h2><p>go map的插入操作，调用mapassign()函数。<br>同学们或许在某些资料上了解过：</p><ul><li>go map需要初始化才能使用，对空map插入会panic。hmap指针传递的方式，决定了map在使用前必须初始化</li><li>go map不支持并发读写，会panic。如果一定要并发，请用sync.Map或自己解决冲突</li></ul><p>上述两个限制，在mapassign()函数开头能找到答案：</p><p>1 参数合法性检测，计算hash值</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mapassign</span><span class="params">(t *maptype, h *hmap, key unsafe.Pointer)</span> <span class="title">unsafe</span>.<span class="title">Pointer</span></span> &#123;</span><br><span class="line">    <span class="comment">// 不熟悉指针操作的同学，用指针传参往往会踩空指针的坑</span></span><br><span class="line">    <span class="comment">// 这里大家可以思考下，为什么h要非空判断？</span></span><br><span class="line">    <span class="comment">// 如果一定要在这里支持空map并检测到map为空时自动初始化，应该怎么写？</span></span><br><span class="line">    <span class="comment">// 提示：指针的指针</span></span><br><span class="line"><span class="keyword">if</span> h == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(plainError(<span class="string">"assignment to entry in nil map"</span>))</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 在这里做并发判断，检测到并发写时，抛异常</span></span><br><span class="line"><span class="comment">// 注意：go map的并发检测是伪检测，并不保证所有的并发都会被检测出来。而且这玩意是在运行期检测。</span></span><br><span class="line"><span class="comment">// 所以对map有并发要求时，应使用sync.map来代替普通map，通过加锁来阻断并发冲突</span></span><br><span class="line"><span class="keyword">if</span> h.flags&amp;hashWriting != <span class="number">0</span> &#123;</span><br><span class="line">throw(<span class="string">"concurrent map writes"</span>)</span><br><span class="line">&#125;</span><br><span class="line">hash := alg.hash(key, <span class="keyword">uintptr</span>(h.hash0)) <span class="comment">// 这里得到uint32的hash值</span></span><br><span class="line">h.flags ^= hashWriting <span class="comment">// 置Writing标志，key写入buckets后才会清除标志</span></span><br><span class="line"><span class="keyword">if</span> h.buckets == <span class="literal">nil</span> &#123; <span class="comment">// map不能为空，但hash数组可以初始是空的，这里会初始化</span></span><br><span class="line">h.buckets = newobject(t.bucket) <span class="comment">// newarray(t.bucket, 1)</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2 定位key在hash表中的位置</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mapassign</span><span class="params">(t *maptype, h *hmap, key unsafe.Pointer)</span> <span class="title">unsafe</span>.<span class="title">Pointer</span></span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">again:</span><br><span class="line">bucket := hash &amp; bucketMask(h.B) <span class="comment">// 这里用hash值的低阶位定位hash数组的下标偏移量</span></span><br><span class="line"><span class="keyword">if</span> h.growing() &#123;</span><br><span class="line">growWork(t, h, bucket) <span class="comment">// 这里是map的扩容缩容操作，我们在第4章单独讲</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 通过下标bucket，偏移定位到具体的桶</span></span><br><span class="line">b := (*bmap)(unsafe.Pointer(<span class="keyword">uintptr</span>(h.buckets) + bucket*<span class="keyword">uintptr</span>(t.bucketsize)))</span><br><span class="line">top := tophash(hash) <span class="comment">// 这里取高8位用于在桶内定位键值对</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3 进一步定位key可以插入的桶及桶中的位置</p><ul><li>两轮循环，外层循环遍历hash桶及其指向的溢出链表，内层循环则在桶内遍历（一个桶最多8个key-value对）</li><li>有可能正好链表上的桶都满了，这时inserti为nil，第4步会链接一个新的溢出桶进来</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mapassign</span><span class="params">(t *maptype, h *hmap, key unsafe.Pointer)</span> <span class="title">unsafe</span>.<span class="title">Pointer</span></span> &#123;</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> inserti *<span class="keyword">uint8</span>          <span class="comment">// tophash插入位置</span></span><br><span class="line"><span class="keyword">var</span> insertk unsafe.Pointer  <span class="comment">// key插入位置</span></span><br><span class="line"><span class="keyword">var</span> val unsafe.Pointer      <span class="comment">// value插入位置</span></span><br><span class="line">bucketloop:</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">uintptr</span>(<span class="number">0</span>); i &lt; bucketCnt; i++ &#123;</span><br><span class="line"><span class="keyword">if</span> b.tophash[i] != top &#123;</span><br><span class="line"><span class="keyword">if</span> isEmpty(b.tophash[i]) &amp;&amp; inserti == <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="comment">// 找到个空位，先记录下tophash、key、value的插入位置</span></span><br><span class="line">    <span class="comment">// 但要遍历完才能确定要不要插入到这个位置，因为后面有可能有重复的元素</span></span><br><span class="line">inserti = &amp;b.tophash[i]</span><br><span class="line">insertk = add(unsafe.Pointer(b), dataOffset+i*<span class="keyword">uintptr</span>(t.keysize))</span><br><span class="line">val = add(unsafe.Pointer(b), dataOffset+bucketCnt*<span class="keyword">uintptr</span>(t.keysize)+i*<span class="keyword">uintptr</span>(t.valuesize))</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> b.tophash[i] == emptyRest &#123;</span><br><span class="line"><span class="keyword">break</span> bucketloop <span class="comment">// 遍历完整个溢出链表，退出循环</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">k := add(unsafe.Pointer(b), dataOffset+i*<span class="keyword">uintptr</span>(t.keysize))</span><br><span class="line"><span class="keyword">if</span> t.indirectkey() &#123;</span><br><span class="line">k = *((*unsafe.Pointer)(k))</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> !alg.equal(key, k) &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 走到这里说明map里找到一个重复的key，更新key-value，跳到第5步</span></span><br><span class="line"><span class="keyword">if</span> t.needkeyupdate() &#123;</span><br><span class="line">typedmemmove(t.key, k, key)</span><br><span class="line">&#125;</span><br><span class="line">val = add(unsafe.Pointer(b), dataOffset+bucketCnt*<span class="keyword">uintptr</span>(t.keysize)+i*<span class="keyword">uintptr</span>(t.valuesize))</span><br><span class="line"><span class="keyword">goto</span> done <span class="comment">// 更新Key后跳到第5步</span></span><br><span class="line">&#125;</span><br><span class="line">ovf := b.overflow(t)</span><br><span class="line"><span class="keyword">if</span> ovf == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">break</span> <span class="comment">// 遍历完整个溢出链表，没找到能插入的空位，结束循环，下一步再追加一个溢出桶进来</span></span><br><span class="line">&#125;</span><br><span class="line">b = ovf <span class="comment">// 继续遍历下一个溢出桶</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4 插入 key</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mapassign</span><span class="params">(t *maptype, h *hmap, key unsafe.Pointer)</span> <span class="title">unsafe</span>.<span class="title">Pointer</span></span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 这里判断要不要扩容，我们第4章再讲</span></span><br><span class="line">    <span class="keyword">if</span> !h.growing() &amp;&amp; (overLoadFactor(h.count+<span class="number">1</span>, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) &#123;</span><br><span class="line">hashGrow(t, h)</span><br><span class="line"><span class="keyword">goto</span> again <span class="comment">// Growing the table invalidates everything, so try again</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> inserti == <span class="literal">nil</span> &#123; <span class="comment">// inserti == nil说明上1步没找到空位，整个链表是满的，这里添加一个新的溢出桶上去</span></span><br><span class="line">newb := h.newoverflow(t, b) <span class="comment">// 分配新溢出桶，优先用3.1章节预留的溢出桶，用完了则分配一个新桶内存</span></span><br><span class="line">inserti = &amp;newb.tophash[<span class="number">0</span>]</span><br><span class="line">insertk = add(unsafe.Pointer(newb), dataOffset)</span><br><span class="line">val = add(insertk, bucketCnt*<span class="keyword">uintptr</span>(t.keysize))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 当key或value的类型大小超过一定值时，桶只存储key或value的指针。这里分配空间并取指针</span></span><br><span class="line"><span class="keyword">if</span> t.indirectkey() &#123;</span><br><span class="line">kmem := newobject(t.key)</span><br><span class="line">*(*unsafe.Pointer)(insertk) = kmem</span><br><span class="line">insertk = kmem</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> t.indirectvalue() &#123;</span><br><span class="line">vmem := newobject(t.elem)</span><br><span class="line">*(*unsafe.Pointer)(val) = vmem</span><br><span class="line">&#125;</span><br><span class="line">typedmemmove(t.key, insertk, key) <span class="comment">// 在桶中对应位置插入key</span></span><br><span class="line">*inserti = top <span class="comment">// 插入tophash，hash值高8位</span></span><br><span class="line">h.count++ <span class="comment">// 插入了新的键值对，h.count数量+1</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>5 结束插入</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">func</span> <span class="title">mapassign</span><span class="params">(t *maptype, h *hmap, key unsafe.Pointer)</span> <span class="title">unsafe</span>.<span class="title">Pointer</span></span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line"> done:</span><br><span class="line"><span class="keyword">if</span> h.flags&amp;hashWriting == <span class="number">0</span> &#123;</span><br><span class="line">throw(<span class="string">"concurrent map writes"</span>)</span><br><span class="line">&#125;</span><br><span class="line">h.flags &amp;^= hashWriting <span class="comment">// 释放hashWriting标志位</span></span><br><span class="line"><span class="keyword">if</span> t.indirectvalue() &#123;</span><br><span class="line">val = *((*unsafe.Pointer)(val))</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> val <span class="comment">// 返回value可插入位置的指针，注意，value还没插入</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>只插入了tophash和key，就结束了吗？value还没插入呢</li><li>是的，mapassign()只插入tophash和key，并返回val指针，编译器会在调用mapassign()后用汇编往val插入value</li><li>google大佬这么骚气的操作，是为了减少value值传递的次数吗？</li></ul><h2 id="33-删除"><span id="33-删除">3.3 删除</span></h2><ol><li>删除与插入类似，前面的步骤都是参数和状态判断、定位key-value位置，然后clear对应的内存。不展开说。以下是几个关键点：</li></ol><ul><li>删除过程中也会置hashWriting标志</li><li>当key/value过大时，hash表里存储的是指针，这时候用软删除，置指针为nil，数据交给gc去删。当然，这是map的内部处理，外层是无感知的，拿到的都是值拷贝</li><li>无论Key/value是值类型还是指针类型，删除操作都只影响hash表，外层已经拿到的数据不受影响。尤其是指针类型，外层的指针还能继续使用</li></ul><ol><li>由于定位key位置的方式是查找tophash，所以删除操作对tophash的处理是关键：</li></ol><ul><li>map首先将对应位置的tophash[i]置为emptyOne，表示该位置已被删除</li><li>如果tophash[i]不是整个链表的最后一个，则只置emptyOne标志，该位置被删除但未释放，后续插入操作不能使用此位置</li><li>如果tophash[i]是链表最后一个有效节点了，则把链表最后面的所有标志为emptyOne的位置，都置为emptyRest。置为emptyRest的位置可以在后续的插入操作中被使用。</li><li>这种删除方式，以少量空间来避免桶链表和桶内的数据移动。事实上，go 数据一旦被插入到桶的确切位置，map是不会再移动该数据在桶中的位置了。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mapdelete</span><span class="params">(t *maptype, h *hmap, key unsafe.Pointer)</span></span> &#123;</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">            b.tophash[i] = emptyOne <span class="comment">// 先标记删除</span></span><br><span class="line"><span class="comment">// 如果b.tophash[i]不是最后一个元素，则暂时先占着坑。emptyOne标记的位置暂时不能被插入新元素(见3.2章节插入函数)</span></span><br><span class="line"><span class="keyword">if</span> i == bucketCnt<span class="number">-1</span> &#123;</span><br><span class="line"><span class="keyword">if</span> b.overflow(t) != <span class="literal">nil</span> &amp;&amp; b.overflow(t).tophash[<span class="number">0</span>] != emptyRest &#123;</span><br><span class="line"><span class="keyword">goto</span> notLast</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">if</span> b.tophash[i+<span class="number">1</span>] != emptyRest &#123;</span><br><span class="line"><span class="keyword">goto</span> notLast</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> &#123; <span class="comment">// 如果b.tophash[i]是最后一个元素，则把末尾的emptyOne全部清除置为emptyRest</span></span><br><span class="line">b.tophash[i] = emptyRest</span><br><span class="line"><span class="keyword">if</span> i == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">if</span> b == bOrig &#123;</span><br><span class="line"><span class="keyword">break</span> <span class="comment">// beginning of initial bucket, we're done.</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Find previous bucket, continue at its last entry.</span></span><br><span class="line">c := b</span><br><span class="line"><span class="keyword">for</span> b = bOrig; b.overflow(t) != c; b = b.overflow(t) &#123;</span><br><span class="line">&#125;</span><br><span class="line">i = bucketCnt - <span class="number">1</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">i--</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> b.tophash[i] != emptyOne &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="34-查找"><span id="34-查找">3.4 查找</span></h2><p>查找操作由mapaccess开头的一组函数实现。前面的章节在插入和删除之前都得先定位查找到元素，逻辑是类似的，也比较简单，就不细说了：</p><ul><li>mapaccess1()：通过Key查找，返回value指针，用于val := map[key]。未找到时返回value类型的0值。</li><li>mapaccess2()：通过key查找，返回value指针，以及bool类型的是否查找成功的标志，用于val, ok := map[key]。未找到时返回value类型的0值。</li><li>mapaccessK()：通过key查找，返回key和value指针，用于迭代器(range)。未找到时返回空指针</li><li>mapaccess1_fat()，对mapaccess1()的封装，区别是mapaccess1_fat()多了个zero参数，未找到时返回zero</li><li>mapaccess2_fat()，也是对mapaccess1()的封装。相比mapaccess1_fat()，本函数增加一个是否查找成功的标志</li></ul><h2 id="35-range迭代"><span id="35-range迭代">3.5 range迭代</span></h2><p>map的迭代是通过hiter结构和对应的两个辅助函数实现的。hiter结构由编译器在调用辅助函数之前创建并传入，每次迭代结果也由hiter结构传回。下方的it即是hiter结构体的指针变量。</p><h3 id="351-初始化迭代器mapiterinit"><span id="351-初始化迭代器mapiterinit">3.5.1 初始化迭代器mapiterinit()</span></h3><p>mapiterinit()函数主要是决定我们从哪个位置开始迭代，为什么是从哪个位置，而不是直接从hash数组头部开始呢？《go程序设计语言》好像提到过，hash表中数据每次插入的位置是变化的（其实是因为实现的原因，一方面hash种子是随机的，这导致相同的数据在不同的map变量内的hash值不同；另一方面即使同一个map变量内，数据删除再添加的位置也有可能变化，因为在同一个桶及溢出链表中数据的位置不分先后），所以为了防止用户错误的依赖于每次迭代的顺序，map作者干脆让相同的map每次迭代的顺序也是随机的。<br>迭代顺序随机的实现方式也简单，直接从随机的一个位置开始就行了：</p><ul><li>it.startBucket：这个是hash数组的偏移量，表示遍历从这个桶开始</li><li>it.offset：这个是桶内的偏移量，表示每个桶的遍历都从这个偏移量开始</li></ul><p>于是，map的遍历过程如下：</p><ul><li>从hash数组中第it.startBucket个桶开始，先遍历hash桶，然后是这个桶的溢出链表。</li><li>之后hash数组偏移量+1，继续前一步动作。</li><li>遍历每一个桶，无论是hash桶还是溢出桶，都从it.offset偏移量开始。（如果只是随机一个开始的桶，range结果还是有序的；但每个桶都加it.offset偏移，这个输出结果就有点扑朔迷离，大家可以亲手试下，对同一个map多次range）</li><li>当迭代器经过一轮循环回到it.startBucket的位置，结束遍历。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mapiterinit</span><span class="params">(t *maptype, h *hmap, it *hiter)</span></span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 随机一个偏移量来开始</span></span><br><span class="line">    r := <span class="keyword">uintptr</span>(fastrand())</span><br><span class="line">    <span class="keyword">if</span> h.B &gt; <span class="number">31</span>-bucketCntBits &#123;</span><br><span class="line">r += <span class="keyword">uintptr</span>(fastrand()) &lt;&lt; <span class="number">31</span></span><br><span class="line">    &#125;</span><br><span class="line">it.startBucket = r &amp; bucketMask(h.B)</span><br><span class="line">it.offset = <span class="keyword">uint8</span>(r &gt;&gt; h.B &amp; (bucketCnt - <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">mapiternext(it) <span class="comment">// 初始化迭代器的同时也返回第1对key/value</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="352-迭代过程mapiternext"><span id="352-迭代过程mapiternext">3.5.2 迭代过程mapiternext()</span></h3><p>上一节迭代循环的过程很清晰了，这里我们说明几个重要的参数：</p><ul><li>it.startBucket：开始的桶</li><li>it.offset：每个桶开始的偏移量</li><li>it.bptr：当前遍历的桶</li><li>it.i：it.bptr已经遍历的键值对数量，i初始为0，当i=8时表示这个桶遍历完了，将it.bptr移向下一个桶</li><li>it.key：每次迭代的结果</li><li>it.value：每次迭代的结果</li></ul><p>此外，迭代还需要关注扩容缩容的情况：</p><ul><li>如果是在迭代开始后才growing，这种情况当前的逻辑没处理，迭代有可能异常。呃，go map不支持并发。</li><li>如果是先growing，再开始迭代，这是有可能的。这种情况下，会先到旧hash表中检查key对应的桶有没有被疏散，未疏散则遍历旧桶，已疏散则遍历新hash表里对应的桶。</li></ul><h1 id="4-go-map的扩容缩容"><span id="4-go-map的扩容缩容">4. go map的扩容缩容</span></h1><h2 id="41-扩容缩容的基本原理"><span id="41-扩容缩容的基本原理">4.1 扩容缩容的基本原理</span></h2><p>go map的扩容缩容都是grow相关的函数，这里扩容是真的，缩容是伪缩容，后面我会解释。我们先看下触发条件：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mapassign</span><span class="params">(t *maptype, h *hmap, key unsafe.Pointer)</span> <span class="title">unsafe</span>.<span class="title">Pointer</span></span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> !h.growing() &amp;&amp; (overLoadFactor(h.count+<span class="number">1</span>, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) &#123;</span><br><span class="line">hashGrow(t, h)</span><br><span class="line"><span class="keyword">goto</span> again <span class="comment">// Growing the table invalidates everything, so try again</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// overLoadFactor()返回true则触发扩容，即map的count大于hash桶数量(2^B)*6.5</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">overLoadFactor</span><span class="params">(count <span class="keyword">int</span>, B <span class="keyword">uint8</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> count &gt; bucketCnt &amp;&amp; <span class="keyword">uintptr</span>(count) &gt; loadFactorNum*(bucketShift(B)/loadFactorDen)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// tooManyOverflowBuckets()，顾名思义，溢出桶太多了触发缩容</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">tooManyOverflowBuckets</span><span class="params">(noverflow <span class="keyword">uint16</span>, B <span class="keyword">uint8</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> B &gt; <span class="number">15</span> &#123;</span><br><span class="line">B = <span class="number">15</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> noverflow &gt;= <span class="keyword">uint16</span>(<span class="number">1</span>)&lt;&lt;(B&amp;<span class="number">15</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>map只在插入元素即mapassign()函数中对是否扩容缩容进行触发，条件即是上面这段代码：</p><ul><li>条件1：当前不处在growing状态</li><li>条件2-1：触发扩容：map的数据量count大于hash桶数量(2B)*6.5。注意这里的(2B)只是hash数组大小，不包括溢出的桶</li><li>条件2-2：触发缩容：溢出的桶数量noverflow&gt;=32768(1&lt;&lt;15)或者&gt;=hash数组大小。</li></ul><p>仔细观察触发的代码，扩容和缩容是同一个函数，这是怎么做到的呢？在hashGrow()开始，会先判断是否满足扩容条件，如果满足就表明这次是扩容，不满足就一定是缩容条件触发了。扩容和缩容剩下的逻辑，主要区别就在于容量变化，就是hmap.B参数，扩容时B+1则hash表容量扩大1倍，缩容时hash表容量不变。</p><ul><li>h.oldbuckets：指向旧的hash数组，即当前的h.buckets</li><li>h.buckets：指向新创建的hash数组</li></ul><p>到这里触发的主要工作已经完成，接下来就是怎么把元素搬迁到新hash表里了。如果现在就一次全量搬迁过去，显然接下来会有比较长的一段时间map被占用（不支持并发）。所以搬迁的工作是异步增量搬迁的。<br>在插入和删除的函数内都有下面一段代码用于在每次插入和删除操作时，执行一次搬迁工作：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> h.growing() &#123; <span class="comment">// 当前处于搬迁状态</span></span><br><span class="line">growWork(t, h, bucket) <span class="comment">// 调用搬迁函数</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">growWork</span><span class="params">(t *maptype, h *hmap, bucket <span class="keyword">uintptr</span>)</span></span> &#123;</span><br><span class="line"><span class="comment">// 将当前需要处理的桶搬迁</span></span><br><span class="line">evacuate(t, h, bucket&amp;h.oldbucketmask())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> h.growing() &#123; <span class="comment">// 再多搬迁一个桶</span></span><br><span class="line">evacuate(t, h, h.nevacuate)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>每执行一次插入或删除，都会调用growWork搬迁0~2个hash桶（有可能这次需要搬迁的2个桶在此之前都被搬过了）</li><li>搬迁是以hash桶为单位的，包含对应的hash桶和这个桶的溢出链表</li><li>被delete掉的元素(emptyone标志)会被舍弃（这是缩容的关键）</li></ul><h2 id="42-为什么叫伪缩容如何实现真缩容"><span id="42-为什么叫伪缩容如何实现真缩容">4.2 为什么叫“伪缩容”？如何实现“真缩容”？</span></h2><p>现在可以解释为什么我把map的缩容叫做伪缩容了：因为缩容仅仅针对溢出桶太多的情况，触发缩容时hash数组的大小不变，即hash数组所占用的空间只增不减。也就是说，如果我们把一个已经增长到很大的map的元素挨个全部删除掉，hash表所占用的内存空间也不会被释放。</p><p>所以如果要实现“真缩容”，需自己实现缩容搬迁，即创建一个较小的map，将需要缩容的map的元素挨个搬迁过来：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// go map缩容代码示例</span></span><br><span class="line">myMap := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">int</span>, <span class="number">1000000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 假设这里我们对bigMap做了很多次插入，之后又做了很多次删除，此时bigMap的元素数量远小于hash表大小</span></span><br><span class="line"><span class="comment">// 接下来我们开始缩容</span></span><br><span class="line">smallMap := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">int</span>, <span class="built_in">len</span>(myMap))</span><br><span class="line"><span class="keyword">for</span> k, v := <span class="keyword">range</span> myMap &#123;</span><br><span class="line">    smallMap[k] = v</span><br><span class="line">&#125;</span><br><span class="line">myMap = smallMap <span class="comment">// 缩容完成，原来的map被我们丢弃，交给gc去清理</span></span><br></pre></td></tr></table></figure><h1 id="5-qampa关键知识点"><span id="5-qampa关键知识点">5 Q&amp;A关键知识点</span></h1><h2 id="51-基本原理"><span id="51-基本原理">5.1 基本原理</span></h2><ul><li>底层是hash实现，数据结构为hash数组 + 桶 + 溢出的桶链表，每个桶存储最多8个key-value对</li><li>查找和插入的原理：key的hash值（低阶位）与桶数量相与，得到key所在的hash桶，再用key的高8位与桶中的tophash[i]对比，相同则进一步对比key值，key值相等则找到</li><li>go map不支持并发。插入、删除、搬迁等操作会置writing标志，检测到并发直接panic</li><li>每次扩容hash表增大1倍，hash表只增不减</li><li>支持有限缩容，delete操作只置删除标志位，释放溢出桶的空间依靠触发缩容来实现。</li><li>map在使用前必须初始化，否则panic：已初始化的map是make(map[key]value)或make(map[key]value, hint)这两种形式。而new或var xxx map[key]value这两种形式是未初始化的，直接使用会panic。</li></ul><h2 id="52-时间复杂度和空间复杂度分析"><span id="52-时间复杂度和空间复杂度分析">5.2 时间复杂度和空间复杂度分析</span></h2><p>时间复杂度，go map是hash实现，我们先不管具体原理，江湖套路hash实现的就叫它O(1)的时间复杂度：</p><ul><li>正常情况，且不考虑扩容状态，复杂度O(1)：通过hash值定位桶是O(1)，一个桶最多8个元素，合理的hash算法应该能把元素相对均匀散列，所以溢出链表（如果有）也不会太长，所以虽然在桶和溢出链表上定位key是遍历，考虑到数量小也可以认为是O(1)</li><li>正常情况，处于扩容状态时，复杂度也是O(1)：相比于上一种状态，扩容会增加搬迁最多2个桶和溢出链表的时间消耗，当溢出链表不太长时，复杂度也可以认为是O(1)</li><li>极端情况，散列极不均匀，大部分数据被集中在一条散列链表上，复杂度退化为O(n)。</li></ul><p>go采用的hash算法应是很成熟的算法，极端情况暂不考虑。所以综合情况下go map的时间复杂度应为O(1)</p><p>空间复杂度分析：<br>首先我们不考虑因删除大量元素导致的空间浪费情况（这种情况现在go是留给程序员自己解决），只考虑一个持续增长状态的map的一个空间使用率：<br>由于溢出桶数量超过hash桶数量时会触发缩容，所以最坏的情况是数据被集中在一条链上，hash表基本是空的，这时空间浪费O(n)。<br>最好的情况下，数据均匀散列在hash表上，没有元素溢出，这时最好的空间复杂度就是扩散因子决定了，当前go的扩散因子由全局变量决定，即loadFactorNum/loadFactorDen = 6.5。即平均每个hash桶被分配到6.5个元素以上时，开始扩容。所以最小的空间浪费是(8-6.5)/8 = 0.1875，即O(0.1875n)</p><p>结论：go map的空间复杂度（指除去正常存储元素所需空间之外的空间浪费）是O(0.1875n) ~ O(n)之间。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-前言&quot;&gt;1. 前言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-go-map的数据结构&quot;&gt;2. go map的数据结构&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#21-核心结体体&quot;&gt;2.1 核心结体体&lt;
      
    
    </summary>
    
    
      <category term="Golang" scheme="https://lxb.wiki/categories/Golang/"/>
    
    
      <category term="Go" scheme="https://lxb.wiki/tags/Go/"/>
    
  </entry>
  
  <entry>
    <title>网络 IO 模型</title>
    <link href="https://lxb.wiki/3af5472b/"/>
    <id>https://lxb.wiki/3af5472b/</id>
    <published>2021-08-16T14:52:32.000Z</published>
    <updated>2022-02-26T06:27:17.851Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#互联网服务端处理网络请求的原理">互联网服务端处理网络请求的原理</a></li><li><a href="#io-模型的基本认识">“I/O 模型”的基本认识</a></li><li><a href="#网络io模型">网络IO模型</a><ul><li><a href="#io模型">IO模型</a><ul><li><a href="#阻塞式-io">阻塞式 IO</a></li><li><a href="#非阻塞式-io">非阻塞式 IO</a></li><li><a href="#多路复用io">多路复用IO</a></li><li><a href="#信号驱动-io">信号驱动 IO</a></li><li><a href="#异步-io">异步 IO</a></li></ul></li><li><a href="#五大-io-模型比较">五大 IO 模型比较</a><ul><li><a href="#blocking和non-blocking区别">blocking和non-blocking区别</a></li><li><a href="#synchronous-io和asynchronous-io区别">synchronous IO和asynchronous IO区别</a></li></ul></li><li><a href="#selectpollepoll比较">select，poll，epoll比较</a><ul><li><a href="#select">select</a></li><li><a href="#poll">poll</a></li><li><a href="#epoll">epoll</a></li><li><a href="#应用场景">应用场景</a></li></ul></li><li><a href="#web服务器设计模型">web服务器设计模型</a><ul><li><a href="#并发并行">并发&amp;并行</a></li><li><a href="#reactor模型">Reactor模型</a></li><li><a href="#proacotr模型">Proacotr模型</a></li></ul></li><li><a href="#参考资料">参考资料</a></li></ul></li></ul><!-- tocstop --><h2 id="互联网服务端处理网络请求的原理"><span id="互联网服务端处理网络请求的原理">互联网服务端处理网络请求的原理</span></h2><p><strong>一个典型互联网服务端处理网络请求的典型过程：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226140211.png" alt></p><p><strong>由上图可以看到，主要处理步骤包括：</strong></p><p>1）获取请求数据，客户端与服务器建立连接发出请求，服务器接受请求（1-3）；</p><p>2）构建响应，当服务器接收完请求，并在用户空间处理客户端的请求，直到构建响应完成（4）；</p><p>3）返回数据，服务器将已构建好的响应再通过内核空间的网络 I/O 发还给客户端（5-7）。</p><p><strong>设计服务端并发模型时，主要有如下两个关键点：</strong></p><p>1）服务器如何管理连接，获取输入数据；</p><p>2）服务器如何处理请求。</p><p>以上两个关键点最终都与操作系统的 I/O 模型以及线程(进程)模型相关，这也是本文和下篇《高性能网络编程(六)：一文读懂高性能网络编程中的线程模型》将要介绍的内容。下面先详细介绍这I/O模型。</p><h2 id="io-模型的基本认识"><span id="io-模型的基本认识">“I/O 模型”的基本认识</span></h2><p><strong>介绍操作系统的 I/O 模型之前，先了解一下几个概念：</strong></p><p>1）阻塞调用与非阻塞调用；</p><p>2）阻塞调用是指调用结果返回之前，当前线程会被挂起，调用线程只有在得到结果之后才会返回；</p><p>3）非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。</p><p>两者的最大区别在于被调用方在收到请求到返回结果之前的这段时间内，调用方是否一直在等待。</p><p><strong>阻塞</strong>是指调用方一直在等待而且别的事情什么都不做；<strong>非阻塞</strong>是指调用方先去忙别的事情。</p><p><strong>同步处理与异步处理：</strong>同步处理是指被调用方得到最终结果之后才返回给调用方；异步处理是指被调用方先返回应答，然后再计算调用结果，计算完最终结果后再通知并返回给调用方。</p><p><strong>阻塞、非阻塞和同步、异步的区别（</strong>阻塞、非阻塞和同步、异步其实针对的对象是不一样的）<strong>：</strong></p><p>1）阻塞、非阻塞的讨论对象是调用者；</p><p>2）同步、异步的讨论对象是被调用者。</p><p><strong>recvfrom 函数：</strong></p><p>recvfrom 函数(经 Socket 接收数据)，这里把它视为系统调用。</p><p><strong>一个输入操作通常包括两个不同的阶段：</strong></p><p>1）等待数据准备好；</p><p>2）从内核向进程复制数据。</p><p>对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待分组到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。</p><p>实际应用程序在系统调用完成上面的 2 步操作时，调用方式的阻塞、非阻塞，操作系统在处理应用程序请求时，处理方式的同步、异步处理的不同，可以分为 5 种 I/O 模型</p><h2 id="网络io模型"><span id="网络io模型">网络IO模型</span></h2><blockquote><p>网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作</p></blockquote><p>IO其实我们并不陌生，站在操作系统的角度上说，io一般指访问磁盘数据，可以分为两步，以read操作举例的话：</p><ol><li>第一阶段：等待数据准备 (Waiting for the data to be ready)。</li><li>第二阶段：将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)。</li></ol><p>而网络IO也是如此，只不过它是读取的不是磁盘，而是socket：</p><ol><li>第一步：通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区。</li><li>第二步：把数据从内核缓冲区复制到应用进程缓冲区。</li></ol><p>在理解网络IO模型之前，我们得先准备些IO模型的基础知识</p><h3 id="io模型"><span id="io模型">IO模型</span></h3><p>Unix 有五种 I/O 模型：</p><ul><li>阻塞IO（bloking IO）</li><li>非阻塞IO（non-blocking IO）</li><li>多路复用IO（multiplexing IO）</li><li>信号驱动式IO（signal-driven IO）</li><li>异步IO（asynchronous IO）</li></ul><p>每个 IO 模型都有自己的使用模式，它们对于特定的应用程序都有自己的优点。下面提供一个简单的图片以供了解。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226140555.png" alt></p><h4 id="阻塞式-io"><span id="阻塞式-io">阻塞式 IO</span></h4><p>应用进程被阻塞，直到数据复制到应用进程缓冲区中才返回。</p><p>应该注意到，在阻塞的过程中，其它程序还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其他程序还可以执行，因此不消耗 CPU 时间，这种模型的 CPU 利用率效率会比较高。</p><p>下图中，recvfrom 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226140921.png" alt></p><p><img src="https://upload-images.jianshu.io/upload_images/16533261-a71605af7a6d472c?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img"></p><h4 id="非阻塞式-io"><span id="非阻塞式-io">非阻塞式 IO</span></h4><p>应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。</p><p>由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率是比较低的。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226141038.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226141052.png" alt></p><h4 id="多路复用io"><span id="多路复用io">多路复用IO</span></h4><p>由于阻塞式IO通过轮询得到的只是一个IO任务是否完成，而可能有多个任务在同时进行，因此就想到了能否轮询多个IO任务的状态，只要有任何一个任务完成，就去处理它。这就是所谓的IO多路复用。LINUX下具体的实现方式就是select、poll、epoll。</p><p>这种机制可以让单个进程具有处理多个 IO 事件的能力。又被称为 Event Driven IO，即事件驱动 IO。</p><p>最实际的应用场景就是web服务器响应连接的方式，IO 复用可支持<strong>更多的连接</strong>，同时不需要进程线程创建和切换的开销，系统开销更小。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226141126.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226141140.png" alt></p><blockquote><p>多路复用的特点是通过一种机制一个进程能同时等待多个IO文件描述符，内核监视这些文件描述符（套接字描述符），其中的任意一个进入读就绪状态，select， poll，epoll函数就可以返回。对于监视的方式，又可以分为 select， poll， epoll三种方式。</p></blockquote><p>在IO多路复用中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的进程其实是一直被block的。只不过进程是被select这个函数block，而不是被socket IO给block。所以IO多路复用是阻塞在select，epoll这样的系统调用之上，而没有阻塞在真正的I/O系统调用如recvfrom之上。</p><h4 id="信号驱动-io"><span id="信号驱动-io">信号驱动 IO</span></h4><p>应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。</p><p>相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226141353.png" alt></p><h4 id="异步-io"><span id="异步-io">异步 IO</span></h4><p>应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。</p><p>异步 IO 与信号驱动 IO 的区别在于，异步 IO 的信号是通知应用进程 IO 完成，而信号驱动 IO 的信号是通知应用进程可以开始 IO。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226141447.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226141502.png" alt></p><h3 id="五大-io-模型比较"><span id="五大-io-模型比较">五大 IO 模型比较</span></h3><p>前四种 I/O 模型的主要区别在于第一个阶段，而第二个阶段是一样的：将数据从内核复制到应用进程过程中，应用进程会被阻塞。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226141649.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226141702.png" alt></p><p>从上图中我们可以看出，越往后，阻塞越少，理论上效率也是最优。</p><p>这五种 I/O 模型中，前四种属于同步 I/O，因为其中真正的 I/O 操作(recvfrom)将阻塞进程/线程，只有异步 I/O 模型才与 POSIX 定义的异步 I/O 相匹配。</p><h4 id="blocking和non-blocking区别"><span id="blocking和non-blocking区别">blocking和non-blocking区别</span></h4><p>调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。</p><h4 id="synchronous-io和asynchronous-io区别"><span id="synchronous-io和asynchronous-io区别">synchronous IO和asynchronous IO区别</span></h4><p>在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的：</p><blockquote><p>A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;</p></blockquote><blockquote><p>An asynchronous I/O operation does not cause the requesting process to be blocked;</p></blockquote><ul><li>同步 I/O：应用进程在调用 recvfrom 操作时会阻塞。</li><li>异步 I/O：不会阻塞。</li></ul><p>阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O 都是同步 I/O，虽然非阻塞式 I/O 和信号驱动 I/O 在等待数据阶段不会阻塞，但是在之后的将数据从内核复制到应用进程这个操作会阻塞。</p><h3 id="selectpollepoll比较"><span id="selectpollepoll比较">select，poll，epoll比较</span></h3><p>select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。</p><h4 id="select"><span id="select">select</span></h4><p>select的调用过程如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226141946.png" alt></p><p>（1）使用copy_from_user从用户空间拷贝fd_set到内核空间</p><p>（2）注册回调函数__pollwait</p><p>（3）遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll）</p><p>（4）以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。</p><p>（5）__pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk-&gt;sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。</p><p>（6）poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。</p><p>（7）如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。</p><p>（8）把fd_set从内核空间拷贝到用户空间。</p><h5 id="总结"><span id="总结">总结：</span></h5><p>select的几大缺点：</p><p>（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大</p><p>（2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大</p><p>（3）select支持的文件描述符数量太小了，默认是1024</p><h4 id="poll"><span id="poll">poll</span></h4><p>poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构，其他的都差不多。</p><h4 id="epoll"><span id="epoll">epoll</span></h4><p>epoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。</p><p>对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。</p><p>对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。</p><p>对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。</p><h5 id="总结"><span id="总结">总结</span></h5><p>（1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。</p><p>（2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。</p><h4 id="应用场景"><span id="应用场景">应用场景</span></h4><p>很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。</p><h5 id="1-select-应用场景"><span id="1-select-应用场景">1. select 应用场景</span></h5><p>select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时要求更高的场景，比如核反应堆的控制。</p><p>select 可移植性更好，几乎被所有主流平台所支持。</p><h5 id="2-poll-应用场景"><span id="2-poll-应用场景">2. poll 应用场景</span></h5><p>poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。</p><p>需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。</p><p>需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且epoll 的描述符存储在内核，不容易调试。</p><h5 id="3-epoll-应用场景"><span id="3-epoll-应用场景">3. epoll 应用场景</span></h5><p>只需要运行在 Linux 平台上，并且有非常大量的描述符需要同时轮询，而且这些连接最好是长连接。</p><h3 id="web服务器设计模型"><span id="web服务器设计模型">web服务器设计模型</span></h3><h4 id="并发amp并行"><span id="并发amp并行">并发&amp;并行</span></h4><blockquote><p>并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。<br> 并行需要硬件支持，如多流水线或者多处理器。<br> 操作系统通过引入进程和线程，使得程序能够并发运行。</p></blockquote><p>对于web服务而言，并发是指同时进行的任务数（如同时服务的 HTTP 请求），而并行是可以同时工作的物理资源数量（如 CPU 核数）。</p><p>而针对并发IO而言，Reactor模型是一种常见的处理方式</p><h4 id="reactor模型"><span id="reactor模型">Reactor模型</span></h4><p>Reactor的中心思想是将所有要处理的I/O事件注册到一个中心I/O多路复用器上，同时主线程/进程阻塞在多路复用器上；一旦有I/O事件到来或是准备就绪(文件描述符或socket可读、写)，多路复用器返回并将事先注册的相应I/O事件分发到对应的处理器中。</p><p>Reactor是一种事件驱动机制，用“好莱坞原则”来形容Reactor再合适不过了：不要打电话给我们，我们会打电话通知你。<br> Reactor模式与Observer模式在某些方面极为相似：当一个主体发生改变时，所有依属体都得到通知。不过，观察者模式与单个事件源关联，而反应器模式则与多个事件源关联 。</p><p>在Reactor模式中，有5个关键的参与者：</p><ul><li><strong>描述符（handle）</strong>：由操作系统提供的资源，用于识别每一个事件，如Socket描述符、文件描述符、信号的值等。在Linux中，它用一个整数来表示。事件可以来自外部，如来自客户端的连接请求、数据等。事件也可以来自内部，如信号、定时器事件。</li><li><strong>同步事件多路分离器（event demultiplexer）</strong>：事件的到来是随机的、异步的，无法预知程序何时收到一个客户连接请求或收到一个信号。所以程序要循环等待并处理事件，这就是事件循环。在事件循环中，等待事件一般使用I/O复用技术实现。在linux系统上一般是select、poll、epol_waitl等系统调用，用来等待一个或多个事件的发生。I/O框架库一般将各种I/O复用系统调用封装成统一的接口，称为事件多路分离器。调用者会被阻塞，直到分离器分离的描述符集上有事件发生。</li><li><strong>事件处理器（event handler）</strong>：I/O框架库提供的事件处理器通常是由一个或多个模板函数组成的接口。这些模板函数描述了和应用程序相关的对某个事件的操作，用户需要继承它来实现自己的事件处理器，即具体事件处理器。因此，事件处理器中的回调函数一般声明为虚函数，以支持用户拓展。</li><li><strong>具体的事件处理器（concrete event handler）</strong>：是事件处理器接口的实现。它实现了应用程序提供的某个服务。每个具体的事件处理器总和一个描述符相关。它使用描述符来识别事件、识别应用程序提供的服务。</li><li><strong>Reactor 管理器（reactor）</strong>：定义了一些接口，用于应用程序控制事件调度，以及应用程序注册、删除事件处理器和相关的描述符。它是事件处理器的调度核心。 Reactor管理器使用同步事件分离器来等待事件的发生。一旦事件发生，Reactor管理器先是分离每个事件，然后调度事件处理器，最后调用相关的模 板函数来处理这个事件。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226142433.png" alt></p><p>可以看出，是Reactor管理器并不是应用程序负责等待事件、分离事件和调度事件。Reactor并没有被具体的事件处理器调度，而是管理器调度具体的事件处理器，由事件处理器对发生的事件作出处理，这就是Hollywood原则。应用程序要做的仅仅是实现一个具体的事件处理器，然后把它注册到Reactor管理器中。接下来的工作由管理器来完成：如果有相应的事件发生，Reactor会主动调用具体的事件处理器，由事件处理器对发生的事件作出处理。</p><h5 id="为什么使用reactor"><span id="为什么使用reactor">为什么使用Reactor</span></h5><p>有了I/O复用，有了epoll已经可以使服务器并发几十万连接的同时，维持高TPS了，难道这还不够吗？</p><p>答案是，技术层面足够了，但在软件工程层面却是不够的。</p><p>程序使用IO复用的难点在哪里呢？</p><p>1个请求可能由多次IO处理完成，但相比传统的单线程完整处理请求生命期的方法，IO复用在人的大脑思维中并不自然，因为，程序员编程中，处理请求A的时候，假定A请求必须经过多个IO操作A1-An（两次IO间可能间隔很长时间），每经过一次IO操作，再调用IO复用时，IO复用的调用返回里，非常可能不再有A，而是返回了请求B。即请求A会经常被请求B打断，处理请求B时，又被C打断。这种思维下，编程容易出错。</p><p><strong>在程序中：</strong><br> 某一瞬间，服务器共有10万个并发连接，此时，一次IO复用接口的调用返回了100个活跃的连接等待处理。先根据这100个连接找出其对应的对象，这并不难，epoll的返回连接数据结构里就有这样的指针可以用。接着，循环的处理每一个连接，找出这个对象此刻的上下文状态，再使用read、write这样的网络IO获取此次的操作内容，结合上下文状态查询此时应当选择哪个业务方法处理，调用相应方法完成操作后，若请求结束，则删除对象及其上下文。</p><p>这样，我们就陷入了<strong>面向过程编程</strong>方法之中了，在面向应用、快速响应为王的移动互联网时代，这样做早晚得把自己玩死。我们的主程序需要关注各种不同类型的请求，在不同状态下，对于不同的请求命令选择不同的业务处理方法。这会导致随着请求类型的增加，请求状态的增加，请求命令的增加，<strong>主程序复杂度快速膨胀</strong>，导致维护越来越困难，苦逼的程序员再也不敢轻易接新需求、重构。</p><p>反应堆是解决上述软件工程问题的一种途径，它也许并不优雅，开发效率上也不是最高的，但其执行效率与面向过程的使用IO复用却几乎是等价的，所以，无论是nginx、memcached、redis等等这些高性能组件的代名词，都义无反顾的一头扎进了反应堆的怀抱中。</p><p>反应堆模式可以在软件工程层面，将事件驱动框架分离出具体业务，将不同类型请求之间用OO的思想分离。通常，反应堆不仅使用IO复用处理网络事件驱动，还会实现定时器来处理时间事件的驱动（请求的超时处理或者定时任务的处理）</p><h5 id="reactor的几种模式"><span id="reactor的几种模式">Reactor的几种模式</span></h5><h6 id="1-单线程模式"><span id="1-单线程模式">1 单线程模式</span></h6><p>这是最简单的单Reactor单线程模型。Reactor线程是个多面手，负责多路分离套接字，Accept新连接，并分派请求到处理器链中。该模型适用于处理器链中业务处理组件能快速完成的场景。不过这种单线程模型不能充分利用多核资源，所以实际使用的不多。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226142550.png" alt></p><h6 id="2-多线程模式单reactor"><span id="2-多线程模式单reactor">2 多线程模式（单Reactor）</span></h6><p>该模型在事件处理器（Handler）链部分采用了多线程（线程池），也是后端程序常用的模型。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226142614.png" alt></p><h6 id="3-多线程模式多个reactor"><span id="3-多线程模式多个reactor">3 多线程模式（多个Reactor）</span></h6><p>比起第二种模型，它是将Reactor分成两部分，mainReactor负责监听并accept新连接，然后将建立的socket通过多路复用器（Acceptor）分派给subReactor。subReactor负责多路分离已连接的socket，读写网络数据；业务处理功能，其交给worker线程池完成。通常，subReactor个数上可与CPU个数等同。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226142645.png" alt></p><h4 id="proacotr模型"><span id="proacotr模型">Proacotr模型</span></h4><p>Proactor是和异步I/O相关的。</p><h5 id="比较"><span id="比较">比较</span></h5><p>以读操作为例：<br> 在Reactor（同步）中实现读：</p><ul><li>注册读就绪事件和相应的事件处理器</li><li>事件分离器等待事件</li><li>事件到来，激活分离器，分离器调用事件对应的处理器。</li><li>事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。</li></ul><p>Proactor（异步）中的读：</p><ul><li>处理器发起异步读操作（注意：操作系统必须支持异步IO）。在这种情况下，处理器无视IO就绪事件，它关注的是完成事件。</li><li>事件分离器等待操作完成事件</li><li>在分离器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分离器读操作完成。</li><li>事件分离器呼唤处理器。</li><li>事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分离器。</li></ul><h3 id="参考资料"><span id="参考资料">参考资料</span></h3><p><a href="https://zhuanlan.zhihu.com/p/43933717" target="_blank" rel="noopener">一文读懂高性能网络编程中的I/O模型 - 知乎 (zhihu.com)</a></p><p><a href="https://www.cnblogs.com/Zhangyq-yard/p/10114785.html" target="_blank" rel="noopener">网络I/O模型–5种常见的网络I/O模型 - QiangAnan - 博客园 (cnblogs.com)</a></p><p><a href="https://www.jianshu.com/p/ad548bb816ec" target="_blank" rel="noopener">如何理解高性能网络模型</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#互联网服务端处理网络请求的原理&quot;&gt;互联网服务端处理网络请求的原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#io-模型的基本认识&quot;&gt;“I/O 模型”的基本认识&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#网络
      
    
    </summary>
    
    
      <category term="Web" scheme="https://lxb.wiki/categories/Web/"/>
    
    
      <category term="网络" scheme="https://lxb.wiki/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>MySQL的四种事务隔离级别</title>
    <link href="https://lxb.wiki/689978a2/"/>
    <id>https://lxb.wiki/689978a2/</id>
    <published>2021-08-02T15:20:12.000Z</published>
    <updated>2022-02-26T05:50:14.669Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#一-事务的基本要素acid">一、事务的基本要素（ACID）</a></li><li><a href="#二-事务的并发问题">二、事务的并发问题</a></li><li><a href="#三-mysql事务隔离级别">三、MySQL事务隔离级别</a></li><li><a href="#四-用例子说明各个隔离级别的情况">四、用例子说明各个隔离级别的情况</a><ul><li><a href="#1-读未提交">1、读未提交：</a></li><li><a href="#2-读已提交">2、读已提交</a></li><li><a href="#3-可重复读">3、可重复读</a></li><li><a href="#4串行化">4.串行化</a></li></ul></li></ul><!-- tocstop --><h1 id="一-事务的基本要素acid"><span id="一-事务的基本要素acid">一、事务的基本要素（ACID）</span></h1><p>　　1、原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。</p><p>　　 2、一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。</p><p>　　 3、隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。</p><p>　　 4、持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。</p><h1 id="二-事务的并发问题"><span id="二-事务的并发问题">二、事务的并发问题</span></h1><p>　　1、脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据</p><p>　　2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。</p><p>　　3、幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。</p><p>　　小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表</p><h1 id="三-mysql事务隔离级别"><span id="三-mysql事务隔离级别">三、MySQL事务隔离级别</span></h1><table><thead><tr><th>事务隔离级别</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>读未提交（read-uncommitted）</td><td>是</td><td>是</td><td>是</td></tr><tr><td>不可重复读（read-committed）</td><td>否</td><td>是</td><td>是</td></tr><tr><td>可重复读（repeatable-read）</td><td>否</td><td>否</td><td>是</td></tr><tr><td>串行化（serializable）</td><td>否</td><td>否</td><td>否</td></tr></tbody></table><p>mysql默认的事务隔离级别为repeatable-read</p><h1 id="四-用例子说明各个隔离级别的情况"><span id="四-用例子说明各个隔离级别的情况">四、用例子说明各个隔离级别的情况</span></h1><h2 id="1-读未提交"><span id="1-读未提交">1、读未提交：</span></h2><p>　　　　（1）打开一个客户端A，并设置当前事务模式为read uncommitted（未提交读），查询表account的初始值：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226132329.png" alt></p><p>（2）在客户端A的事务提交之前，打开另一个客户端B，更新表account：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226132440.png" alt></p><p>（3）这时，虽然客户端B的事务还没提交，但是客户端A就可以查询到B已经更新的数据：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226132511.png" alt></p><p>（4）一旦客户端B的事务因为某种原因回滚，所有的操作都将会被撤销，那客户端A查询到的数据其实就是脏数据：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226132642.png" alt></p><p>（5）在客户端A执行更新语句update account set balance = balance - 50 where id =1，lilei的balance没有变成350，居然是400，是不是很奇怪，数据不一致啊，如果你这么想就太天真 了，在应用程序中，我们会用400-50=350，并不知道其他会话回滚了，要想解决这个问题可以采用读已提交的隔离级别</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226132722.png" alt></p><h2 id="2-读已提交"><span id="2-读已提交">2、读已提交</span></h2><p>（1）打开一个客户端A，并设置当前事务模式为read committed（读已提交），查询表account的所有记录：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226132916.png" alt></p><p>（2）在客户端A的事务提交之前，打开另一个客户端B，更新表account：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226133127.png" alt></p><p>（3）这时，客户端B的事务还没提交，客户端A不能查询到B已经更新的数据，解决了脏读问题：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226133227.png" alt></p><p>（4）客户端B的事务提交</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226133253.png" alt></p><p>（5）客户端A执行与上一步相同的查询，结果 与上一步不一致，即产生了不可重复读的问题</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226133509.png" alt></p><h2 id="3-可重复读"><span id="3-可重复读">3、可重复读</span></h2><p>（1）打开一个客户端A，并设置当前事务模式为repeatable read，查询表account的所有记录</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226133541.png" alt></p><p>（2）在客户端A的事务提交之前，打开另一个客户端B，更新表account并提交</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226133617.png" alt></p><p>（3）在客户端A查询表account的所有记录，与步骤（1）查询结果一致，没有出现不可重复读的问题</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226133720.png" alt></p><p>（4）在客户端A，接着执行update balance = balance - 50 where id = 1，balance没有变成400-50=350，lilei的balance值用的是步骤（2）中的350来算的，所以是300，数据的一致性倒是没有被破坏。可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226133747.png" alt></p><p>（5）重新打开客户端B，插入一条新数据后提交</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226133806.png" alt></p><p><a name="待验证">（6）在客户端A查询表account的所有记录，没有 查出 新增数据，所以没有出现幻读</a></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226133936.png" alt></p><h2 id="4串行化"><span id="4串行化">4.串行化</span></h2><p>（1）打开一个客户端A，并设置当前事务模式为serializable，查询表account的初始值：</p><p>（2）打开一个客户端B，并设置当前事务模式为serializable，插入一条记录报错，表被锁了插入失败，mysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到。</p><p>　　<strong>补充：</strong></p><p>　　1、事务隔离级别为读提交时，写数据只会锁住相应的行</p><p>　　2、事务隔离级别为可重复读时，如果检索条件有索引（包括主键索引）的时候，默认加锁方式是next-key 锁；如果****检索条件****没有索引，更新数据时会锁住整张表。一个间隙被事务加了锁，其他事务是不能在这个间隙插入记录的，这样可以防止幻读。</p><p>　　3、事务隔离级别为串行化时，读写数据都会锁住整张表</p><p>　　4、隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。</p><p>　　5、MYSQL MVCC实现机制参考链接：<a href="https://blog.csdn.net/whoamiyang/article/details/51901888" target="_blank" rel="noopener">https://blog.csdn.net/whoamiyang/article/details/51901888</a></p><p>　　 6、关于next-key 锁可以参考链接：<a href="https://blog.csdn.net/bigtree_3721/article/details/73731377" target="_blank" rel="noopener">https://blog.csdn.net/bigtree_3721/article/details/73731377</a></p><p><strong>后注：</strong></p><p>关于 <a href="#待验证">四、3、可重复的的第(6)步</a>， 待验证</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#一-事务的基本要素acid&quot;&gt;一、事务的基本要素（ACID）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#二-事务的并发问题&quot;&gt;二、事务的并发问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#三-mysql事务
      
    
    </summary>
    
    
      <category term="DB" scheme="https://lxb.wiki/categories/DB/"/>
    
    
      <category term="mysql" scheme="https://lxb.wiki/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>消息队列中的问题| 丢消息| 重复消费| 消息积压</title>
    <link href="https://lxb.wiki/ff873094/"/>
    <id>https://lxb.wiki/ff873094/</id>
    <published>2021-07-24T15:05:09.000Z</published>
    <updated>2022-02-24T08:12:37.753Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-丢消息">1. 丢消息</a><ul><li><a href="#检测消息丢失的方法">检测消息丢失的方法</a></li><li><a href="#确保消息可靠传递">确保消息可靠传递</a><ul><li><a href="#1-生产阶段">1. 生产阶段</a></li><li><a href="#2-存储阶段">2. 存储阶段</a></li><li><a href="#3-消费阶段">3. 消费阶段</a></li></ul></li></ul></li><li><a href="#2-重复消息">2. 重复消息</a><ul><li><a href="#消息重复的情况必然存在">消息重复的情况必然存在</a></li><li><a href="#用幂等性解决重复消息问题">用幂等性解决重复消息问题</a><ul><li><a href="#1-利用数据库的唯一约束实现幂等">1. 利用数据库的唯一约束实现幂等</a></li><li><a href="#2-为更新的数据设置前置条件">2. 为更新的数据设置前置条件</a></li><li><a href="#3-记录并检查操作">3. 记录并检查操作</a></li></ul></li></ul></li><li><a href="#3-消息积压问题">3. 消息积压问题</a><ul><li><a href="#优化性能来避免消息积压">优化性能来避免消息积压</a><ul><li><a href="#1-发送端性能优化">1. 发送端性能优化</a></li><li><a href="#2-消费端性能优化">2. 消费端性能优化</a></li></ul></li><li><a href="#消息积压的紧急处理">消息积压的紧急处理</a></li></ul></li><li><a href="#4-如何保证消息的严格顺序">4. 如何保证消息的严格顺序？</a></li></ul><!-- tocstop --><h1 id="1-丢消息"><span id="1-丢消息">1. 丢消息</span></h1><h2 id="检测消息丢失的方法"><span id="检测消息丢失的方法">检测消息丢失的方法</span></h2><p>一般而言，一个新的系统刚刚上线，各方面都不太稳定，需要一个磨合期，这个时候，特别需要监控到你的系统中是否有消息丢失的情况。</p><p>如果是 IT 基础设施比较完善的公司，一般都有分布式链路追踪系统，使用类似的追踪系统可以很方便地追踪每一条消息。</p><p>可以利用消息队列的有序性来验证是否有消息丢失。原理非常简单，在 Producer 端，我们给每个发出的消息附加一个连续递增的序号，然后在 Consumer 端来检查这个序号的连续性。</p><p>如果没有消息丢失，Consumer 收到消息的序号必然是连续递增的，或者说收到的消息，其中的序号必然是上一条消息的序号 +1。如果检测到序号不连续，那就是丢消息了。还可以通过缺失的序号来确定丢失的是哪条消息，方便进一步排查原因。</p><p>大多数消息队列的客户端都支持拦截器机制，你可以利用这个拦截器机制，在 Producer 发送消息之前的拦截器中将序号注入到消息中，在 Consumer 收到消息的拦截器中检测序号的连续性，这样实现的好处是消息检测的代码不会侵入到你的业务代码中，待你的系统稳定后，也方便将这部分检测的逻辑关闭或者删除。</p><p>如果是在一个分布式系统中实现这个检测方法，有几个问题需要你注意。</p><p>首先，像 Kafka 和 RocketMQ 这样的消息队列，它是不保证在 Topic 上的严格顺序的，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。</p><p>如果你的系统中 Producer 是多实例的，由于并不好协调多个 Producer 之间的发送顺序，所以也需要每个 Producer 分别生成各自的消息序号，并且需要附加上 Producer 的标识，在 Consumer 端按照每个 Producer 分别来检测序号的连续性。</p><p>Consumer 实例的数量最好和分区数量一致，做到 Consumer 和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性。</p><h2 id="确保消息可靠传递"><span id="确保消息可靠传递">确保消息可靠传递</span></h2><p>整个消息从生产到消费的过程中，哪些地方可能会导致丢消息，以及应该如何避免消息丢失。一条消息从生产到消费完成这个过程，可以划分三个阶段</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220224160823.png" alt></p><ul><li>生产阶段: 在这个阶段，从消息在 Producer 创建出来，经过网络传输发送到 Broker 端。</li><li>存储阶段: 在这个阶段，消息在 Broker 端存储，如果是集群，消息会在这个阶段被复制到其他的副本上。</li><li>消费阶段: 在这个阶段，Consumer 从 Broker 上拉取消息，经过网络传输发送到 Consumer 上。</li></ul><h3 id="1-生产阶段"><span id="1-生产阶段">1. 生产阶段</span></h3><p>在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传递：当你的代码调用发消息方法时，消息队列的客户端会把消息发送到 Broker，Broker 收到消息后，会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送。</p><p>只要 Producer 收到了 Broker 的确认响应，就可以保证消息在生产阶段不会丢失。有些消息队列在长时间没收到发送确认响应后，会自动重试，如果重试再失败，就会以返回值或者异常的方式告知用户。</p><p>你在编写发送消息代码时，需要注意，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失。以 Kafka 为例，我们看一下如何可靠地发送消息：</p><p><strong>同步发送时，只要注意捕获异常即可</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    RecordMetadata metadata = producer.send(record).get();</span><br><span class="line">    System.out.println(<span class="string">" 消息发送成功。"</span>);</span><br><span class="line">&#125; catch (Throwable e) &#123;</span><br><span class="line">    System.out.println(<span class="string">" 消息发送失败！"</span>);</span><br><span class="line">    System.out.println(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>异步发送时，则需要在回调方法里进行检查。这个地方是需要特别注意的，很多丢消息的原因就是，我们使用了异步发送，却没有在回调中检查发送结果。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">producer.send(record, (metadata, exception) -&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (metadata != null) &#123;</span><br><span class="line">        System.out.println(<span class="string">" 消息发送成功。"</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">" 消息发送失败！"</span>);</span><br><span class="line">        System.out.println(exception);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="2-存储阶段"><span id="2-存储阶段">2. 存储阶段</span></h3><p>在存储阶段正常情况下，只要 Broker 在正常运行，就不会出现丢失消息的问题，但是如果 Broker 出现了故障，比如进程死掉了或者服务器宕机了，还是可能会丢失消息的。</p><p>如果对消息的可靠性要求非常高，可以通过配置 Broker 参数来避免因为宕机丢消息。</p><p>对于单个节点的 Broker，需要配置 Broker 参数，在收到消息后，<strong>将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息</strong>，恢复后还可以继续消费。例如，在 RocketMQ 中，需要将刷盘方式 flushDiskType 配置为 SYNC_FLUSH 同步刷盘。</p><p>如果是 Broker 是由多个节点组成的集群，需要将 Broker 集群配置成：<strong>至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应</strong>。这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker，也不会发生消息丢失。消息队列<strong>通过消息复制来确保消息的可靠性的</strong>。</p><h3 id="3-消费阶段"><span id="3-消费阶段">3. 消费阶段</span></h3><p>消费阶段采用和生产阶段类似的确认机制来保证消息的可靠传递，客户端从 Broker 拉取消息后，执行用户的消费业务逻辑，成功后，才会给 Broker 发送消费确认响应。如果 Broker 没有收到消费确认响应，下</p><p>次拉消息的时候还会返回同一条消息，确保消息不会在网络传输过程中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失。</p><p>你在编写消费代码时需要注意的是，不要在收到消息后就立即发送消费确认，而是应该<strong>在执行完所有消费业务逻辑之后，再发送消费确认</strong>。</p><p>同样，我们以用 Python 语言消费 RabbitMQ 消息为例，来看一下如何实现一段可靠的消费代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">callback</span><span class="params">(ch, method, properties, body)</span>:</span></span><br><span class="line">    print(<span class="string">" [x] 收到消息 %r"</span> % body)</span><br><span class="line">    <span class="comment"># 在这儿处理收到的消息</span></span><br><span class="line">    database.save(body)</span><br><span class="line">    print(<span class="string">" [x] 消费完成 "</span>)</span><br><span class="line">    <span class="comment"># 完成消费业务逻辑后发送消费确认响应</span></span><br><span class="line">    ch.basic_ack(delivery_tag = method.delivery_tag)</span><br><span class="line"> </span><br><span class="line">channel.basic_consume(queue=<span class="string">'hello'</span>, on_message_callback=callback)</span><br></pre></td></tr></table></figure><p>在消费的回调方法 callback 中，正确的顺序先是把消息保存到数据库，然后再发送消费确认响应。这样如果保存消息到数据库失败了，就不会执行消费确认的代码，下次拉到的还是这条消息，直到消费成功。</p><p><strong>两个消费者先后去拉消息是否能拉到同一条消息？</strong></p><p>首先，消息队列一般都会有<strong>协调机制</strong>，不会让这种情况出现，但是由于网络不确定性，这种情况还是在极小概率下会出现的。</p><p>在同一个消费组内，A消费者拉走了index=10的这条消息，还没返回确认，这时候这个分区的消费位置还是10，B消费者来拉消息，可能有2种情况：</p><ul><li>\1. 超时前，Broker认为这个分区还被A占用着，会拒绝B的请求。</li><li>\2. 超时后，Broker认为A已经超时没返回，这次消费失败，当前消费位置还是10，B再来拉消息，会给它返回10这条消息。</li></ul><ul><li>在生产阶段，你需要捕获消息发送的错误，并重发消息。</li><li>在存储阶段，你可以通过配置刷盘和复制相关的参数，让消息写入到多个副本的磁盘上，来确保消息不会因为某个 Broker 宕机或者磁盘损坏而丢失。</li><li>在消费阶段，你需要在处理完全部消费业务逻辑之后，再发送消费确认。</li></ul><p>你在理解了这几个阶段的原理后，如果再出现丢消息的情况，应该可以通过在代码中加一些日志的方式，很快定位到是哪个阶段出了问题，然后再进一步深入分析，快速找到问题原因。</p><h1 id="2-重复消息"><span id="2-重复消息">2. 重复消息</span></h1><p>在消息传递过程中，如果出现传递失败的情况，发送方会执行重试，重试的过程中就有可能会产生重复的消息。对使用消息队列的业务系统来说，如果没有对重复消息进行处理，就有可能会导致系统的数据出现错误。</p><h2 id="消息重复的情况必然存在"><span id="消息重复的情况必然存在">消息重复的情况必然存在</span></h2><p>在 <strong>MQTT 协议</strong>中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是：</p><ul><li>At most once: 至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。</li><li>At least once: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。</li><li>Exactly once：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。</li></ul><p>这个服务质量标准不仅适用于 MQTT，对所有的消息队列都是适用的。我们<strong>现在常用的绝大部分消息队列提供的服务质量都是 At least once，包括 RocketMQ、RabbitMQ 和 Kafka 都是这样。也就是说，消息</strong></p><p><strong>队**</strong>列很难保证消息不重复。**</p><p>Kafka 支持的“Exactly once”和我们刚刚提到的消息传递的服务质量标准“Exactly once”是不一样的，它是 Kafka 提供的另外一个特性，Kafka 中支持的事务也和我们通常意义理解的事务有一定的差异。在 Kafka</p><p>中，<strong>事务和 Excactly once 主要是为了配合流计算使用的特性</strong>。巧妙地用了两个所有人都非常熟悉的概念“事务”和“Exactly once”来包装它的新的特性，实际上它实现的这个事务和 Exactly once 并不是我们通常</p><p>理解的那两个特性。</p><p><strong>为什么大部分消息队列都选择只提供 At least once 的服务质量，而不是级别更高的 Exactly once？</strong></p><p>解决一个问题，往往会引发别的问题。若消息队列实现了exactly once，会引发的问题有：</p><p>①消费端在pull消息时，需要检测此消息是否被消费，这个检测机制无疑会拉低消息消费的速度。可以预想到，随着消息的剧增，消费性能势必会急剧下降，导致消息积压；</p><p>②检查机制还需要业务端去配合实现，若一条消息长时间未返回ack，消息队列需要去回调看下消费结果（这个类似于事物消息的回查机制）。这样就会增加业务端的压力，与很多的未知因素。</p><p>所以，消息队列不实现exactly once，而是at least once + 幂等性，这个幂等性让给我们去处理。</p><p>最重要的原因是消息队列即使做到了Exactly once级别，consumer也还是要做幂等。因为在consumer从消息队列取消息这里，如果consumer消费成功，但是ack失败，consumer还是会取到重复的消息，所以消</p><p>息队列花大力气做成Exactly once并不能解决业务侧消息重复的问题。</p><p>1、At least once + 幂等消费 = Exactly once，所以对于消息队列来讲，要做到Exactly once，其实是需消费端的共同配合（幂等消费）才可完成，消息队列基本只提供At least once的实现；</p><p>2、从给的几种幂等消费的方案看，需要引入数据库、条件更新、分布式事务或锁等额外辅助，消息队列如果需要保障Exactly once，会导致消费端代码侵入，例如需要消费端增加消息队列用来处理幂等的client</p><p>端，而消费端的形态可是太多了，兼容适配工作量巨大。故这个Exactly once留给用户自己处理，并且具有选择权，毕竟不是所有业务场景都需要Exactly once，例如机房温度上报的案例。</p><p><strong>如果队列的实现是At least once，但是为了确保消息不丢失，Broker Service会进行一定的重试，但是不可能一直重试，如果一直重试失败怎么处理了？</strong></p><p>有的消息队列会有一个特殊的队列来保存这些总是消费失败的“坏消息”，然后继续消费之后的消息，避免坏消息卡死队列。这种坏消息一般不会是因为网络原因或者消费者死掉导致的，大多都是消息数据本身有</p><p>问题，消费者的业务逻辑处理不了导致的。</p><h2 id="用幂等性解决重复消息问题"><span id="用幂等性解决重复消息问题">用幂等性解决重复消息问题</span></h2><p>一般解决重复消息的办法是，在消费端，让我们消费消息的操作具备幂等性。</p><p>幂等（Idempotence）是一个数学上的概念，它是这样定义的：</p><blockquote><p><strong>如果一个函数 f(x) 满足：f(f(x)) = f(x)，则函数 f(x) 满足幂等性。</strong></p></blockquote><p>这个概念被拓展到计算机领域，被用来描述一个操作、方法或者服务。一个幂等操作的特点是，<strong>其任意多次执行所产生的影响均与一次执行的影响相同。</strong></p><p><strong>一个幂等的方法，使用同样的参数，对它进行多次调用和一次调用，对系统产生的影响是一样的。所以，对于幂等的方法，不用担心重复执行会对系统造成任何改变。</strong></p><p>比如在不考虑并发的情况下，“将账户 X 的余额设置为 100 元”，执行一次后对系统的影响是，账户 X 的余额变成了 100 元。只要提供的参数 100 元不变，那即使再执行多少次，账户 X 的余额始终都是 100 元，</p><p>不会变化，这个操作就是一个幂等的操作。</p><p>再比如“将账户 X 的余额加 100 元”，这个操作它就不是幂等的，每执行一次，账户余额就会增加 100 元，执行多次和执行一次对系统的影响（也就是账户的余额）是不一样的。</p><p>如果我们系统<strong>消费消息的业务逻辑具备幂等性</strong>，那就不用担心消息重复的问题了，因为<strong>同一条消息，消费一次和消费多次对系统的影响是完全一样的。也就可以认为，消费多次等于消费一次。</strong></p><p><strong>从对系统的影响结果来说：At least once + 幂等消费 = Exactly once。</strong></p><p>那么如何实现幂等操作呢？最好的方式就是，从业务逻辑设计上入手，将消费的业务逻辑设计成具备幂等性的操作。但是，不是所有的业务都能设计成天然幂等的，这里就需要一些方法和技巧来实现幂等。</p><p>下面我给你介绍几种常用的设计幂等操作的方法：</p><h3 id="1-利用数据库的唯一约束实现幂等"><span id="1-利用数据库的唯一约束实现幂等">1. 利用数据库的唯一约束实现幂等</span></h3><p>刚刚提到的那个不具备幂等特性转账的例子：将账户 X 的余额加 100 元。在这个例子中，我们可以通过改造业务逻辑，让它具备幂等性。</p><p>首先，我们可以限定，对于每个转账单每个账户只可以执行一次变更操作，在分布式系统中，这个限制实现的方法非常多，最简单的是我们在数据库中建一张转账流水表，这个表有三个字段：转账单 ID、账户</p><p>ID 和变更金额，然后<strong>给转账单 ID 和账户 ID 这两个字段联合起来创建一个唯一约束，这样对于相同的转账单 ID 和账户 ID，表里至多只能存在一条记录。</strong></p><p>这样，我们消费消息的逻辑可以变为：“在转账流水表中增加一条转账记录，然后再根据转账记录，异步操作更新用户余额即可。”在转账流水表增加一条转账记录这个操作中，由于我们在这个表中预先定义了“账</p><p>户 ID 转账单 ID”的唯一约束，对于同一个转账单同一个账户只能插入一条记录，后续重复的插入操作都会失败，这样就实现了一个幂等的操作。我们只要写一个 SQL，正确地实现它就可以了。</p><p>基于这个思路，不光是可以使用关系型数据库，<strong>只要是支持类似“INSERT IF NOT EXIST”语义的存储类系统都可以用于实现幂等</strong>，</p><p>比如， <strong>Redis 的 SETNX 命令来替代数据库中的唯一约束，来实现幂**</strong>等消费。 （ redis中的hash：<strong>**hsetnx</strong> <strong><key> <field> <value>；</value></field></key></strong> <strong>）</strong></p><p><strong>比如，Elasticsearch中的幂等操作：</strong> <strong>PUT /movie_index/movie/3，加上文档 ID</strong> </p><h3 id="2-为更新的数据设置前置条件"><span id="2-为更新的数据设置前置条件">2. 为更新的数据设置前置条件</span></h3><p>另外一种实现幂等的思路是，给数据变更设置一个前置条件，如果满足条件就更新数据，否则拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。这样，重复执行这个操作时，由于第一次</p><p>更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。</p><p>比如，刚刚我们说过，“将账户 X 的余额增加 100 元”这个操作并不满足幂等性，我们可以把这个操作加上一个前置条件，变为：“如果账户 X 当前的余额为 500 元，将余额加 100 元”，这个操作就具备了幂等</p><p>性。对应到消息队列中的使用时，可以在发消息时在消息体中带上当前的余额，在消费的时候进行判断数据库中，当前余额是否与消息中的余额相等，只有相等才执行变更操作。</p><p>但是，如果我们要更新的数据不是数值，或者我们要做一个比较复杂的更新操作怎么办？用什么作为前置判断条件呢？更加通用的方法是，<strong>给你的数据增加一个版本号属性，每次更数据前，比较当前数据的版本</strong></p><p><strong>号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时将版本号 +1，一样可以实现幂等更新。</strong></p><h3 id="3-记录并检查操作"><span id="3-记录并检查操作">3. 记录并检查操作</span></h3><p>如果上面提到的两种实现幂等方法都不能适用于你的场景，我们还有一种通用性最强，适用范围最广的实现幂等性方法：<strong>记录并检查操作</strong>，也称为“Token 机制或者 GUID（全局唯一 ID）机制”，实现的思路特别</p><p>简单：在执行数据更新操作之前，先检查一下是否执行过这个更新操作。</p><p>具体的实现方法是，<strong>在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。</strong></p><p>原理和实现是不是很简单？其实一点儿都不简单，在分布式系统中，这个方法其实是非常难实现的。首先，给每个消息指定一个全局唯一的 ID 就是一件不那么简单的事儿，方法有很多，但都不太好同时满足简</p><p>单、高可用和高性能，或多或少都要有些牺牲。更加麻烦的是，在“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作保证原子性，才能真正实现幂等，否则就会出现 Bug。</p><p>比如说，对于同一条消息：“全局 ID 为 8，操作为：给 ID 为 666 账户增加 100 元”，有可能出现这样的情况：</p><ul><li>t0 时刻：Consumer A 收到条消息，检查消息执行状态，发现消息未处理过，开始执行“账户增加 100 元”；</li><li>t1 时刻：Consumer B 收到条消息，检查消息执行状态，发现消息未处理过，因为这个时刻，Consumer A 还未来得及更新消息执行状态。</li></ul><p>这样就会导致账户被错误地增加了两次 100 元，这是一个在分布式系统中非常容易犯的错误，一定要引以为戒。</p><p>对于这个问题，当然我们可以用事务来实现，也可以用锁来实现，但是在分布式系统中，无论是分布式事务还是分布式锁都是比较难解决问题。</p><p><strong>几种实现幂等操作的方法</strong></p><ul><li>可以利用数据库的约束来防止重复更新数据，</li><li>可以为数据更新设置一次性的前置条件，来防止重复消息，如果这两种方法都不适用于你的场景，</li><li>还可以用“记录并检查操作”的方式来保证幂等，这种方法适用范围最广，但是实现难度和复杂度也比较高，一般不推荐使用。</li></ul><p>这些实现幂等的方法，不仅可以用于解决重复消息的问题，也同样适用于，在其他场景中来<strong>解决重复请求或者重复调用的问题</strong>。比如，我们可以将 HTTP 服务设计成幂等的，解决前端或者 APP 重复提交表单数</p><p>据的问题；也可以将一个微服务设计成幂等的，解决 RPC 框架自动重试导致的重复调用问题。这些方法都是通用的。</p><h1 id="3-消息积压问题"><span id="3-消息积压问题">3. 消息积压问题</span></h1><p>在使用消息队列遇到的问题中，消息积压这个问题，应该是最常遇到的问题。</p><p>消息积压的直接原因，一定是系统中的某个部分出现了性能问题，来不及处理上游发送的消息，才会导致消息积压。 所以在使用消息队列时，如何来优化代码的性能，避免出现消息积压。</p><h2 id="优化性能来避免消息积压"><span id="优化性能来避免消息积压">优化性能来避免消息积压</span></h2><p>在使用消息队列的系统中，对于性能的优化，主要体现在生产者和消费者这一收一发两部分的业务逻辑中。对于消息队列本身的性能，不需要太关注。</p><p>主要原因是，对于绝大多数使用消息队列的业务来说，消息队列本身的处理能力要远大于业务系统的处理能力。主流消息队列的单个节点，消息收发的性能可以达到每秒钟处理几万至几十万条消息的水平，还可</p><p>以通过水平扩展 Broker 的实例数成倍地提升处理能力。而一般的业务系统需要处理的业务逻辑远比消息队列要复杂，单个节点每秒钟可以处理几百到几千次请求，已经可以算是性能非常好的了。所以，对于消</p><p>息队列的性能优化，我们更关注的是，在消息的收发两端，我们的业务代码怎么和消息队列配合，达到一个最佳的性能。</p><h3 id="1-发送端性能优化"><span id="1-发送端性能优化">1. 发送端性能优化</span></h3><p>如果说，代码发送消息的性能上不去，需要优先检查一下，是不是发消息之前的业务逻辑耗时太多导致的。</p><p>对于发送消息的业务逻辑，只需要注意<strong>设置合适的并发和批量大小，就可以达到很好的发送性能</strong>。</p><p>Producer 发送消息的过程，Producer 发消息给 Broker，Broker 收到消息后返回确认响应，这是一次完整的交互。假设这一次交互的平均时延是 1ms，把这 1ms 的时间分解开，它包括了下面这些步骤的耗时：</p><ul><li>发送端准备数据、序列化消息、构造请求等逻辑的时间，也就是发送端在发送网络请求之前的耗时；</li><li>发送消息和返回响应在网络传输中的耗时；</li><li>Broker 处理消息的时延。</li></ul><p>如果是单线程发送，每次只发送 1 条消息，那么每秒只能发送 1000ms / 1ms * 1 条 /ms = 1000 条 消息，这种情况下并不能发挥出消息队列的全部实力。</p><p>无论是增加每次发送消息的批量大小，还是增加并发，都能成倍地提升发送性能。<strong>至于到底是选择批量发送还是增加并发，主要取决于发送端程序的业务性质</strong>。</p><p>比如说，你的<strong>消息发送端是一个微服务</strong>，主要接受 RPC 请求处理在线业务。很自然的，微服务在处理每次请求的时候，就在当前线程直接发送消息就可以了，因为所有 RPC 框架都是多线程支持多并发的，自</p><p>然也就实现了并行发送消息。并且在线业务比较在意的是请求响应时延，选择批量发送必然会影响 RPC 服务的时延。这种情况，比较明智的方式就是<strong>通过并发来提升发送性能</strong>。</p><p>如果你的<strong>系统是一个离线分析系统</strong>，离线系统在性能上的需求是什么呢？它不关心时延，更注重整个系统的吞吐量。发送端的数据都是来自于数据库，这种情况就更适合批量发送，你可以批量从数据库读取数</p><p>据，然后批量来发送消息，同样<strong>用少量的并发就可以获得非常高的吞吐量</strong>。</p><h3 id="2-消费端性能优化"><span id="2-消费端性能优化">2. 消费端性能优化</span></h3><p>使用消息队列的时候，大部分的性能问题都出现在消费端，如果消费的速度跟不上发送端生产消息的速度，就会造成消息积压。如果这种性能倒挂的问题只是暂时的，那问题不大，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息是可以逐渐被消化掉的。</p><p>要是消费速度一直比生产速度慢，时间长了，整个系统就会出现问题，要么，消息队列的存储被填满无法提供服务，要么消息丢失，这对于整个系统来说都是严重故障。</p><p>所以，在设计系统的时候，<strong>一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。</strong></p><p><strong>消费端的性能优化除了优化消费业务逻辑以外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能</strong>。特别需要注意的一点是，<strong>在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区</strong></p><p><strong>（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的</strong>。因为对于消费者，在每个分区上实际只能支持单线程消费。</p><p><strong>一个解决消费慢的问题常见的错误：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220224161200.png" alt></p><p>它收消息处理的业务逻辑可能比较慢，也很难再优化了，为了避免消息积压，在收到消息的 OnMessage 方法中，不处理任何业务逻辑，把这个消息放到一个内存队列里面就返回了。然后它可以启动很多的业务</p><p>线程，这些业务线程里面是真正处理消息的业务逻辑，这些线程从内存队列里取消息处理，这样它就解决了单个 Consumer 不能并行消费的问题。</p><p>这个方法是不是很完美地实现了并发消费？错误！ 因为会丢消息。如果收消息的节点发生宕机，在内存队列中还没来及处理的这些消息就会丢失。</p><p>在onMessage方法结束后，如果没有抛异常，就自动ACK了。而这个时候，消息只是在内存队列中，并没有被真正处理完。</p><p>如果onMessage方法中，收到消息后不确认，等真正处理完消息再确认，就可以了吧，这样就可以用内存队列了</p><p>理论上是可以的，但要注意，像RocketMQ，采用默认配置的时候，onMessage方法结束后，如果没抛异常，默认就会自动确认了。</p><p><strong>在消费端是否可以通过批量消费的方式来提升消费性能？在什么样场景下，适合使用这种方法？或者说，这种方法有什么局限性？</strong></p><p>批量消费即一次取一批消息，等这一批消息都成功了，再提交最后一条消息的位置作为新的消费位置。如果其中任何一条失败，则认为整批都失败。</p><p>批量消费应该是与消息处理是需要实时与否有关。如果需要实时处理，如订单相关的，就不能批量，但是发送提醒邮件之类的，就可以。</p><p><strong>批量消费有意义的场景要求：</strong></p><ul><li>1.要么消费端对消息的处理支持批量处理，比如批量入库</li><li>\2. 要么消费端支持多线程/协程并发处理，业务上也允许消息无序。</li><li>\3. 或者网络带宽在考虑因素内，需要减少消息的overhead。</li></ul><p><strong>批量消费的局限性：</strong></p><ul><li>\1. 需要一个整体ack的机制，一旦一条靠前的消息消费失败，可能会引起很多消息重试。</li><li>\2. 多线程下批量消费速度受限于最慢的那个线程。</li></ul><p>但其实以上局限并没有影响主流MQ的实现了批量功能。</p><p>1、要求消费端能够批量处理或者开启多线程进行单条处理<br>2、批量消费一旦某一条数据消费失败会导致整批数据重复消费<br>3、对实时性要求不能太高，批量消费需要Broker积累到一定消费数据才会发送到Consumer</p><p>消费端进行批量操作，感觉和上面的先将消息放在内存队列中，然后在并发消费消息，如果机器宕机，这些批量消息都会丢失，如果在数据库层面，批量操作在大事务，会导致锁的竞争，并且也会导致主备的不</p><p>一致。如果是一些不重要的消息如对日志进行备份，就可以使用批量操作之类的提高消费性能，因为一些日志消息丢失也是可以接受的。</p><p>如果使用了批量消费的方式，那么就需要批量确认，如果一次消费十条消息，除了第七条消费失败了，其他的都处理成功了，但是这中情况下broker只能将消费的游标修改成消息7，而之后的消息虽然处理成功</p><p>了，但是也只能使用类似于拉回重传的方式再次消费，浪费性能，而且这种批量消费对于消费者的并发我觉得不是很友好，可能消费者1来了取走了十条消息在处理，这时候消费者2过来了也想取十条消息，但是</p><p>他需要等待消费者1进行ack才可以取走消息。</p><p><strong>如何判断增加多少consumer消费实例的个数？</strong></p><p>可以简单计算一下，消费并行度：单实例平均消费tps * 消费并行度 &gt; 生产消息的总tps<br>消费并行度 = min（consumer实例数，分区数量）</p><h2 id="消息积压的紧急处理"><span id="消息积压的紧急处理">消息积压的紧急处理</span></h2><p>还有一种消息积压的情况是，日常系统正常运转的时候，没有积压或者只有少量积压很快就消费掉了，但是某一个时刻，突然就开始积压消息并且积压持续上涨。这种情况下需要你在短时间内找到消息积压的原</p><p>因，迅速解决问题才不至于影响业务。</p><p>导致突然积压的原因肯定是多种多样的，不同的系统、不同的情况有不同的原因，不能一概而论。但是，排查消息积压原因，是有一些相对固定而且比较有效的方法的。</p><p>能导致积压突然增加，最粗粒度的原因，只有两种：要么是发送变快了，要么是消费变慢了。</p><p>大部分消息队列都内置了监控的功能，只要通过监控数据，很容易确定是哪种原因。如果是单位时间发送的消息增多，比如说是赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升消费性能，唯一的</p><p>方法是通过扩容消费端的实例数来提升总体的消费能力。</p><p>如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。</p><p>还有一种不太常见的情况，你通过监控发现，无论是发送消息的速度还是消费消息的速度和原来都没什么变化，这时候你需要检查一下你的消费端，是不是消费失败导致的一条消息反复消费这种情况比较多，这</p><p>种情况也会拖慢整个系统的消费速度。</p><p>如果监控到消费变慢了，你需要检查你的消费实例，分析一下是什么原因导致消费变慢。优先检查一下日志是否有大量的消费错误，如果没有错误的话，可以通过打印堆栈信息，看一下你的消费线程是不是卡在</p><p>什么地方不动了，比如触发了死锁或者卡在等待某些资源上了。</p><p><strong>优化消息收发性能，</strong>预防消息积压的方法有两种，增加批量或者是增加并发，在发送端这两种方法都可以使用，在消费端需要注意的是，增加并发需要同步扩容分区数量，否则是起不到效果的。</p><p><strong>对于系统发生消息积压的情况</strong>，需要先解决积压，再分析原因，毕竟保证系统的可用性是首先要解决的问题。快速解决积压的方法就是通过水平扩容增加 Consumer 的实例数量。</p><p>消息积压处理：<br>1、发送端优化，增加批量和线程并发两种方式处理<br>2、消费端优化，优化业务逻辑代码、水平扩容增加并发并同步扩容分区数量<br>查看消息积压的方法：<br>1、消息队列内置监控，查看发送端发送消息与消费端消费消息的速度变化<br>2、查看日志是否有大量的消费错误<br>3、打印堆栈信息，查看消费线程卡点信息</p><p>面试解决消息积压的方法：<br>（1）临时扩容，增加消费端，用硬件提升消费速度。<br>（2）服务降级，关闭一些非核心业务，减少消息生产。<br>（3）通过日志分析，监控等找到挤压原因，消息队列三部分，上游生产者是否异常生产大量数据，中游消息队列存储层是否出现问题，下游消费速度是否变慢，就能确定哪个环节出了问题<br>（4）根据排查解决异常部分。<br>（5）等待积压的消息被消费，恢复到正常状态，撤掉扩容服务器。</p><h1 id="4-如何保证消息的严格顺序"><span id="4-如何保证消息的严格顺序">4. 如何保证消息的严格顺序？</span></h1><p>怎么来保证消息的严格顺序？主题层面是无法保证严格顺序的，<strong>只有在队列上才能保证消息的严格顺序。</strong></p><p>如果说，<strong>你的业务必须要求全局严格顺序，就只能把消息队列数配置成 1，生产者和消费者也只能是一个实例，这样才能保证全局严格顺序。</strong></p><p>大部分情况下，并不需要全局严格顺序，只要保证局部有序就可以满足要求了。比如，在传递账户流水记录的时候，<strong>只要保证每个账户的流水有序就可以了，不同账户之间的流水记录是不需要保证顺序的。</strong></p><p>如果需要<strong>保证局部严格顺序</strong>，可以这样来实现。在发送端，我们使用账户 ID 作为 Key，<strong>采用一致性哈希算法计算出队列编号</strong>，<strong>指定队列来发送消息。一致性哈希算法可以保证</strong>，<strong>相同 Key 的消息总是发送到同一</strong></p><p><strong>个队列上</strong>，这样可以保证相同 Key 的消息是严格有序的。如果不考虑队列扩容，也可以用队列数量取模的简单方法来计算队列编号。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-丢消息&quot;&gt;1. 丢消息&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#检测消息丢失的方法&quot;&gt;检测消息丢失的方法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#确保消息可靠传递&quot;&gt;确保消息可靠传递&lt;/a&gt;&lt;ul&gt;

      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxb.wiki/categories/Design/"/>
    
    
      <category term="mq" scheme="https://lxb.wiki/tags/mq/"/>
    
  </entry>
  
  <entry>
    <title>B树和B+树</title>
    <link href="https://lxb.wiki/17ced2c4/"/>
    <id>https://lxb.wiki/17ced2c4/</id>
    <published>2021-07-11T13:07:59.000Z</published>
    <updated>2022-02-12T13:11:28.411Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><!-- tocstop --><p><strong>一 B树</strong></p><p><strong>1.B树的定义：</strong>B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。</p><p><strong>2.B树的特征：</strong></p><ul><li>根节点至少有两个子节点</li><li>每个中间节点都包含k-1个元素和k个孩子，其中 m/2 ≤ k ≤ m （m为树的阶）</li><li>每个叶子节点都包含k-1个元素，其中 m/2 ≤ k ≤ m （m为树的阶）</li><li>每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域划分（一个结点有k个孩子时，必有k-1个元素才能将子树中所有元素划分为k个子集）</li></ul><p><strong>3.B树的操作</strong></p><p><strong>3.1 B树的查找：</strong>如下图，查询元素8</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212210837.png" alt></p><p>第一次磁盘IO：把15所在节点读到内存中，然后与8做比较，小于15，找到下一个节点（5和9对应的节点）</p><p>第二次磁盘IO：把5和9所在的节点读到内存中，然后与8做比较，5&lt;8&lt;9，找到下一个节点（6和8对应的节点）</p><p>第三次磁盘IO：把6和8所在节点读到内存中，然后与8做比较，找到了元素8</p><p><strong>3.1 B树的插入：</strong> 将元素7插入下图中的B树</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212211015.png" alt></p><p>步骤一：自顶向下查找元素7应该在的位置，即在6和8之间</p><p>步骤二：三阶B树中的节点最多有两个元素，把6 7 8里面的中间元素上移（中间元素上移是插入操作的关键）</p><p>步骤三：上移之后，上一层节点元素也超载了，5 7 9中间元素上移，现在根节点变为了 7 15</p><p>步骤四：要对B树进行调整，使其满足B树的特性，最终如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212211040.png" alt></p><p><strong>二 B+树</strong> </p><p> B+树是B树的一种变形体，它与B树的差异在于：</p><ul><li><p>有K个子节点的节点必然有K个关键码</p></li><li><p>非叶节点仅具有索引作用，元素信息均存放在叶节点中</p></li><li><p>树的所有叶节点构成一个有序链表，可以按照关键码排序的次序遍历全部记录</p><p>B+树的优势：</p></li><li><p>由于B+树在内部节点上不包含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子节点上关联的数据也具有更好的缓存命中率。</p></li><li><p>B+树的叶子节点都是相连的，因此对整棵树的遍历只需要一次线性遍历叶子节点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212211103.png" alt></p><p>总结：我们知道二叉查找树的时间复杂度是Ｏ(logN)，效率已经足够高。为什么出现B树和B+树呢？当大量数据存储在磁盘上，进行查询操作时，需要先将数据加载到内存中（磁盘IO操作），而数据并不能一次性全部加载到内存中，只能逐一加载每个磁盘页（对应树的一个节点），并且磁盘IO操作很慢，平衡二叉树由于树深度过大而造成磁盘IO读写过于频繁，进而导致效率低下。为了减少磁盘IO的次数，就需要降低树的深度，那么就引出了B树和B+树：每个节点存储多个元素，采用多叉树结构。这样就提高了效率，比如数据库索引，就是存储在磁盘上，采用的就是B+树的数据结构。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;



&lt;!-- tocstop --&gt;

&lt;p&gt;&lt;strong&gt;一 B树&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.B树的定义：&lt;/strong&gt;B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间
      
    
    </summary>
    
    
      <category term="DB" scheme="https://lxb.wiki/categories/DB/"/>
    
    
      <category term="tree" scheme="https://lxb.wiki/tags/tree/"/>
    
  </entry>
  
  <entry>
    <title>Redis-Sorted-Set底层数据结构</title>
    <link href="https://lxb.wiki/f1113725/"/>
    <id>https://lxb.wiki/f1113725/</id>
    <published>2021-06-22T14:56:12.000Z</published>
    <updated>2022-02-12T13:05:54.216Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#sortedset底层存储结构">Sortedset底层存储结构</a><ul><li><a href="#1-跳跃表">1 跳跃表</a></li><li><a href="#2-跳跃表的结构">2 跳跃表的结构</a></li><li><a href="#3-压缩列表">3 压缩列表</a><ul><li><a href="#连锁更新">连锁更新</a></li></ul></li><li><a href="#4-quicklist">4 quicklist</a><ul><li><a href="#数据压缩">数据压缩</a></li></ul></li></ul></li></ul><!-- tocstop --><h1 id="sortedset底层存储结构"><span id="sortedset底层存储结构">Sortedset底层存储结构</span></h1><p>sortedset同时会由两种数据结构支持,ziplist和skiplist.</p><p>只有同时满足如下条件是,使用的是ziplist,其他时候则是使用skiplist</p><ul><li>有序集合保存的元素数量小于128个</li><li>有序集合保存的所有元素的长度小于64字节</li></ul><p>当ziplist作为存储结构时候,每个集合元素使用两个紧挨在一起的压缩列表结点来保存,第一个节点保存元素的成员,第二个元素保存元素的分值.</p><p>当使用skiplist作为存储结构时,使用skiplist按序保存元素分值,使用dict来保存元素和分值的对应关系</p><h2 id="1-跳跃表"><span id="1-跳跃表">1 跳跃表</span></h2><p>跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。跳跃表支持平均O（logN）、最坏O（N）复杂度的节点查找，还可以通过顺序性操作来批量处理节点。</p><p>在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单。</p><p><strong>Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员（member）是比较长的字符串时，Redis就会使用跳跃表来作为有序集合键的底层实现。</strong></p><p>Redis只在两个地方用到了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构，除此之外，跳跃表在Redis里面没有其他用途。</p><p>Redis的配置文件中关于有序集合底层实现的两个配置。<br>1）zset-max-ziplist-entries 128:zset采用压缩列表时，元素个数最大值。默认值为128。<br>2）zset-max-ziplist-value 64:zset采用压缩列表时，每个元素的字符串长度最大值。默认值为64。<br>zset插入第一个元素时，会判断下面两种条件：</p><ul><li>zset-max-ziplist-entries的值是否等于0；</li><li>zset-max-ziplist-value小于要插入元素的字符串长度。满足任一条件Redis就会采用跳跃表作为底层实现，否则采用压缩列表作为底层实现方式。</li></ul><p>一般情况下，不会将zset-max-ziplist-entries配置成0，元素的字符串长度也不会太长，所以在创建有序集合时，默认使用压缩列表的底层实现。zset新插入元素时，会判断以下两种条件：</p><ul><li>zset中元素个数大于zset_max_ziplist_entries；</li><li>插入元素的字符串长度大于zset_max_ziplist_value。当满足任一条件时，Redis便会将zset的底层实现由压缩列表转为跳跃表。</li></ul><blockquote><p>zset在转为跳跃表之后，即使元素被逐渐删除，也不会重新转为压缩列表。</p></blockquote><h2 id="2-跳跃表的结构"><span id="2-跳跃表的结构">2 跳跃表的结构</span></h2><p>其c语言代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> &#123;</span></span><br><span class="line"><span class="comment">//成员对象</span></span><br><span class="line">    robj *obj;</span><br><span class="line">    <span class="keyword">double</span> score;<span class="comment">//分值</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">backward</span>;</span><span class="comment">//回退指针</span></span><br><span class="line">    <span class="comment">//层</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistLevel</span> &#123;</span></span><br><span class="line">    <span class="comment">//前进指针</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">forward</span>;</span></span><br><span class="line">        <span class="comment">//跨度</span></span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br></pre></td></tr></table></figure><p>1）obj：用于存储字符串类型的数据。<br>2）score：用于存储排序的分值。<br>3）backward：后退指针，只能指向当前节点最底层的前一个节点，头节点和第一个节点——backward指向NULL，从后向前遍历跳跃表时使用。<br>4）level：为柔性数组。每个节点的数组长度不一样，在生成跳跃表节点时，随机生成一个1～64的值，值越大出现的概率越低。<br>level数组的每项包含以下两个元素。</p><ul><li>forward：指向本层下一个节点，尾节点的forward指向NULL。</li><li>span:forward指向的节点与本节点之间的元素个数。span值越大，跳过的节点个数越多。</li></ul><p>除了跳跃表节点外，还需要一个跳跃表结构来管理节点，Redis使用zskiplist结构体，定义如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplist</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">header</span>, *<span class="title">tail</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> length;</span><br><span class="line">    <span class="keyword">int</span> level;</span><br><span class="line">&#125; zskiplist;</span><br></pre></td></tr></table></figure><p>1）header：指向跳跃表头节点。头节点是跳跃表的一个特殊节点，它的level数组元素个数为64。头节点在有序集合中不存储任何member和score值，ele值为NULL, score值为0；也不计入跳跃表的总长度。头节点在初始化时，64个元素的forward都指向NULL, span值都为0。<br>2）tail：指向跳跃表尾节点。<br>3）length：跳跃表长度，表示除头节点之外的节点总数。<br>4）level：跳跃表的高度。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212210023.png" alt></p><blockquote><p>查找从最高层开始，如果本层的next节点大于要查找的值或next节点为NULL，则从本节点开始，降低一层继续向后查找，依次类推，如果找到则返回节点；否则返回NULL。采用该原理查找节点，在节点数量比较多时，可以跳过一些节点，查询效率大大提升，这就是跳跃表的基本思想。</p></blockquote><p>1）跳跃表由很多层构成。<br>2）跳跃表有一个头（header）节点，头节点中有一个64层的结构，每层的结构包含指向本层的下个节点的指针，指向本层下个节点中间所跨越的节点个数为本层的跨度（span）。<br>3）除头节点外，层数最多的节点的层高为跳跃表的高度（level）<br>4）每层都是一个有序链表，数据递增。<br>5）除header节点外，一个元素在上层有序链表中出现，则它一定会在下层有序链表中出现。<br>6）跳跃表每层最后一个节点指向NULL，表示本层有序链表的结束。<br>7）跳跃表拥有一个tail指针，指向跳跃表最后一个节点。<br>8）最底层的有序链表包含所有节点，最底层的节点个数为跳跃表的长度（length）（不包括头节点）。<br>9）每个节点包含一个后退指针，头节点和第一个节点指向NULL；其他节点指向最底层的前一个节点。</p><blockquote><p>Redis通过zslRandomLevel函数随机生成一个1～64的值作为新建节点的高度</p></blockquote><h2 id="3-压缩列表"><span id="3-压缩列表">3 压缩列表</span></h2><p>压缩列表ziplist本质上就是一个字节数组，是Redis为了节约内存而设计的一种线性数据结构，可以包含多个元素，每个元素可以是一个字节数组或一个整数。</p><blockquote><p>Redis的有序集合、散列和列表都直接或者间接使用了压缩列表。当有序集合或散列表的元素个数比较少，且元素都是短字符串时，Redis便使用压缩列表作为其底层数据存储结构。列表使用快速链表（quicklist）数据结构存储，而快速链表就是双向链表与压缩列表的组合。</p></blockquote><p>一个压缩列表可以包含任意多个节点（entry），<strong>每个节点可以保存一个字节数组或者一个整数值。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212210219.png" alt></p><p>1）zlbytes：压缩列表的字节长度，占4个字节，因此压缩列表最多有232-1个字节。<br>2）zltail：压缩列表尾元素相对于压缩列表起始地址的偏移量，占4个字节。3）zllen：压缩列表的元素个数，占2个字节。zllen无法存储元素个数超过65535（216-1）的压缩列表，必须遍历整个压缩列表才能获取到元素个数。4）entryX：压缩列表存储的元素，可以是字节数组或者整数，长度不限。entry的编码结构将在后面详细介绍。<br>5）zlend：压缩列表的结尾，占1个字节，恒为0xFF。</p><p>而压缩列表元素(entry)的编码结构：<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212210255.png" alt></p><ul><li>previous_entry_length字段表示前一个元素的字节长度<br>  占1个或者5个字节，当前一个元素的长度小于254字节时，用1个字节表示；当前一个元素的长度大于或等于254字节时，用5个字节来表示。</li><li>encoding字段表示当前元素的编码</li><li>数据内容存储在content字段</li></ul><p>其中包含了很多复杂的解码运算，想详细了解的可以找对应的书来看。</p><h3 id="连锁更新"><span id="连锁更新">连锁更新</span></h3><p>每个节点的previous_entry_length属性都记录了前一个节点的长度，添加新节点可能会引发连锁更新之外，删除节点也可能会引发连锁更新。<br>因为某个可能的结点previous_entry_length属性仅长1字节，它没办法保存新节点new的长度，所以程序将对压缩列表执行空间重分配操作，并将则个节点的previous_entry_length属性从原来的1字节长扩展为5字节长。进而引发后面的连锁更新。<br>其最坏复杂度是O（N 2）。</p><p>尽管连锁更新的复杂度较高，但它真正造成性能问题的几率是很低的：</p><p>压缩列表里要恰好有多个连续的、长度介于250字节至253字节之间的节点，连锁更新才有可能被引发，在实际中，这种情况并不多见；<br>即使出现连锁更新，但只要被更新的节点数量不多，就不会对性能造成任何影响：比如说，对三五个节点进行连锁更新是绝对不会影响性能的；</p><h2 id="4-quicklist"><span id="4-quicklist">4 quicklist</span></h2><p>quicklist是Redis底层最重要的数据结构之一，它是Redis对外提供的6种基本数据结构中List的底层实现，在Redis 3.2版本中引入。</p><p>在引入quicklist之前，Redis采用压缩链表（ziplist）以及双向链表（adlist）作为List的底层实现。当元素个数比较少并且元素长度比较小时，Redis采用ziplist作为其底层存储；当任意一个条件不满足时，Redis采用adlist作为底层存储结构。</p><p>这么做的主要原因是，当元素长度较小时，采用ziplist可以有效节省存储空间，但ziplist的存储空间是连续的，当元素个数比较多时，修改元素时，必须重新分配存储空间，这无疑会影响Redis的执行效率，故而采用一般的双向链表。</p><p>结构如下：<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212210432.png" alt></p><p>代码如下</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklist</span>&#123;</span></span><br><span class="line">quicklistNode *head;</span><br><span class="line">quicklistNode *tail;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> count;<span class="comment">//quicklist中元素总数</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> len;<span class="comment">//quicklist Node（节点）个数</span></span><br><span class="line"><span class="keyword">int</span> fill : <span class="number">16</span>;<span class="comment">//每个quicklistNode中ziplist长度</span></span><br><span class="line">&#125;quicklist;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span>&#123;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">prev</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">next</span>;</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">char</span> *zl;<span class="comment">//zl指向该节点对应的ziplist结构；</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> sz;<span class="comment">//整个ziplist结构的大小</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> count:<span class="number">16</span>;<span class="comment">//ziplist的个数</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> coding：<span class="number">2</span>;<span class="comment">//1代表是原生的，2代表使用LZF进行压缩；</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> containnr：<span class="number">2</span>;<span class="comment">//container为quicklistNode节点zl指向的容器类型：1代表none,2代表使用ziplist存储数据；</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> recompress:<span class="number">1</span>;<span class="comment">//recompress代表这个节点之前是否是压缩节点</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> extra:<span class="number">10</span>;<span class="comment">//extra为预留</span></span><br><span class="line">&#125;quicklistNode;</span><br></pre></td></tr></table></figure><h3 id="数据压缩"><span id="数据压缩">数据压缩</span></h3><p>quicklist每个节点的实际数据存储结构为ziplist，这种结构的主要优势在于节省存储空间。为了进一步降低ziplist所占用的空间，Redis允许对ziplist进一步压缩，Redis采用的压缩算法是LZF，压缩过后的数据可以分成多个片段，每个片段有2部分：一部分是解释字段，另一部分是存放具体的数据字段。<br>解释字段可以占用1～3个字节，数据字段可能不存在。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistLZF</span>&#123;</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> sz;<span class="comment">//sz表示compressed所占字节大小</span></span><br><span class="line"><span class="keyword">char</span> compress[];</span><br><span class="line">&#125;quicklistLZF;</span><br></pre></td></tr></table></figure><p>解释字段有3种:<br>1）字面型，解释字段占用1个字节，数据字段长度由解释字段后5位决定。<br>2）简短重复型，解释字段占用2个字节，没有数据字段，数据内容与前面数据内容重复，重复长度小于8。<br>3）批量重复型，解释字段占3个字节，没有数据字段，数据内容与前面内容重复。</p><p>压缩：<br>数据与前面重复的，记录重复位置以及重复长度，否则直接记录原始数据内容。压缩算法的流程如下：遍历输入字符串，对当前字符及其后面2个字符进行散列运算，如果在Hash表中找到曾经出现的记录，则计算重复字节的长度以及位置，反之直接输出数据。<br>解压：<br>可能存在重复数据与当前位置重叠的情况，例如在当前位置前的15个字节处，重复了20个字节，此时需要按位逐个复制。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#sortedset底层存储结构&quot;&gt;Sortedset底层存储结构&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-跳跃表&quot;&gt;1 跳跃表&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-跳跃表的结构&quot;&gt;2 跳跃表的
      
    
    </summary>
    
    
      <category term="DB" scheme="https://lxb.wiki/categories/DB/"/>
    
    
      <category term="redis" scheme="https://lxb.wiki/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis的线程模型</title>
    <link href="https://lxb.wiki/9106c914/"/>
    <id>https://lxb.wiki/9106c914/</id>
    <published>2021-06-11T14:33:18.000Z</published>
    <updated>2022-02-12T12:54:04.957Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#文件事件处理器">文件事件处理器</a></li><li><a href="#消息处理流程">消息处理流程</a></li><li><a href="#io-多路复用程序的实现">I/O 多路复用程序的实现</a></li><li><a href="#文件事件的类型">文件事件的类型</a></li><li><a href="#文件事件的处理器">文件事件的处理器</a><ul><li><a href="#连接应答处理器">连接应答处理器</a></li><li><a href="#命令请求处理器">命令请求处理器</a></li><li><a href="#命令回复处理器">命令回复处理器</a></li></ul></li><li><a href="#一次完整的客户端与服务器连接事件示例">一次完整的客户端与服务器连接事件示例</a></li><li><a href="#思考问题">思考问题</a></li></ul><!-- tocstop --><h2 id="文件事件处理器"><span id="文件事件处理器">文件事件处理器</span></h2><p>Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器。它的组成结构为4部分：多个<a href="https://so.csdn.net/so/search?q=套接字&spm=1001.2101.3001.7020" target="_blank" rel="noopener">套接字</a>、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212203719.png" alt></p><h2 id="消息处理流程"><span id="消息处理流程">消息处理流程</span></h2><ul><li>文件事件处理器使用I/O多路复用(multiplexing)程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。</li><li>当被监听的套接字准备好执行连接应答(accept)、读取(read)、写入(write)、关闭(close)等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。</li></ul><p>尽管多个文件事件可能会并发地出现，但I/O多路复用程序总是会将所有产生事件的套接字都推到一个队列里面，然后通过这个队列，以有序（sequentially）、同步（synchronously）、每次一个套接字的方式向文件事件分派器传送套接字：当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕）， I/O多路复用程序才会继续向文件事件分派器传送下一个套接字。</p><h2 id="io-多路复用程序的实现"><span id="io-多路复用程序的实现">I/O 多路复用程序的实现</span></h2><p>Redis的I/O多路复用程序的所有功能是通过包装select、epoll、evport和kqueue这些I/O多路复用函数库来实现的，每个I/O多路复用函数库在Redis源码中都对应一个单独的文件，比如ae_select.c、ae_epoll.c、ae_kqueue.c等。</p><p>因为Redis为每个I/O多路复用函数库都实现了相同的API，所以I/O多路复用程序的底层实现是可以互换的，如下图所示<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212203919.png" alt></p><p>Redis在I/O多路复用程序的实现源码中用#include宏定义了相应的规则，程序会在编译时自动选择系统中性能最好的I/O多路复用函数库来作为Redis的I/O多路复用程序的底层实现：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Include the best multiplexing layer supported by this system.</span></span><br><span class="line"><span class="comment"> * The following should be ordered by performances, descending. */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> HAVE_EVPORT</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_evport.c"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifdef</span> HAVE_EPOLL</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_epoll.c"</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">ifdef</span> HAVE_KQUEUE</span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_kqueue.c"</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_select.c"</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><h2 id="文件事件的类型"><span id="文件事件的类型">文件事件的类型</span></h2><p>I/O 多路复用程序可以监听多个套接字的ae.h/AE_READABLE事件和ae.h/AE_WRITABLE事件，这两类事件和套接字操作之间的对应关系如下：</p><ul><li>当套接字变得可读时（客户端对套接字执行write操作，或者执行close操作），或者有新的可应答（acceptable）套接字出现时（客户端对服务器的监听套接字执行connect操作），套接字产生AE_READABLE 事件</li><li>当套接字变得可写时（客户端对套接字执行read操作），套接字产生AE_WRITABLE事件。I/O多路复用程序允许服务器同时监听套接字的AE_READABLE事件和AE_WRITABLE事件，如果一个套接字同时产生了这两种事件，那么文件事件分派器会优先处理AE_READABLE事件，等到AE_READABLE事件处理完之后，才处理AE_WRITABLE 事件。这也就是说，如果一个套接字又可读又可写的话，那么服务器将先读套接字，后写套接字。</li></ul><h2 id="文件事件的处理器"><span id="文件事件的处理器">文件事件的处理器</span></h2><p>Redis为文件事件编写了多个处理器，这些事件处理器分别用于实现不同的网络通讯需求，常用的处理器如下：</p><p>为了对连接服务器的各个客户端进行应答， 服务器要为监听套接字关联连接应答处理器。<br>为了接收客户端传来的命令请求， 服务器要为客户端套接字关联命令请求处理器。<br>为了向客户端返回命令的执行结果， 服务器要为客户端套接字关联命令回复处理器。</p><h3 id="连接应答处理器"><span id="连接应答处理器">连接应答处理器</span></h3><p>networking.c中acceptTcpHandler函数是Redis的连接应答处理器，这个处理器用于对连接服务器监听套接字的客户端进行应答，具体实现为sys/socket.h/accept函数的包装。</p><p>当Redis服务器进行初始化的时候，程序会将这个连接应答处理器和服务器监听套接字的AE_READABLE事件关联起来，当有客户端用sys/socket.h/connect函数连接服务器监听套接字的时候， 套接字就会产生AE_READABLE 事件， 引发连接应答处理器执行， 并执行相应的套接字应答操作，如图所示。<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212204113.png" alt></p><h3 id="命令请求处理器"><span id="命令请求处理器">命令请求处理器</span></h3><p>networking.c中readQueryFromClient函数是Redis的命令请求处理器，这个处理器负责从套接字中读入客户端发送的命令请求内容， 具体实现为unistd.h/read函数的包装。</p><p>当一个客户端通过连接应答处理器成功连接到服务器之后， 服务器会将客户端套接字的AE_READABLE事件和命令请求处理器关联起来，当客户端向服务器发送命令请求的时候，套接字就会产生 AE_READABLE事件，引发命令请求处理器执行，并执行相应的套接字读入操作，如图所示。<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212204151.png" alt></p><p>在客户端连接服务器的整个过程中，服务器都会一直为客户端套接字的AE_READABLE事件关联命令请求处理器。</p><h3 id="命令回复处理器"><span id="命令回复处理器">命令回复处理器</span></h3><p>networking.c中sendReplyToClient函数是Redis的命令回复处理器，这个处理器负责将服务器执行命令后得到的命令回复通过套接字返回给客户端，具体实现为unistd.h/write函数的包装。</p><p>当服务器有命令回复需要传送给客户端的时候，服务器会将客户端套接字的AE_WRITABLE事件和命令回复处理器关联起来，当客户端准备好接收服务器传回的命令回复时，就会产生AE_WRITABLE事件，引发命令回复处理器执行，并执行相应的套接字写入操作， 如图所示。<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212204231.png" alt></p><p>当命令回复发送完毕之后， 服务器就会解除命令回复处理器与客户端套接字的 AE_WRITABLE 事件之间的关联</p><h2 id="一次完整的客户端与服务器连接事件示例"><span id="一次完整的客户端与服务器连接事件示例">一次完整的客户端与服务器连接事件示例</span></h2><p>假设Redis服务器正在运作，那么这个服务器的监听套接字的AE_READABLE事件应该正处于监听状态之下，而该事件所对应的处理器为连接应答处理器。</p><p>如果这时有一个Redis客户端向Redis服务器发起连接，那么监听套接字将产生AE_READABLE事件， 触发连接应答处理器执行：处理器会对客户端的连接请求进行应答， 然后创建客户端套接字，以及客户端状态，并将客户端套接字的 AE_READABLE 事件与命令请求处理器进行关联，使得客户端可以向主服务器发送命令请求。</p><p>之后，客户端向Redis服务器发送一个命令请求，那么客户端套接字将产生 AE_READABLE事件，引发命令请求处理器执行，处理器读取客户端的命令内容， 然后传给相关程序去执行。</p><p>执行命令将产生相应的命令回复，为了将这些命令回复传送回客户端，服务器会将客户端套接字的AE_WRITABLE事件与命令回复处理器进行关联：当客户端尝试读取命令回复的时候，客户端套接字将产生AE_WRITABLE事件， 触发命令回复处理器执行， 当命令回复处理器将命令回复全部写入到套接字之后， 服务器就会解除客户端套接字的AE_WRITABLE事件与命令回复处理器之间的关联。<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212204316.png" alt> </p><h2 id="思考问题"><span id="思考问题">思考问题</span></h2><p>Q：<br>Redis是单线程模型为什么效率还这么高？<br>A：</p><p>纯内存访问：数据存放在内存中，内存的响应时间大约是100纳秒，这是Redis每秒万亿级别访问的重要基础。<br>非阻塞I/O：Redis采用epoll做为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接，读写，关闭都转换为了时间，不在I/O上浪费过多的时间。<br>单线程避免了线程切换和竞态产生的消耗。<br>Redis采用单线程模型，每条命令执行如果占用大量时间，会造成其他线程阻塞，对于Redis这种高性能服务是致命的，所以Redis是面向高速执行的数据库</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#文件事件处理器&quot;&gt;文件事件处理器&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#消息处理流程&quot;&gt;消息处理流程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#io-多路复用程序的实现&quot;&gt;I/O 多路复用程序的实现&lt;/
      
    
    </summary>
    
    
      <category term="DB" scheme="https://lxb.wiki/categories/DB/"/>
    
    
      <category term="redis" scheme="https://lxb.wiki/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>epoll高效运行的原理</title>
    <link href="https://lxb.wiki/3bdc8aea/"/>
    <id>https://lxb.wiki/3bdc8aea/</id>
    <published>2021-06-06T14:18:57.000Z</published>
    <updated>2022-02-11T07:27:15.262Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#概念">概念</a></li><li><a href="#io">I/O</a></li><li><a href="#事件">事件</a></li><li><a href="#通知机制">通知机制</a></li><li><a href="#epoll-的通俗解释">epoll 的通俗解释</a><ul><li><a href="#1-int-epoll_createint-size">1. int epoll_create(int size)</a></li><li><a href="#2-int-epoll_ctlint-epfd-int-op-int-fd-struct-epoll_event-event">2. int epoll_ctl(int epfd， int op， int fd， struct epoll_event *event)</a></li><li><a href="#3-int-epoll_waitint-epfd-struct-epoll_event-events-int-maxevents-int-timeout">3. int epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeout)</a></li></ul></li><li><a href="#epoll的两种触发方式">epoll的两种触发方式</a><ul><li><a href="#1水平触发的时机">1.水平触发的时机</a></li><li><a href="#2边缘触发的时机">2.边缘触发的时机</a></li></ul></li><li><a href="#epoll与select-poll的对比">epoll与select、poll的对比</a><ul><li><a href="#1-用户态将文件描述符传入内核的方式">1. 用户态将文件描述符传入内核的方式</a></li><li><a href="#2-内核态检测文件描述符读写状态的方式">2. 内核态检测文件描述符读写状态的方式</a></li><li><a href="#3-找到就绪的文件描述符并传递给用户态的方式">3. 找到就绪的文件描述符并传递给用户态的方式</a></li><li><a href="#4-重复监听的处理方式">4. 重复监听的处理方式</a></li></ul></li><li><a href="#epoll更高效的原因">epoll更高效的原因</a></li></ul><!-- tocstop --><h1 id="概念"><span id="概念">概念</span></h1><p>epoll是一种I/O事件通知机制，是linux 内核实现IO多路复用的一个实现。<br>IO多路复用是指，在一个操作里同时监听多个输入输出源，在其中一个或多个输入输出源可用的时候返回，然后对其的进行读写操作。</p><h1 id="io"><span id="io">I/O</span></h1><p>输入输出(input/output)的对象可以是文件(file)， 网络(socket)，进程之间的管道(pipe)。在linux系统中，都用文件描述符(fd)来表示。</p><h1 id="事件"><span id="事件">事件</span></h1><ul><li>可读事件，当文件描述符关联的内核读缓冲区可读，则触发可读事件。(可读：内核缓冲区非空，有数据可以读取)</li><li>可写事件，当文件描述符关联的内核写缓冲区可写，则触发可写事件。(可写：内核缓冲区不满，有空闲空间可以写入）</li></ul><h1 id="通知机制"><span id="通知机制">通知机制</span></h1><p>通知机制，就是当事件发生的时候，则主动通知。通知机制的反面，就是轮询机制。</p><h1 id="epoll-的通俗解释"><span id="epoll-的通俗解释">epoll 的通俗解释</span></h1><p>结合以上三条，epoll的通俗解释是一种当文件描述符的内核缓冲区非空的时候，发出可读信号进行通知，当写缓冲区不满的时候，发出可写信号通知的机制</p><p>epoll 的 API</p><p>epoll的核心是3个API，核心数据结构是：1个红黑树和1个链表</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220211152245.png" alt></p><h2 id="1-int-epoll_createint-size"><span id="1-int-epoll_createint-size">1. int epoll_create(int size)</span></h2><p>功能：</p><ul><li>内核会产生一个epoll 实例数据结构并返回一个文件描述符，这个特殊的描述符就是epoll实例的句柄，后面的两个接口都以它为中心（即epfd形参）。</li></ul><blockquote><p>size参数表示所要监视文件描述符的最大值，不过在后来的Linux版本中已经被弃用（同时，size不要传0，会报invalid argument错误）</p></blockquote><h2 id="2-int-epoll_ctlint-epfd-int-op-int-fd-struct-epoll_event-event"><span id="2-int-epoll_ctlint-epfd-int-op-int-fd-struct-epoll_event-event">2. int epoll_ctl(int epfd， int op， int fd， struct epoll_event *event)</span></h2><p>功能：</p><ul><li>将被监听的描述符添加到红黑树或从红黑树中删除或者对监听事件进行修改</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">union</span> epoll_data &#123;</span><br><span class="line">    <span class="keyword">void</span> *ptr; <span class="comment">/* 指向用户自定义数据 */</span></span><br><span class="line">    <span class="keyword">int</span> fd; <span class="comment">/* 注册的文件描述符 */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> u32; <span class="comment">/* 32-bit integer */</span></span><br><span class="line">    <span class="keyword">uint64_t</span> u64; <span class="comment">/* 64-bit integer */</span></span><br><span class="line">&#125; <span class="keyword">epoll_data_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> events; <span class="comment">/* 描述epoll事件 */</span></span><br><span class="line">    <span class="keyword">epoll_data_t</span> data; <span class="comment">/* 见上面的结构体 */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>对于需要监视的文件描述符集合，epoll_ctl对红黑树进行管理，红黑树中每个成员由描述符值和所要监控的文件描述符指向的文件表项的引用等组成。</p><p>op参数说明操作类型：</p><ul><li>EPOLL_CTL_ADD：向interest list添加一个需要监视的描述符</li><li>EPOLL_CTL_DEL：从interest list中删除一个描述符</li><li>EPOLL_CTL_MOD：修改interest list中一个描述符</li></ul><p>struct epoll_event结构描述一个文件描述符的epoll行为。在使用epoll_wait函数返回处于ready状态的描述符列表时，</p><ul><li>data域是唯一能给出描述符信息的字段，所以在调用epoll_ctl加入一个需要监测的描述符时，一定要在此域写入描述符相关信息</li><li>events域是bit mask，描述一组epoll事件，在epoll_ctl调用中解释为：描述符所期望的epoll事件，可多选。</li></ul><p>常用的epoll事件描述如下：</p><ul><li>EPOLLIN：描述符处于可读状态</li><li>EPOLLOUT：描述符处于可写状态</li><li>EPOLLET：将epoll event通知模式设置成edge triggered</li><li>EPOLLONESHOT：第一次进行通知，之后不再监测</li><li>EPOLLHUP：本端描述符产生一个挂断事件，默认监测事件</li><li>EPOLLRDHUP：对端描述符产生一个挂断事件</li><li>EPOLLPRI：由带外数据触发</li><li>EPOLLERR：描述符产生错误时触发，默认检测事件</li></ul><h2 id="3-int-epoll_waitint-epfd-struct-epoll_event-events-int-maxevents-int-timeout"><span id="3-int-epoll_waitint-epfd-struct-epoll_event-events-int-maxevents-int-timeout">3. int epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeout)</span></h2><p>功能：</p><ul><li>阻塞等待注册的事件发生，返回事件的数目，并将触发的事件写入events数组中。</li><li>events: 用来记录被触发的events，其大小应该和maxevents一致</li><li>maxevents: 返回的events的最大个数</li></ul><p>处于ready状态的那些文件描述符会被复制进ready list中，epoll_wait用于向用户进程返回ready list。events和maxevents两个参数描述一个由用户分配的struct epoll event数组，调用返回时，内核将ready list复制到这个数组中，并将实际复制的个数作为返回值。注意，如果ready list比maxevents长，则只能复制前maxevents个成员；反之，则能够完全复制ready list。<br>另外，struct epoll event结构中的events域在这里的解释是：在被监测的文件描述符上实际发生的事件。<br>参数timeout描述在函数调用中阻塞时间上限，单位是ms：</p><ul><li>timeout = -1表示调用将一直阻塞，直到有文件描述符进入ready状态或者捕获到信号才返回；</li><li>timeout = 0用于非阻塞检测是否有描述符处于ready状态，不管结果怎么样，调用都立即返回；</li><li>timeout &gt; 0表示调用将最多持续timeout时间，如果期间有检测对象变为ready状态或者捕获到信号则返回，否则直到超时。</li></ul><h1 id="epoll的两种触发方式"><span id="epoll的两种触发方式">epoll的两种触发方式</span></h1><p>epoll监控多个文件描述符的I/O事件。epoll支持边缘触发(edge trigger，ET)或水平触发（level trigger，LT)，通过epoll_wait等待I/O事件，如果当前没有可用的事件则阻塞调用线程。</p><blockquote><p>select和poll只支持LT工作模式，epoll的默认的工作模式是LT模式。</p></blockquote><h2 id="1水平触发的时机"><span id="1水平触发的时机">1.水平触发的时机</span></h2><ol><li>对于读操作，只要缓冲内容不为空，LT模式返回读就绪。</li><li>对于写操作，只要缓冲区还不满，LT模式会返回写就绪。</li></ol><p>当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它还会通知你在上没读写完的文件描述符上继续读写，当然如果你一直不去读写，它会一直通知你。如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率。</p><h2 id="2边缘触发的时机"><span id="2边缘触发的时机">2.边缘触发的时机</span></h2><ul><li>对于读操作</li></ul><ol><li>当缓冲区由不可读变为可读的时候，即缓冲区由空变为不空的时候。</li><li>当有新数据到达时，即缓冲区中的待读数据变多的时候。</li><li>当缓冲区有数据可读，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLIN事件时。</li></ol><ul><li>对于写操作</li></ul><ol><li>当缓冲区由不可写变为可写时。</li><li>当有旧数据被发送走，即缓冲区中的内容变少的时候。</li><li>当缓冲区有空间可写，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLOUT事件时。</li></ol><p>当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你。这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。</p><blockquote><p>在ET模式下， 缓冲区从不可读变成可读，会唤醒应用进程，缓冲区数据变少的情况，则不会再唤醒应用进程。</p></blockquote><p>举例1：</p><ol><li>读缓冲区刚开始是空的</li><li>读缓冲区写入2KB数据</li><li>水平触发和边缘触发模式此时都会发出可读信号</li><li>收到信号通知后，读取了1KB的数据，读缓冲区还剩余1KB数据</li><li>水平触发会再次进行通知，而边缘触发不会再进行通知</li></ol><p>举例2：（以脉冲的高低电平为例）</p><ul><li>水平触发：0为无数据，1为有数据。缓冲区有数据则一直为1，则一直触发。</li><li>边缘触发发：0为无数据，1为有数据，只要在0变到1的上升沿才触发。</li></ul><blockquote><p>JDK并没有实现边缘触发，Netty重新实现了epoll机制，采用边缘触发方式；另外像Nginx也采用边缘触发。</p></blockquote><p>JDK在Linux已经默认使用epoll方式，但是JDK的epoll采用的是水平触发，而Netty重新实现了epoll机制，采用边缘触发方式，netty epoll transport 暴露了更多的nio没有的配置参数，如 TCP_CORK, SO_REUSEADDR等等；另外像Nginx也采用边缘触发。</p><h1 id="epoll与select-poll的对比"><span id="epoll与select-poll的对比">epoll与select、poll的对比</span></h1><h2 id="1-用户态将文件描述符传入内核的方式"><span id="1-用户态将文件描述符传入内核的方式">1. 用户态将文件描述符传入内核的方式</span></h2><ul><li>select：创建3个文件描述符集并拷贝到内核中，分别监听读、写、异常动作。这里受到单个进程可以打开的fd数量限制，默认是1024。</li><li>poll：将传入的struct pollfd结构体数组拷贝到内核中进行监听。</li><li>epoll：执行epoll_create会在内核的高速cache区中建立一颗红黑树以及就绪链表(该链表存储已经就绪的文件描述符)。接着用户执行的epoll_ctl函数添加文件描述符会在红黑树上增加相应的结点。</li></ul><h2 id="2-内核态检测文件描述符读写状态的方式"><span id="2-内核态检测文件描述符读写状态的方式">2. 内核态检测文件描述符读写状态的方式</span></h2><ul><li>select：采用轮询方式，遍历所有fd，最后返回一个描述符读写操作是否就绪的mask掩码，根据这个掩码给fd_set赋值。</li><li>poll：同样采用轮询方式，查询每个fd的状态，如果就绪则在等待队列中加入一项并继续遍历。</li><li>epoll：采用回调机制。在执行epoll_ctl的add操作时，不仅将文件描述符放到红黑树上，而且也注册了回调函数，内核在检测到某文件描述符可读/可写时会调用回调函数，该回调函数将文件描述符放在就绪链表中。</li></ul><h2 id="3-找到就绪的文件描述符并传递给用户态的方式"><span id="3-找到就绪的文件描述符并传递给用户态的方式">3. 找到就绪的文件描述符并传递给用户态的方式</span></h2><ul><li>select：将之前传入的fd_set拷贝传出到用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。</li><li>poll：将之前传入的fd数组拷贝传出用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。</li><li>epoll：epoll_wait只用观察就绪链表中有无数据即可，最后将链表的数据返回给数组并返回就绪的数量。内核将就绪的文件描述符放在传入的数组中，所以只用遍历依次处理即可。这里返回的文件描述符是通过mmap让内核和用户空间共享同一块内存实现传递的，减少了不必要的拷贝。</li></ul><h2 id="4-重复监听的处理方式"><span id="4-重复监听的处理方式">4. 重复监听的处理方式</span></h2><ul><li>select：将新的监听文件描述符集合拷贝传入内核中，继续以上步骤。</li><li>poll：将新的struct pollfd结构体数组拷贝传入内核中，继续以上步骤。</li><li>epoll：无需重新构建红黑树，直接沿用已存在的即可。</li></ul><h1 id="epoll更高效的原因"><span id="epoll更高效的原因">epoll更高效的原因</span></h1><ol><li>select和poll的动作基本一致，只是poll采用链表来进行文件描述符的存储，而select采用fd标注位来存放，所以select会受到最大连接数的限制，而poll不会。</li><li>select、poll、epoll虽然都会返回就绪的文件描述符数量。但是select和poll并不会明确指出是哪些文件描述符就绪，而epoll会。造成的区别就是，系统调用返回后，调用select和poll的程序需要遍历监听的整个文件描述符找到是谁处于就绪，而epoll则直接处理即可。</li><li>select、poll都需要将有关文件描述符的数据结构拷贝进内核，最后再拷贝出来。而epoll创建的有关文件描述符的数据结构本身就存于内核态中，系统调用返回时利用mmap()文件映射内存加速与内核空间的消息传递：即epoll使用mmap减少复制开销。</li><li>select、poll采用轮询的方式来检查文件描述符是否处于就绪态，而epoll采用回调机制。造成的结果就是，随着fd的增加，select和poll的效率会线性降低，而epoll不会受到太大影响，除非活跃的socket很多。</li><li>epoll的边缘触发模式效率高，系统不会充斥大量不关心的就绪文件描述符</li></ol><blockquote><p>虽然epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#概念&quot;&gt;概念&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#io&quot;&gt;I/O&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#事件&quot;&gt;事件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#通知机制&quot;&gt;通知机制&lt;/a&gt;&lt;/
      
    
    </summary>
    
    
      <category term="Web" scheme="https://lxb.wiki/categories/Web/"/>
    
    
      <category term="网络" scheme="https://lxb.wiki/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Redis持久化机制</title>
    <link href="https://lxb.wiki/f885fe0f/"/>
    <id>https://lxb.wiki/f885fe0f/</id>
    <published>2021-06-01T13:18:51.000Z</published>
    <updated>2022-02-12T12:32:23.109Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#一-持久化流程">一、持久化流程</a></li><li><a href="#二-rdb机制">二、RDB机制</a></li><li><a href="#三-aof机制">三、AOF机制</a></li><li><a href="#四-rdb和aof到底该如何选择">四、RDB和AOF到底该如何选择</a></li><li><a href="#其他资料">其他资料</a></li></ul><!-- tocstop --><p>redis是一个内存数据库，数据保存在内存中，但是我们都知道内存的数据变化是很快的，也容易发生丢失。幸好Redis还为我们提供了持久化的机制，分别是RDB(Redis DataBase)和AOF(Append Only File)。</p><h3 id="一-持久化流程"><span id="一-持久化流程">一、持久化流程</span></h3><p>既然redis的数据可以保存在磁盘上，那么这个流程是什么样的呢？</p><p>要有下面五个过程：</p><p>（1）客户端向服务端发送写操作(数据在客户端的内存中)。</p><p>（2）数据库服务端接收到写请求的数据(数据在服务端的内存中)。</p><p>（3）服务端调用write这个系统调用，将数据往磁盘上写(数据在系统内存的缓冲区中)。</p><p>（4）操作系统将缓冲区中的数据转移到磁盘控制器上(数据在磁盘缓存中)。</p><p>（5）磁盘控制器将数据写到磁盘的物理介质中(数据真正落到磁盘上)。</p><p>这5个过程是在理想条件下一个正常的保存流程，但是在大多数情况下，我们的机器等等都会有各种各样的故障，这里划分了两种情况：</p><p>（1）Redis数据库发生故障，只要在上面的第三步执行完毕，那么就可以持久化保存，剩下的两步由操作系统替我们完成。</p><p>（2）操作系统发生故障，必须上面5步都完成才可以。</p><p>在这里只考虑了保存的过程可能发生的故障，其实保存的数据也有可能发生损坏，需要一定的恢复机制，不过在这里就不再延伸了。现在主要考虑的是redis如何来实现上面5个保存磁盘的步骤。它提供了两种策略机制，也就是RDB和AOF。</p><h3 id="二-rdb机制"><span id="二-rdb机制">二、RDB机制</span></h3><p>RDB其实就是把数据以快照的形式保存在磁盘上。什么是快照呢，你可以理解成把当前时刻的数据拍成一张照片保存下来。</p><p>RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是默认的持久化方式，这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。</p><p>在我们安装了redis之后，所有的配置都是在redis.conf文件中，里面保存了RDB和AOF两种持久化机制的各种配置。</p><p>既然RDB机制是通过把某个时刻的所有数据生成一个快照来保存，那么就应该有一种触发机制，是实现这个过程。对于RDB来说，提供了三种机制：save、bgsave、自动化。我们分别来看一下</p><p><strong>1、save触发方式</strong></p><p>该命令会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成为止。具体流程如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212202507.png" alt></p><p>执行完成时候如果存在老的RDB文件，就把新的替代掉旧的。我们的客户端可能都是几万或者是几十万，这种方式显然不可取。</p><p><strong>2、bgsave触发方式</strong></p><p>执行该命令时，Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。具体流程如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212202435.png" alt></p><p>具体操作是Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。基本上 Redis 内部所有的RDB操作都是采用 bgsave 命令。</p><p><strong>3、自动触发</strong></p><p>自动触发是由我们的配置文件来完成的。在redis.conf配置文件中，里面有如下配置，我们可以去设置：</p><p><strong>①save：</strong>这里是用来配置触发 Redis的 RDB 持久化条件，也就是什么时候将内存中的数据保存到硬盘。比如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。</p><p>默认如下配置：</p><p>#表示900 秒内如果至少有 1 个 key 的值变化，则保存save 900 1#表示300 秒内如果至少有 10 个 key 的值变化，则保存save 300 10#表示60 秒内如果至少有 10000 个 key 的值变化，则保存save 60 10000</p><p>不需要持久化，那么你可以注释掉所有的 save 行来停用保存功能。</p><p><strong>②stop-writes-on-bgsave-error ：</strong>默认值为yes。当启用了RDB且最后一次后台保存数据失败，Redis是否停止接收数据。这会让用户意识到数据没有正确持久化到磁盘上，否则没有人会注意到灾难（disaster）发生了。如果Redis重启了，那么又可以重新开始接收数据了</p><p><strong>③rdbcompression ；</strong>默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。</p><p><strong>④rdbchecksum ：</strong>默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。</p><p><strong>⑤dbfilename ：</strong>设置快照的文件名，默认是 dump.rdb</p><p><strong>⑥dir：</strong>设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名。</p><p>我们可以修改这些配置来实现我们想要的效果。因为第三种方式是配置的，所以我们对前两种进行一个对比：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212202559.png" alt></p><p><strong>4、RDB 的优势和劣势</strong></p><p>①、优势</p><p>（1）RDB文件紧凑，全量备份，非常适合用于进行备份和灾难恢复。</p><p>（2）生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。</p><p>（3）RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</p><p>②、劣势</p><p>RDB快照是一次全量备份，存储的是内存数据的二进制序列化形式，存储上非常紧凑。当进行快照持久化时，会开启一个子进程专门负责快照持久化，子进程会拥有父进程的内存数据，父进程修改内存子进程不会反应出来，所以在快照持久化期间修改的数据不会被保存，可能丢失数据。</p><h3 id="三-aof机制"><span id="三-aof机制">三、AOF机制</span></h3><p>全量备份总是耗时的，有时候我们提供一种更加高效的方式AOF，工作机制很简单，redis会将每一个收到的写命令都通过write函数追加到文件中。通俗的理解就是日志记录。</p><p><strong>1、持久化原理</strong></p><p>他的原理看下面这张图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212202651.png" alt></p><p>每当有一个写命令过来时，就直接保存在我们的AOF文件中。</p><p><strong>2、文件重写原理</strong></p><p>AOF的方式也同时带来了另一个问题。持久化文件会变的越来越大。为了压缩aof的持久化文件。redis提供了bgrewriteaof命令。将内存中的数据以命令的方式保存到临时文件中，同时会fork出一条新进程来将文件重写。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212202823.png" alt></p><p>重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。</p><p><strong>3、AOF也有三种触发机制</strong></p><p>（1）每修改同步always：同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好</p><p>（2）每秒同步everysec：异步操作，每秒记录 如果一秒内宕机，有数据丢失</p><p>（3）不同no：从不同步</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212202930.png" alt></p><p><strong>4、优点</strong></p><p>（1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据。（2）AOF日志文件没有任何磁盘寻址的开销，写入性能非常高，文件不容易破损。</p><p>（3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。</p><p>（4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据</p><p><strong>5、缺点</strong></p><p>（1）对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大</p><p>（2）AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的</p><p>（3）以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。</p><h3 id="四-rdb和aof到底该如何选择"><span id="四-rdb和aof到底该如何选择">四、RDB和AOF到底该如何选择</span></h3><p>选择的话，两者加一起才更好。因为两个持久化机制你明白了，剩下的就是看自己的需求了，需求不同选择的也不一定，但是通常都是结合使用。有一张图可供总结：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220212203019.png" alt></p><h3 id="其他资料"><span id="其他资料">其他资料</span></h3><p><a href="[Redis持久化原理(RDB)_小麦大大博客-CSDN博客_rdb持久化](https://blog.csdn.net/qq_35433716/article/details/82191511)">Redis持久化原理(RDB)</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#一-持久化流程&quot;&gt;一、持久化流程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#二-rdb机制&quot;&gt;二、RDB机制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#三-aof机制&quot;&gt;三、AOF机制&lt;/a&gt;&lt;/li&gt;
&lt;
      
    
    </summary>
    
    
      <category term="DB" scheme="https://lxb.wiki/categories/DB/"/>
    
    
      <category term="redis" scheme="https://lxb.wiki/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>如何保证服务稳定性</title>
    <link href="https://lxb.wiki/d0f092bd/"/>
    <id>https://lxb.wiki/d0f092bd/</id>
    <published>2021-05-25T13:57:43.000Z</published>
    <updated>2022-02-11T07:19:36.655Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-sla">1 SLA</a></li><li><a href="#2-单服务稳定性">2 单服务稳定性</a></li><li><a href="#3-集群稳定性">3 集群稳定性</a></li><li><a href="#4-稳定性专项">4 稳定性专项</a></li><li><a href="#5-稳定性建设">5 稳定性建设</a></li></ul><!-- tocstop --><h1 id="1-sla"><span id="1-sla">1 SLA</span></h1><p>业内喜欢用SLA （服务等级协议，全称：service level agreement）来衡量系统的稳定性，对互联网公司来说就是网站服务可用性的一个保证。9越多代表全年服务可用时间越长服务越可靠，停机时间越短。就以一个标准99.99%为例，停机时间52.6分钟，平均到每周也就是只能有差不多1分钟的停机时间，也就是说网络抖动这个时间可能就没了。保证一个系统四个9或者更高的五个9，需要一套全体共识严格标准的规章制度，没有规矩不成方圆。创建的规范有如下几种：</p><p>1、研发规范、自身稳定；</p><p>2、事务中不能包含远程调用；</p><p>3、超时时间和重试次数要合理；</p><p>4、表数据操作必须double check，合理利用索引，避免出现慢查询、分库分表不走分表键；</p><p>5、没有有效的资源隔离， 避免不同业务共用一个线程池或连接池；</p><p>6、合理的系统拓扑，禁止不合理服务依赖，能依赖就依赖，否则同步尽量改成异步弱依赖；</p><p>7、精简的代码逻辑；</p><p>8、核心路径流程必须进行资源隔离，确保任何突发情况主流程不能受影响。</p><h1 id="2-单服务稳定性"><span id="2-单服务稳定性">2 单服务稳定性</span></h1><p><strong>关键字：开关可控、单一职责、服务隔离、异常兜底、监控发现！</strong></p><p>对于稳定性来说，抛开整体系统架构设计，单就每个业务域服务的稳定性也是非常的重要。只有每个业务环节都稳如泰山，才能保障整个稳定性。单服务稳定可以从以下几个方面来进行：</p><p><strong>1、禁用设计</strong>：应该提供控制具体功能是否开启可用的配置，在相应的功能服务出现故障时，快速下线局部功能，以保证整体服务的可用性；</p><p><strong>2、必要的缓存</strong>：缓存是解决并发的利器，可以有效的提高系统的吞吐量。按照业务以及技术的纬度必要时可以增加多级缓存来保证其命中率；</p><p><strong>3、接口无状态性</strong>：服务接口应是无状态的，当前接口访问不应该依赖上层接口的状态逻辑；</p><p><strong>4、接口单一职责性</strong>：对于核心功能的接口，不应该过多的耦合不属于它的功能。如果一个接口做的事情太多应做拆分，保证单接口的稳定性和快速响应；</p><p><strong>5、第三方服务隔离性</strong>：任何依赖于第三方的服务（不论接口还是中间件等），都应该做到熔断和降级，不能有强耦合的依赖；</p><p><strong>6、业务场景兜底方案</strong>：核心业务场景要做到完整兜底方法，从前端到后端都应有兜底措施；</p><p><strong>7、服务监控与及时响应</strong>：每个服务应做好对应监控工作，如有异常应及时响应，不应累积。</p><h1 id="3-集群稳定性"><span id="3-集群稳定性">3 集群稳定性</span></h1><p><strong>关键字：系统架构、部署发布、限流熔断、监控体系、压测机制！</strong></p><p>对于集群维度的稳定性来说，稳定性保障会更加复杂。单服务是局部，集群是全局。一个见微知著，一个高瞻远瞩。</p><p><strong>1、合理的系统架构</strong>：合理的系统架构是稳定的基石；</p><p><strong>2、小心的代码逻辑</strong>：代码时刻都要小心，多担心一点这里会不会有性能问题，那里会不会出现并发，代码就不会有多少问题；</p><p><strong>3、优秀的集群部署</strong>：一台机器永远会有性能瓶颈，优秀的集群部署，可以将一台机器的稳定放大无限倍，是高并发与大流量的保障；</p><p><strong>4、科学的限流熔断</strong>：高并发来临时，科学的限流和熔断是系统稳定的必要条件；</p><p><strong>5、精细的监控体系</strong>：没有监控体系，你永远不会知道你的系统到底有多少隐藏的问题和坑，也很难知道瓶颈在哪里；</p><p><strong>6、强悍的压测机制</strong>：压测是高并发稳定性的试金石，能提前预知高并发来临时，系统应该出现的模样；</p><p><strong>7、胆小的开发人员</strong>：永远需要一群胆小的程序员，他们讨厌bug，害怕error，不放过每一个波动，不信任所有的依赖。</p><h1 id="4-稳定性专项"><span id="4-稳定性专项">4 稳定性专项</span></h1><p>专项指的是<strong>针对某些特定场景下的特定问题而梳理出对应的方案</strong>。下面是针对一些常见的稳定性专项的概述：</p><p><strong>1、预案</strong>：分为定时预案和紧急预案，定时预案是大促常规操作对于一系列开关的编排，紧急预案是应对突发情况的特殊处理，都依赖于事前梳理；</p><p><strong>2、预热</strong>：分为JIT代码预热和数据预热，阿里内部有专门的一个产品负责这块，通过存储线上的常态化流量或者热点流量进行回放来提前预热， 起源于某年双十一零点的毛刺问题，原因是访问了数据库的冷数据rt增高导致的一系列上层限流，现在预热已经成了大促之前的一个必要流程。</p><p><strong>3、强弱依赖</strong>:梳理强弱依赖是一个偏人肉的过程，但是非常重要，这是一个系统自查识别潜在风险点并为后续整理开关限流预案和根因分析的一个重要参考，阿里内部有一个强弱依赖检测的平台，通过对测试用例注入RPC调用的延迟或异常来观察链路的依赖变化，自动梳理出强弱依赖关系。</p><p><strong>4、限流降级熔断</strong>:应对突发流量防止请求超出自身处理能力系统被击垮的必要手段；</p><p><strong>5、监控告警&amp;链路追踪</strong>:监控分为业务监控、系统监控和中间件监控和基础监控，作为线上问题发现和排查工具，重要性不言而喻。</p><h1 id="5-稳定性建设"><span id="5-稳定性建设">5 稳定性建设</span></h1><p>稳定性建设，就和基础技术建设一样，是一个<strong>长期迭代和不断调整的过程</strong>，业内常见的稳定性建设类型，主要有如下几种：</p><p><strong>1、容量规划</strong>：个人感觉容量规划在大厂里也并没有做的很好，更多依赖的是业务方自己拍脑袋，然后全链路压测期间验证，不够就再加机器。</p><p><strong>2、混沌工程</strong>：混沌工程是近几年比较火的名词，通过不断给系统找麻烦来验证并完善系统能力，阿里在这块花了很大的精力建设红蓝军对抗攻防，进行定期和不定期的演练，最后以打分的形式来给各个部门系统做排名，除了系统层面的故障演练外还有资金演练，篡改线上sql语句制造资损来测试业务监控纠错的能力，通过制造小错来避免大错。</p><p>跳转门：<a href="https://link.zhihu.com/?target=https%3A//www.cnblogs.com/imyalost/p/12271620.html" target="_blank" rel="noopener">混沌工程-初识</a></p><p><strong>3、流量调度</strong>：通过metric秒级监控和聚类算法实时找出异常单机来降低RPC流量权重，提升集群整体吞吐能力减少异常请求。</p><p><strong>4、容灾&amp;异地多活</strong>：起源于15年某施工队将光纤挖断带来的支付宝故障，由此出来的三地五中心和单元化架构，异地多活本身的成本比较高，然后又存在数据同步的延时问题和切流带来的脏数据问题，对于业务和技术都有比较高的要求。常见的容灾有如下几种：</p><p>　 1）缓存挂掉，集群重启缓存预热如何处理？本地缓存，多级缓存是否可以替代？</p><p>　 2）分布式锁，是否有开关一键切换？比如：ZK/ETCD编写的分布式锁；</p><p>　 3）大促峰值流量，如何防止外部ddos攻击？如何识别流量类型？</p><p>　 4）资源隔离：资源隔离，服务分组，流量隔离；</p><p>　 5）高可用思想：避免单点设计！</p><p>　 6）容错：容错上游，防御下游。容错主要需要注意如下几点：</p><p>　 　 6-1：外部依赖的地方都要做熔断，避免雪崩；</p><p>　　 6-2：对于依赖我们的上游要限流，防止上游突发超过自己系统能够扛住的最大QPS；</p><p>　　 6-3：对于下游既要评估好接口超时时间，防止下游接口超时导致自己系统被拖累；</p><p>　　 6-4：下游接口要考虑各种异常情况，需要考虑中间状态，通过引入柔性事务，确保数</p><p>据最终一致</p><p><strong>5、异地多活</strong></p><p><strong>异地多活的本质，是数据中心架构的演进</strong>。</p><p><strong>1）演进</strong>：单机房——双机房——异地灾备——异地多活；</p><p><strong>2）定义</strong>：分多个地域、多个数据中心运行线上的业务，并且每个IDC均提供在线服务；</p><p><strong>3）优点</strong>：弹性扩展能力、流量就近接入、灵活调度、提升可用性与用户体验、容灾；</p><p><strong>4）步骤</strong>：</p><p>　 4-1：基础设施：机房之间专线互联，保证网络质量稳定；</p><p>　 4-2：持久存储：一主三从，主IDC同步复制，异地IDC异步复制；</p><p>　 4-3：中间件：DB、MQ、分布式存储；</p><p>　 4-4：应用部署：根据应用域划分，不同应用部署在不同地域，保持亲缘性；</p><p>　 4-5：流量接入与调度：网络协议兼容，DNS，动态调度用户就近访问；</p><p>　 4-6：监控与运维保障：专线实时监控，确保发生故障时可以触发Failover（失效备援）和</p><p>流量调度。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-sla&quot;&gt;1 SLA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-单服务稳定性&quot;&gt;2 单服务稳定性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#3-集群稳定性&quot;&gt;3 集群稳定性&lt;/a&gt;&lt;/li&gt;
&lt;li
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxb.wiki/categories/Design/"/>
    
    
      <category term="稳定性" scheme="https://lxb.wiki/tags/%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>Mac iTerm2，使用rz和sz无效，解决方式</title>
    <link href="https://lxb.wiki/32451f0a/"/>
    <id>https://lxb.wiki/32451f0a/</id>
    <published>2021-05-13T15:25:13.000Z</published>
    <updated>2021-05-13T15:28:17.442Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1安装lrzsz要先安装brew">1.安装lrzsz（要先安装brew）</a></li><li><a href="#2配置">2.配置</a></li></ul><!-- tocstop --><h1 id="1安装lrzsz要先安装brew"><span id="1安装lrzsz要先安装brew">1.安装lrzsz（要先安装brew）</span></h1><p><code>brew install lrzsz</code></p><h1 id="2配置"><span id="2配置">2.配置</span></h1><p><code>cd /usr/local/bin</code><br>   在/usr/loal/bin 目录下创建两个文件</p><p>命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi iterm2-recv-zmodem.sh</span><br><span class="line">vi iterm2-send-zmodem.sh</span><br></pre></td></tr></table></figure><p>创建好两个文件后分别添加内容：</p><ol><li><strong>iterm2-recv-zmodem.sh</strong></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># Author: Matt Mastracci (matthew@mastracci.com)</span><br><span class="line"># AppleScript from http://stackoverflow.com/questions/4309087/cancel-button-on-osascript-in-a-bash-script</span><br><span class="line"># licensed under cc-wiki with attribution required </span><br><span class="line"># Remainder of script public domain</span><br><span class="line"> </span><br><span class="line">osascript -e &apos;tell application &quot;iTerm2&quot; to version&apos; &gt; /dev/null 2&gt;&amp;1 &amp;&amp; NAME=iTerm2 || NAME=iTerm</span><br><span class="line">if [[ $NAME = &quot;iTerm&quot; ]]; then</span><br><span class="line">    FILE=`osascript -e &apos;tell application &quot;iTerm&quot; to activate&apos; -e &apos;tell application &quot;iTerm&quot; to set thefile to choose folder with prompt &quot;Choose a folder to place received files in&quot;&apos; -e &quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;`</span><br><span class="line">else</span><br><span class="line">    FILE=`osascript -e &apos;tell application &quot;iTerm2&quot; to activate&apos; -e &apos;tell application &quot;iTerm2&quot; to set thefile to choose folder with prompt &quot;Choose a folder to place received files in&quot;&apos; -e &quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;`</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line">if [[ $FILE = &quot;&quot; ]]; then</span><br><span class="line">    echo Cancelled.</span><br><span class="line">    # Send ZModem cancel</span><br><span class="line">    echo -e \\x18\\x18\\x18\\x18\\x18</span><br><span class="line">    sleep 1</span><br><span class="line">    echo</span><br><span class="line">    echo \# Cancelled transfer</span><br><span class="line">else</span><br><span class="line">    cd &quot;$FILE&quot;</span><br><span class="line">    /usr/local/bin/rz -E -e -b</span><br><span class="line">    sleep 1</span><br><span class="line">    echo</span><br><span class="line">    echo</span><br><span class="line">    echo \# Sent \-\&gt; $FILE</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol start="2"><li><strong>iterm2-send-zmodem.sh</strong></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># Author: Matt Mastracci (matthew@mastracci.com)</span><br><span class="line"># AppleScript from http://stackoverflow.com/questions/4309087/cancel-button-on-osascript-in-a-bash-script</span><br><span class="line"># licensed under cc-wiki with attribution required </span><br><span class="line"># Remainder of script public domain</span><br><span class="line"> </span><br><span class="line">osascript -e &apos;tell application &quot;iTerm2&quot; to version&apos; &gt; /dev/null 2&gt;&amp;1 &amp;&amp; NAME=iTerm2 || NAME=iTerm</span><br><span class="line">if [[ $NAME = &quot;iTerm&quot; ]]; then</span><br><span class="line">    FILE=`osascript -e &apos;tell application &quot;iTerm&quot; to activate&apos; -e &apos;tell application &quot;iTerm&quot; to set thefile to choose file with prompt &quot;Choose a file to send&quot;&apos; -e &quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;`</span><br><span class="line">else</span><br><span class="line">    FILE=`osascript -e &apos;tell application &quot;iTerm2&quot; to activate&apos; -e &apos;tell application &quot;iTerm2&quot; to set thefile to choose file with prompt &quot;Choose a file to send&quot;&apos; -e &quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;`</span><br><span class="line">fi</span><br><span class="line">if [[ $FILE = &quot;&quot; ]]; then</span><br><span class="line">    echo Cancelled.</span><br><span class="line">    # Send ZModem cancel</span><br><span class="line">    echo -e \\x18\\x18\\x18\\x18\\x18</span><br><span class="line">    sleep 1</span><br><span class="line">    echo</span><br><span class="line">    echo \# Cancelled transfer</span><br><span class="line">else</span><br><span class="line">    /usr/local/bin/sz &quot;$FILE&quot; -e -b</span><br><span class="line">    sleep 1</span><br><span class="line">    echo</span><br><span class="line">    echo \# Received $FILE</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>将文件写好后保存好，使用如下命令添加权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 iterm2-*</span><br></pre></td></tr></table></figure><p>配置好配置文件之后，开始对iTerm2进行配置</p><p>点击 iTerm2 的设置界面 Perference-&gt; Profiles -&gt; Default -&gt; Advanced -&gt; Triggers 的 Edit 按钮，加入以下配置</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210513232741.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Regular expression: rz waiting to receive.\*\*B0100</span><br><span class="line">Action: Run Silent Coprocess</span><br><span class="line">Parameters: /usr/local/bin/iterm2-send-zmodem.sh</span><br><span class="line"> </span><br><span class="line">Regular expression: \*\*B00000000000000</span><br><span class="line">Action: Run Silent Coprocess</span><br><span class="line">Parameters: /usr/local/bin/iterm2-recv-zmodem.sh</span><br></pre></td></tr></table></figure><p><strong><em>\</em>备注：**</strong></p><p>rz 上传功能  ：在bash中，也就是iTerm2终端输入rz 就会弹出文件选择框，选择文件 choose 就开始上传，会上传到当前目录<br>sz 下载功能 ：sz fileName(你要下载的文件的名字) 回车，会弹出窗体 我们选择要保存的地方即可。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1安装lrzsz要先安装brew&quot;&gt;1.安装lrzsz（要先安装brew）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2配置&quot;&gt;2.配置&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;

&lt;h1
      
    
    </summary>
    
    
      <category term="Tools" scheme="https://lxb.wiki/categories/Tools/"/>
    
    
      <category term="工具" scheme="https://lxb.wiki/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="Mac" scheme="https://lxb.wiki/tags/Mac/"/>
    
      <category term="iTerm" scheme="https://lxb.wiki/tags/iTerm/"/>
    
  </entry>
  
  <entry>
    <title>误删了Mac中Chrome书签后如何恢复</title>
    <link href="https://lxb.wiki/ef3fb32/"/>
    <id>https://lxb.wiki/ef3fb32/</id>
    <published>2021-05-01T10:44:48.000Z</published>
    <updated>2021-05-03T03:31:22.040Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><!-- tocstop --><p>书签误删该如何恢复</p><p>1 打开访达，在菜单栏上点击【前往】—【前往文件夹】，或者使用快捷键【Command+Shift+G】即可打开【前往文件夹】</p><p>输入以下路径【/Users/用户名/Library/Application Support/Google/Chrome】（注：路径中的用户名就是你电脑用户名称），如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503113055.png" alt></p><p>2 在chrome文件目录下找到 【Default】文件夹，将里面的 【Bookmarks.bak】 的文件复制到桌面，将.bak名的后缀去掉，如下图所示：</p><p>注：如果你有多个用户的话，则需要找到对应的用户，一般在文件名为“Profile1、2、3”底下。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210501185251.png" alt></p><p>3 在同样的文件夹底下，将修改好的 Bookmarks 复制进 去替换，重启chrome即可。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;



&lt;!-- tocstop --&gt;

&lt;p&gt;书签误删该如何恢复&lt;/p&gt;
&lt;p&gt;1 打开访达，在菜单栏上点击【前往】—【前往文件夹】，或者使用快捷键【Command+Shift+G】即可打开【前往文件夹】&lt;/p&gt;
&lt;p&gt;输入以下路径【/Users/用户
      
    
    </summary>
    
    
      <category term="Tools" scheme="https://lxb.wiki/categories/Tools/"/>
    
    
      <category term="Chrome" scheme="https://lxb.wiki/tags/Chrome/"/>
    
  </entry>
  
  <entry>
    <title>可靠性、可用性、稳定性</title>
    <link href="https://lxb.wiki/18166f99/"/>
    <id>https://lxb.wiki/18166f99/</id>
    <published>2021-03-29T15:01:42.000Z</published>
    <updated>2022-02-12T13:20:02.198Z</updated>
    
    <content type="html"><![CDATA[<h2 id="对比availability可用性-reliability可靠性-stability稳定性"><span id="对比availability可用性-reliability可靠性-stability稳定性">对比Availability可用性、Reliability可靠性、Stability稳定性</span></h2><!-- toc --><ul><li><a href="#区分">区分</a></li><li><a href="#总体对比">总体对比</a><ul><li><a href="#可用性">可用性</a></li><li><a href="#可靠性">可靠性</a><ul><li><a href="#mtbfmean-time-between-failure">MTBF（Mean Time Between Failure）</a></li><li><a href="#mttrmean-time-to-repair">MTTR（Mean Time To Repair）</a></li><li><a href="#mttfmean-time-to-failure">MTTF（Mean Time To Failure）</a></li></ul></li><li><a href="#稳定性">稳定性</a></li></ul></li></ul><!-- tocstop --><h1 id="区分"><span id="区分">区分</span></h1><p>从事故、稳定方面简单理解如下：</p><table><thead><tr><th></th><th>描述</th></tr></thead><tbody><tr><td>可靠性</td><td>不出事故</td></tr><tr><td>可用性</td><td>出事故后，快速止损</td></tr><tr><td>稳定性</td><td>解决故障问题基础上，服务持续稳定、性能稳定</td></tr></tbody></table><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210509160538.png" alt></p><h1 id="总体对比"><span id="总体对比">总体对比</span></h1><table>     <tr>        <td></td>        <td>可用性</td>        <td>可靠性</td>        <td>稳定性</td>    </tr>    <tr>        <td>英文</td>        <td>Availability</td>        <td>Reliability</td>        <td>Stability</td>    </tr>    <tr>        <td>关注点</td>        <td>关注的是服务总体的持续时间。系统在给定时间内总体的运行时间越长，可用性越高。</td>        <td>关注系统可以无故障地持续运行的概率，关注的是故障率。<br>故障的频率越高，可靠性越低。<br>影响可靠性的因素就是能够引起故障的所有因素，包括软件设计错误，编码错误，硬件故障等等。</td>        <td>指软件在一个运行周期内、在一定的压力条件下，在持续操作时间内出错的概率，性能劣化趋势等等。<br>如果一个系统的性能时好时坏，它一定是不稳定的，而不一定是不可靠的。<br>稳定性更关注系统在给定条件下的响应是否一致，行为是否稳定。<br>可靠是可用的前提，稳定是可靠的进一步提升。</td>    </tr>    <tr>        <td>对比</td>        <td colspan="2">在《分布式系统原理与范型》中提到的下面例子中比较准确的解释了两者的区别：<br>如果系统在每小时崩溃1ms，那么它的可用性就超过99.9999%，但是它还是高度不可靠。<br>与之类似，如果一个系统从来不崩溃，但是每年要停机两星期，那么它是高度可靠的，但是可用性只有96%。<br>作为系统的响应，首要目标是先降低故障的次数，频率要低，从而提高可靠性；<br>同时在故障出现后，要提高故障的恢复时间，速度要快，从而提高业务的可用性。</td>        <td></td>    </tr>    <tr>        <td>对比</td>        <td></td>        <td colspan="2">对于电力系统而言，<br>稳定性就是“人民用电不要忽明忽暗忽快忽慢”，可靠性就是”不要用着用着突然没有啦“。<br>故障与出错的差别</td>    </tr></table><h2 id="可用性"><span id="可用性">可用性</span></h2><p>可用性指系统在给定时间内可以正常工作的概率，通常用SLA（服务等级协议，service level agreement）指标来表示。</p><p>这是这段时间的总体的可用性指标。</p><table><thead><tr><th>通俗叫法</th><th>可用性级别</th><th>年度宕机时间</th><th>周宕机时间</th><th>每天宕机时间</th></tr></thead><tbody><tr><td>1个9</td><td>90%</td><td>36.5天</td><td>16.8小时</td><td>2.4小时</td></tr><tr><td>2个9</td><td>99%</td><td>87.6小时</td><td>1.68小时</td><td>14分钟</td></tr><tr><td>3个9</td><td>99.9%</td><td>8.76小时</td><td>10.1分钟</td><td>86秒</td></tr><tr><td>4个9</td><td>99.99%</td><td>52.6分钟</td><td>1.01分钟</td><td>8.6秒</td></tr><tr><td>5个9</td><td>99.999%</td><td>5.26分钟，315.36秒</td><td>6.05秒</td><td>0.86秒</td></tr></tbody></table><h2 id="可靠性"><span id="可靠性">可靠性</span></h2><p>可靠性相关的几个指标如下：</p><h3 id="mtbfmean-time-between-failure"><span id="mtbfmean-time-between-failure">MTBF（Mean Time Between Failure）</span></h3><p>即平均无故障时间，是指从新的产品在规定的工作环境条件下开始工作到出现第一个故障的时间的平均值。</p><p>MTBF越长表示可靠性越高，正确工作能力越强 。</p><h3 id="mttrmean-time-to-repair"><span id="mttrmean-time-to-repair">MTTR（Mean Time To Repair）</span></h3><p>即平均修复时间，是指可修复产品的平均修复时间，就是从出现故障到修复中间的这段时间。</p><p>MTTR越短表示易恢复性越好。</p><h3 id="mttfmean-time-to-failure"><span id="mttfmean-time-to-failure">MTTF（Mean Time To Failure）</span></h3><p>即平均失效时间。系统平均能够正常运行多长时间，才发生一次故障。</p><p>系统的可靠性越高，平均无故障时间越长。</p><p>这些指标跟可用性关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Availability = UpTime/(UpTime+DownTime) = MTBF / (MTBF + MTTR)</span><br></pre></td></tr></table></figure><h2 id="稳定性"><span id="稳定性">稳定性</span></h2><p>Stackoverflow 看到这样一段代码来表示稳定性和可靠性的区别，甚为有趣：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Reliable but unstable:</span></span><br><span class="line">    add(a,b):</span><br><span class="line">     <span class="keyword">if</span> randomInt mod <span class="number">5</span> == <span class="number">0</span>: </span><br><span class="line">        throw exception</span><br><span class="line">     <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">print</span> a+b        </span><br><span class="line"></span><br><span class="line"><span class="comment"># Stable but unreliable:</span></span><br><span class="line">    add(a,b):</span><br><span class="line">     <span class="keyword">if</span> randomInt mod <span class="number">5</span> == <span class="number">0</span>: </span><br><span class="line">         <span class="keyword">print</span> a+a</span><br><span class="line">     <span class="keyword">else</span></span><br><span class="line">         <span class="keyword">print</span> a+b</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;对比availability可用性-reliability可靠性-stability稳定性&quot;&gt;&lt;span id=&quot;对比availability可用性-reliability可靠性-stability稳定性&quot;&gt;对比Availability可用性、Reliabilit
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxb.wiki/categories/Design/"/>
    
    
      <category term="稳定性" scheme="https://lxb.wiki/tags/%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>Joplin+坚果云作为主力笔记工具</title>
    <link href="https://lxb.wiki/f5496f4b/"/>
    <id>https://lxb.wiki/f5496f4b/</id>
    <published>2021-03-09T13:07:57.000Z</published>
    <updated>2021-05-09T08:48:49.165Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#前言">前言</a></li><li><a href="#joplin-介绍">Joplin 介绍</a></li><li><a href="#joplin-安装">Joplin 安装</a></li><li><a href="#界面说明">界面说明</a></li><li><a href="#配置坚果云同步">配置坚果云同步</a></li></ul><!-- tocstop --><h1 id="前言"><span id="前言">前言</span></h1><p>之前的云笔记工具一直是有道云，免费版本已经足够使用了。</p><p>让我下定决心放弃有道云的导火索是，突然有一天，我发现 MAC 和 Android 端都无法登录了。微博、知乎随便一搜“有道云不能登录”，发现这个问题从 2016 年就有很多用户遇到过（是很多用户，我遇到的问题并不是偶发），一直到 2021 年还没有解决（后来还发现，有道云把微博和知乎有关“有道云不能登录”的用户发帖全删了）。有道云连最基本的可用性和可靠性都无法保证，遂决定弃用有道云，转战其他工具平台。</p><p>尝试过的笔记工具：</p><ul><li>印象笔记</li><li>OneNote</li><li>Notion</li><li>语雀</li><li>为知笔记</li></ul><p>最后决定，使用开源的 joplin。<a href="https://joplinapp.org/" target="_blank" rel="noopener">joplin 官网</a></p><h1 id="joplin-介绍"><span id="joplin-介绍">Joplin 介绍</span></h1><p>Joplin 旨在取代印象笔记，成为全平台的免费开源笔记，其笔记的的书写格式是 markdown，界面支持中文。</p><p>优点：</p><ul><li>开源</li><li>多种同步方式可选择。WebDav、OneDrive、DroupOut、Nextcloud<ul><li>支持 WebDav 的网盘：<ul><li>国外网盘：Box、Dropbox、teracloud、yandex、TransIP</li><li>国内网盘：坚果云、城通网盘</li></ul></li></ul></li><li>支持笔记加密，防止数据存储平台偷看笔记内容</li><li>全平台支持。我使用的平台有 MacOS、Android、Linux</li><li>支持从印象笔记和 markdown 文件导入</li><li>有浏览器剪藏插件</li><li>笔记格式为 markdown</li><li>支持各种插件</li></ul><h1 id="joplin-安装"><span id="joplin-安装">Joplin 安装</span></h1><p><a href="https://joplinapp.org/#installation" target="_blank" rel="noopener">Joplin 官网</a> 下载 + 安装</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210509103914.png" alt></p><h1 id="界面说明"><span id="界面说明">界面说明</span></h1><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210509103956.png" alt></p><h1 id="配置坚果云同步"><span id="配置坚果云同步">配置坚果云同步</span></h1><ol><li>注册<a href="https://www.jianguoyun.com/#/" target="_blank" rel="noopener">坚果云</a></li><li>创建文件夹，起名为 joplin</li><li>点击右上角 <strong>账户信息 -&gt; 安全选项 -&gt; 添加应用</strong>；应用名称为 joplin</li></ol><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210509104440.png" alt></p><ol start="4"><li>打开 Joplin，点击菜单<strong>首选项-&gt;同步</strong> <ol><li><strong>同步目标</strong> WebDAV</li><li><strong>工具-&gt;选项-&gt;同步</strong> <a href="https://dav.jianguoyun.com/dav/joplin" target="_blank" rel="noopener">https://dav.jianguoyun.com/dav/joplin</a></li><li><strong>WebDAV 用户名</strong> 注册坚果云的用户名</li><li><strong>WebDAV 密码</strong> 坚果云新添加的 joplin 的应用密码（不是坚果云登录密码）</li></ol></li></ol><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210509104829.png" alt></p><ol start="5"><li><p>点击<strong>检查同步配置</strong>，显示成功即可点击应用开始同步</p></li><li><p>配置外部编辑器（可选）。<strong>首选项 -&gt; 通用选项 -&gt; Path</strong>，在应用程序中选择 Typora</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210509105652.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#joplin-介绍&quot;&gt;Joplin 介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#joplin-安装&quot;&gt;Joplin 安装&lt;/a&gt;&lt;/li&gt;
&lt;li
      
    
    </summary>
    
    
      <category term="Tools" scheme="https://lxb.wiki/categories/Tools/"/>
    
    
      <category term="joplin" scheme="https://lxb.wiki/tags/joplin/"/>
    
  </entry>
  
  <entry>
    <title>redis 跳表分析并用 Go 实现</title>
    <link href="https://lxb.wiki/e98e0a2b/"/>
    <id>https://lxb.wiki/e98e0a2b/</id>
    <published>2021-03-03T15:09:59.000Z</published>
    <updated>2021-05-03T15:30:45.240Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-跳表结构">1. 跳表结构</a></li><li><a href="#2-节点的插入">2. 节点的插入</a><ul><li><a href="#21-查找比s25小的最大节点">2.1. 查找比s2.5小的最大节点</a></li><li><a href="#22-插入节点s25">2.2. 插入节点s2.5</a></li></ul></li><li><a href="#3-删除节点">3. 删除节点</a><ul><li><a href="#32-查找比s3小的最大节点">3.2. 查找比s3小的最大节点</a></li><li><a href="#23-删除节点">2.3. 删除节点</a></li></ul></li><li><a href="#总结">总结</a></li></ul><!-- tocstop --><p>redis的zset和set都使用跳表实现。跳表简单地说，就是在链表上构造多级索引，以加速查找，是用空间换时间。它比红黑树实现更简单，不需要耗费大量的精力维护树的平衡。跳表的各个节点是有顺序的，可以进行范围查询。</p><p>本文将分析跳表的构成、插入、删除等操作，并使用go实现。</p><h2 id="1-跳表结构"><span id="1-跳表结构">1.  跳表结构</span></h2><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503231105.png" alt></p><p>上图就是一个包含5个节点的跳表结构。跳表的结构包含一个又一个的节点，和header节点。header节点是查询的起始点。跳表定义如下，包含头结点、尾节点、长度以及跳表的索引层数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">// skiplist 持有一个跳表的完整数据</span><br><span class="line">type skiplist struct &#123;</span><br><span class="line">  // header和tail表示跳表的头结点和尾节点</span><br><span class="line">  header, tail *skiplistNode</span><br><span class="line">  // length 表示跳表的长度</span><br><span class="line">  length int</span><br><span class="line">  // level 表示该跳表索引的层数</span><br><span class="line">  level int</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面跳表的定义看不出什么，跳表每个节点的定义就有很多东西了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">// skiplistLevel 表示skiplist每一节点在每一层持有的数据结构</span><br><span class="line">type skiplistLevel struct &#123;</span><br><span class="line">  // 该层节点的下一个节点，redis使用forward</span><br><span class="line">  next *skiplistNode</span><br><span class="line">  // 该层节点到下一节点中间间隔的跳数</span><br><span class="line">  span int</span><br><span class="line">&#125;</span><br><span class="line">// skiplistNode 表示skiplist的每一个节点</span><br><span class="line">type skiplistNode struct &#123;</span><br><span class="line">  // robj 代表该节点的数据</span><br><span class="line">  robj interface&#123;&#125;</span><br><span class="line">  // score 表示该节点的分数，以便排序</span><br><span class="line">  score float64</span><br><span class="line">  // prev 表示该节点的上一节点，redis 中使用backward</span><br><span class="line">  prev *skiplistNode</span><br><span class="line">  // levels 表示该节点在每一层索引中到下一节点的信息</span><br><span class="line">  levels []skiplistLevel</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每一个节点中持有数据robj、该数据的分数score用来排序、上一节点的指针prev以便于反向遍历、各层索引信息levels。每一层的索引信息skiplistlevel包括该层索引中该节点指向的下一个节点的指针next、该节点到下一节点的间隔span。例如上图中，节点s2在第三层索引的下一节点是s4，而在第二层索引的下一节点是s3，而且间隔span分别是2和1。</p><p>每个节点的索引层数通过随机数生成，redis设计的思路：使用第n级索引是使用第n-1级索引概率的1/4，最多使用32级索引，如果真用到了32级索引，这个跳表所持有的数据也是巨大的，因此不用担心索引不够用。</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">func randomLevel() int &#123;</span><br><span class="line">  var level = 1</span><br><span class="line">    // SKIPLIST_P = 0.25</span><br><span class="line">  for rand.Float64() &lt; SKIPLIST_P &#123;</span><br><span class="line">    level ++</span><br><span class="line">  &#125;</span><br><span class="line">  if level &lt; SKIPLIST_MAXLEVEL &#123;</span><br><span class="line">    return level</span><br><span class="line">  &#125;</span><br><span class="line">  return SKIPLIST_MAXLEVEL</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>跳表按照score和robj从小到大进行排序，因此它的各个节点是有序的，可以进行范围查找。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">// compareObj 如果obj1&gt;obj2，返回true</span><br><span class="line">func compareObj(obj1, obj2 interface&#123;&#125;) bool &#123;</span><br><span class="line">  var t1, t2 reflect.Type</span><br><span class="line">  t1 = reflect.TypeOf(obj1)</span><br><span class="line">  t2 = reflect.TypeOf(obj2)</span><br><span class="line">  if t1.Kind() != t2.Kind() &#123;</span><br><span class="line">    compareObj(fmt.Sprint(obj1), fmt.Sprint(obj2))</span><br><span class="line">  &#125;</span><br><span class="line">  var v1, v2 reflect.Value</span><br><span class="line">  v1 = reflect.ValueOf(obj1)</span><br><span class="line">  v2 = reflect.ValueOf(obj2)</span><br><span class="line">  switch t1.Kind() &#123;</span><br><span class="line">  case reflect.Int:</span><br><span class="line">    return v1.Int() &gt; v2.Int()</span><br><span class="line">  case reflect.Float64, reflect.Float32:</span><br><span class="line">    return v1.Float() &gt; v2.Float()</span><br><span class="line">  case reflect.String:</span><br><span class="line">    return v1.String() &gt; v2.String()</span><br><span class="line">  &#125;</span><br><span class="line">  return compareObj(fmt.Sprint(obj1), fmt.Sprint(obj2))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-节点的插入"><span id="2-节点的插入">2.  节点的插入</span></h2><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503231517.png" alt></p><p>在链表中如果要插入一个节点S，需要找到在链表中比S小的最大节点F，把S挂在F节点后面。那么在跳表中也是这样的套路，只不过更复杂一些。下面分几步将上图中s2.5节点挂在s2后面，已知s2.5的score或者obj比s2的score或obj要大，但是小于s3。</p><h3 id="21-查找比s25小的最大节点"><span id="21-查找比s25小的最大节点">2.1.  查找比s2.5小的最大节点</span></h3><p>在插入新节点之前，需要找到新节点可以插入的位置，就需要找出每一层索引中新节点的前一节点，这里就是比s2.5小的最大节点。跳表有五层索引，表示为0-4。跳表的起点是header，因此查找节点时需要从header的level 4开始进行，表示为header.levels[4]。代码中使用update[i]表示第i层索引中比s2.5小的最大节点指针。注意下面的代码还有一个rank数组，rank[i]就表示第i层索引中，update[i]节点到header的span，下面注意它是怎么增加的。</p><ol><li>从header.levels[4]开始向右遍历，此时rank[4]=0；header.levels[4]下一节点是s4比s2.5大，因此该层索引中s2.5的上一节点就是header，即update[4]=header，接下来向下进入第3层索引，即header.levels[3]</li><li>第3层索引中，初始rank[3] =rank[4]=0，向右遍历搜索到header的下一节点s2。s2就是这一层s2.5需要插入的位置的前一节点，因此update[3]=s2，rank[3]=rank[3]+header.levels[3].span=2，然后向下进入s2.levels[2]</li><li>依次遍历第2、1、0层索引，路径为s2.levels[2]-&gt;s2.levels[1]-&gt;s2.levels[0]，求得update[2]=update[1]=update[0]=s2，rank[2]=rank[1]=rank[0]=rank[3]=2。到这里，通过走楼梯的方式将s2.5需要插入的位置全找出来了</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">x = sl.header</span><br><span class="line"> for i := sl.level-1; i &gt;= 0; i -- &#123;</span><br><span class="line">   if i == sl.level-1 &#123;</span><br><span class="line">     rank[i] = 0</span><br><span class="line">   &#125; else &#123;</span><br><span class="line">     rank[i] = rank[i+1]</span><br><span class="line">   &#125;</span><br><span class="line">   // 寻找比score和robj小的最近节点</span><br><span class="line">   for x.levels[i].next != nil &amp;&amp; (x.levels[i].next.score &lt; score ||</span><br><span class="line">         (x.levels[i].next.score == score &amp;&amp; compareObj(robj, x.levels[i].next.robj))) &#123;</span><br><span class="line">     rank[i] += x.levels[i].span</span><br><span class="line">     x = x.levels[i].next</span><br><span class="line">   &#125;</span><br><span class="line">   update[i] = x</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h3 id="22-插入节点s25"><span id="22-插入节点s25">2.2.  插入节点s2.5</span></h3><p>现在有了update数组表示各层索引中s2.5的上一节点位置，以及rank数组表示update各节点到header的距离，就可以进行s2.5的插入了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">var level = randomLevel()</span><br><span class="line">  // 代码1</span><br><span class="line">  if level &gt; sl.level &#123;</span><br><span class="line">    for i := sl.level; i &lt; level; i ++ &#123;</span><br><span class="line">      rank[i] = 0</span><br><span class="line">      update[i] = sl.header</span><br><span class="line">      update[i].levels[i].span = sl.length</span><br><span class="line">    &#125;</span><br><span class="line">    sl.level = level</span><br><span class="line">  &#125;</span><br><span class="line">  //-----</span><br><span class="line">  x = createSkiplistNode(level, score, robj)</span><br><span class="line">  // 代码2</span><br><span class="line">  for i := 0; i &lt; level; i ++ &#123;</span><br><span class="line">    x.levels[i].next = update[i].levels[i].next</span><br><span class="line">    update[i].levels[i].next = x</span><br><span class="line"></span><br><span class="line">    x.levels[i].span = update[i].levels[i].span - (rank[0]-rank[i])</span><br><span class="line">    update[i].levels[i].span = rank[0] - rank[1] + 1</span><br><span class="line">  &#125;</span><br><span class="line">  // -----</span><br><span class="line">  // 代码3</span><br><span class="line">  for i := level-1; i &lt; sl.level; i ++ &#123;</span><br><span class="line">    update[i].levels[i].span ++</span><br><span class="line">  &#125;</span><br><span class="line">  //-----</span><br><span class="line">  // 如果当前节点是插入的第一个节点，它的prev是nil</span><br><span class="line">  if update[0] == sl.header &#123;</span><br><span class="line">    x.prev = nil</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    x.prev = update[0]</span><br><span class="line">  &#125;</span><br><span class="line">  if x.levels[0].next != nil &#123;</span><br><span class="line">    x.levels[0].next.prev = x</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    sl.tail = x</span><br><span class="line">  &#125;</span><br><span class="line">  sl.length ++</span><br></pre></td></tr></table></figure><ol><li><p>首先通过随机算法randomLevel()获取该节点的索引层数</p></li><li><p>现在有两种情况：level比跳表原来的层数sl.level要大或者level小于等于sl.level</p></li><li><ul><li>首先处理level&gt;sl.level的情况（代码1）。高于sl.level小于level的索引i中，s2.5的前一节点就直接是header，因此设置update[i]=header，同时rank[i]=0。header.levels[i].span设置为跳表的长度。设置sl.level=level。<ul><li>现在只有level&lt;=sl.level的情况了（代码2）。当索引i&lt;level时，直接将s2.5挂在update[i].levels[i]的后面，并更新update[i].levels[i]和s2.5.levels[i]的span</li><li>而在level&lt;=sl.level的情况（代码3），当level&lt;=索引i&lt;sl.level时，直接把update节点的span加一。因为此时新节点的索引层数level比跳表的层数少，那么新节点的插入对于比level高的索引节点来说就是将其与后面节点的距离增加了一个单位。</li></ul></li></ul></li><li><p>处理s2.5的prev指针，由上面的图也可以知道prev指针和第0层的索引是反向的，但是并不会指向header。这里我认为是为了方便反向遍历，如果s1.prev指向header，在反向遍历时需要加一层header的判断。</p></li><li><p>处理跳表的tail指针，如果插入的节点在最后，则重新设置tail</p></li><li><p>更新跳表长度</p></li></ol><h2 id="3-删除节点"><span id="3-删除节点">3.  删除节点</span></h2><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503231624.png" alt></p><p>上图中，如果想删除s3节点，需要两步：找到s3节点在各层索引处的上一节点；删除s3节点。</p><h3 id="32-查找比s3小的最大节点"><span id="32-查找比s3小的最大节点">3.2.  查找比s3小的最大节点</span></h3><p>查找的算法依旧是从header的最高层索引开始下楼梯，并使用update数组保存每一层索引中s3的前一个节点。</p><p>在上图中：</p><ol><li>从header.levels[4]开始向右遍历，找不到其他的节点小于s3，因此向下遍历header.levels[3]，第4层的最大节点是header，即update[4]=header</li><li>依次类推，update[3]=s2，update[2]=s2，update[1]=update[0]=s2，遍历路径见图中的蓝色箭头。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">// 查找最近节点</span><br><span class="line">  x = sl.header</span><br><span class="line">  for i := sl.level-1; i &gt;= 0; i -- &#123;</span><br><span class="line">    for x.levels[i].next != nil &amp;&amp; (x.levels[i].next.score &lt; score || </span><br><span class="line">      (x.levels[i].next.score == score &amp;&amp; compareObj(robj, x.levels[i].next.robj))) &#123;</span><br><span class="line">      x = x.levels[i].next</span><br><span class="line">    &#125;</span><br><span class="line">    update[i] = x</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="23-删除节点"><span id="23-删除节点">2.3.  删除节点</span></h3><p>删除节点就比较简单了，但是在这之前需要验证一下x指向的下一节点是不是需要删除的数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">// x之后的节点可能是需要删除的节点，也可能不是</span><br><span class="line">x = x.levels[0].next</span><br><span class="line">if x != nil &amp;&amp; x.score == score &amp;&amp; equalObj(x.robj, robj) &#123;</span><br><span class="line">  sl.deleteNode(update, x)</span><br><span class="line">  return true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在deleteNode中，进行如下删除步骤：</p><ol><li><p>对每一层的update[i]进行：</p></li><li><ul><li>如果update[i].levels[i]的下一节点是x，则进行x的删除，包括节点指针和span的改变<ul><li>如果update[i].levels[i]的下一节点不是x，例如：删除s3节点，它的update[4].levels[4]下一节点是s4，此时直接将update[4].levels[4]的span减一</li></ul></li></ul></li><li><p>将x的next节点（如果有的话）挂在x的prev节点后面</p></li><li><p>更新跳表的level值。以删除s4节点为例，删除完该节点之后跳表实际层数应该调整为3。从第4层开始向下遍历，如果header.levels[i].next是nil，说明该层索引已经没必要存在了，就将跳表的level减一</p></li><li><p>别忘了把跳表的length减一</p></li></ol><h2 id="总结"><span id="总结">总结</span></h2><p>跳表听起来挺难，如果仔细研究它的代码的话还是挺简单的。跳表主要难的地方就在于节点的插入和删除，只要理解了跳表的多级索引是怎么使用的，其他的操作：范围查询、查询排名等都比较简单了。这块的代码可以看redis的源码，在它的t_zset.c和redis.h中有zsl开头的代码就是跳表相关内容。不过我觉得更难的是写文档，写文档的时候需要阅读完代码之后理清思路，这块我发现通过画图还是可以加深理解的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-跳表结构&quot;&gt;1. 跳表结构&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-节点的插入&quot;&gt;2. 节点的插入&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#21-查找比s25小的最大节点&quot;&gt;2.1. 查找比s2.
      
    
    </summary>
    
    
      <category term="Golang" scheme="https://lxb.wiki/categories/Golang/"/>
    
    
      <category term="redis" scheme="https://lxb.wiki/tags/redis/"/>
    
      <category term="跳表" scheme="https://lxb.wiki/tags/%E8%B7%B3%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>APNG与 GIF</title>
    <link href="https://lxb.wiki/941edb97/"/>
    <id>https://lxb.wiki/941edb97/</id>
    <published>2021-02-24T15:00:47.000Z</published>
    <updated>2021-05-03T04:20:05.787Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#关于-apng">关于 APNG</a></li><li><a href="#apng-简史">APNG 简史</a></li><li><a href="#为什么-gif-能存活29年之久">为什么 GIF 能存活29年之久？</a></li><li><a href="#为什么要取代它">为什么要取代它？</a></li><li><a href="#apng-的组成">APNG 的组成</a></li><li><a href="#apng-帧间优化">APNG 帧间优化</a></li><li><a href="#为什么没有普及">为什么没有普及？</a></li><li><a href="#特性检测">特性检测</a></li><li><a href="#apng-to-canvas">APNG to Canvas</a></li><li><a href="#制作工具">制作工具</a></li><li><a href="#参考资料">参考资料</a></li></ul><!-- tocstop --><h3 id="关于-apng"><span id="关于-apng">关于 APNG</span></h3><p>APNG（Animated Portable Network Graphics）顾名思义是基于 PNG 格式扩展的一种动画格式，增加了对动画图像的支持，同时加入了 24 位图像和 8 位 Alpha 透明度的支持，这意味着动画将拥有更好的质量，其诞生的目的是为了替代老旧的 GIF 格式，但它目前并没有获得 PNG 组织官方的认可。</p><h3 id="apng-简史"><span id="apng-简史">APNG 简史</span></h3><p><strong>MNG</strong></p><p>在 APNG 之前它还有一个老冤家叫 MNG（Multiple-image Network Graphics）即多图像网络图形，1996 年 6 月提出 PNF（Portable Network Frame）草案，同年8月更名为 MNG ，2001 年 1 月 31 日发布 MNG 规范 1.0 版本，MNG 是出自 PNG 开发组之手，但由于结构复杂的 MNG 程序库，使用过程会占用大量的资源，早期只有较少的浏览器支持，Chrome、IE、Opera、Safari 则从未支持过。</p><p><strong>APNG</strong></p><p>2004 年，由 Mozilla 公司两位 Mozilla 程序员 Stuart Parmenter 和 Vladimir Vukićević 共同设计出 APNG，他们希望 Mozilla 社区能使用它，但提案未能通过。</p><p><strong>libpng程序库</strong></p><p>2006 年，Google Summer of Code 活动中，加拿大圣力嘉学院的学生为 libpng 程序库加入了对 APNG 支持，此后开发者再次推荐给 Mozilla 社区，不过仍然遭到拒绝。</p><p><strong>首次支持</strong></p><p>2007 年 3 月 23 日，Mozilla 后知后觉，在 Mozilla Firefox 3.0 中 首次支持 APNG 格式。</p><p><strong>标准化申请</strong></p><p>2007 年 4 月 20 日，Mozilla 希望 APNG 能成为官方标准，因此 PNG 组织发起投票，最终以8：10的票数否决了 APNG 进了官方标准，因为 PNG 组织决心继续推广 MNG，但这不并影响 Mozilla 继续支持 APNG。</p><h3 id="为什么-gif-能存活29年之久"><span id="为什么-gif-能存活29年之久">为什么 GIF 能存活29年之久？</span></h3><p>开头讲 APNG 时提到，APNG 的出现就是为了替代 GIF，诞生于 1987 年的 GIF 为什么能存活 29 年之久？</p><p>主要有四个原因：</p><ul><li>几乎所有的主流浏览器都支持 GIF</li><li>早期选择不多，GIF 几乎是唯一选择（GIF - 1987、JPEG - 1992、PNG - 1996、APNG - 2004、WebP - 2010）</li><li>实现起来简单，制作的工具多</li><li>采用 LZW 数据压缩算法，使得 GIF 体积小，在早期慢速的互联网易于传播</li></ul><h3 id="为什么要取代它"><span id="为什么要取代它">为什么要取代它？</span></h3><p><strong>1、图片质量</strong></p><div style="width: 100%;"><img style="width: 20%;background: #000;" src="//misc.aotu.io/ONE-SUNDAY/gif_spinfox.gif"><img style="width: 20%;background: #fff;" src="//misc.aotu.io/ONE-SUNDAY/gif_spinfox.gif"><img style="width: 20%;background: #dd0041;" src="//misc.aotu.io/ONE-SUNDAY/gif_spinfox.gif"><img style="width: 20%;background: #6752b7;" src="//misc.aotu.io/ONE-SUNDAY/gif_spinfox.gif"><img style="width: 20%;background: url(//misc.aotu.io/ONE-SUNDAY/apng_checker.png);background-size: 8px 8px;" src="//misc.aotu.io/ONE-SUNDAY/gif_spinfox.gif"><p style="color: #bbb;text-align: center;">GIF</p></div><div style="width: 100%;"><img style="width: 20%;background: #000;" src="//misc.aotu.io/ONE-SUNDAY/apng_spinfox.png"><img style="width: 20%;background: #fff;" src="//misc.aotu.io/ONE-SUNDAY/apng_spinfox.png"><img style="width: 20%;background: #dd0041;" src="//misc.aotu.io/ONE-SUNDAY/apng_spinfox.png"><img style="width: 20%;background: #6752b7;" src="//misc.aotu.io/ONE-SUNDAY/apng_spinfox.png"><img style="width: 20%;background: url(//misc.aotu.io/ONE-SUNDAY/apng_checker.png);background-size: 8px 8px;" src="//misc.aotu.io/ONE-SUNDAY/apng_spinfox.png"><p style="color: #bbb;text-align: center;">APNG</p></div><p>如果你使用的是非 Firefox、Safari 浏览器，那 APNG 格式的图片会向下兼容显示为静态图，你可以更换 Firefox、Safari 浏览器或者在 Chrome 浏览器安装 <a href="https://chrome.google.com/webstore/detail/apng/ehkepjiconegkhpodgoaeamnpckdbblp" target="_blank" rel="noopener">APNG Extension for Google Chrome </a>扩展来兼容，通过两者对比能总结出以下区别：</p><p><strong>GIF：</strong></p><ul><li>最多支持 8 位 256 色，色阶过渡糟糕，图片具有颗粒感</li><li>不支持 Alpha 透明通道，边缘有杂边</li></ul><p><strong>APNG：</strong></p><ul><li>支持 24 位真彩色图片</li><li>支持 8 位 Alpha 透明通道</li><li>向下兼容 PNG</li></ul><p><strong>2、图片体积</strong></p><p>如果你使用的浏览器不支持WebP，下面对比的 WebP 格式的图片将无法显示。</p><table><tbody><tr><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/SteamEngine.gif"></td><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/SteamEngine.png"></td></tr><tr><td style="text-align: center;">GIF = 43 920 bytes</td><td style="text-align: center;">APNG = 34 210 bytes</td></tr><tr><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/SteamEngine.webp" alt="SteamEngine.webp"></td><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/SteamEngine_lossy.webp" alt="SteamEngine_lossy.webp"></td></tr><tr><td style="text-align: center;">WebP = 41 064 bytes</td><td style="text-align: center;">Lossy WebP = 73 774 bytes</td></tr><tr><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/world-cup_2014_42.gif"></td><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/world_cup_2014_42.png"></td></tr><tr><td style="text-align: center;">GIF = 43 132 bytes</td><td style="text-align: center;">APNG = 30 823 bytes</td></tr><tr><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/world_cup_2014_42.webp" alt="world_cup_2014_42.webp"></td><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/world_cup_2014_42_lossy.webp" alt="world_cup_2014_42_lossy.webp"></td></tr><tr><td style="text-align: center;">WebP = 55 968 bytes</td><td style="text-align: center;">Lossy WebP = 114 518 bytes</td></tr><tr><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/BladeRunner.gif"></td><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/BladeRunner.png"></td></tr><tr><td style="text-align: center;">GIF = 200 700 bytes</td><td style="text-align: center;">APNG = 168 411 bytes</td></tr><tr><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/BladeRunner.webp" alt="BladeRunner.webp"></td><td style="text-align: center;"><img src="//misc.aotu.io/ONE-SUNDAY/BladeRunner_lossy.webp" alt="BladeRunner_lossy.webp"></td></tr><tr><td style="text-align: center;">WebP = 424 752 bytes</td><td style="text-align: center;">Lossy WebP = 394 118 bytes</td></tr></tbody></table><p>从几组 GIF、APNG、WebP 的对比中可以发现，无论在纯色的图片或是多彩的图片，大部分情况下 APNG 依旧能比 GIF、WebP 以及有损的 WebP 的体积小。</p><h3 id="apng-的组成"><span id="apng-的组成">APNG 的组成</span></h3><p>APNG 是基于 PNG 格式扩展的，首先需要了解一个简单的 PNG 文件组成结构：</p><table><tbody><tr><td>PNG Signature</td><td>IHDR</td><td>IDAT</td><td>IEND</td></tr></tbody></table><p>PNG 由 4 部分组成，首先以 PNG Signature（PNG签名块）开头，紧接着一个 IHDR（图像头部块），然后是一个或多个的 IDAT（图像数据块），最终以 IEND（图像结束块）结尾。</p><p>APNG 规范引入了三个新大块，分别是：acTL（动画控制块）、fcTL（帧控制块）、fdAT（帧数据块），下图是三个独立的 PNG 文件组成 APNG 的示意图。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503115051.png" alt></p><ul><li>acTL 块必须在第一个 IDAT 块之前，用于告诉解析器这是一个动画 PNG，包含动画帧总数和循环次数的信息</li><li>fcTL 块是每一帧都必须的，出现在 IDAT 或 fdAT 之前，包含顺序号、宽高、帧位置、延时等信息</li><li>fdAT 块与 IDAT 块有着相同的结构，除了 fcTL 中的顺序号</li></ul><p>从图中可以发现第一帧与后面两帧不同，那是因为第一帧 APNG 文件存储的为一个正常的 PNG 数据块，对于不支持 APNG 的浏览器或软件，只会显示 APNG 文件的第一帧，忽略后面附加的动画块，这也是为什么 APNG 能向下兼容 PNG 的原因。</p><h3 id="apng-帧间优化"><span id="apng-帧间优化">APNG 帧间优化</span></h3><p>假设使用一个 4 帧图片合成 APNG</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503115139.png" alt></p><p>APNG 会通过算法计算帧之间的差异，只存储帧之前的差异，而不是存储全帧。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503115211.png" alt></p><p>通过 TweakPNG 软件观察 IDAT 图像数据块和 fdAT 帧数据块的大小，可以明显的看出来存储全帧与差异帧的区别，使得 APNG 文件大小有显著的减少。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503115247.png" alt></p><h3 id="为什么没有普及"><span id="为什么没有普及">为什么没有普及？</span></h3><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503115312.png" alt></p><p>主要的原因是缺乏浏览器的支持，从 Can I use 查询可知 Firefox 从 3 到 49 版本自始自终支持着，Opera 早期只有三个版本支持过（10.1、11.5、12.1），后续版本则取消了对 APNG 的支持，而 Chrome、IE、Edge 则从未支持过 APNG，Chrome 和 Opera 都在推广自家的 WebP，而微软则一直是个不合群的家伙。</p><p>但是，重要的一点是 2014 年 9 月 17 号 Apple 向用户推送了 iOS 8，这意味着 Safari 8 新增了对 APNG 的支持，这能有效的推动 APNG 的发展，至少在移动端。</p><h3 id="特性检测"><span id="特性检测">特性检测</span></h3><p>既然存在兼容问题，那就需要通过判断应用场景。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="meta">    "use strict"</span>;</span><br><span class="line">    <span class="keyword">var</span> apngTest = <span class="keyword">new</span> Image(),</span><br><span class="line">    ctx = <span class="built_in">document</span>.createElement(<span class="string">"canvas"</span>).getContext(<span class="string">"2d"</span>);</span><br><span class="line">    apngTest.onload = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">        ctx.drawImage(apngTest, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">        self.apng_supported = ctx.getImageData(<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>).data[<span class="number">3</span>] === <span class="number">0</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">    apngTest.src = <span class="string">"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAACGFjVEwAAAABAAAAAcMq2TYAAAANSURBVAiZY2BgYPgPAAEEAQB9ssjfAAAAGmZjVEwAAAAAAAAAAQAAAAEAAAAAAAAAAAD6A+gBAbNU+2sAAAARZmRBVAAAAAEImWNgYGBgAAAABQAB6MzFdgAAAABJRU5ErkJggg=="</span>;</span><br><span class="line">&#125;());</span><br></pre></td></tr></table></figure><p>方法与 WebP 检测相似，同样是加载一张 1x1 像素大小的 Base64 编码图片，不同在于 WebP 加载完成后是判断图片宽高是否大于 1，而 APNG 则是将其绘制到画布中，通过 getImageData() 方法去获取该图片的像素数据，主要是获取 data[3] 的 Alpha 透明通道（值的范围：0 - 255），当返回 0（0代表透明的）时则表示支持 APNG，返回 255（255 代表完全可见的）则表示不支持 APNG。</p><h3 id="apng-to-canvas"><span id="apng-to-canvas">APNG to Canvas</span></h3><p>当然，目前也有用于兼容的库： <a href="https://github.com/davidmz/apng-canvas" target="_blank" rel="noopener">apng-canvas</a></p><p>使用该库需要以下条件支持：</p><ul><li>Canvas</li><li>Typed Arrays</li><li>Blob URLs</li><li>requestAnimationFrame</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;img src=&quot;example.png&quot; class=&quot;apng-image&quot;&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">APNG.ifNeeded().then(function() &#123;</span><br><span class="line">    var images = document.querySelectorAll(&quot;.apng-image&quot;);</span><br><span class="line">    for (var i = 0; i &lt; images.length; i++) &#123;</span><br><span class="line">        APNG.animateImage(images[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="制作工具"><span id="制作工具">制作工具</span></h3><p>在了解 APNG 后，是不是心痒痒想制作 APNG 呢？在制作工具方面，APNG 已经不像早期那样工具匮乏了， <a href="http://littlesvr.ca/apng/" target="_blank" rel="noopener">APNG Software </a>网站上有大量的制作工具，有客户端版本（大部分只支持 Widnows）也有命令行版本，可以非常轻松的制作 APNG，比如下面这款软件。</p><p><strong>Windows客户端 - APNG Assembler</strong></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503115617.png" alt></p><p><strong>Mac客户端 - APNGb</strong></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503121205.png" alt></p><p><strong>功能说明：</strong></p><ul><li>Playback Settings 可设置循环的次数，0 表示无限循环，可跳过第一帧</li><li>Delays - All Frames 可设置所有帧播放时所停留的时间</li><li>Compression Settings 可设置压缩参数，有三种压缩方式（zlib、7zip、Zopfli）以及颜色类型和调色板优化</li><li>Delays - Selected Frames 可设置选中帧播放时所停留的时间</li></ul><p>这里演示图分别是 Windows 版本和 Mac 版本，功能基本一致，将序列帧图片拖拽到指定位置，设置一些基本的参数即可生成 APNG 图，Mac 版本比 Windows 版本多出一个将 APNG 图片 Disassembly（分解）功能，可分解为多个 PNG 图片。</p><p><a href="https://sourceforge.net/projects/apngasm/" target="_blank" rel="noopener">下载地址戳这里</a></p><h3 id="参考资料"><span id="参考资料">参考资料</span></h3><p><a href="http://people.mozilla.org/~dolske/apng/demo.html" target="_blank" rel="noopener">Animated PNG demos </a><a href="http://littlesvr.ca/apng/gif_apng_webp.html" target="_blank" rel="noopener">GIF vs APNG vs WebP </a><a href="http://littlesvr.ca/apng/inter-frame.html" target="_blank" rel="noopener">Inter-frame Optimization in APNG </a><a href="https://github.com/davidmz/apng-canvas" target="_blank" rel="noopener">davidmz/apng-canvas - Github </a><a href="https://en.wikipedia.org/wiki/GIF" target="_blank" rel="noopener">GIF - Wikipedia </a><a href="https://en.wikipedia.org/wiki/APNG" target="_blank" rel="noopener">APNG - Wikipedia </a><a href="https://wiki.mozilla.org/APNG_Specification" target="_blank" rel="noopener">APNG Specification </a><a href="http://caniuse.com/#search=APNG" target="_blank" rel="noopener">Can I use - APNG </a><a href="https://zh.wikipedia.org/wiki/PNG" target="_blank" rel="noopener">Portable Network Graphics - Wikipedia </a><a href="https://en.wikipedia.org/wiki/Multiple-image_Network_Graphics" target="_blank" rel="noopener">Multiple-image Network Graphics - Wikipedia </a><a href="http://littlesvr.ca/apng/" target="_blank" rel="noopener">APNG Software</a></p><p><a href="https://wiki.mozilla.org/APNG_Specification" target="_blank" rel="noopener">https://wiki.mozilla.org/APNG_Specification</a></p><p><a href="https://philip.html5.org/tests/apng/tests.html" target="_blank" rel="noopener">https://philip.html5.org/tests/apng/tests.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#关于-apng&quot;&gt;关于 APNG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#apng-简史&quot;&gt;APNG 简史&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#为什么-gif-能存活29年之久&quot;&gt;为什么 GIF 能
      
    
    </summary>
    
    
      <category term="Pic" scheme="https://lxb.wiki/categories/Pic/"/>
    
    
      <category term="apng" scheme="https://lxb.wiki/tags/apng/"/>
    
      <category term="gif" scheme="https://lxb.wiki/tags/gif/"/>
    
  </entry>
  
  <entry>
    <title>Linux 下 su 和 su - 的区别</title>
    <link href="https://lxb.wiki/686a477f/"/>
    <id>https://lxb.wiki/686a477f/</id>
    <published>2021-02-13T13:24:47.000Z</published>
    <updated>2021-05-03T03:25:41.115Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><!-- tocstop --><p>大部分Linux发行版的默认账户是普通用户，而更改系统文件或者执行某些命令，需要root身份才能进行，这就需要从当前用户切换到root用户。Linux中切换用户的命令是su或su -。前天我在使用useradd这个命令时，才体会到这两者的本质区别。如图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503112328.png" alt></p><p>我首先是用su命令切换到root身份的，但是运行useradd时，出现错误：bash: useradd: command not found。google了一下，原因是在这个用su命令切换过来的root用户上。</p><p><strong>su命令和su -命令最大的本质区别就是：前者只是切换了root身份，但Shell环境仍然是普通用户的Shell；而后者连用户和Shell环境一起切换成root身份了。只有切换了Shell环境才不会出现PATH环境变量错误。su切换成root用户以后，pwd一下，发现工作目录仍然是普通用户的工作目录；而用su -命令切换以后，工作目录变成root的工作目录了。用echo $PATH命令看一下su和su -以后的环境变量有何不同。以此类推，要从当前用户切换到其它用户也一样，应该使用su -命令。</strong> 如图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210503112427.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;



&lt;!-- tocstop --&gt;

&lt;p&gt;大部分Linux发行版的默认账户是普通用户，而更改系统文件或者执行某些命令，需要root身份才能进行，这就需要从当前用户切换到root用户。Linux中切换用户的命令是su或su -。前天我在使用usera
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://lxb.wiki/categories/Linux/"/>
    
    
      <category term="root" scheme="https://lxb.wiki/tags/root/"/>
    
  </entry>
  
  <entry>
    <title>raft 算法</title>
    <link href="https://lxb.wiki/3d118e3a/"/>
    <id>https://lxb.wiki/3d118e3a/</id>
    <published>2021-02-06T12:36:12.000Z</published>
    <updated>2021-02-26T13:05:52.078Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#拜占庭将军问题">拜占庭将军问题</a></li><li><a href="#针对简化版拜占庭将军问题raft-解决方案类比">针对简化版拜占庭将军问题，Raft 解决方案类比</a><ul><li><a href="#1-raft-节点状态">1. Raft 节点状态</a></li><li><a href="#2-选主-leader-election">2. 选主 Leader Election</a><ul><li><a href="#21-正常情况下选主">2.1 正常情况下选主</a></li><li><a href="#22-leader-出故障情况下的选主">2.2 Leader 出故障情况下的选主</a></li><li><a href="#23-多个-candidate-情况下的选主">2.3 多个 Candidate 情况下的选主</a></li></ul></li><li><a href="#3-复制日志-log-replication">3. 复制日志 Log Replication</a><ul><li><a href="#31-正常情况下复制日志">3.1 正常情况下复制日志</a></li><li><a href="#32-network-partition-情况下进行复制日志">3.2 Network Partition 情况下进行复制日志</a></li></ul></li><li><a href="#小总结">小总结</a></li></ul></li></ul><!-- tocstop --><h1 id="拜占庭将军问题"><span id="拜占庭将军问题">拜占庭将军问题</span></h1><p>拜占庭将军问题是 Leslie Lamport 在 <a href="https://web.archive.org/web/20170205142845/http://lamport.azurewebsites.net/pubs/byz.pdf" target="_blank" rel="noopener">The Byzantine Generals Problem</a> 论文中提出的分布式领域的容错问题，它是分布式领域中最复杂、最严格的容错模型。</p><p>在该模型下，系统不会对集群中的节点做任何的限制，它们可以向其他节点发送随机数据、错误数据，也可以选择不响应其他节点的请求，这些无法预测的行为使得容错这一问题变得更加复杂。</p><p>拜占庭将军问题描述了一个如下的场景，有一组将军分别指挥一部分军队，每一个将军都不知道其它将军是否是可靠的，也不知道其他将军传递的信息是否可靠，但是它们需要通过投票选择是否要进攻或者撤退：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204025.png" alt></p><p>在这一节中，黄色代表状态未知，绿色代表进攻，蓝色代表撤退，最后红色代表当前将军的信息不可靠。</p><p>在这时，无论将军是否可靠，只要所有的将军达成了统一的方案，选择进攻或者撤退其实就是没有任何问题的：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204121.png" alt></p><p>上述的情况不会对当前的战局有太多的影响，也不会造成损失，但是如果其中的一个将军告诉其中一部分将军选择进攻、另一部分选择撤退，就会出现非常严重的问题了。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204149.png" alt></p><p>由于将军的队伍中出了一个叛徒或者信息在传递的过程中被拦截，会导致一部分将军会选择进攻，剩下的一部分会选择撤退，它们都认为自己的选择是大多数人的选择，这时就出现了严重的不一致问题。</p><p>拜占庭将军问题是对分布式系统容错的最高要求，然而这不是日常工作中使用的大多数分布式系统中会面对的问题，我们遇到更多的还是节点故障宕机或者不响应等情况，这就大大简化了系统对容错的要求；不过类似 Bitcoin、Ethereum 等分布式系统确实需要考虑拜占庭容错的问题。</p><blockquote><p>​    拜占庭将军问题是分布式领域最复杂、最严格的容错模型。但在日常工作中使用的分布式系统面对的问题不会那么复杂，更多的是计算机故障挂掉了，或者网络通信问题而没法传递信息，这种情况不考虑计算机之间互相发送恶意信息，极大简化了系统对容错的要求，最主要的是达到一致性。</p></blockquote><p>所以将拜占庭将军问题根据常见的工作上的问题进行简化：<strong>假设将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成一致性决定？</strong></p><p>对于这个简化后的问题，有许多解决方案，第一个被证明的共识算法是 Paxos，由拜占庭将军问题的作者 Leslie Lamport 在1990年提出，最初以论文难懂而出名，后来这哥们在2001重新发了一篇简单版的论文 <a href="https://link.jianshu.com?t=%5Bhttps%3A%2F%2Flamport.azurewebsites.net%2Fpubs%2Fpaxos-simple.pdf%5D(https%3A%2F%2Flamport.azurewebsites.net%2Fpubs%2Fpaxos-simple.pdf)" target="_blank" rel="noopener">Paxos Made Simple</a>，然而还是挺难懂的。</p><p>因为 Paxos 难懂，难实现，所以斯坦福大学的教授在2014年发表了新的分布式协议 Raft。与 Paxos 相比，Raft 有着基本相同运行效率，但是更容易理解，也更容易被用在系统开发上。</p><h1 id="针对简化版拜占庭将军问题raft-解决方案类比"><span id="针对简化版拜占庭将军问题raft-解决方案类比">针对简化版拜占庭将军问题，Raft 解决方案类比</span></h1><p>我们还是用拜占庭将军的例子来帮助理解 Raft。</p><blockquote><p>​    假设将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成一致性决定？</p></blockquote><p>Raft 的解决方案大概可以理解成 先在所有将军中选出一个大将军，所有的决定由大将军来做。<strong>选举环节</strong>：比如说现在一共有3个将军 A, B, C，每个将军都有一个<strong>随机时间</strong>的倒计时器，倒计时一结束，这个将军就会把自己当成大将军候选人，然后派信使去问其他几个将军，能不能选我为总将军？假设现在将军A倒计时结束了，他派信使传递选举投票的信息给将军B和C，如果将军B和C还没把自己当成候选人（倒计时还没有结束），并且没有把选举票投给其他，他们把票投给将军A，信使在回到将军A时，将军A知道自己收到了足够的票数，成为了大将军。在这之后，是否要进攻就由大将军决定，然后派信使去通知另外两个将军，如果在一段时间后还没有收到回复（可能信使被暗杀），那就再重派一个信使，直到收到回复。</p><p>故事先讲到这里，希望不做技术方面的朋友可以大概能理解 Raft 的原理，下面从比较技术的角度讲讲 Raft 的原理。 </p><h2 id="1-raft-节点状态"><span id="1-raft-节点状态">1. Raft 节点状态</span></h2><p>从拜占庭将军的故事映射到分布式系统上，每个将军相当于一个分布式网络节点，每个节点有<strong>三种状态：Follower，Candidate，Leader</strong>，状态之间是互相转换的，可以参考下图，具体的后面说。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204532.png" alt></p><p>每个节点上都有一个倒计时器 (Election Timeout)，时间随机在 150ms 到 300ms 之间。有几种情况会重设 Timeout：</p><ol><li>收到选举的请求</li><li>收到 Leader 的 Heartbeat (后面会讲到)</li></ol><p>在 Raft 运行过程中，最主要进行两个活动：</p><ol><li>选主 Leader Election</li><li>复制日志 Log Replication</li></ol><h2 id="2-选主-leader-election"><span id="2-选主-leader-election">2. 选主 Leader Election</span></h2><h3 id="21-正常情况下选主"><span id="21-正常情况下选主">2.1 正常情况下选主</span></h3><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204600.png" alt></p><p>假设现在有如图5个节点，5个节点一开始的状态都是 Follower。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204614.png" alt></p><p>在一个节点倒计时结束 (Timeout) 后，这个节点的状态变成 Candidate 开始选举，它给其他几个节点发送选举请求 (RequestVote)</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204652.png" alt></p><p>其他四个节点都返回成功，这个节点的状态由 Candidate 变成了 Leader，并在每个一小段时间后，就给所有的 Follower 发送一个 Heartbeat 以保持所有节点的状态，Follower 收到 Leader 的 Heartbeat 后重设 Timeout。</p><p>这是最简单的选主情况，<strong>只要有超过一半的节点投支持票了，Candidate 才会被选举为 Leader</strong>，5个节点的情况下，3个节点 (包括 Candidate 本身) 投了支持就行。</p><h3 id="22-leader-出故障情况下的选主"><span id="22-leader-出故障情况下的选主">2.2 Leader 出故障情况下的选主</span></h3><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204743.png" alt></p><p>一开始已经有一个 Leader，所有节点正常运行。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204807.png" alt></p><p>Leader 出故障挂掉了，其他四个 Follower 将进行重新选主。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204831.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204909.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226204929.png" alt></p><p>4个节点的选主过程和5个节点的类似，在选出一个新的 Leader 后，原来的 Leader 恢复了又重新加入了，这个时候怎么处理？在 Raft 里，第几轮选举是有记录的，重新加入的 Leader 是第一轮选举 (Term 1) 选出来的，而现在的 Leader 则是 Term 2，所有原来的 Leader 会自觉降级为 Follower</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205008.png" alt></p><h3 id="23-多个-candidate-情况下的选主"><span id="23-多个-candidate-情况下的选主">2.3 多个 Candidate 情况下的选主</span></h3><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205055.png" alt></p><p>假设一开始有4个节点，都还是 Follower。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205115.png" alt></p><p>有两个 Follower 同时 Timeout，都变成了 Candidate 开始选举，分别给一个 Follower 发送了投票请求。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205141.png" alt></p><p>两个 Follower 分别返回了ok，这时两个 Candidate 都只有2票，要3票才能被选成 Leader。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205210.png" alt></p><p>两个 Candidate 会分别给另外一个还没有给自己投票的 Follower 发送投票请求。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205227.png" alt></p><p>但是因为 Follower 在这一轮选举中，都已经投完票了，所以都拒绝了他们的请求。所以在 Term 2 没有 Leader 被选出来。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205242.png" alt></p><p>这时，两个节点的状态是 Candidate，两个是 Follower，但是他们的倒计时器仍然在运行，最先 Timeout 的那个节点会进行发起新一轮 Term 3 的投票。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205257.png" alt></p><p>两个 Follower 在 Term 3 还没投过票，所以返回 OK，这时 Candidate 一共有三票，被选为了 Leader。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205319.png" alt></p><p>如果 Leader Heartbeat 的时间晚于另外一个 Candidate timeout 的时间，另外一个 Candidate 仍然会发送选举请求。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205340.png" alt></p><p>两个 Follower 已经投完票了，拒绝了这个 Candidate 的投票请求。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205354.png" alt></p><p>Leader 进行 Heartbeat， Candidate 收到后状态自动转为 Follower，完成选主。</p><p>以上是 Raft 最重要活动之一选主的介绍，以及在不同情况下如何进行选主。</p><h2 id="3-复制日志-log-replication"><span id="3-复制日志-log-replication">3. 复制日志 Log Replication</span></h2><h3 id="31-正常情况下复制日志"><span id="31-正常情况下复制日志">3.1 正常情况下复制日志</span></h3><p>Raft 在实际应用场景中的一致性更多的是体现在不同节点之间的数据一致性，客户端发送请求到任何一个节点都能收到一致的返回，当一个节点出故障后，其他节点仍然能以已有的数据正常进行。在选主之后的复制日志就是为了达到这个目的。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205420.png" alt></p><p>一开始，Leader 和 两个 Follower 都没有任何数据。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205438.png" alt></p><p>客户端发送请求给 Leader，储存数据 “sally”，Leader 先将数据写在本地日志，这时候数据还是 <strong>Uncommitted</strong> (还没最终确认，红色表示)</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205539.png" alt></p><p>Leader 给两个 Follower 发送 AppendEntries 请求，数据在 Follower 上没有冲突，则将数据暂时写在本地日志，Follower 的数据也还是 Uncommitted。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205616.png" alt></p><p>Follower 将数据写到本地后，返回 OK。Leader 收到后成功返回，<strong>只要收到的成功的返回数量超过半数 (包含Leader)</strong>，Leader 将数据 “sally” 的状态改成 Committed。( 这个时候 Leader 就可以返回给客户端了)</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205634.png" alt></p><p>Leader 再次给 Follower 发送 AppendEntries 请求，收到请求后，Follower 将本地日志里 Uncommitted 数据改成 Committed。这样就完成了一整个复制日志的过程，三个节点的数据是一致的，</p><h3 id="32-network-partition-情况下进行复制日志"><span id="32-network-partition-情况下进行复制日志">3.2 Network Partition 情况下进行复制日志</span></h3><p>在 Network Partition 的情况下，部分节点之间没办法互相通信，Raft 也能保证在这种情况下数据的一致性。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205655.png" alt></p><p>一开始有 5 个节点处于同一网络状态下。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205712.png" alt></p><p>Network Partition 将节点分成两边，一边有两个节点，一边三个节点。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205803.png" alt></p><p>两个节点这边已经有 Leader 了，来自客户端的数据 “bob” 通过 Leader 同步到 Follower。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205819.png" alt></p><p>因为只有两个节点，少于3个节点，所以 “bob” 的状态仍是 Uncommitted。所以在这里，<strong>服务器会返回错误给客户端</strong></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205832.png" alt></p><p>另外一个 Partition 有三个节点，进行重新选主。客户端数据 “tom” 发到新的 Leader，通过和上节网络状态下相似的过程，同步到另外两个 Follower。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205851.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226205919.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226210105.png" alt></p><p>因为这个 Partition 有3个节点，超过半数，所以数据 “tom” 都 Commit 了。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226210129.png" alt></p><p>网络状态恢复，5个节点再次处于同一个网络状态下。但是这里出现了数据冲突 “bob” 和 “tom”</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226210159.png" alt></p><p>三个节点的 Leader 广播 AppendEntries</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226210245.png" alt></p><p>两个节点 Partition 的 Leader 自动降级为 Follower，因为这个 Partition 的数据 “bob” 没有 Commit，返回给客户端的是错误，客户端知道请求没有成功，所以 Follower 在收到 AppendEntries 请求时，可以把 “bob“ 删除，然后同步 ”tom”，通过这么一个过程，就完成了在 Network Partition 情况下的复制日志，保证了数据的一致性。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20210226210329.png" alt></p><h2 id="小总结"><span id="小总结">小总结</span></h2><p>Raft 是能够实现分布式系统强一致性的算法，每个系统节点有三种状态 Follower，Candidate，Leader。实现 Raft 算法两个最重要的事是：选主和复制日志</p><p><strong>参考链接：</strong><br>Raft 官网：<a href="https://link.jianshu.com?t=https%3A%2F%2Fraft.github.io%2F" target="_blank" rel="noopener">https://raft.github.io/</a></p><p>Raft 原理动画 (推荐看看)：<a href="https://link.jianshu.com?t=http%3A%2F%2Fthesecretlivesofdata.com%2Fraft%2F" target="_blank" rel="noopener">http://thesecretlivesofdata.com/raft/</a></p><p>Raft 算法解析图片来源：<a href="https://link.jianshu.com?t=http%3A%2F%2Fwww.infoq.com%2Fcn%2Farticles%2Fcoreos-analyse-etcd" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/coreos-analyse-etcd</a></p><p>分布式一致性与共识算法 <a href="https://draveness.me/consensus/" target="_blank" rel="noopener">https://draveness.me/consensus/</a></p><p>共识算法：Raft <a href="https://www.jianshu.com/p/8e4bbe7e276c" target="_blank" rel="noopener">https://www.jianshu.com/p/8e4bbe7e276c</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#拜占庭将军问题&quot;&gt;拜占庭将军问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#针对简化版拜占庭将军问题raft-解决方案类比&quot;&gt;针对简化版拜占庭将军问题，Raft 解决方案类比&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a hr
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="https://lxb.wiki/categories/Algorithm/"/>
    
    
      <category term="算法" scheme="https://lxb.wiki/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="raft" scheme="https://lxb.wiki/tags/raft/"/>
    
  </entry>
  
</feed>
