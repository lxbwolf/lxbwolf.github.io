<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xiaobin&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://lxb.wiki/"/>
  <updated>2022-11-29T01:07:29.212Z</updated>
  <id>https://lxb.wiki/</id>
  
  <author>
    <name>Xiaobin.Liu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Mac上移除EasyConnect常驻后台进程</title>
    <link href="https://lxb.wiki/446d3604/"/>
    <id>https://lxb.wiki/446d3604/</id>
    <published>2022-05-01T12:04:28.000Z</published>
    <updated>2022-11-29T01:07:29.212Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#禁用">禁用</a></li><li><a href="#启用">启用</a></li><li><a href="#mac-下禁用开机自启软件">Mac 下禁用开机自启软件</a></li></ul><!-- tocstop --><p>EasyConnect 会在后台强行添加名为 EasyMonitor 的开机自启守护进程，执行以下命令关闭</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo launchctl unload /Library/LaunchDaemons/com.sangfor.EasyMonitor.plist</span><br></pre></td></tr></table></figure><p>可实际上 EasyConnect 还启动了另一个“杀不掉”的后台进程 ECAgent，活动频率很低，似乎不会造成内存泄漏，略显不起眼。但这无法作为它肆意常驻的理由。</p><h4><span id="禁用">禁用</span></h4><p>首先找到 plist 文件，在 <code>/Library/LaunchAgents/com.sangfor.ECAgentProxy.plist</code>。它无法被 launchctl unload，不过没关系，你可以直接把它挪走或删除，并且今后都不再需要它。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mv /Library/LaunchAgents/com.sangfor.ECAgentProxy.plist ~</span><br></pre></td></tr></table></figure><p>当然这时候它还是不能被 kill 掉，要想从 launchctl 中删除而不重启电脑，可以采用 launchctl remove。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">launchctl remove com.sangfor.ECAgentProxy</span><br></pre></td></tr></table></figure><h4><span id="启用">启用</span></h4><p>关闭后台进程之后，启动 EasyConnect 会弹出警告：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Alert</span><br><span class="line"></span><br><span class="line">Initialization failed. Please try reinstalling!</span><br></pre></td></tr></table></figure><p>所以 需要使用时，必须重新加载 EasyMonitor。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># EasyConnect v7.6.7 开始 EasyMonitor 必须在 root 权限下运行，此前版本可以不加 sudo</span><br><span class="line">sudo launchctl load /Library/LaunchDaemons/com.sangfor.EasyMonitor.plist</span><br></pre></td></tr></table></figure><p>而 ECAgent 就没这么麻烦了，它根本不必后台常驻 —— EasyConnect 启动时会自己创建一个，并且会随着 EasyConnect 进程一起退出。最终我删掉了 <code>com.sangfor.ECAgentProxy.plist</code> 文件的备份。</p><h4><span id="mac-下禁用开机自启软件">Mac 下禁用开机自启软件</span></h4><p>有部分软件的开机启动项放在 <code>/Library/LaunchDaemons</code></p><p>使用 <code>sudo launchctl unload xxx.plist</code> 可以去掉某个软件的开机自启</p><p>深信服的 EasyConnect 有一个进程叫做 EasyMonitor 可以说是非常流氓了，开机自启 + 常驻内存 + 内存泄露，时间长了以后会占用 1g 以上的内存。<br>它的 plist 位于 <code>/Library/LaunchDaemons/com.sangfor.EasyMonitor.plist</code> 使用上述命令可以干掉它。</p><p>干掉他这个进程非常开心，但是会遇到一个问题，再次启动 EasyConnect 的时候，它不乐意了，会提示初始化失败，请重新安装，这时候就得重新 load 这个 plist 了，执行 <code>sudo launchctl load /Library/LaunchDaemons/com.sangfor.EasyMonitor.plist</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#禁用&quot;&gt;禁用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#启用&quot;&gt;启用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#mac-下禁用开机自启软件&quot;&gt;Mac 下禁用开机自启软件&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-
      
    
    </summary>
    
    
      <category term="Tools" scheme="https://lxb.wiki/categories/Tools/"/>
    
    
      <category term="进程" scheme="https://lxb.wiki/tags/%E8%BF%9B%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>【译】如何把WordPress网站迁移到新主机</title>
    <link href="https://lxb.wiki/ea5f4ef1/"/>
    <id>https://lxb.wiki/ea5f4ef1/</id>
    <published>2022-04-24T13:36:34.000Z</published>
    <updated>2022-11-24T13:39:00.123Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#一个-wordpress-网站的组成部分">一个 WordPress 网站的组成部分</a></li><li><a href="#初始配置">初始配置</a></li><li><a href="#前期工作">前期工作</a><ul><li><a href="#安装-apache-和-mariadb">安装 Apache 和 MariaDB</a></li><li><a href="#新服务器防火墙配置">新服务器防火墙配置</a></li><li><a href="#httpd-配置">HTTPD 配置</a></li></ul></li><li><a href="#迁移过程">迁移过程</a></li><li><a href="#最终的修改">最终的修改</a></li><li><a href="#测试和清理">测试和清理</a></li><li><a href="#总结">总结</a></li></ul><!-- tocstop --><blockquote><p>使用这个简单的方法来迁移一个网站以及管理防火墙配置。</p></blockquote><p>你有过把一个 WordPress 网站迁移到一台新主机上的需求吗？我曾经迁移过好多次，迁移过程相当简单。当然，的的市场时候我都不会用通用的推荐方法，这次也不例外 —— 我用更简单的方法，这才是我推荐的方法。</p><p>这个迁移方法没有破坏性，因此如果出于某些原因你需要还原到原来的服务器上，很容易可以实现。</p><h3><span id="一个-wordpress-网站的组成部分">一个 WordPress 网站的组成部分</span></h3><p>运行一个基于 <a href="#">WordPress</a> 的网站有三个重要组成部分：WordPress 本身，一个 web 服务器，如 <a href="#">Apache</a>（我正在用），以及 <a href="#">MariaDB</a>。MariaDB 是 MySQL 的一个分支，功能相似。</p><p>业界有大量的 Web 服务器，由于我使用了 Apache 很长时间，因此我推荐用 Apache。你可能需要把 Apache 的配置方法改成你用的 Web 服务器的方法。</p><h3><span id="初始配置">初始配置</span></h3><p>我使用一台 Linux 主机作为防火墙和网络路由。在我的网络中 Web 服务器是另一台主机。我的内部网络使用的是 C 类私有网络地址范围，按 [无类别域间路由][5]Classless Internet Domain Routing（CIDR）方式简单地记作 192.168.0.0/24。</p><p>对于防火墙，相比于更复杂的 <code>firewalld</code>，我更喜欢用非常简单的 <a href="#">IPTables</a>。这份防火墙配置中的一行会把 80 端口（HTTP）接收到的包发送给 Web 服务器。在 <code>/etc/sysconfig/iptables</code> 文件中，你可以在注释中看到，我添加了规则，把其他入站服务器连接转发到同一台服务器上合适的端口。</p><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang cid="n22" mdtype="fences"> <span role="presentation"># Reroute ports for inbound connections to the appropriate web/email/etc server.</span><br> <span role="presentation"># HTTPD goes to 192.168.0.75</span><br> <span role="presentation">-A PREROUTING -d 45.20.209.41/255.255.255.248 -p tcp -m tcp --dport 80 \</span><br> <span role="presentation"><span cm-text cm-zwsp></span></span><br> <span role="presentation">  -j DNAT --to-destination 192.168.0.75:80</span></pre><p>我使用命名虚拟主机named virtual host来配置原来的 Apache Web 服务器，因为我在这个 HTTPD 实例上运行着多个网站。使用命名虚拟主机配置是个不错的方法，因为（像我一样）未来你可能会在运行其他的网站，这个方法可以使其变得容易。</p><p><code>/etc/httpd/conf/httpd.conf</code> 中需要迁移的虚拟主机的网站相关部分请参考下面代码。这个片段中不涉及到 IP 地址的修改，因此在新服务器上使用时不需要修改。</p><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang cid="n25" mdtype="fences"> <span role="presentation">&lt;VirtualHost *:80&gt;</span><br> <span role="presentation">   ServerName www.website1.org</span><br> <span role="presentation">   ServerAlias server.org</span><br> <span role="presentation"><span cm-text cm-zwsp></span></span><br> <span role="presentation">DocumentRoot &#34;/var/website1/html&#34;</span><br> <span role="presentation">   ErrorLog &#34;logs/error_log&#34;</span><br> <span role="presentation">   ServerAdmin me@website1.org</span><br> <span role="presentation"> </span><br> <span role="presentation">&lt;Directory &#34;/var/website1/html&#34;&gt;</span><br> <span role="presentation">      Options Indexes FollowSymLinks</span><br> <span role="presentation"> </span><br> <span role="presentation">AllowOverride None</span><br> <span role="presentation">      Require all granted</span><br> <span role="presentation"> </span><br> <span role="presentation">&lt;/Directory&gt;</span><br> <span role="presentation">&lt;/VirtualHost&gt;</span></pre><p>在迁移之前，你需要在 <code>httpd.conf</code> 的最顶端附近找到 <code>Listen</code> 声明并修改成类似下面这样。这个地址是服务器的真实私有 IP 地址，不是公开 IP 地址。</p><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang cid="n27" mdtype="fences"> <span role="presentation">Listen 192.168.0.75:80</span></pre><p>你需要修改新主机上 <code>Listen</code> 的 IP 地址。</p><h3><span id="前期工作">前期工作</span></h3><p>准备工作分为以下三步：</p><ul><li>安装服务</li><li>配置防火墙</li><li>配置 web 服务器</li></ul><h4><span id="安装-apache-和-mariadb">安装 Apache 和 MariaDB</span></h4><p>如果你的新服务器上还没有 Apache 和 MariaDB，那么就安装它们。WordPress 的安装不是必要的。</p><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang cid="n40" mdtype="fences"> <span role="presentation">dnf -y install httpd mariadb</span></pre><h4><span id="新服务器防火墙配置">新服务器防火墙配置</span></h4><p>确认下新服务器上的防火墙允许访问 80 端口。你<em>每台</em>电脑上都有一个防火墙，对吗？大部分现代发行版使用的初始化配置包含的防火墙会阻止所有进来的网络流量，以此来提高安全等级。</p><p>下面片段的第一行内容可能已经在你的 IPTables 或其他基于防火墙的网络过滤器中存在了。它标识已经被识别为来自可接受来源的入站包，并绕过后面的其它 INPUT 过滤规则，这样可以节省时间和 CPU 周期。片段中最后一行标识并放行 80 端口新进来的请求到 HTTPD 的连接。</p><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang cid="n44" mdtype="fences"> <span role="presentation">-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br> <span role="presentation">&lt;删节&gt;</span><br> <span role="presentation"># HTTP</span><br> <span role="presentation">-A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT</span></pre><p>下面的示例 <code>/etc/sysconfig/iptables</code> 文件是 IPTables 最少规则的例子，可以允许 SSH（端口 22）和 HTTPD（端口 80）连接。</p><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang cid="n46" mdtype="fences"> <span role="presentation">*filter</span><br> <span role="presentation">:INPUT ACCEPT [0:0]</span><br> <span role="presentation">:FORWARD ACCEPT [0:0]</span><br> <span role="presentation">:OUTPUT ACCEPT [0:0]</span><br> <span role="presentation">-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br> <span role="presentation">-A INPUT -p icmp -j ACCEPT</span><br> <span role="presentation">-A INPUT -i lo -j ACCEPT</span><br> <span role="presentation"># SSHD</span><br> <span role="presentation">-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT</span><br> <span role="presentation"># HTTP</span><br> <span role="presentation">-A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT</span><br> <span role="presentation"><span cm-text cm-zwsp></span></span><br> <span role="presentation"># Final disposition for unmatched packets</span><br> <span role="presentation">-A INPUT -j REJECT --reject-with icmp-host-prohibited</span><br> <span role="presentation">-A FORWARD -j REJECT --reject-with icmp-host-prohibited</span><br> <span role="presentation">COMMIT</span></pre><p>在新服务器主机上我需要做的就是在 <code>/etc/sysconfig/iptables</code> 文件的防火墙规则里添加上面片段的最后一行，然后重新加载修改后的规则集。</p><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang cid="n48" mdtype="fences"> <span role="presentation">iptables-restore /etc/sysconfig/iptables</span></pre><p>大部分基于红帽的发行版本，如 Fedora，使用的是 <code>firewalld</code>。我发现对于它的适用场景（如家用、小到中型企业）而言，它过于复杂，因此我不用它。我建议你参照 <a href="#">firewalld 网页</a> 来向 <code>firewalld</code> 添加入站端口 80。</p><p>你的防火墙及其配置可能跟这个有些差异，但最终的目的是允许新 Web 服务器 80 端口接收 HTTPD 连接。</p><h4><span id="httpd-配置">HTTPD 配置</span></h4><p>在 <code>/etc/httpd/conf/httpd.conf</code> 文件中配置 HTTPD。像下面一样在 <code>Listen</code> 片段中设置 IP 地址。我的新 Web 服务器 IP 地址是 <code>192.168.0.125</code>。</p><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang cid="n53" mdtype="fences"> <span role="presentation">Listen 192.168.0.125:80</span></pre><p>复制（对应要迁移的网站的） <code>VirtualHost</code> 片段，粘贴到新服务器上 <code>httpd.conf</code> 文件的末尾。</p><h3><span id="迁移过程">迁移过程</span></h3><p>只有两组数据需要迁移到新服务器 —— 数据库本身和网站目录结构。把两个目录打包成 <code>tar</code> 文档。</p><pre class="md-fences mock-cm md-end-block md-fences-with-lineno" spellcheck="false" lang cid="n57" mdtype="fences">cd /var ; tar -cvf /tmp/website.tar website1/<br>cd /var/lib ; tar -cvf /tmp/database.tar mysql/</pre><p>把两个 tar 文件复制到新服务器。我通常会把这类文件放到 <code>/tmp</code> 下，这个目录就是用来做这种事的。在新服务器上运行下面的命令，把 tar 文档解压到正确的目录。</p><pre class="md-fences mock-cm md-end-block md-fences-with-lineno" spellcheck="false" lang cid="n59" mdtype="fences">cd /var ; tar -xvf /tmp/website.tar<br>cd /var/lib ; tar -xvf /tmp/database.tar</pre><p>WordPress 的所有文件都在 <code>/var/website1</code> 下，因此不需要在新服务器上安装它。新服务器上不需要执行 WordPress 安装过程。</p><p>这个目录就是需要迁移到新服务器上的全部内容。</p><p>最后一步是启动（或重启）<code>mysqld</code> 和 <code>httpd</code> 服务守护进程。WrodPress 不是一个服务，因此不使用守护进程的方式来启动。</p><pre class="md-fences mock-cm md-end-block md-fences-with-lineno" spellcheck="false" lang cid="n63" mdtype="fences">systemctl start mysqld ; systemctl start httpd</pre><p>启动之后，你应该检查下这些服务的状态。</p><pre class="md-fences mock-cm md-end-block md-fences-with-lineno" spellcheck="false" lang cid="n65" mdtype="fences">systemctl status mysqld<br>● mariadb.service - MariaDB 10.5 database server<br>    Loaded: loaded (/usr/lib/systemd/system/mariadb.service; enabled; vendor preset: disabled)<br>    Active: active (running) since Sat 2021-08-21 14:03:44 EDT; 4 days ago<br>        Docs: man:mariadbd(8)<br><br>https://mariadb.com/kb/en/library/systemd/<br>   Process: 251783 ExecStartPre=/usr/libexec/mariadb-check-socket (code=exited, status=0/SUCCESS)<br>   Process: 251805 ExecStartPre=/usr/libexec/mariadb-prepare-db-dir mariadb.service (code=exited, status=0/SUCCESS)<br>   Process: 251856 ExecStartPost=/usr/libexec/mariadb-check-upgrade (code=exited, status=0/SUCCESS)<br> Main PID: 251841 (mariadbd)<br>      Status: &#34;Taking your SQL requests now...&#34;<br>      Tasks: 15 (limit: 19003)<br>    Memory: 131.8M<br>        CPU: 1min 31.793s<br>    CGroup: /system.slice/mariadb.service<br>└─251841 /usr/libexec/mariadbd --basedir=/usr<br><br>Aug 21 14:03:43 simba.stmarks-ral.org systemd[1]: Starting MariaDB 10.5 database server...<br>Aug 21 14:03:43 simba.stmarks-ral.org mariadb-prepare-db-dir[251805]: Database MariaDB is probably initialized in /var/lib/mysql already, n&gt;<br>Aug 21 14:03:43 simba.stmarks-ral.org mariadb-prepare-db-dir[251805]: If this is not the case, make sure the /var/lib/mysql is empty before&gt;<br>Aug 21 14:03:44 simba.stmarks-ral.org mariadbd[251841]: 2021-08-21 14:03:44 0 [Note] /usr/libexec/mariadbd (mysqld 10.5.11-MariaDB) startin&gt;<br>Aug 21 14:03:44 simba.stmarks-ral.org systemd[1]: Started MariaDB 10.5 database server.<br><br>systemctl status httpd<br>● httpd.service - The Apache HTTP Server<br>   Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled)<br>   Drop-In: /usr/lib/systemd/system/httpd.service.d<br>└─php-fpm.conf<br>      Active: active (running) since Sat 2021-08-21 14:08:39 EDT; 4 days ago<br>        Docs: man:httpd.service(8)<br>   Main PID: 252458 (httpd)<br>      Status: &#34;Total requests: 10340; Idle/Busy workers 100/0;Requests/sec: 0.0294; Bytes served/sec: 616 B/sec&#34;<br>        Tasks: 278 (limit: 19003)<br>      Memory: 44.7M<br>        CPU: 2min 31.603s<br>   CGroup: /system.slice/httpd.service<br>├─252458 /usr/sbin/httpd -DFOREGROUND<br>├─252459 /usr/sbin/httpd -DFOREGROUND<br>├─252460 /usr/sbin/httpd -DFOREGROUND<br>├─252461 /usr/sbin/httpd -DFOREGROUND<br>├─252462 /usr/sbin/httpd -DFOREGROUND<br>└─252676 /usr/sbin/httpd -DFOREGROUND<br><br>Aug 21 14:08:39 simba.stmarks-ral.org systemd[1]: Starting The Apache HTTP Server...<br>Aug 21 14:08:39 simba.stmarks-ral.org httpd[252458]: AH00112: Warning: DocumentRoot [/var/teststmarks-ral/html] does not exist<br>Aug 21 14:08:39 simba.stmarks-ral.org httpd[252458]: Server configured, listening on: port 80<br>Aug 21 14:08:39 simba.stmarks-ral.org systemd[1]: Started The Apache HTTP Server.</pre><h3><span id="最终的修改">最终的修改</span></h3><p>现在所需的服务都已经运行了，你可以把 <code>/etc/sysconfig/iptables</code> 文件中 HTTDP 的防火墙规则改成下面的样子：</p><pre class="md-fences mock-cm md-end-block md-fences-with-lineno" spellcheck="false" lang cid="n68" mdtype="fences">-A PREROUTING -d 45.20.209.41/255.255.255.248 -p tcp -m tcp --dport 80 \<br>  -j DNAT --to-destination 192.168.0.125:80</pre><p>然后重新加载设置的 IPTables 规则。</p><pre class="md-fences mock-cm md-end-block md-fences-with-lineno" spellcheck="false" lang cid="n70" mdtype="fences">iptables-restore /etc/sysconfig/iptables</pre><p>由于防火墙规则是在防火墙主机上，因此不需要把外部 DNS 入口改成指向新服务器。如果你使用的是内部 DNS 服务器，那么你需要把 IP 地址改成内部 DNS 数据库里的 A 记录。如果你没有用内部 DNS 服务器，那么请确保主机 <code>/etc/hosts</code> 文件里新服务器地址设置得没有问题。</p><h3><span id="测试和清理">测试和清理</span></h3><p>请确保对新配置进行测试。首先，停止旧服务器上的 <code>mysqld</code> 和 <code>httpd</code> 服务。然后通过浏览器访问网站。如果一切符合预期，那么你可以关掉旧服务器上的 <code>mysqld</code> 和 <code>httpd</code>。如果有失败，你可以把 IPTables 的路由规则改回去到旧服务器上，直到问题解决。</p><p>之后我把 MySQL 和 HTTPD 从旧服务器上删除了，这样来确保它们不会意外地被启动。</p><h3><span id="总结">总结</span></h3><p>就是这么简单。不需要执行数据库导出和导入的过程，因为 <code>mysql</code> 目录下所有需要的东西都已经复制过去了。需要执行导出/导入过程的场景是：有网站自己的数据库之外的数据库；MariaDB 实例上还有其他网站，而你不想把这些网站复制到新服务器上。</p><p>迁移旧服务器上的其他网站也很容易。其他网站依赖的所有数据库都已经随着 MariaDB 的迁移被转移到了新服务器上。你只需要把 <code>/var/website</code> 目录迁移到新服务器，添加合适的虚拟主机片段，然后重启 HTTPD。</p><p>我遵循这个过程把很多个网站从一个服务器迁移到另一个服务器，每次都没有问题。</p><hr><p>via: <a href="https://opensource.com/article/21/9/migrate-wordpress">https://opensource.com/article/21/9/migrate-wordpress</a></p><p>作者：<a href="#">David Both</a><br>选题：<a href="#">lujun9972</a><br>译者：<a href="https://github.com/lxbwolf">lxbwolf</a><br>校对：<a href="https://github.com/wxy">wxy</a></p><p>本文由 <a href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创编译，<a href="https://linux.cn/">Linux中国</a> 荣誉推出</p><p>[a]    <a href="https://opensource.com/users/dboth">https://opensource.com/users/dboth</a></p><p>[b]    <a href="https://github.com/lujun9972">https://github.com/lujun9972</a></p><p>[1]    <a href="https://opensource.com/sites/default/files/styles/image-full-size/public/lead-images/browser_blue_text_editor_web.png?itok=lcf-m6N7">https://opensource.com/sites/default/files/styles/image-full-size/public/lead-images/browser_blue_text_editor_web.png?itok=lcf-m6N7</a> Text editor on a browser, in blue</p><p>[2]    <a href="https://wordpress.org/">https://wordpress.org/</a></p><p>[3]    <a href="https://opensource.com/article/18/2/how-configure-apache-web-server">https://opensource.com/article/18/2/how-configure-apache-web-server</a></p><p>[4]    <a href="https://mariadb.org/">https://mariadb.org/</a></p><p>[5]    <a href="https://opensource.com/article/16/12/cidr-network-notation-configuration-linux">https://opensource.com/article/16/12/cidr-network-notation-configuration-linux</a></p><p>[6]    <a href="https://en.wikipedia.org/wiki/Iptables">https://en.wikipedia.org/wiki/Iptables</a></p><p>[7]    <a href="http://www.website1.org">http://www.website1.org</a></p><p>[8]    mailto:<a href="mailto:me@website1.org">me@website1.org</a></p><p>[9]    <a href="https://firewalld.org/documentation/howto/open-a-port-or-service.html">https://firewalld.org/documentation/howto/open-a-port-or-service.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#一个-wordpress-网站的组成部分&quot;&gt;一个 WordPress 网站的组成部分&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#初始配置&quot;&gt;初始配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#前期工作&quot;&gt;前
      
    
    </summary>
    
    
      <category term="Tools" scheme="https://lxb.wiki/categories/Tools/"/>
    
    
      <category term="工具" scheme="https://lxb.wiki/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="翻译" scheme="https://lxb.wiki/tags/%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>【译】Go中的模糊测试</title>
    <link href="https://lxb.wiki/dfd7f257/"/>
    <id>https://lxb.wiki/dfd7f257/</id>
    <published>2022-04-19T13:30:29.000Z</published>
    <updated>2022-11-24T13:33:42.510Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#什么是模糊测试">什么是模糊测试？</a></li><li><a href="#go-中的软件测试">Go 中的软件测试</a></li><li><a href="#新增对模糊测试的支持">新增对模糊测试的支持</a></li><li><a href="#安装-gotip-来获取最新的功能">安装 gotip 来获取最新的功能</a></li><li><a href="#社区对于模糊测试的观点">社区对于模糊测试的观点</a></li><li><a href="#现实中的模糊测试">现实中的模糊测试</a></li><li><a href="#为什么在-go-中新增对模糊测试的原生支持">为什么在 Go 中新增对模糊测试的原生支持</a></li><li><a href="#模糊测试工具">模糊测试工具</a></li></ul><!-- tocstop --><blockquote><p>Go 团队接受了新增对模糊测试的支持的提议。</p></blockquote><p><a href="https://go.dev/">Go</a> 的应用越来越广泛。现在它是云原生软件、容器软件、命令行工具和数据库等等的首选语言。Go 很早之前就已经有了内建的 <a href="https://pkg.go.dev/testing">对测试的支持</a>。这使得写测试代码和运行都相当简单。</p><h3><span id="什么是模糊测试">什么是模糊测试？</span></h3><p><ruby>模糊测试<rt>fuzz testing</rt></ruby>（fuzzing）是指向你的软件输入非预期的数据。理想情况下，这种测试会让你的应用程序崩溃或有非预期的表现。抛开最终的结果，从程序对非预期的输入数据的处理结果中你可以得到很多信息，这样你就可以增加一些合适的错误处理。</p><p>任何一个软件都有对不同来源的输入或数据的接收说明，软件会对这些数据进行处理并返回适当的结果。软件开发后，测试工程师团队对其进行测试，找出软件中的错误，给出测试报告，并（由开发者）修复。通常测试的目的是验证软件的行为是否符合预期。测试又可以细分为不同的类型，如功能测试、集成测试、性能测试等等。每种测试方法关注软件功能的某一个方面，以便发现错误或者提升可靠性或性能。</p><p>模糊测试在这一测试过程上更进一步，尝试向软件程序输入一些“无效”或“随机”的数据。这种输入是故意的，期望得到的结果就是程序崩溃或输出异常，这样就可以暴露程序中的错误以便由开发者来修复它们。与其他测试类似，很少需要手动进行模糊测试，业界有大量的模糊测试工具可以将这个过程自动化。</p><h3><span id="go-中的软件测试">Go 中的软件测试</span></h3><p>举个例子，假如你想测试 <code>add.go</code> 中的 <code>Add()</code> 函数，你可以在 <code>add_test.go</code> 中导入 <code>testing</code> 包并把测试体写在以 <code>TestXXX()</code>  开头的函数内。</p><p>考虑如下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">func Add(num1, num2 int) int &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 <code>add_test.go</code> 文件中，你可能有如下测试代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import &quot;testing&quot;</span><br><span class="line"></span><br><span class="line">func TestAdd(t *testing.T) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行测试：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ go test</span><br></pre></td></tr></table></figure><h3><span id="新增对模糊测试的支持">新增对模糊测试的支持</span></h3><p>Go 团队已经接受了 <a href="https://github.com/golang/go/issues/44551">新增对模糊测试的支持的提议</a>，以进一步推动这项工作。这涉及到新增一个 <code>testing.F</code> 类型，在 <code>_test.go</code> 文件中新增 <code>FuzzXXX()</code> 函数，在 Go 工具中会新增一个 <code>-fuzz</code> 选项来执行这些测试。</p><p>在 <code>add_test.go</code> 文件中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">func FuzzAdd(f *testing.F) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行以下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ go test -fuzz</span><br></pre></td></tr></table></figure><p>在本文编写时，这个 <a href="https://go.dev/blog/fuzz-beta">功能还是试验性的</a>，但是应该会在 1.18 发布版本中包含。（LCTT 译注：<a href="https://go.dev/blog/go1.18">Go 1.18</a> 刚刚发布，已经包含了对模糊测试的支持）目前很多功能如 <code>-keepfuzzing</code>、<code>-race</code> 等也还没有支持。Go 团队最近发布了一篇 <a href="https://go.dev/doc/tutorial/fuzz">模糊测试教程</a>，值得读一下。</p><h3><span id="安装-gotip-来获取最新的功能">安装 gotip 来获取最新的功能</span></h3><p>如果你极度渴望在正式发布之前尝试这些功能，你可以使用 <code>gotip</code> 来测试即将正式发布的 Go 功能并反馈给他们。你可以使用下面的命令来安装 <code>gotip</code>。安装之后，你可以用 <code>gotip</code> 程序代替以前的 <code>go</code> 程序来编译和运行程序。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ go install golang.org/dl/gotip@latest</span><br><span class="line">$ gotip download</span><br><span class="line"></span><br><span class="line">$ gotip version</span><br><span class="line">go version devel go1.18-f009910 Thu Jan 6 16:22:21 2022 +0000 linux/amd64</span><br></pre></td></tr></table></figure><h3><span id="社区对于模糊测试的观点">社区对于模糊测试的观点</span></h3><p>软件社区中经常会讨论模糊测试，不同的人对模糊测试有不同的看法。有些人认为这是一种有用的技术，可以找到错误，尤其是在安全方面。然而考虑到模糊测试所需要的资源（CPU、内存），有人就认为这是一种浪费，而他们更愿意用其他的测试方法。即使在 Go 团队内部，意见也不统一。我们可以看到 Go 的联合创始人 Rob Pike 对模糊测试的使用和在 Go 中的实现是持轻微的怀疑态度的。</p><blockquote><p>…<em>虽然模糊测试有助于发现某类错误，但是它会占用大量的 CPU 和存储资源，并且效益成本比率也不明确。我担心为了写模糊测试浪费精力，或者 git 仓库中充斥大量无用的测试数据</em></p><p>~<a href="https://github.com/golang/go/issues/44551#issuecomment-784584785">Rob Pike</a></p></blockquote><p>然而，Go 安全团队的另一个成员，Filo Sottile，似乎对 Go 新增支持模糊测试很乐观，举了很多例子来支持，也希望模糊测试能成为开发过程中的一部分。</p><blockquote><p><em>我想说模糊测试可以发现极端情况下的错误。这是我们作为安全团队对其感兴趣的原因：在极端情况下发现的错误可以避免在生产环境中成为弱点。</em></p><p><em>我们希望模糊测试能成为开发的一部分 —— 不只是构建或安全方面 —— 而是整个开发过程：它能提升相关代码的质量…</em></p><p>~<a href="https://github.com/golang/go/issues/44551#issuecomment-784655571">Filo Sottile</a></p></blockquote><h3><span id="现实中的模糊测试">现实中的模糊测试</span></h3><p>对我而言，模糊测试在发现错误以及让系统变得更安全和更有弹性方面似乎非常有效。举个例子，Linux 内核也会使用名为 <a href="https://github.com/google/syzkaller">syzkaller</a> 的工具进行模糊测试，这个工具已经发现了 <a href="https://github.com/google/syzkaller/blob/master/docs/linux/found_bugs.md">大量</a> 错误。</p><p><a href="https://github.com/google/AFL">AFL</a> 也是比较流行的模糊测试工具，用来测试 C/C++ 写的程序。</p><p>之前也有对 Go 程序进行模糊测试的观点，其中之一就是 Filo 在 GitHub 评论中提到的 <a href="https://github.com/dvyukov/go-fuzz">go-fuzz</a>。</p><blockquote><p><em>go-fuzz 的记录提供了相当惊人的证据，证明模糊处理能很好地找到人类没有发现的错误。根据我的经验，我们只需要消耗一点点 CPU 的时间就可以得到极端情况下非常高效的测试结果。</em></p></blockquote><h3><span id="为什么在-go-中新增对模糊测试的原生支持">为什么在 Go 中新增对模糊测试的原生支持</span></h3><p>如果我们的需求是对 Go 程序进行模糊测试，之前的工具像 <code>go-fuzz</code> 就可以完成，那么为什么要在这种语言中增加原生支持呢？<a href="https://go.googlesource.com/proposal/+/master/design/draft-fuzzing.md">Go 模糊测试设计草案</a> 中说明了这样做的一些根本原因。设计的思路是让开发过程更简单，因为前面说的工具增加了开发者的工作量，还有功能缺失。如果你没有接触过模糊测试，那么我建议你读一下设计草案文档。</p><blockquote><p>开发者可以使用诸如 <code>go-fuzz</code> 或 <code>fzgo</code>（基于 <code>go-fuzz</code>）来解决某些需求。然而，已有的每种解决方案都需要在典型的 Go 测试上做更多的事，而且还缺少关键的功能。相比于其他的 Go 测试（如基准测试和单元测试），模糊测试不应该比它们复杂，功能也不应该比它们少。已有的解决方案增加了额外的开销，比如自定义命令行工具。</p></blockquote><h3><span id="模糊测试工具">模糊测试工具</span></h3><p>在大家期望 Go 语言新增功能的列表中，模糊测试是其中很受欢迎的一项。虽然现在还是试验性的，但在将要到来的发布版本中会变得更强大。这给了我们足够的时间去尝试它以及探索它的使用场景。我们不应该把它视为一种开销，如果使用得当它会是一种发现错误非常高效的测试工具。使用 Go 的团队应该推动它的使用，开发者可以写简单的模糊测试，测试团队去慢慢扩展以此来使用它全部的能力。</p><hr><p>via: <a href="https://opensource.com/article/22/1/native-go-fuzz-testing">https://opensource.com/article/22/1/native-go-fuzz-testing</a></p><p>作者：<a href="https://opensource.com/users/gkamathe">Gaurav Kamathe</a><br>选题：<a href="https://github.com/lujun9972">lujun9972</a><br>译者：<a href="https://github.com/lxbwolf">lxbwolf</a><br>校对：<a href="https://github.com/wxy">wxy</a></p><p>本文由 <a href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创编译，<a href="https://linux.cn/">Linux中国</a> 荣誉推出</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#什么是模糊测试&quot;&gt;什么是模糊测试？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#go-中的软件测试&quot;&gt;Go 中的软件测试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#新增对模糊测试的支持&quot;&gt;新增对模糊测试的支持
      
    
    </summary>
    
    
      <category term="Golang" scheme="https://lxb.wiki/categories/Golang/"/>
    
    
      <category term="Go" scheme="https://lxb.wiki/tags/Go/"/>
    
      <category term="翻译" scheme="https://lxb.wiki/tags/%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>【转】Redis 分布式锁使用不当事故记录</title>
    <link href="https://lxb.wiki/f17b426c/"/>
    <id>https://lxb.wiki/f17b426c/</id>
    <published>2022-04-01T13:42:21.000Z</published>
    <updated>2022-09-12T06:54:25.682Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#前言">前言</a></li><li><a href="#事故现场">事故现场</a></li><li><a href="#事故原因">事故原因</a></li><li><a href="#事故分析">事故分析</a></li><li><a href="#解决方案">解决方案</a></li><li><a href="#深度思考">深度思考</a></li></ul><!-- tocstop --><h2><span id="前言">前言</span></h2><p>某电商项目中，抢购订单采用的是分布式锁来解决的。某次茅台抢购活动，库存共 100 瓶，分布式锁设计不当，最终超卖。</p><h2><span id="事故现场">事故现场</span></h2><p>核心代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> SeckillActivityRequestVO <span class="title function_">seckillHandle</span><span class="params">(SeckillActivityRequestVO request)</span> &#123;</span><br><span class="line">SeckillActivityRequestVO response;</span><br><span class="line">    <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> <span class="string">&quot;key:&quot;</span> + request.getSeckillId;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="type">Boolean</span> <span class="variable">lockFlag</span> <span class="operator">=</span> redisTemplate.opsForValue().setIfAbsent(key, <span class="string">&quot;val&quot;</span>, <span class="number">10</span>, TimeUnit.SECONDS);</span><br><span class="line">        <span class="keyword">if</span> (lockFlag) &#123;</span><br><span class="line">            <span class="comment">// HTTP请求用户服务进行用户相关的校验</span></span><br><span class="line">            <span class="comment">// 用户活动校验</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 库存校验</span></span><br><span class="line">            <span class="type">Object</span> <span class="variable">stock</span> <span class="operator">=</span> redisTemplate.opsForHash().get(key+<span class="string">&quot;:info&quot;</span>, <span class="string">&quot;stock&quot;</span>);</span><br><span class="line">            <span class="keyword">assert</span> stock != <span class="literal">null</span>;</span><br><span class="line">            <span class="keyword">if</span> (Integer.parseInt(stock.toString()) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">// 业务异常</span></span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                redisTemplate.opsForHash().increment(key+<span class="string">&quot;:info&quot;</span>, <span class="string">&quot;stock&quot;</span>, -<span class="number">1</span>);</span><br><span class="line">                <span class="comment">// 生成订单</span></span><br><span class="line">                <span class="comment">// 发布订单创建成功事件</span></span><br><span class="line">                <span class="comment">// 构建响应VO</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">// 释放锁</span></span><br><span class="line">        stringRedisTemplate.delete(<span class="string">&quot;key&quot;</span>);</span><br><span class="line">        <span class="comment">// 构建响应VO</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> response;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码，通过分布式锁过期时间有效期 10s 来保障业务逻辑有足够的执行时间；采用 try-finally 语句块保证锁一定会及时释放。</p><h2><span id="事故原因">事故原因</span></h2><p>飞天茅台抢购活动吸引了大量新用户下载注册我们的 APP，其中，不乏很多羊毛党，采用专业的手段来注册新用户来薅羊毛和刷单。正因如此，让用户服务一直处于较高的运行负载中。</p><p>抢购活动开始的一瞬间，大量的用户校验请求打到了用户服务。</p><p>导致用户服务网关出现了短暂的响应延迟，有些请求的响应时长超过了 10s，但由于 HTTP 请求的响应超时我们设置的是 30s。</p><p>这就导致接口一直阻塞在用户校验那里，10s 后，分布式锁已经失效了，此时有新的请求进来是可以拿到锁的，也就是说锁被覆盖了。</p><p>这些阻塞的接口执行完之后，又会执行释放锁的逻辑，这就把其他线程的锁释放了，导致新的请求也可以竞争到锁~这真是一个极其恶劣的循环。</p><p>这个时候只能依赖库存校验，但是偏偏库存校验不是非原子性的，采用的是 get and compare 的方式，超卖的悲剧就这样发生了<del>~</del></p><h2><span id="事故分析">事故分析</span></h2><p>仔细分析下来，可以发现，这个抢购接口在高并发场景下，是有严重的安全隐患的，主要集中在三个地方：</p><p><strong>①没有其他系统风险容错处理</strong></p><p>由于用户服务吃紧，网关响应延迟，但没有任何应对方式，这是超卖的导火索。</p><p><strong>②看似安全的分布式锁其实一点都不安全</strong></p><p>虽然采用了 set key value [EX seconds] [PX milliseconds] [NX|XX]的方式，但是如果线程 A 执行的时间较长没有来得及释放，锁就过期了，此时线程 B 是可以获取到锁的。</p><p>当线程 A 执行完成之后，释放锁，实际上就把线程 B 的锁释放掉了。这个时候，线程 C 又是可以获取到锁的，而此时如果线程 B 执行完释放锁实际上就是释放的线程 C 设置的锁。这是超卖的直接原因。</p><p><strong>③非原子性的库存校验</strong></p><p>非原子性的库存校验导致在并发场景下，库存校验的结果不准确。这是超卖的根本原因。</p><p>通过以上分析，问题的根本原因在于库存校验严重依赖了分布式锁。因为在分布式锁正常 set、del 的情况下，库存校验是没有问题的。</p><p>但是，当分布式锁不安全可靠的时候，库存校验就没有用了。</p><h2><span id="解决方案">解决方案</span></h2><p><strong>实现相对安全的分布式锁</strong></p><p>相对安全的定义：set、del 是一一映射的，不会出现把其他现成的锁 del 的情况。</p><p>从实际情况的角度来看，即使能做到 set、del一一映射，也无法保障业务的绝对安全。</p><p>因为锁的过期时间始终是有界的，除非不设置过期时间或者把过期时间设置的很长，但这样做也会带来其他问题。故没有意义。</p><p>要想实现相对安全的分布式锁，必须依赖 key 的 value 值。在释放锁的时候，通过 value 值的唯一性来保证不会勿删。</p><p><em>我们基于 LUA 脚本实现原子性的 get and compare</em>，如下：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public void safedUnLock(String key, String val) &#123;</span><br><span class="line">    String luaScript = <span class="string">&quot;local in = ARGV[1] local curr=redis.call(&#x27;get&#x27;, KEYS[1]) if in==curr then redis.call(&#x27;del&#x27;, KEYS[1]) end return &#x27;OK&#x27;&quot;</span><span class="string">&quot;;</span></span><br><span class="line"><span class="string">    RedisScript&lt;String&gt; redisScript = RedisScript.of(luaScript);</span></span><br><span class="line"><span class="string">    redisTemplate.execute(redisScript, Collections.singletonList(key), Collections.singleton(val));</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><p>我们通过 LUA 脚本来实现安全地解锁。</p><p><strong>实现安全的库存校验</strong></p><p>如果我们对于并发有比较深入的了解的话，会发现想 get and compare/ read and save 等操作，都是非原子性的。如果要实现原子性，我们也可以借助 LUA 脚本来实现。</p><p>在公众号互联网架构师回复“2T”，获取惊喜礼包。</p><p>但就我们这个例子中，由于抢购活动一单只能下 1 瓶，因此可以不用基于 LUA 脚本实现而是基于 Redis 本身的原子性。</p><p>原因在于：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// redis会返回操作之后的结果，这个过程是原子性的</span></span><br><span class="line"><span class="type">Long</span> <span class="variable">currStock</span> <span class="operator">=</span> redisTemplate.opsForHash().increment(<span class="string">&quot;key&quot;</span>, <span class="string">&quot;stock&quot;</span>, -<span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>发现没有，代码中的库存校验完全是“画蛇添足”。 </p><p><strong>改进之后的代码</strong></p><p>经过以上的分析之后，我们决定新建一个 DistributedLocker 类专门用于处理分布式锁：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> SeckillActivityRequestVO <span class="title function_">seckillHandle</span><span class="params">(SeckillActivityRequestVO request)</span> &#123;</span><br><span class="line">SeckillActivityRequestVO response;</span><br><span class="line">    <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> <span class="string">&quot;key:&quot;</span> + request.getSeckillId();</span><br><span class="line">    <span class="type">String</span> <span class="variable">val</span> <span class="operator">=</span> UUID.randomUUID().toString();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="type">Boolean</span> <span class="variable">lockFlag</span> <span class="operator">=</span> distributedLocker.lock(key, val, <span class="number">10</span>, TimeUnit.SECONDS);</span><br><span class="line">        <span class="keyword">if</span> (!lockFlag) &#123;</span><br><span class="line">            <span class="comment">// 业务异常</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 用户活动校验</span></span><br><span class="line">        <span class="comment">// 库存校验，基于redis本身的原子性来保证</span></span><br><span class="line">        <span class="type">Long</span> <span class="variable">currStock</span> <span class="operator">=</span> stringRedisTemplate.opsForHash().increment(key + <span class="string">&quot;:info&quot;</span>, <span class="string">&quot;stock&quot;</span>, -<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span> (currStock &lt; <span class="number">0</span>) &#123; <span class="comment">// 说明库存已经扣减完了。</span></span><br><span class="line">            <span class="comment">// 业务异常。</span></span><br><span class="line">            log.error(<span class="string">&quot;[抢购下单] 无库存&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 生成订单</span></span><br><span class="line">            <span class="comment">// 发布订单创建成功事件</span></span><br><span class="line">            <span class="comment">// 构建响应</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        distributedLocker.safedUnLock(key, val);</span><br><span class="line">        <span class="comment">// 构建响应</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> response;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="深度思考">深度思考</span></h2><p><strong>①分布式锁有必要么</strong></p><p>改进之后，其实可以发现，我们借助于 Redis 本身的原子性扣减库存，也是可以保证不会超卖的。</p><p>对的。但是如果没有这一层锁的话，那么所有请求进来都会走一遍业务逻辑，由于依赖了其他系统，此时就会造成对其他系统的压力增大。</p><p>这会增加的性能损耗和服务不稳定性，得不偿失。基于分布式锁可以在一定程度上拦截一些流量。</p><p><strong>②分布式锁的选型</strong></p><p>有人提出用 RedLock 来实现分布式锁。RedLock 的可靠性更高，但其代价是牺牲一定的性能。</p><p>在本场景，这点可靠性的提升远不如性能的提升带来的性价比高。如果对于可靠性极高要求的场景，则可以采用 RedLock 来实现。</p><p><strong>③再次思考分布式锁有必要么</strong></p><p>由于 Bug 需要紧急修复上线，因此我们将其优化并在测试环境进行了压测之后，就立马热部署上线了。</p><p>实际证明，这个优化是成功的，性能方面略微提升了一些，并在分布式锁失效的情况下，没有出现超卖的情况。</p><p>然而，还有没有优化空间呢？有的！由于服务是集群部署，我们可以将库存均摊到集群中的每个服务器上，通过广播通知到集群的各个服务器。</p><p>网关层基于用户 ID 做 hash 算法来决定请求到哪一台服务器。这样就可以基于应用缓存来实现库存的扣减和判断。</p><p>性能又进一步提升了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通过消息提前初始化好，借助ConcurrentHashMap实现高效线程安全</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> ConcurrentHashMap&lt;Long, Boolean&gt; SECKILL_FLAG_MAP = <span class="keyword">new</span> <span class="title class_">ConcurrentHashMap</span>&lt;&gt;();</span><br><span class="line"><span class="comment">// 通过消息提前设置好。由于AtomicInteger本身具备原子性，因此这里可以直接使用HashMap</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Map&lt;Long, AtomicInteger&gt; SECKILL_STOCK_MAP = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> SeckillActivityRequestVO <span class="title function_">seckillHandle</span><span class="params">(SeckillActivityRequestVO request)</span> &#123;</span><br><span class="line">SeckillActivityRequestVO response;</span><br><span class="line"></span><br><span class="line">    <span class="type">Long</span> <span class="variable">seckillId</span> <span class="operator">=</span> request.getSeckillId();</span><br><span class="line">    <span class="keyword">if</span>(!SECKILL_FLAG_MAP.get(requestseckillId)) &#123;</span><br><span class="line">        <span class="comment">// 业务异常</span></span><br><span class="line">    &#125;</span><br><span class="line">     <span class="comment">// 用户活动校验</span></span><br><span class="line">     <span class="comment">// 库存校验</span></span><br><span class="line">    <span class="keyword">if</span>(SECKILL_STOCK_MAP.get(seckillId).decrementAndGet() &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        SECKILL_FLAG_MAP.put(seckillId, <span class="literal">false</span>);</span><br><span class="line">        <span class="comment">// 业务异常</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 生成订单</span></span><br><span class="line">    <span class="comment">// 发布订单创建成功事件</span></span><br><span class="line">    <span class="comment">// 构建响应</span></span><br><span class="line">    <span class="keyword">return</span> response;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过以上的改造，我们就完全不需要依赖 Redis 了。性能和安全性两方面都能进一步得到提升！</p><p>当然，此方案没有考虑到机器的动态扩容、缩容等复杂场景，如果还要考虑这些话，则不如直接考虑分布式锁的解决方案。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#事故现场&quot;&gt;事故现场&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#事故原因&quot;&gt;事故原因&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#事故分析&quot;&gt;事故分
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxb.wiki/categories/Design/"/>
    
    
      <category term="redis" scheme="https://lxb.wiki/tags/redis/"/>
    
      <category term="事故" scheme="https://lxb.wiki/tags/%E4%BA%8B%E6%95%85/"/>
    
  </entry>
  
  <entry>
    <title>【译】解决 CI/CD 中的仓库阻抗失配</title>
    <link href="https://lxb.wiki/f5fbcabb/"/>
    <id>https://lxb.wiki/f5fbcabb/</id>
    <published>2022-03-26T06:32:25.000Z</published>
    <updated>2022-03-26T08:25:32.543Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#阻抗失配scm-与镜像仓库">阻抗失配：SCM 与镜像仓库</a></li><li><a href="#二进制与部署描述符">二进制与部署描述符</a></li><li><a href="#解决阻抗失配">解决阻抗失配</a></li><li><a href="#实践中的思考">实践中的思考</a></li><li><a href="#结语">结语</a></li></ul><!-- tocstop --><blockquote><p>对齐部署镜像和描述符是很困难的，但是某些策略可以使整个过程更高效。<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220326161918.png" alt></p></blockquote><p>在软件架构中，当两个组件之间有某些概念性或技术上的差异时会出现 <ruby>阻抗失配<rt>impedance mismatch</rt></ruby>。这个术语其实是从电子工程中借用的，表示电路中输入和输出的电子阻抗必须要匹配。</p><p>在软件开发中，存储在镜像仓库中的镜像与存储在源码控制管理系统（LCTT 译注：SCM，Source Code Management）中它的<ruby>部署描述符<rt>deployment descriptor</rt></ruby>之间存在阻抗失配。你如何确定存储在 SCM 中的部署描述符表示的是正确的镜像？两个仓库追踪数据的方式并不一致，因此将一个镜像（在镜像仓库中独立存储的不可修改的二进制）和它的部署描述符（Git 中以文本文件形式存储的一系列修改记录）相匹配并不那么直观。</p><p><strong>注意</strong>：本文假定读者已经熟悉以下概念：</p><ul><li><ruby>源码控制管理<rt>Source Control Management</rt></ruby>（SCM）系统和分支</li><li>Docker 或符合 OCI 标准的镜像和容器</li><li><ruby>容器编排系统<rt>Container Orchestration Platforms</rt></ruby>（COP），如 Kubernetes</li><li><ruby>持续集成/持续交付<rt>Continuous Integration/Continuous Delivery</rt></ruby>（CI/CD）</li><li><ruby>软件开发生命周期<rt>Software development lifecycle</rt></ruby>（SDLC）环境</li></ul><h3><span id="阻抗失配scm-与镜像仓库">阻抗失配：SCM 与镜像仓库</span></h3><p>为了更好地理解阻抗失配在什么场景下会成为问题，请考虑任意项目中的软件开发生命周期环境（SDLC），如开发、测试或发布环境。</p><p>测试环境不会有阻抗失配。现在使用 CI/CD 的最佳实践中开发分支的最新提交都会对应开发环境中的最新部署。因此，一个典型的、成功的 CI/CD 开发流程如下：</p><ol><li>向 SCM 的开发分支提交新的修改</li><li>新提交触发一次镜像构建</li><li>新生成的镜像被推送到镜像仓库，标记为开发中</li><li>镜像被部署到容器编排系统（COP）中的开发环境，该镜像的部署描述符也更新为从 SCM 拉取的最新描述符。</li></ol><p>换句话说，开发环境中最新的镜像永远与最新的部署描述符匹配。回滚到前一个构建的版本也不是问题，因为 SCM 也会跟着回滚。</p><p>最终，随着开发流程继续推进，需要进行更多正式的测试，因此某个镜像 —— 镜像对应着 SCM 中的某次提交 —— 被推到测试环境。如果是一次成功的构建，那么不会有大问题，因为从开发环境推过来的镜像应该会与开发分支的最新提交相对应。</p><ol><li>开发环境的最新部署被允许入库，触发入库过程</li><li>最新部署的镜像被标记为测试中</li><li>镜像在测试环境中被拉取和部署，（该镜像）对应从 SCM 拉取的最新部署描述符</li></ol><p>到目前为止,一切都没有问题，对吗？如果出现下面的场景，会有什么问题？</p><p><strong>场景 A</strong>：镜像被推到下游环境，如<ruby>用户验收测试<rt>user acceptance testing </rt></ruby>（UAT），或者是生产环境。</p><p><strong>场景 B</strong>：测试环境中发现了一个破坏性的 bug，镜像需要回滚到某个确定正常的版本。</p><p>在任一场景中，开发过程并没有停止，即开发分支上游有了一次或多次新的提交，而这意味着最新的部署描述符已经发生了变化，最新的镜像与之前部署在测试环境中的镜像不一致。对部署描述符的修改可能会也可能不会对之前版本的镜像起作用，但是它们一定是不可信任的。如果它们有了变化，那么它们就一定与目前为止你测试过的想要部署的镜像的部署描述符不一致。</p><p>问题的关键是：<strong>如果部署的镜像不是镜像库中的最新版本，你怎么确定与部署的镜像相对应的是 SCM 中的哪个部署描述符？</strong> 一言以蔽之，无法确定。两个库直接有阻抗失配。如果要详细阐述下，那么是有方法可以解决的，但是你需要做很多工作，这部分内容就是文章接下来的主题了。请注意，下面的方案并不是解决问题的唯一办法，但是已经投入到生产环境并已经对很多项目起了作用，而且已经被构建并部署到生产环境中运行了超过一年。</p><h3><span id="二进制与部署描述符">二进制与部署描述符</span></h3><p>源码通常被构建成一个 Docker 镜像或符合 OCI 标准的镜像，该镜像通常被部署到一个容器编排平台（COP）上，如 Kubernetes。部署到 COP 需要部署描述符来定义镜像被如何部署以及作为容器运行，如 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">Kubernetes 部署</a> 或 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/">CronJobs</a>。这是因为在镜像和它的部署描述符之间有本质差异，在这里可以看到阻抗失配。在这次讨论中，我们认为镜像是存储在镜像仓库中不可修改的二进制。对源码的任何修改都不会修改镜像，而是用另一个新的镜像去替换它。</p><p>相比之下，部署描述符是文本文件，因而可以被认为是源码且可修改。如果遵循最佳实践，那么部署描述符是被存储在 SCM，所有修改都会提交，而这很容易回溯。</p><h3><span id="解决阻抗失配">解决阻抗失配</span></h3><p>建议的解决方案的第一部分，就是提供一个能匹配镜像仓库中的镜像与对保存部署描述符的 SCM 做的代码提交的方法。最直接的解决方案是用源提交的哈希值标记镜像。这个方法可以区分不同版本的镜像、容易分辨，并且提供足够的信息来查找正确的部署描述符，以便镜像更好地部署到 COP。</p><p>再回顾下上面的场景：</p><p><strong>场景 A</strong> _镜像被推到下游环境_： 当镜像被从测试环境推到 UAT 环境时，我们可以从镜像的标签中知道应该从 SCM 的哪一次源码提交拉取部署描述符。</p><p><strong>场景 B</strong> _当一个镜像需要在某一环节中回滚_：无论我们选择回滚到那个镜像版本，我们都可以知道从 SCM 的哪一次源码提交拉取正确的部署描述符。</p><p>在每一种情景中，无论在某个镜像被部署到测试环境后开发分支有多少次提交和构建，对于每一次升级的镜像，我们都可以找到它当初部署时对应的部署描述符。</p><p>然而，这并不是阻抗失配的完整解决方案。再考虑两个场景：</p><p><strong>场景 C</strong> 在负载测试环境中，会尝试对不同的部署描述符进行多次部署，以此来验证某一次构建的表现。</p><p><strong>场景 D</strong> 一个镜像被推送到下游环境，在该环境中部署描述符有一个错误。</p><p>在上面的所有场景中，我们都需要修改部署描述符，但是目前为止我们只有一个源码提交哈希。请记住，最佳实践要求我们所有对源码的修改都要先提交到 SCM。某次提交的哈希本身是无法修改的，因此我们需要一个比仅仅追踪原来的源码提交哈希更好地解决方案。</p><p>解决方案是基于原来的源码提交哈希新建一个分支。我们把这个分支称为<strong>部署分支</strong>。每当一个镜像被推到下游测试或发布环境时，你应该<strong>基于前一个 SDLC 环境的部署分支的最新提交</strong>创建一个新的部署分支。</p><p>这样同一个镜像可以重复多次部署到不同的 SDLC 环境，并在后面每个环境中可以感知前面发现的改动或对镜像做的修改。</p><p><strong>注意：</strong> 在某个环境中做的修改是如何影响下一个环境的，是用可以共享数据的工具（如 Helm Charts）还是手动剪切、粘贴到其他目录，都不在本文讨论的范围内。</p><p>因此，当一个镜像被从一个 SDLC 环境中推到下一环境时：</p><ol><li>创建一个部署分支<ol><li>如果镜像是从开发环境中推过来的，那么部署分支就基于构建这个镜像的源码提交哈希创建</li><li>否则，<em>部署分支基于当前部署分支的最新提交创建</em></li></ol></li><li>镜像被部署到下一个 SDLC 环境，使用的部署描述符是该环境中新创建的部署分支的部署描述符</li></ol><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220326162117.png" alt="deployment branching tree"></p><p><em>图 1：部署分支树</em></p><ol><li>部署分支</li><li>下游环境的第一个部署分支，只有一次提交</li><li>下游环境的第二个部署分支，只有一次提交</li></ol><p>有了部署分支这个解决方案，再回顾下上面的场景 C 和场景 D：</p><p><strong>场景 C</strong> 修改已经部署到下游 SDLC 环境中的镜像的部署描述符</p><p><strong>场景 D</strong> 修复某个 SDLC 环境中部署描述符的错误</p><p>两个场景中，工作流如下：</p><ol><li>把对部署描述符做的修改提交到 SLDC 环境和镜像对应的部署分支</li><li>通过部署分支最新提交对应的部署描述符把镜像重新部署到 SLDC 环境</li></ol><p>这样，部署分支彻底解决了（存储着代表一次独一无二的构建的单一的、不可修改的镜像的）镜像仓库与（存储着对应一个或多个 SDLC 环境的可修改的部署描述符的）SCM 仓库之间的阻抗失配。</p><h3><span id="实践中的思考">实践中的思考</span></h3><p>这看起来像是行得通的解决方案，但同时它也为开发者和运维人员带来了新的实践中的问题，比如：</p><p>A. 为了更好地管理部署分支，部署描述符作为资源应该保存在哪里，是否要与构建镜像的源码保存在同一个 SCM 仓库？</p><p>到目前为止，我们都在避免谈论应该把部署描述符放在哪个仓库里。在还没有太多细节需要处理时，我们推荐把所有 SDLC 环境的部署描述符与镜像源码放在同一个 SCM 仓库。当部署分支创建后，镜像的源码可以作为方便找到部署的容器中运行的镜像的引用来使用。</p><p>上面提到过，可以通过镜像的标签来关联镜像与原始的源码提交。在一个单独的仓库中查找某次提交的源码的引用，会给开发者带来更大的困难（即便借助工具），这就是没有必要把所有资源都分开存储的原因。</p><p>B. 应该在部署分支上修改构建镜像的源码吗？</p><p>简答：<strong>不应该</strong>。</p><p>详细阐述：不应该，因为永远不要在部署分支上构建镜像，它们是在开发分支上构建的。修改部署分支上定义一个镜像的源码会破坏被部署的镜像的构建记录，而且这些修改并不会对镜像的功能生效。在对比两个部署分支的版本时这也会成为问题。这可能会导致两个版本的功能差异有错误的测试结果（这是使用部署分支的一个很小的额外好处）。</p><p>C. 为什么使用镜像 <ruby>标签<rt>tag</rt></ruby>？<ruby>标记<rt>label</rt></ruby> 不可以吗？</p><p>通过 <ruby>标签<rt>tag</rt></ruby> 可以在仓库中很容易地查找镜像，可读性也很好。在一组镜像中读取和查找 <ruby>标记<rt>label</rt></ruby> 的值需要拉取所有镜像的<ruby>清单文件<rt>manifest</rt></ruby>，而这会增加复杂度、降低性能。而且，考虑到历史记录的追踪和不同版本的查找，对不同版本的镜像添加 <ruby>标签<rt>tag</rt></ruby> 也很有必要，因此使用源码提交哈希是保证唯一性，以及保存能即时生效的有用信息的最简单的解决方案。</p><p>D. 创建部署分支的最佳实践是怎样的？</p><p>DevOps 最重要的三个原则：自动化、自动化、自动化。</p><p>依赖资源来持续地强迫遵循最佳实践，充其量只是碰运气，因此在实现镜像的升级、回滚等 CI/CD 流水线时，把自动化部署分支写到脚本里。</p><p>E. 对部署分支的命名规范有建议吗？</p><p>&lt;<strong>部署分支标识</strong>&gt;-&lt;<strong>环境</strong>&gt;-&lt;<strong>源码提交哈希</strong>&gt;</p><ul><li><strong>部署分支标识</strong>： 所有部署分支范围内唯一的字符串；如 “deployment” 或 “deploy”</li><li><strong>环境</strong>： 部署分支适用的 SDLC 环境；如 “qa”（测试环境）、 “stg”（预生产环境）、 或 “prod”（生产环境）</li><li><strong>源码提交哈希</strong>： 源码提交哈希中包含原来构建被部署的镜像的源码，开发者可以通过它很容易地查找到创建镜像的原始提交，同时也能保证分支名唯一。</li></ul><p>例如， <code>deployment-qa-asdf78s</code> 表示推到 QA 环境的部署分支， <code>deployment-stg-asdf78s</code> 表示推到 STG 环境的部署分支。</p><p>F. 你怎么识别环境中运行的哪个镜像版本？</p><p>我们的建议是把最新的部署分支提交哈希和源码提交哈希添加到 <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/">标记</a> 中。开发者和运维人员可以通过这两个独一无二的标识符查找到部署的所有东西及其来源。在诸如执行回滚或前滚操作时，使用那些不同版本的部署的选择器也能清理资源碎片。</p><p>G. 什么时候应该把部署分支的修改合并回开发分支？</p><p>这完全取决于开发团队。</p><p>如果你修改的目的是为了做负载测试，只是想验证什么情况会让程序崩溃，那么这些修改不应该被合并回开发分支。另一方面，如果你发现和修复了一个错误，或者对下游环境的部署做了调整，那么就应该把部署分支的修改合并回开发分支。</p><p>H. 有现成的部署分支示例让我们试水吗？</p><p><a href="https://github.com/elcicd">el-CICD</a> 已经在生产上使用这个策略持续一年半应用到超过一百个项目了，覆盖所有的 SDLC 环境，包括管理生产环境的部署。如果你可以访问 <a href="https://www.okd.io/">OKD</a>、Red Hat OpenShift lab cluster 或 <a href="https://cloud.redhat.com/openshift/create/local">Red Hat CodeReady Containers</a>，你可以下载<a href="https://github.com/elcicd/el-CICD-RELEASES">el-CICD 的最新版本</a>，参照 <a href="https://github.com/elcicd/el-CICD-docs/blob/master/tutorial.md">教程</a> 来学习部署分支是何时以怎样的方式创建和使用的。</p><h3><span id="结语">结语</span></h3><p>通过实践上面的例子可以帮助你更好的理解开发过程中阻抗失配相关的问题。对齐镜像和部署描述符是成功管理部署的关键部分。</p><hr><p>via: <a href="https://opensource.com/article/21/8/impedance-mismatch-cicd">https://opensource.com/article/21/8/impedance-mismatch-cicd</a></p><p>作者：<a href="https://opensource.com/users/hippyod">Evan “Hippy” Slatis</a><br>选题：<a href="https://github.com/lujun9972">lujun9972</a><br>译者：<a href="https://github.com/lxbwolf">lxbwolf</a><br>校对：<a href="https://github.com/wxy">wxy</a></p><p>本文由 <a href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创编译，<a href="https://linux.cn/">Linux中国</a> 荣誉推出</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#阻抗失配scm-与镜像仓库&quot;&gt;阻抗失配：SCM 与镜像仓库&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#二进制与部署描述符&quot;&gt;二进制与部署描述符&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#解决阻抗失配&quot;&gt;解决
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxb.wiki/categories/Design/"/>
    
    
      <category term="翻译" scheme="https://lxb.wiki/tags/%E7%BF%BB%E8%AF%91/"/>
    
      <category term="解决" scheme="https://lxb.wiki/tags/%E8%A7%A3%E5%86%B3/"/>
    
      <category term="优化" scheme="https://lxb.wiki/tags/%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Postman 自动填充 Header</title>
    <link href="https://lxb.wiki/3632d5ff/"/>
    <id>https://lxb.wiki/3632d5ff/</id>
    <published>2022-03-10T14:51:15.000Z</published>
    <updated>2022-07-10T11:09:54.393Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#基本流程">基本流程</a></li><li><a href="#postman实现">Postman实现</a><ul><li><a href="#新增一个环境">新增一个环境</a></li><li><a href="#设置环境变量">设置环境变量</a></li><li><a href="#设置-tests">设置 Tests</a></li><li><a href="#设置自定义固定头部">设置自定义固定头部</a></li></ul></li></ul><!-- tocstop --><h3><span id="基本流程">基本流程</span></h3><pre class="mermaid">sequenceDiagramparticipant c as Clientparticipant s as Serverc ->> s: request Head为空s ->> c: token在response中c ->> s: 取出token；设置Head</pre><h3><span id="postman实现">Postman实现</span></h3><h4><span id="新增一个环境">新增一个环境</span></h4><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710185857.png" alt></p><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710185930.png" alt></p><h4><span id="设置环境变量">设置环境变量</span></h4><p><code>VARIABLE</code> 名为为 <code>token</code>, <code>VALUE</code> 为空</p><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710190008.png" alt></p><h4><span id="设置-tests">设置 Tests</span></h4><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710190305.png" alt></p><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710190344.png" alt></p><p>然后点击发送。如果请求正常，那值就会填充到你的环境中。</p><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710190423.png" alt></p><h4><span id="设置自定义固定头部">设置自定义固定头部</span></h4><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710190508.png" alt></p><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710190527.png" alt></p><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710190547.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#基本流程&quot;&gt;基本流程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#postman实现&quot;&gt;Postman实现&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#新增一个环境&quot;&gt;新增一个环境&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a
      
    
    </summary>
    
    
      <category term="Tools" scheme="https://lxb.wiki/categories/Tools/"/>
    
    
      <category term="工具" scheme="https://lxb.wiki/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="postman" scheme="https://lxb.wiki/tags/postman/"/>
    
  </entry>
  
  <entry>
    <title>Joplin配置TeraCloud的WebDav进行同步</title>
    <link href="https://lxb.wiki/f3376d3f/"/>
    <id>https://lxb.wiki/f3376d3f/</id>
    <published>2022-01-15T12:01:15.000Z</published>
    <updated>2022-07-10T10:49:20.345Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#为什么不再使用坚果云">为什么不再使用坚果云</a></li><li><a href="#joplin-配置teracloud-的webdav">Joplin 配置teracloud 的WebDav</a><ul><li><a href="#teracloud注册">TeraCLOUD注册</a></li><li><a href="#登录填写推荐码">登录&amp;填写推荐码</a></li><li><a href="#设置teracloud">设置TeraCLOUD</a></li></ul></li></ul><!-- tocstop --><h3><span id="为什么不再使用坚果云">为什么不再使用坚果云</span></h3><p>使用坚果云同步笔记，出现了无法解决的灾难性问题</p><blockquote><p>第三方应用访问的限制<br>文件上传大小限制： 当前 WebDAV 客户端和网页端上传大小的限制是一致的，默认为 500M（私有云可以通过相关设置调整）。</p><p>访问频率限制： 由于WebDAV协议比较占用系统资源，免费版用户限制访问频率为每30分钟不超过600次请求。付费用户限制访问频率为每30分钟不超过1500次请求。</p><p>同步目录数限制： 目前坚果云的WebDAV协议单次请求文件数（包含文件和文件夹）为750个，支持分多页多次加载。如果您使用WebDAV的三方工具未实现按分页多次加载，可能会出现文件同步不完整的情况，建议您使用坚果云客户端进行直接同步。</p></blockquote><p>用坚果云同步joplin是个糟糕的选择，目前有两个问题：<br>一个是短时间大量同步文件，会触发坚果云的限制，导致同步失败，当触发该限制后，我们能做的只有耐心等待6个小时，该限制与免费版/专业版没有关系。<br>另一个才是灾难，坚果云对同一文件夹内的文件采取分页传输的机制，导致Joplin一次不能获取全部文件列表，导致Joplin认为有些文件在服务器端不存在，即认为该文件要被删除，Joplin就会删除本地对应的内容，直接的表现就是当笔记达到一定数量后用坚果云同步就会出现频繁的丢笔记现象。</p><p>目前Joplin官方也不建议使用坚果云。</p><p><a href="https://joplinapp.org/faq/#the-following-webdav-hosts-are-not-supported">FAQ | Joplin (joplinapp.org)</a></p><p>在 2021 年 1 月已经有用户提过 issue</p><p><a href="https://github.com/laurent22/joplin/issues/4294">Data lost when using the webdav to sync data · Issue #4294 · laurent22/joplin (github.com)</a></p><h3><span id="joplin-配置teracloud-的webdav">Joplin 配置teracloud 的WebDav</span></h3><h4><span id="teracloud注册">TeraCLOUD注册</span></h4><p>官网地址：<a href="https://teracloud.jp/en/。">https://teracloud.jp/en/。</a></p><p>进入上述官网地址之后，点击 <code>Create Account</code></p><h4><span id="登录amp填写推荐码">登录&amp;填写推荐码</span></h4><p>注册账号之后，在官网地址点击 <code>Login</code> 登录。<br>登录之后，点击 <code>My Page</code> ，进入我的页面。</p><p>免费用户默认只给10G空间，如果使用推荐码，可以再增加5G空间。</p><p>在 <code>My Page</code> 页面，<code>Referral Bonus-&gt;Enter Friends Referral Code</code>，填写推荐码即可，如下所示。</p><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710182918.png" alt></p><p>我的推荐码：BQMZ7。</p><h4><span id="设置teracloud">设置TeraCLOUD</span></h4><p><strong>开启WebDAV</strong></p><p>进入 <a href="https://teracloud.jp/en/modules/mypage/usage/">My Page</a> 页面，找到<code>Apps Connection</code>，勾选<code>Turn on Apps Connection</code>，如下图所示：</p><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710183145.png" alt></p><p><strong>创建Joplin同步文件夹</strong></p><p>从首页进入 <a href="https://aki.teracloud.jp/browser/">File Browser</a> 页面，创建用于Joplin同步的文件夹，如创建一个名为 <code>terajoplin</code> 的文件件</p><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710183450.png" alt></p><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710183642.png" alt></p><p><strong>配置Joplin</strong></p><p>打开 Joplin 客户端的 <code>同步</code> 选项</p><p><img src="https://raw.githubusercontent.com/lxbwolf/blog_source_image/main/20220710184839.png" alt></p><ul><li><p>同步目标选 <code>Nextcloud</code></p></li><li><p><code>Nextcloud WebDAV URL</code> 为 <a href="https://teracloud.jp/en/modules/mypage/usage/">My Page|TeraCLOUD</a> 中 <code>Apps Connection</code> 里的 <code>WebDAV Connection URL</code>后加刚刚在 <code>File Browser</code> 创建的目录名</p></li><li><p><code>Nextcloud username</code> 为 <a href="https://teracloud.jp/en/modules/mypage/usage/">My Page|TeraCLOUD</a> 中 <code>Apps Connection</code> 里的 <code>Connection ID</code></p></li><li><p><code>Nextcloud password</code> 为 <a href="https://teracloud.jp/en/modules/mypage/usage/">My Page|TeraCLOUD</a> 中 <code>Apps Connection</code> 里的 <code>Apps Password</code></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#为什么不再使用坚果云&quot;&gt;为什么不再使用坚果云&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#joplin-配置teracloud-的webdav&quot;&gt;Joplin 配置teracloud 的WebDav&lt;/a&gt;&lt;ul
      
    
    </summary>
    
    
      <category term="Tools" scheme="https://lxb.wiki/categories/Tools/"/>
    
    
      <category term="joplin" scheme="https://lxb.wiki/tags/joplin/"/>
    
  </entry>
  
  <entry>
    <title>SLO 和 SLA 的区别</title>
    <link href="https://lxb.wiki/ee700d45/"/>
    <id>https://lxb.wiki/ee700d45/</id>
    <published>2021-12-15T13:08:32.000Z</published>
    <updated>2022-03-29T03:20:54.417Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#前言">前言</a></li><li><a href="#service">Service</a></li><li><a href="#sli">SLI</a><ul><li><a href="#1-常见的测量指标有以下几个方面">1. 常见的测量指标有以下几个方面：</a></li><li><a href="#2-测量时的系统状态在什么情况下测量会严重影响测量的结果">2. 测量时的系统状态，在什么情况下测量会严重影响测量的结果</a></li><li><a href="#3-如何汇总处理测量的指标">3. 如何汇总处理测量的指标？</a></li><li><a href="#4-测量指标能否准确描述服务质量">4. 测量指标能否准确描述服务质量？</a></li><li><a href="#5-测量指标的可靠度">5. 测量指标的可靠度</a></li></ul></li><li><a href="#slo">SLO</a></li><li><a href="#sla">SLA</a></li></ul><!-- tocstop --><h2><span id="前言">前言</span></h2><p><strong>SLO和SLA是大家常见的两个名词：服务等级目标和服务等级协议。</strong></p><p>云计算时代，各大云服务提供商都发布有自己服务的SLA条款，比如Amazon的EC2和S3服务都有相应的SLA条款。这些大公司的SLA看上去如此的高达上，一般是怎么定义出来的呢？本文就尝试从技术角度解剖一下SLA的制定过程。</p><p>说SLA不能不提SLO，这个是众所周知的，但是还有一个概念知道的人就不多了，那就是SLI（Service Level Indicator），<strong>定义一个可执行的SLA，好的SLO和SLI是必不可少的</strong>。</p><p>再有就是SLI/SLO/SLA都是和服务联系在一起的，脱离了服务这三个概念就没有什么意义了。</p><h2><span id="service">Service</span></h2><p><strong>什么是服务？</strong></p><p>简单说就是一切提供给客户的有用功能都可以称为服务。</p><p>服务一般会由服务提供者提供，提供这个有用功能的组织被称为服务提供者，通常是人加上软件，软件的运行需要计算资源，为了能对外提供有用的功能软件可能会有对其他软件系统的依赖。</p><p>客户是使用服务提供者提供的服务的人或公司。</p><h2><span id="sli">SLI</span></h2><p>SLI是经过仔细定义的测量指标，它根据不同系统特点确定要测量什么，SLI的确定是一个非常复杂的过程。</p><p><strong>SLI的确定需要回答以下几个问题：</strong></p><ol><li>要测量的指标是什么？</li><li>测量时的系统状态？</li><li>如何汇总处理测量的指标？</li><li>测量指标能否准确描述服务质量？</li><li>测量指标的可靠度(trustworthy)？</li></ol><h3><span id="1-常见的测量指标有以下几个方面">1. 常见的测量指标有以下几个方面：</span></h3><ul><li><p>性能</p></li><li><ul><li>响应时间(latency)<ul><li>吞吐量(throughput)</li><li>请求量(qps)</li><li>实效性(freshness)</li></ul></li></ul></li><li><p>可用性</p></li><li><ul><li>运行时间(uptime)<ul><li>故障时间/频率</li><li>可靠性</li></ul></li></ul></li><li><p>质量</p></li><li><ul><li>准确性(accuracy)<ul><li>正确性(correctness)</li><li>完整性(completeness)</li><li>覆盖率(coverage)</li><li>相关性(relevance)</li></ul></li></ul></li><li><p>内部指标</p></li><li><ul><li>队列长度(queue length)<ul><li>内存占用(RAM usage)</li></ul></li></ul></li><li><p>因素人</p></li><li><ul><li>响应时间(time to response)<ul><li>修复时间(time to fix)</li><li>修复率(fraction fixed)</li></ul></li></ul></li></ul><p><strong>下面通过一个例子来说明一下：</strong>hotmail的downtime SLI</p><ul><li>错误率(error rate)计算的是服务返回给用户的error总数</li><li>如果错误率大于X%，就算是服务down了，开始计算downtime</li><li>如果错误率持续超过Y分钟，这个downtime就会被计算在内</li><li>间断性的小于Y分钟的downtime是不被计算在内的。</li></ul><h3><span id="2-测量时的系统状态在什么情况下测量会严重影响测量的结果">2. 测量时的系统状态，在什么情况下测量会严重影响测量的结果</span></h3><ul><li>测量异常(badly-formed)请求，还是失败(fail)请求还是超时请求(timeout)</li><li>测量时的系统负载（是否最大负载）</li><li>测量的发起位置，服务器端还是客户端</li><li>测量的时间窗口（仅工作日、还是一周7天、是否包括计划内的维护时间段）</li></ul><h3><span id="3-如何汇总处理测量的指标">3. 如何汇总处理测量的指标？</span></h3><ul><li>计算的时间区间是什么：是一个滚动时间窗口，还是简单的按照月份计算</li><li>使用平均值还是百分位值，比如：某服务X的ticket处理响应时间SLI的</li><li>测量指标：统计所有成功解决请求，从用户创建ticket到问题被解决的时间</li><li>怎么测量：用ticket自带的时间戳，统计所有用户创建的ticket</li><li>什么情况下的测量：只包括工作时间，不包含法定假日</li><li>用于SLI的数据指标：以一周为滑动窗口，95%分位的解决时间</li></ul><h3><span id="4-测量指标能否准确描述服务质量">4. 测量指标能否准确描述服务质量？</span></h3><ul><li>性能：时效性、是否有偏差</li><li>准确性：精度、覆盖率、数据稳定性</li><li>完整性：数据丢失、无效数据、异常(outlier)数据</li></ul><h3><span id="5-测量指标的可靠度">5. 测量指标的可靠度</span></h3><ul><li>是否服务提供者和客户都认可</li><li>是否可被独立验证，比如三方机构</li><li>客户端还是服务器端测量，取样间隔</li><li>错误请求是如何计算的</li></ul><h2><span id="slo">SLO</span></h2><p><strong>SLO(服务等级目标)</strong>指定了服务所提供功能的一种期望状态。SLO里面应该包含什么呢？所有能够描述服务应该提供什么样功能的信息。</p><p>服务提供者用它来指定系统的预期状态；开发人员编写代码来实现；客户依赖于SLO进行商业判断。SLO里没有提到，如果目标达不到会怎么样。</p><p><strong>SLO是用SLI来描述的，一般描述为：</strong><br>比如以下SLO：</p><ul><li>每分钟平均qps &gt; 100k/s</li><li>99% 访问延迟 &lt; 500ms</li><li>99% 每分钟带宽 &gt; 200MB/s</li></ul><p><strong>设置SLO时的几个最佳实践：</strong></p><ul><li>指定计算的时间窗口</li><li>使用一致的时间窗口(XX小时滚动窗口、季度滚动窗口)</li><li>要有一个免责条款，比如：95%的时间要能够达到SLO</li></ul><p>如果Service是第一次设置SLO，可以遵循以下原则</p><ul><li><p>测量系统当前状态</p></li><li><ul><li>设置预期(expectations)，而不是保证(guarantees)<ul><li>初期的SLO不适合作为服务质量的强化工具</li></ul></li></ul></li><li><p>改进SLO</p></li><li><ul><li>设置更低的响应时间、更改的吞吐量等</li></ul></li><li><p>保持一定的安全缓冲</p></li><li><ul><li>内部用的SLO要高于对外宣称的SLO</li></ul></li><li><p>不要超额完成</p></li><li><ul><li>定期的downtime来使SLO不超额完成</li></ul></li></ul><p>设置SLO时的目标依赖于系统的不同状态(conditions)，根据不同状态设置不同的SLO：<strong>总SLO = service1.SLO1 *weight1 service2.SLO2* weight2 …</strong></p><p>为什么要有SLO，设置SLO的好处是什么呢？</p><ul><li><p>对于客户而言，是可预期的服务质量，可以简化客户端的系统设计</p></li><li><p>对于服务提供者而言</p></li><li><ul><li>可预期的服务质量<ul><li>更好的取舍成本/收益</li><li>更好的风险控制(当资源受限的时候)</li><li>故障时更快的反应，采取正确措施</li></ul></li></ul></li></ul><p>SLO设好了，怎么保证能够达到目标呢？<br>需要一个控制系统来：</p><ul><li>监控/测量SLIs</li><li>对比检测到的SLIs值是否达到目标</li><li>如果需要，修证目标或者修正系统以满足目标需要</li><li>实施目标的修改或者系统的修改</li></ul><p>该控制系统需要重复的执行以上动作，以形成一个标准的反馈环路，不断的衡量和改进SLO/服务本身。</p><p>我们讨论了目标以及目标是怎么测量的，还讨论了控制机制来达到设置的目标，但是如果因为某些原因，设置的目标达不到该怎么办呢？</p><p>也许是因为大量的新增负载；也许是因为底层依赖不能达到标称的SLO而影响上次服务的SLO。这就需要SLA出场了。</p><h2><span id="sla">SLA</span></h2><p>SLA是一个涉及2方的合约，双方必须都要同意并遵守这个合约。当需要对外提供服务时，SLA是非常重要的一个服务质量信号，需要产品和法务部门的同时介入。</p><p>SLA用一个简单的公式来描述就是： <strong>SLA = SLO 后果</strong></p><ul><li><p>SLO不能满足的一系列动作，可以是部分不能达到</p></li><li><ul><li>比如：达到响应时间SLO 未达到可用性SLO</li></ul></li><li><p>对动作的具体实施</p></li><li><ul><li>需要一个通用的货币来奖励/惩罚，比如：钱</li></ul></li></ul><p>SLA是一个很好的工具，可以用来帮助合理配置资源。一个有明确SLA的服务最理想的运行状态是：<strong>增加额外资源来改进系统所带来的收益小于把该资源投给其他服务所带来的收益。</strong></p><p>一个简单的例子就是某服务可用性从99.9%提高到99.99%所需要的资源和带来的收益之比，是决定该服务是否应该提供4个9的重要依据。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#service&quot;&gt;Service&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#sli&quot;&gt;SLI&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-常见的测
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxb.wiki/categories/Design/"/>
    
    
      <category term="架构" scheme="https://lxb.wiki/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>如何写好业务代码</title>
    <link href="https://lxb.wiki/4c5cb7f3/"/>
    <id>https://lxb.wiki/4c5cb7f3/</id>
    <published>2021-12-08T13:51:01.000Z</published>
    <updated>2022-03-28T03:09:04.589Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#一个复杂业务的处理过程">一个复杂业务的处理过程</a><ul><li><a href="#业务背景">业务背景</a></li><li><a href="#过程分解">过程分解</a></li><li><a href="#过程分解后的两个问题">过程分解后的两个问题</a><ul><li><a href="#1-领域知识被割裂肢解">1、领域知识被割裂肢解</a></li><li><a href="#2-代码的业务表达能力缺失">2、代码的业务表达能力缺失</a></li></ul></li><li><a href="#过程分解对象模型">过程分解+对象模型</a></li></ul></li><li><a href="#写复杂业务的方法论">写复杂业务的方法论</a><ul><li><a href="#上下结合">上下结合</a></li><li><a href="#能力下沉">能力下沉</a><ul><li><a href="#套概念阶段">套概念阶段</a></li><li><a href="#融会贯通阶段">融会贯通阶段</a></li></ul></li></ul></li><li><a href="#业务技术要怎么做">业务技术要怎么做</a></li></ul><!-- tocstop --><p>基于阿里的零售通业务，总结出的方法论。</p><h2><span id="一个复杂业务的处理过程">一个复杂业务的处理过程</span></h2><h3><span id="业务背景">业务背景</span></h3><p>零售通是给线下小店供货的B2B模式，我们希望通过数字化重构传统供应链渠道，提升供应链效率，为新零售助力。阿里在中间是一个平台角色，提供的是Bsbc中的service的功能。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220328105411.png" alt></p><p>在商品域，运营会操作一个“上架”动作，上架之后，商品就能在零售通上面对小店进行销售了。<strong>是零售通业务非常关键的业务操作之一，因此涉及很多的数据校验和关联操作</strong>。</p><p>针对上架，一个简化的业务流程如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220328105454.png" alt></p><h3><span id="过程分解">过程分解</span></h3><p>像这么复杂的业务，我想应该没有人会写在一个service方法中吧。一个类解决不了，那就分治吧。</p><p>说实话，能想到分而治之的工程师，已经做的不错了，至少比没有分治思维要好很多。我也见过复杂程度相当的业务，连分解都没有，就是一堆方法和类的堆砌。</p><p>不过，这里存在一个问题：即很多同学过度的依赖工具或是辅助手段来实现分解。比如在我们的商品域中，类似的分解手段至少有3套以上，有自制的<a href="流程引擎">流程引擎</a>，有依赖于数据库配置的流程处理：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220328105631.png" alt></p><p>本质上来讲，这些辅助手段做的都是一个pipeline的处理流程，没有其它。因此，我建议此处最好保持KISS（Keep It Simple and Stupid），即<strong>最好是什么工具都不要用，次之是用一个极简的Pipeline模式，最差是使用像流程引擎这样的重方法</strong>。</p><p>除非你的应用有极强的流程可视化和编排的诉求，否则我非常不推荐使用流程引擎等工具。第一，它会引入额外的复杂度，特别是那些需要持久化状态的流程引擎；第二，它会割裂代码，导致阅读代码的不顺畅。<strong>大胆断言一下，全天下估计80%对流程引擎的使用都是得不偿失的</strong>。</p><p>回到商品上架的问题，这里问题核心是工具吗？是设计模式带来的代码灵活性吗？显然不是，<strong>问题的核心应该是如何分解问题和抽象问题</strong>，知道金<a href="金字塔原理">字塔原理</a>的应该知道，此处，我们可以使用结构化分解将问题解构成一个有层级的金字塔结构：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220328105756.png" alt></p><p>按照这种分解写的代码，就像一本书，目录和内容清晰明了。</p><p>以商品上架为例，程序的入口是一个上架命令（OnSaleCommand）, 它由三个阶段（Phase）组成。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Command</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OnSaleNormalItemCmdExe</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> OnSaleContextInitPhase onSaleContextInitPhase;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> OnSaleDataCheckPhase onSaleDataCheckPhase;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> OnSaleProcessPhase onSaleProcessPhase;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Response <span class="title function_">execute</span><span class="params">(OnSaleNormalItemCmd cmd)</span> &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="type">OnSaleContext</span> <span class="variable">onSaleContext</span> <span class="operator">=</span> init(cmd);</span><br><span class="line">        </span><br><span class="line">        checkData(onSaleContext);</span><br><span class="line"></span><br><span class="line">        process(onSaleContext);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Response.buildSuccess();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> OnSaleContext <span class="title function_">init</span><span class="params">(OnSaleNormalItemCmd cmd)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> onSaleContextInitPhase.init(cmd);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">checkData</span><span class="params">(OnSaleContext onSaleContext)</span> &#123;</span><br><span class="line">        onSaleDataCheckPhase.check(onSaleContext);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(OnSaleContext onSaleContext)</span> &#123;</span><br><span class="line">        onSaleProcessPhase.process(onSaleContext);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每个Phase又可以拆解成多个步骤（Step），以<code>OnSaleProcessPhase</code>为例，它是由一系列Step组成的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Phase</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OnSaleProcessPhase</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> PublishOfferStep publishOfferStep;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> BackOfferBindStep backOfferBindStep;</span><br><span class="line">    <span class="comment">//省略其它step</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(OnSaleContext onSaleContext)</span>&#123;</span><br><span class="line">        <span class="type">SupplierItem</span> <span class="variable">supplierItem</span> <span class="operator">=</span> onSaleContext.getSupplierItem();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 生成OfferGroupNo</span></span><br><span class="line">        generateOfferGroupNo(supplierItem);</span><br><span class="line">       </span><br><span class="line">       <span class="comment">// 发布商品</span></span><br><span class="line">        publishOffer(supplierItem);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 前后端库存绑定 backoffer域</span></span><br><span class="line">        bindBackOfferStock(supplierItem);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 同步库存路由 backoffer域</span></span><br><span class="line">        syncStockRoute(supplierItem);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置虚拟商品拓展字段</span></span><br><span class="line">        setVirtualProductExtension(supplierItem);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 发货保障打标 offer域</span></span><br><span class="line">        markSendProtection(supplierItem);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 记录变更内容ChangeDetail</span></span><br><span class="line">        recordChangeDetail(supplierItem);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 同步供货价到BackOffer</span></span><br><span class="line">        syncSupplyPriceToBackOffer(supplierItem);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果是组合商品打标，写扩展信息</span></span><br><span class="line">        setCombineProductExtension(supplierItem);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 去售罄标</span></span><br><span class="line">        removeSellOutTag(offerId);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 发送领域事件</span></span><br><span class="line">        fireDomainEvent(supplierItem);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 关闭关联的待办事项</span></span><br><span class="line">        closeIssues(supplierItem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看到了吗，这就是商品上架这个复杂业务的业务流程。需要流程引擎吗？不需要，需要设计模式支撑吗？也不需要。对于这种业务流程的表达，简单朴素的组合方法模式（Composed Method）是再合适不过的了。</p><p>因此，在做过程分解的时候，我建议工程师不要把太多精力放在工具上，放在设计模式带来的灵活性上。而是应该多花时间在对问题分析，结构化分解，最后通过合理的抽象，形成合适的阶段（Phase）和步骤（Step）上。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220328110024.png" alt></p><h3><span id="过程分解后的两个问题">过程分解后的两个问题</span></h3><h4><span id="1-领域知识被割裂肢解">1、领域知识被割裂肢解</span></h4><p>什么叫被肢解？因为我们到目前为止做的都是过程化拆解，导致没有一个聚合领域知识的地方。每个Use Case的代码只关心自己的处理流程，知识没有沉淀。</p><p>相同的业务逻辑会在多个Use Case中被重复实现，导致代码重复度高，即使有复用，最多也就是抽取一个util，代码对业务语义的表达能力很弱，从而影响代码的可读性和可理解性。</p><h4><span id="2-代码的业务表达能力缺失">2、代码的业务表达能力缺失</span></h4><p>试想下，在过程式的代码中，所做的事情无外乎就是取数据–做计算–存数据，在这种情况下，要如何通过代码显性化的表达我们的业务呢？ 说实话，很难做到，因为我们缺失了模型，以及模型之间的关系。脱离模型的业务表达，是缺少韵律和灵魂的。</p><p>举个例子，在上架过程中，有一个校验是检查库存的，其中对于组合品（CombineBackOffer）其库存的处理会和普通品不一样。原来的代码是这么写的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">boolean</span> <span class="variable">isCombineProduct</span> <span class="operator">=</span> supplierItem.getSign().isCombProductQuote();</span><br><span class="line"></span><br><span class="line"><span class="comment">// supplier.usc warehouse needn&#x27;t check</span></span><br><span class="line"><span class="keyword">if</span> (WarehouseTypeEnum.isAliWarehouse(supplierItem.getWarehouseType())) &#123;</span><br><span class="line"><span class="comment">// quote warehosue check</span></span><br><span class="line"><span class="keyword">if</span> (CollectionUtil.isEmpty(supplierItem.getWarehouseIdList()) &amp;&amp; !isCombineProduct) &#123;</span><br><span class="line">    <span class="keyword">throw</span> ExceptionFactory.makeFault(ServiceExceptionCode.SYSTEM_ERROR, <span class="string">&quot;亲，不能发布Offer，请联系仓配运营人员，建立品仓关系！&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// inventory amount check</span></span><br><span class="line"><span class="type">Long</span> <span class="variable">sellableAmount</span> <span class="operator">=</span> <span class="number">0L</span>;</span><br><span class="line"><span class="keyword">if</span> (!isCombineProduct) &#123;</span><br><span class="line">    sellableAmount = normalBiz.acquireSellableAmount(supplierItem.getBackOfferId(), supplierItem.getWarehouseIdList());</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">//组套商品</span></span><br><span class="line">    <span class="type">OfferModel</span> <span class="variable">backOffer</span> <span class="operator">=</span> backOfferQueryService.getBackOffer(supplierItem.getBackOfferId());</span><br><span class="line">    <span class="keyword">if</span> (backOffer != <span class="literal">null</span>) &#123;</span><br><span class="line">        sellableAmount = backOffer.getOffer().getTradeModel().getTradeCondition().getAmountOnSale();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (sellableAmount &lt; <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> ExceptionFactory.makeFault(ServiceExceptionCode.SYSTEM_ERROR, <span class="string">&quot;亲，实仓库存必须大于0才能发布，请确认已补货.\r[id:&quot;</span> + supplierItem.getId() + <span class="string">&quot;]&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然而，如果我们在系统中引入领域模型之后，其代码会简化为如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(backOffer.isCloudWarehouse())&#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (backOffer.isNonInWarehouse())&#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">BizException</span>(<span class="string">&quot;亲，不能发布Offer，请联系仓配运营人员，建立品仓关系！&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (backOffer.getStockAmount() &lt; <span class="number">1</span>)&#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">BizException</span>(<span class="string">&quot;亲，实仓库存必须大于0才能发布，请确认已补货.\r[id:&quot;</span> + backOffer.getSupplierItem().getCspuCode() + <span class="string">&quot;]&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有没有发现，使用模型的表达要清晰易懂很多，而且也不需要做关于组合品的判断了，因为我们在系统中引入了更加贴近现实的对象模型（CombineBackOffer继承BackOffer），通过对象的多态可以消除我们代码中的大部分的 if-else。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220328110230.png" alt></p><h3><span id="过程分解对象模型">过程分解+对象模型</span></h3><p>通过上面的案例，我们可以看到<strong>有过程分解要好于没有分解</strong>，<strong>过程分解+对象模型要好于仅仅是过程分解</strong>。对于商品上架这个case，如果采用过程分解+对象模型的方式，最终我们会得到一个如下的系统结构：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220328110335.png" alt></p><h2><span id="写复杂业务的方法论">写复杂业务的方法论</span></h2><p>通过上面案例的讲解，我想说，我已经交代了复杂业务代码要怎么写：<strong>即自上而下的结构化分解+自下而上的<a href="面向对象分析">面向对象分析</a></strong>。</p><p>接下来，让我们把上面的案例进行进一步的提炼，形成一个可落地的方法论，从而可以泛化到更多的复杂业务场景。</p><h3><span id="上下结合">上下结合</span></h3><p>所谓上下结合，是指我们要<strong>结合自上而下的过程分解和自下而上的对象建模</strong>，螺旋式的构建我们的应用系统。这是一个动态的过程，两个步骤可以交替进行、也可以同时进行。</p><p>这两个步骤是相辅相成的，<strong>上面的分析可以帮助我们更好的理清模型之间的关系，而下面的模型表达可以提升我们代码的复用度和业务语义表达能力</strong>。</p><p>其过程如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220328110449.png" alt></p><p>使用这种上下结合的方式，我们就有可能在面对任何复杂的业务场景，都能写出干净整洁、易维护的代码。</p><h3><span id="能力下沉">能力下沉</span></h3><p>一般来说实践DDD有两个过程：</p><ol><li><h4><span id="套概念阶段">套概念阶段</span></h4></li></ol><p>了解了一些DDD的概念，然后在代码中“使用”Aggregation Root，Bonded Context，Repository等等这些概念。更进一步，也会使用一定的分层策略。然而这种做法一般对<a href="https://www.zhihu.com/search?q=复杂度&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={" sourcetype"%3a"answer"%2c"sourceid"%3a874296743}">复杂度</a>的治理并没有多大作用。</p><ol start="2"><li><h4><span id="融会贯通阶段">融会贯通阶段</span></h4></li></ol><p>术语已经不再重要，理解DDD的本质是统一语言、边界划分和面向对象分析的方法。</p><p>大体上而言，我大概是在1.7的阶段，因为有一个问题一直在困扰我，就是哪些能力应该放在Domain层，是不是按照传统的做法，将所有的业务都收拢到Domain上，这样做合理吗？说实话，这个问题我一直没有想清楚。</p><p>因为在现实业务中，很多的功能都是用例特有的（Use case specific）的，如果“盲目”的使用Domain收拢业务并不见得能带来多大的益处。相反，这种收拢会导致Domain层的膨胀过厚，不够纯粹，反而会影响复用性和表达能力。</p><p>鉴于此，我最近的思考是我们应该采用<strong>能力下沉</strong>的策略。</p><p>所谓的能力下沉，是指我们不强求一次就能设计出Domain的能力，也不需要强制要求把所有的业务功能都放到Domain层，而是采用实用主义的态度，即只对那些需要在多个场景中需要被复用的能力进行抽象下沉，而不需要复用的，就暂时放在App层的Use Case里就好了。</p><p>注：Use Case是《架构整洁之道》里面的术语，简单理解就是响应一个Request的处理过程</p><p>通过实践，<strong>我发现这种循序渐进的能力下沉策略，应该是一种更符合实际、更敏捷的方法。因为我们承认模型不是一次性设计出来的，而是迭代演化出来的。</strong></p><p>下沉的过程如下图所示，假设两个use case中，我们发现uc1的step3和uc2的step1有类似的功能，我们就可以考虑让其下沉到Domain层，从而增加代码的复用性。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220328110552.png" alt></p><p><strong>指导下沉有两个关键指标：代码的复用性和内聚性</strong>。</p><p>复用性是告诉我们When（什么时候该下沉了），即有重复代码的时候。内聚性是告诉我们How（要下沉到哪里），功能有没有内聚到恰当的实体上，有没有放到合适的层次上（因为Domain层的能力也是有两个层次的，一个是Domain Service这是相对比较粗的粒度，另一个是Domain的Model这个是最细粒度的复用）。</p><p>比如，在我们的商品域，经常需要判断一个商品是不是最小单位，是不是中包商品。像这种能力就非常有必要直接挂载在Model上。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CSPU</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String code;</span><br><span class="line">    <span class="keyword">private</span> String baseCode;</span><br><span class="line">    <span class="comment">//省略其它属性</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 单品是否为最小单位。</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isMinimumUnit</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> StringUtils.equals(code, baseCode);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 针对中包的特殊处理</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isMidPackage</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> StringUtils.equals(code, midPackageCode);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之前，因为老系统中没有领域模型，没有CSPU这个实体。你会发现像判断单品是否为最小单位的逻辑是以<code>StringUtils.equals(code, baseCode)</code>的形式散落在代码的各个角落。这种代码的可理解性是可想而知的，至少我在第一眼看到这个代码的时候，是完全不知道什么意思。</p><h2><span id="业务技术要怎么做">业务技术要怎么做</span></h2><p><strong>业务技术到底是在做业务，还是做技术？业务技术的技术性体现在哪里？</strong></p><p>通过上面的案例，我们可以看到业务所面临的复杂性并不亚于底层技术，要想写好业务代码也不是一件容易的事情。业务技术和底层技术人员唯一的区别是他们所面临的问题域不一样。</p><p>业务技术面对的问题域变化更多、面对的人更加庞杂。而底层技术面对的问题域更加稳定、但对技术的要求更加深。比如，如果你需要去开发Pandora，你就要对Classloader有更加深入的了解才行。</p><p>但是，不管是业务技术还是底层技术人员，有一些思维和能力都是共通的。比如，<strong>分解问题的能力，抽象思维，结构化思维</strong>等等。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220328110806.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#一个复杂业务的处理过程&quot;&gt;一个复杂业务的处理过程&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#业务背景&quot;&gt;业务背景&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#过程分解&quot;&gt;过程分解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxb.wiki/categories/Design/"/>
    
    
      <category term="业务" scheme="https://lxb.wiki/tags/%E4%B8%9A%E5%8A%A1/"/>
    
      <category term="代码" scheme="https://lxb.wiki/tags/%E4%BB%A3%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Go 语言内存分配</title>
    <link href="https://lxb.wiki/57be14fe/"/>
    <id>https://lxb.wiki/57be14fe/</id>
    <published>2021-11-20T14:39:07.000Z</published>
    <updated>2022-03-12T12:48:52.319Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#基础概念">基础概念</a></li><li><a href="#内存管理单元">内存管理单元</a></li><li><a href="#内存管理组件">内存管理组件</a></li><li><a href="#mcache">mcache</a></li><li><a href="#mcentral">mcentral</a></li><li><a href="#mheap">mheap</a></li><li><a href="#分配流程">分配流程</a></li><li><a href="#总结">总结</a></li></ul><!-- tocstop --><p>Go语言内置运行时（就是runtime），抛弃了传统的内存分配方式，改为自主管理。这样可以自主地实现更好的内存使用模式，比如内存池、预分配等等。这样，不会每次内存分配都需要进行系统调用。</p><p>Golang运行时的内存分配算法主要源自 Google 为 C 语言开发的 TCMalloc算法，全称 Thread-CachingMalloc。核心思想就是把内存分为多级管理，从而降低锁的粒度。它将可用的堆内存采用二级分配的方式进行管理：每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向全局内存池申请，以避免不同线程对全局内存池的频繁竞争。</p><h2><span id="基础概念">基础概念</span></h2><p>Go在程序启动的时候，会先向操作系统申请一块内存（注意这时还只是一段虚拟的地址空间，并不会真正地分配内存），切成小块后自己进行管理。</p><p>申请到的内存块被分配了三个区域，在X64上分别是512MB，16GB，512GB大小。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312204105.png" alt></p><p><code>arena区域</code>就是我们所谓的堆区，Go动态分配的内存都是在这个区域，它把内存分割成<code>8KB</code>大小的页，一些页组合起来称为<code>mspan</code>。</p><p><code>bitmap区域</code>标识<code>arena</code>区域哪些地址保存了对象，并且用<code>4bit</code>标志位表示对象是否包含指针、<code>GC</code>标记信息。<code>bitmap</code>中一个<code>byte</code>大小的内存对应<code>arena</code>区域中4个指针大小（指针大小为 8B ）的内存，所以<code>bitmap</code>区域的大小是<code>512GB/(4*8B)=16GB</code>。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312204132.png" alt></p><p>从上图其实还可以看到bitmap的高地址部分指向arena区域的低地址部分，也就是说bitmap的地址是由高地址向低地址增长的。</p><p><code>spans区域</code>存放<code>mspan</code>（也就是一些<code>arena</code>分割的页组合起来的内存管理基本单元，后文会再讲）的指针，每个指针对应一页，所以<code>spans</code>区域的大小就是<code>512GB/8KB*8B=512MB</code>。除以8KB是计算<code>arena</code>区域的页数，而最后乘以8是计算<code>spans</code>区域所有指针的大小。创建<code>mspan</code>的时候，按页填充对应的<code>spans</code>区域，在回收<code>object</code>时，根据地址很容易就能找到它所属的<code>mspan</code>。</p><h2><span id="内存管理单元">内存管理单元</span></h2><p><code>mspan</code>：Go中内存管理的基本单元，是由一片连续的<code>8KB</code>的页组成的大块内存。注意，这里的页和操作系统本身的页并不是一回事，它一般是操作系统页大小的几倍。一句话概括：<code>mspan</code>是一个包含起始地址、<code>mspan</code>规格、页的数量等内容的双端链表。</p><p>每个<code>mspan</code>按照它自身的属性<code>Size Class</code>的大小分割成若干个<code>object</code>，每个<code>object</code>可存储一个对象。并且会使用一个位图来标记其尚未使用的<code>object</code>。属性<code>Size Class</code>决定<code>object</code>大小，而<code>mspan</code>只会分配给和<code>object</code>尺寸大小接近的对象，当然，对象的大小要小于<code>object</code>大小。还有一个概念：<code>Span Class</code>，它和<code>Size Class</code>的含义差不多，</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Size_Class = Span_Class / <span class="number">2</span></span><br></pre></td></tr></table></figure><p>这是因为其实每个 <code>Size Class</code>有两个<code>mspan</code>，也就是有两个<code>Span Class</code>。其中一个分配给含有指针的对象，另一个分配给不含有指针的对象。这会给垃圾回收机制带来利好，之后的文章再谈。</p><p>如下图，<code>mspan</code>由一组连续的页组成，按照一定大小划分成<code>object</code>。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312204238.png" alt></p><p>Go1.9.2里<code>mspan</code>的<code>Size Class</code>共有67种，每种<code>mspan</code>分割的object大小是8*2n的倍数，这个是写死在代码里的：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// path: /usr/local/go/src/runtime/sizeclasses.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> _NumSizeClasses = <span class="number">67</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> class_to_size = [_NumSizeClasses]<span class="type">uint16</span>&#123;<span class="number">0</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">48</span>, <span class="number">64</span>, <span class="number">80</span>, <span class="number">96</span>, <span class="number">112</span>, <span class="number">128</span>, <span class="number">144</span>, <span class="number">160</span>, <span class="number">176</span>, <span class="number">192</span>, <span class="number">208</span>, <span class="number">224</span>, <span class="number">240</span>, <span class="number">256</span>, <span class="number">288</span>, <span class="number">320</span>, <span class="number">352</span>, <span class="number">384</span>, <span class="number">416</span>, <span class="number">448</span>, <span class="number">480</span>, <span class="number">512</span>, <span class="number">576</span>, <span class="number">640</span>, <span class="number">704</span>, <span class="number">768</span>, <span class="number">896</span>, <span class="number">1024</span>, <span class="number">1152</span>, <span class="number">1280</span>, <span class="number">1408</span>, <span class="number">1536</span>,<span class="number">1792</span>, <span class="number">2048</span>, <span class="number">2304</span>, <span class="number">2688</span>, <span class="number">3072</span>, <span class="number">3200</span>, <span class="number">3456</span>, <span class="number">4096</span>, <span class="number">4864</span>, <span class="number">5376</span>, <span class="number">6144</span>, <span class="number">6528</span>, <span class="number">6784</span>, <span class="number">6912</span>, <span class="number">8192</span>, <span class="number">9472</span>, <span class="number">9728</span>, <span class="number">10240</span>, <span class="number">10880</span>, <span class="number">12288</span>, <span class="number">13568</span>, <span class="number">14336</span>, <span class="number">16384</span>, <span class="number">18432</span>, <span class="number">19072</span>, <span class="number">20480</span>, <span class="number">21760</span>, <span class="number">24576</span>, <span class="number">27264</span>, <span class="number">28672</span>, <span class="number">32768</span>&#125;</span><br></pre></td></tr></table></figure><p>根据<code>mspan</code>的<code>Size Class</code>可以得到它划分的<code>object</code>大小。 比如<code>Size Class</code>等于3，<code>object</code>大小就是32B。 32B大小的object可以存储对象大小范围在17B~32B的对象。而对于微小对象（小于16B），分配器会将其进行合并，将几个对象分配到同一个<code>object</code>中。</p><p>数组里最大的数是32768，也就是32KB，超过此大小就是大对象了，它会被特别对待，这个稍后会再介绍。顺便提一句，类型<code>Size Class</code>为0表示大对象，它实际上直接由堆内存分配，而小对象都要通过<code>mspan</code>来分配。</p><p>对于mspan来说，它的<code>Size Class</code>会决定它所能分到的页数，这也是写死在代码里的：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// path: /usr/local/go/src/runtime/sizeclasses.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> _NumSizeClasses = <span class="number">67</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> class_to_allocnpages = [_NumSizeClasses]<span class="type">uint8</span>&#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">10</span>, <span class="number">7</span>, <span class="number">4</span>&#125;</span><br></pre></td></tr></table></figure><p>比如当我们要申请一个<code>object</code>大小为<code>32B</code>的<code>mspan</code>的时候，在class_to_size里对应的索引是3，而索引3在<code>class_to_allocnpages</code>数组里对应的页数就是1。</p><p><code>mspan</code>结构体定义：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// path: /usr/local/go/src/runtime/mheap.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> mspan <span class="keyword">struct</span> &#123;</span><br><span class="line">    <span class="comment">//链表前向指针，用于将span链接起来</span></span><br><span class="line">    next *mspan </span><br><span class="line">    <span class="comment">//链表前向指针，用于将span链接起来</span></span><br><span class="line">    prev *mspan </span><br><span class="line">    <span class="comment">// 起始地址，也即所管理页的地址</span></span><br><span class="line">    startAddr <span class="type">uintptr</span> </span><br><span class="line">    <span class="comment">// 管理的页数</span></span><br><span class="line">    npages <span class="type">uintptr</span> </span><br><span class="line">    <span class="comment">// 块个数，表示有多少个块可供分配</span></span><br><span class="line">    nelems <span class="type">uintptr</span> </span><br><span class="line"></span><br><span class="line">    <span class="comment">//分配位图，每一位代表一个块是否已分配</span></span><br><span class="line">    allocBits *gcBits </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 已分配块的个数</span></span><br><span class="line">    allocCount <span class="type">uint16</span> </span><br><span class="line">    <span class="comment">// class表中的class ID，和Size Classs相关</span></span><br><span class="line">    spanclass spanClass  </span><br><span class="line"></span><br><span class="line">    <span class="comment">// class表中的对象大小，也即块大小</span></span><br><span class="line">    elemsize <span class="type">uintptr</span> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们将<code>mspan</code>放到更大的视角来看：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312204350.png" alt></p><p>上图可以看到有两个<code>S</code>指向了同一个<code>mspan</code>，因为这两个<code>S</code>指向的<code>P</code>是同属一个<code>mspan</code>的。所以，通过<code>arena</code>上的地址可以快速找到指向它的<code>S</code>，通过<code>S</code>就能找到<code>mspan</code>，回忆一下前面我们说的<code>mspan</code>区域的每个指针对应一页。</p><p>假设最左边第一个<code>mspan</code>的<code>Size Class</code>等于10，根据前面的<code>class_to_size</code>数组，得出这个<code>msapn</code>分割的<code>object</code>大小是144B，算出可分配的对象个数是<code>8KB/144B=56.89</code>个，取整56个，所以会有一些内存浪费掉了，Go的源码里有所有<code>Size Class</code>的<code>mspan</code>浪费的内存的大小；再根据<code>class_to_allocnpages</code>数组，得到这个<code>mspan</code>只由1个<code>page</code>组成；假设这个<code>mspan</code>是分配给无指针对象的，那么<code>spanClass</code>等于20。</p><p><code>startAddr</code>直接指向<code>arena</code>区域的某个位置，表示这个<code>mspan</code>的起始地址，<code>allocBits</code>指向一个位图，每位代表一个块是否被分配了对象；<code>allocCount</code>则表示总共已分配的对象个数。</p><p>这样，左起第一个<code>mspan</code>的各个字段参数就如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312204458.png" alt></p><h2><span id="内存管理组件">内存管理组件</span></h2><p>内存分配由内存分配器完成。分配器由3种组件构成：<code>mcache</code>, <code>mcentral</code>, <code>mheap</code>。</p><h2><span id="mcache">mcache</span></h2><p><code>mcache</code>：每个工作线程都会绑定一个mcache，本地缓存可用的<code>mspan</code>资源，这样就可以直接给Goroutine分配，因为不存在多个Goroutine竞争的情况，所以不会消耗锁资源。</p><p><code>mcache</code>的结构体定义：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//path: /usr/local/go/src/runtime/mcache.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> mcache <span class="keyword">struct</span> &#123;</span><br><span class="line">    alloc [numSpanClasses]*mspan</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">numSpanClasses = _NumSizeClasses &lt;&lt; <span class="number">1</span></span><br></pre></td></tr></table></figure><p><code>mcache</code>用<code>Span Classes</code>作为索引管理多个用于分配的<code>mspan</code>，它包含所有规格的<code>mspan</code>。它是<code>_NumSizeClasses</code>的2倍，也就是<code>67*2=134</code>，为什么有一个两倍的关系，前面我们提到过：为了加速之后内存回收的速度，数组里一半的<code>mspan</code>中分配的对象不包含指针，另一半则包含指针。</p><p>对于无指针对象的<code>mspan</code>在进行垃圾回收的时候无需进一步扫描它是否引用了其他活跃的对象。 后面的垃圾回收文章会再讲到，这次先到这里。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312204550.png" alt></p><p><code>mcache</code>在初始化的时候是没有任何<code>mspan</code>资源的，在使用过程中会动态地从<code>mcentral</code>申请，之后会缓存下来。当对象小于等于32KB大小时，使用<code>mcache</code>的相应规格的<code>mspan</code>进行分配。</p><h2><span id="mcentral">mcentral</span></h2><p><code>mcentral</code>：为所有<code>mcache</code>提供切分好的<code>mspan</code>资源。每个<code>central</code>保存一种特定大小的全局<code>mspan</code>列表，包括已分配出去的和未分配出去的。 每个<code>mcentral</code>对应一种<code>mspan</code>，而<code>mspan</code>的种类导致它分割的<code>object</code>大小不同。当工作线程的<code>mcache</code>中没有合适（也就是特定大小的）的<code>mspan</code>时就会从<code>mcentral</code>获取。</p><p><code>mcentral</code>被所有的工作线程共同享有，存在多个Goroutine竞争的情况，因此会消耗锁资源。结构体定义：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//path: /usr/local/go/src/runtime/mcentral.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> mcentral <span class="keyword">struct</span> &#123;</span><br><span class="line">    <span class="comment">// 互斥锁</span></span><br><span class="line">    lock mutex </span><br><span class="line">    <span class="comment">// 规格</span></span><br><span class="line">    sizeclass <span class="type">int32</span> </span><br><span class="line">    <span class="comment">// 尚有空闲object的mspan链表</span></span><br><span class="line">    nonempty mSpanList </span><br><span class="line">    <span class="comment">// 没有空闲object的mspan链表，或者是已被mcache取走的msapn链表</span></span><br><span class="line">    empty mSpanList </span><br><span class="line">    <span class="comment">// 已累计分配的对象个数</span></span><br><span class="line">    nmalloc <span class="type">uint64</span> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312204644.png" alt></p><p><code>empty</code>表示这条链表里的<code>mspan</code>都被分配了<code>object</code>，或者是已经被<code>cache</code>取走了的<code>mspan</code>，这个<code>mspan</code>就被那个工作线程独占了。而<code>nonempty</code>则表示有空闲对象的<code>mspan</code>列表。每个<code>central</code>结构体都在<code>mheap</code>中维护。</p><p>简单说下<code>mcache</code>从<code>mcentral</code>获取和归还<code>mspan</code>的流程：</p><ul><li>获取 加锁；从<code>nonempty</code>链表找到一个可用的<code>mspan</code>；并将其从<code>nonempty</code>链表删除；将取出的<code>mspan</code>加入到<code>empty</code>链表；将<code>mspan</code>返回给工作线程；解锁。</li><li>归还 加锁；将<code>mspan</code>从<code>empty</code>链表删除；将<code>mspan</code>加入到<code>nonempty</code>链表；解锁。</li></ul><h2><span id="mheap">mheap</span></h2><p><code>mheap</code>：代表Go程序持有的所有堆空间，Go程序使用一个<code>mheap</code>的全局对象<code>_mheap</code>来管理堆内存。</p><p>当<code>mcentral</code>没有空闲的<code>mspan</code>时，会向<code>mheap</code>申请。而<code>mheap</code>没有资源时，会向操作系统申请新内存。<code>mheap</code>主要用于大对象的内存分配，以及管理未切割的<code>mspan</code>，用于给<code>mcentral</code>切割成小对象。</p><p>同时我们也看到，<code>mheap</code>中含有所有规格的<code>mcentral</code>，所以，当一个<code>mcache</code>从<code>mcentral</code>申请<code>mspan</code>时，只需要在独立的<code>mcentral</code>中使用锁，并不会影响申请其他规格的<code>mspan</code>。</p><p><code>mheap</code>结构体定义：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//path: /usr/local/go/src/runtime/mheap.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> mheap <span class="keyword">struct</span> &#123;</span><br><span class="line">    lock mutex</span><br><span class="line">    <span class="comment">// spans: 指向mspans区域，用于映射mspan和page的关系</span></span><br><span class="line">    spans []*mspan </span><br><span class="line">    <span class="comment">// 指向bitmap首地址，bitmap是从高地址向低地址增长的</span></span><br><span class="line">    bitmap <span class="type">uintptr</span> </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 指示arena区首地址</span></span><br><span class="line">    arena_start <span class="type">uintptr</span> </span><br><span class="line">    <span class="comment">// 指示arena区已使用地址位置</span></span><br><span class="line">    arena_used  <span class="type">uintptr</span> </span><br><span class="line">    <span class="comment">// 指示arena区末地址</span></span><br><span class="line">    arena_end   <span class="type">uintptr</span> </span><br><span class="line"></span><br><span class="line">    central [<span class="number">67</span>*<span class="number">2</span>]<span class="keyword">struct</span> &#123;</span><br><span class="line">        mcentral mcentral</span><br><span class="line">        pad [sys.CacheLineSize - unsafe.Sizeof(mcentral&#123;&#125;)%sys.CacheLineSize]<span class="type">byte</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312204738.png" alt></p><p>上图我们看到，bitmap和arena_start指向了同一个地址，这是因为bitmap的地址是从高到低增长的，所以他们指向的内存位置相同。</p><h2><span id="分配流程">分配流程</span></h2><p>变量是在栈上分配还是在堆上分配，是由逃逸分析的结果决定的。通常情况下，编译器是倾向于将变量分配到栈上的，因为它的开销小，最极端的就是”zero garbage”，所有的变量都会在栈上分配，这样就不会存在内存碎片，垃圾回收之类的东西。</p><p>Go的内存分配器在分配对象时，根据对象的大小，分成三类：小对象（小于等于16B）、一般对象（大于16B，小于等于32KB）、大对象（大于32KB）。</p><p>大体上的分配流程：</p><ul><li>32KB 的对象，直接从mheap上分配；</li><li>&lt;=16B 的对象使用mcache的tiny分配器分配；</li><li>(16B,32KB] 的对象，首先计算对象的规格大小，然后使用mcache中相应规格大小的mspan分配；</li><li>如果mcache没有相应规格大小的mspan，则向mcentral申请</li><li>如果mcentral没有相应规格大小的mspan，则向mheap申请</li><li>如果mheap中也没有合适大小的mspan，则向操作系统申请</li></ul><h2><span id="总结">总结</span></h2><ul><li>Go在程序启动时，会向操作系统申请一大块内存，之后自行管理。</li><li>Go内存管理的基本单元是mspan，它由若干个页组成，每种mspan可以分配特定大小的object。</li><li>mcache, mcentral, mheap是Go内存管理的三大组件，层层递进。mcache管理线程在本地缓存的mspan；mcentral管理全局的mspan供所有线程使用；mheap管理Go的所有动态分配内存。</li><li>极小对象会分配在一个object中，以节省资源，使用tiny分配器分配内存；一般小对象通过mspan分配内存；大对象则直接由mheap分配内存。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#基础概念&quot;&gt;基础概念&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#内存管理单元&quot;&gt;内存管理单元&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#内存管理组件&quot;&gt;内存管理组件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href
      
    
    </summary>
    
    
      <category term="Golang" scheme="https://lxb.wiki/categories/Golang/"/>
    
    
      <category term="Go" scheme="https://lxb.wiki/tags/Go/"/>
    
  </entry>
  
  <entry>
    <title>Go channel 原理</title>
    <link href="https://lxb.wiki/7b2461e3/"/>
    <id>https://lxb.wiki/7b2461e3/</id>
    <published>2021-11-10T13:56:56.000Z</published>
    <updated>2022-03-12T10:03:22.492Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#section1-channel-使用">Section1 channel 使用</a><ul><li><a href="#11-make-channel">1.1 make channel</a></li><li><a href="#12-sends-and-receives">1.2 sends and receives</a></li></ul></li><li><a href="#section2-channel源码">Section2 channel源码</a><ul><li><a href="#21-channel数据存储结构">2.1 channel数据存储结构</a></li><li><a href="#22-环形队列">2.2 环形队列</a></li><li><a href="#23-等待队列">2.3 等待队列</a></li><li><a href="#24-类型信息">2.4 类型信息</a></li><li><a href="#25-锁">2.5 锁</a></li></ul></li><li><a href="#section3-channel读写">Section3 channel读写</a><ul><li><a href="#31-创建channel">3.1 创建channel</a></li><li><a href="#32-协程向channel写入数据goroutine-sender-data">3.2 协程向channel写入数据(goroutine sender data)</a></li><li><a href="#33-协程从channel接收数据goroutine-receive-data">3.3 协程从channel接收数据(goroutine receive data)</a></li><li><a href="#34-关闭channel">3.4 关闭channel</a></li></ul></li><li><a href="#section4-常见用法">Section4 常见用法</a><ul><li><a href="#41-单向channel">4.1 单向channel</a></li><li><a href="#42-select">4.2 select</a></li><li><a href="#43-range">4.3 range</a></li></ul></li></ul><!-- tocstop --><h1><span id="section1-channel-使用">Section1 channel 使用</span></h1><h2><span id="11-make-channel">1.1 make channel</span></h2><p>一种是带缓冲的channel一种是不带缓冲的channel。创建方式分别如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// buffered</span></span><br><span class="line">ch := <span class="built_in">make</span>(<span class="keyword">chan</span> Task, <span class="number">3</span>)</span><br><span class="line"><span class="comment">// unbuffered</span></span><br><span class="line">ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br></pre></td></tr></table></figure><p><strong>buffered channel</strong></p><p>如果我们创建一个带buffer的channel，底层的数据模型如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312170000.png" alt></p><p>当我们向channel里面写入数据时候，会直接把数据存入circular queue(send)。当Queue存满了之后就会是如下的状态：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312170039.png" alt></p><p>当dequeue一个元素时候，如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312170108.png" alt></p><p>从上图可知，recvx自增加一，表示出队了一个元素，其实也就是循环数组实现FIFO语义。</p><p>那么还有一个问题，当我们新建channel的时候，底层创建的hchan数据结构是在哪里分配内存的呢？其实Section2里面源码分析时候已经做了分析，hchan是在heap里面分配的。</p><p>如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312170236.png" alt></p><p>当我们使用make去创建一个channel的时候，实际上返回的是一个指向channel的pointer，所以我们能够在不同的function之间直接传递channel对象，而不用通过指向channel的指针。</p><h2><span id="12-sends-and-receives">1.2 sends and receives</span></h2><p>不同goroutine在channel上面进行读写时，涉及到的过程比较复杂，比如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312170342.png" alt></p><p>上图中G1会往channel里面写入数据，G2会从channel里面读取数据。</p><p>G1作用于底层hchan的流程如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312170423.png" alt></p><ol><li>先获取全局锁；</li><li>然后enqueue元素(通过移动拷贝的方式)；</li><li>释放锁；</li></ol><p>G2读取时候作用于底层数据结构流程如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312170525.png" alt></p><ol><li>先获取全局锁；</li><li>然后dequeue元素(通过移动拷贝的方式)；</li><li>释放锁；</li></ol><p>上面的读写思路其实很简单，除了hchan数据结构外，不要通过共享内存去通信；而是通过通信(复制)实现共享内存。</p><p><strong>写入满channel的场景</strong></p><p>如下图所示：channel写入3个task之后队列已经满了，这时候G1再写入第四个task的时候会发生什么呢？</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312170644.png" alt></p><p>G1这时候会暂停直到出现一个receiver。</p><p>这个地方需要介绍一下Golang的scheduler的。我们知道goroutine是用户空间的线程，创建和管理协程都是通过Go的runtime，而不是通过OS的thread。</p><p>但是Go的runtime调度执行goroutine却是基于OS thread的。如下图：<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312173326.png" alt></p><p>当向已经满的channel里面写入数据时候，会发生什么呢？如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312173420.png" alt></p><p>上图流程大概如下：</p><p>当前goroutine（G1）会调用gopark函数，将当前协程置为waiting状态；<br>将M和G1绑定关系断开；<br>scheduler会调度另外一个就绪态的goroutine与M建立绑定关系，然后M 会运行另外一个G。<br>所以整个过程中，OS thread会一直处于运行状态，不会因为协程G1的阻塞而阻塞。最后当前的G1的引用会存入channel的sender队列(队列元素是持有G1的sudog)。</p><p>那么blocked的G1怎么恢复呢？<strong>当有一个receiver接收channel数据的时候，会恢复 G1。</strong></p><p>实际上hchan数据结构也存储了channel的sender和receiver的等待队列。数据原型如下：<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312173537.png" alt></p><p>等待队列里面是sudog的单链表，sudog持有一个G代表goroutine对象引用，elem代表channel里面保存的元素。当G1执行<code>ch&lt;-task4</code>的时候，G1会创建一个sudog然后保存进入sendq队列，实际上hchan结构如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312173614.png" alt></p><p>这个时候，如果G2进行一个读取channel操作，读取前和读取后的变化图如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312173709.png" alt></p><p>整个过程如下：</p><ol><li>G2调用 t:=&lt;-ch 获取一个元素；</li><li>从channel的buffer里面取出一个元素task1；</li><li>从sender等待队列里面pop一个sudog；</li><li>将task4复制buffer中task1的位置，然后更新buffer的sendx和recvx索引值；</li><li>这时候需要将G1置为Runable状态，表示G1可以恢复运行；</li></ol><p>这个时候将G1恢复到可运行状态需要scheduler的参与。G2会调用goready(G1)来唤醒G1。流程如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312173855.png" alt></p><ol><li>首先G2会调用goready(G1)，唤起scheduler的调度；</li><li>将G1设置成Runable状态；</li><li>G1会加入到局部调度器P的local queue队列，等待运行。</li></ol><p><strong>读取空channel的场景</strong></p><p>当channel的buffer里面为空时，这时候如果G2首先发起了读取操作。如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312173959.png" alt></p><p>会创建一个sudog，将代表G2的sudog存入recvq等待队列。然后G2会调用gopark函数进入等待状态，让出OS thread，然后G2进入阻塞态。</p><p>这个时候，如果有一个G1执行写入操作，最直观的流程就是：</p><ol><li><p>将recvq中的task存入buffer；</p></li><li><p>goready(G2) 唤醒G2；</p></li></ol><pre><code>**但是**我们有更加智能的方法：direct send; 其实也就是G1直接把数据写入到G2中的elem中，这样就不用走G2中的elem复制到buffer中，再从buffer复制给G1。如下图：![](https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312174123.png)具体过程就是G1直接把数据写入到G2的栈中。这样 G2 不需要去获取channel的全局锁和操作缓冲。</code></pre><h1><span id="section2-channel源码">Section2 channel源码</span></h1><h2><span id="21-channel数据存储结构">2.1 channel数据存储结构</span></h2><p>在源码<code>runtime/chan.go</code> 里面定义了channel的数据模型，channel可以理解成一个缓冲队列，这个缓冲队列用来存储元素，并且提供FIFO的语义。源码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> hchan <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">//channel队列里面总的数据量</span></span><br><span class="line">qcount   <span class="type">uint</span>           <span class="comment">// total data in the queue</span></span><br><span class="line"><span class="comment">// 循环队列的容量，如果是非缓冲的channel就是0</span></span><br><span class="line">dataqsiz <span class="type">uint</span>           <span class="comment">// size of the circular queue</span></span><br><span class="line"><span class="comment">// 缓冲队列，数组类型。</span></span><br><span class="line">buf      unsafe.Pointer <span class="comment">// points to an array of dataqsiz elements</span></span><br><span class="line"><span class="comment">// 元素占用字节的size</span></span><br><span class="line">elemsize <span class="type">uint16</span></span><br><span class="line"><span class="comment">// 当前队列关闭标志位，非零表示关闭</span></span><br><span class="line">closed   <span class="type">uint32</span></span><br><span class="line"><span class="comment">// 队列里面元素类型</span></span><br><span class="line">elemtype *_type <span class="comment">// element type</span></span><br><span class="line"><span class="comment">// 队列send索引</span></span><br><span class="line">sendx    <span class="type">uint</span>   <span class="comment">// send index</span></span><br><span class="line"><span class="comment">// 队列索引</span></span><br><span class="line">recvx    <span class="type">uint</span>   <span class="comment">// receive index</span></span><br><span class="line"><span class="comment">// 等待channel的G队列。</span></span><br><span class="line">recvq    waitq  <span class="comment">// list of recv waiters</span></span><br><span class="line"><span class="comment">// 向channel发送数据的G队列。</span></span><br><span class="line">sendq    waitq  <span class="comment">// list of send waiters</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// lock protects all fields in hchan, as well as several</span></span><br><span class="line"><span class="comment">// fields in sudogs blocked on this channel.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Do not change another G&#x27;s status while holding this lock</span></span><br><span class="line"><span class="comment">// (in particular, do not ready a G), as this can deadlock</span></span><br><span class="line"><span class="comment">// with stack shrinking.</span></span><br><span class="line"><span class="comment">// 全局锁</span></span><br><span class="line">lock mutex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>channel的数据结构相对比较简单，主要是两个结构：<br>1）一个数组实现的环形队列，数组有两个下标索引分别表示读写的索引，用于保存channel缓冲区数据。<br>2）channel的send和recv队列，队列里面都是持有goroutine的sudog元素，队列都是双链表实现的。<br>3）channel的全局锁。</p><h2><span id="22-环形队列">2.2 环形队列</span></h2><p>chan内部实现了一个环形队列作为其缓冲区，队列的长度是创建chan时指定的。</p><p>下图展示了一个可缓存6个元素的channel示意图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312174357.png" alt></p><ul><li>dataqsiz指示了队列长度为6，即可缓存6个元素；</li><li>buf指向队列的内存，队列中还剩余两个元素；</li><li>qcount表示队列中还有两个元素；</li><li>sendx指示后续写入的数据存储的位置，取值[0, 6)；</li><li>recvx指示从该位置读取数据, 取值[0, 6)；</li></ul><h2><span id="23-等待队列">2.3 等待队列</span></h2><p>从channel读数据，如果channel缓冲区为空或者没有缓冲区，当前goroutine会被阻塞。<br>向channel写数据，如果channel缓冲区已满或者没有缓冲区，当前goroutine会被阻塞。</p><p>被阻塞的goroutine将会挂在channel的等待队列中：</p><ul><li>因读阻塞的goroutine会被向channel写入数据的goroutine唤醒；</li><li>因写阻塞的goroutine会被从channel读数据的goroutine唤醒；</li></ul><p>下图展示了一个没有缓冲区的channel，有几个goroutine阻塞等待读数据：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312174513.png" alt></p><p>注意，一般情况下recvq和sendq至少有一个为空。只有一个例外，那就是同一个goroutine使用select语句向channel一边写数据，一边读数据。</p><h2><span id="24-类型信息">2.4 类型信息</span></h2><p>一个channel只能传递一种类型的值，类型信息存储在hchan数据结构中。</p><ul><li>elemtype代表类型，用于数据传递过程中的赋值；</li><li>elemsize代表类型大小，用于在buf中定位元素位置。</li></ul><h2><span id="25-锁">2.5 锁</span></h2><p>一个channel同时仅允许被一个goroutine读写，为简单起见，本章后续部分说明读写过程时不再涉及加锁和解锁。</p><h1><span id="section3-channel读写">Section3 channel读写</span></h1><h2><span id="31-创建channel">3.1 创建channel</span></h2><p>我们新建一个channel的时候一般使用 <code>make(chan, n)</code> 语句，这个语句的执行编译器会重写然后执行 chan.go里面的 makechan函数。函数源码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">makechan</span><span class="params">(t *chantype, size <span class="type">int</span>)</span></span> *hchan &#123;</span><br><span class="line">elem := t.elem</span><br><span class="line"></span><br><span class="line"><span class="comment">// compiler checks this but be safe.</span></span><br><span class="line"><span class="keyword">if</span> elem.size &gt;= <span class="number">1</span>&lt;&lt;<span class="number">16</span> &#123;</span><br><span class="line">throw(<span class="string">&quot;makechan: invalid channel element type&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> hchanSize%maxAlign != <span class="number">0</span> || elem.align &gt; maxAlign &#123;</span><br><span class="line">throw(<span class="string">&quot;makechan: bad alignment&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> size &lt; <span class="number">0</span> || <span class="type">uintptr</span>(size) &gt; maxSliceCap(elem.size) || <span class="type">uintptr</span>(size)*elem.size &gt; maxAlloc-hchanSize &#123;</span><br><span class="line"><span class="built_in">panic</span>(plainError(<span class="string">&quot;makechan: size out of range&quot;</span>))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers.</span></span><br><span class="line"><span class="comment">// buf points into the same allocation, elemtype is persistent.</span></span><br><span class="line"><span class="comment">// SudoG&#x27;s are referenced from their owning thread so they can&#x27;t be collected.</span></span><br><span class="line"><span class="comment">// TODO(dvyukov,rlh): Rethink when collector can move allocated objects.</span></span><br><span class="line"><span class="keyword">var</span> c *hchan</span><br><span class="line"><span class="keyword">switch</span> &#123;</span><br><span class="line"><span class="keyword">case</span> size == <span class="number">0</span> || elem.size == <span class="number">0</span>:</span><br><span class="line"><span class="comment">// Queue or element size is zero.</span></span><br><span class="line">c = (*hchan)(mallocgc(hchanSize, <span class="literal">nil</span>, <span class="literal">true</span>))</span><br><span class="line"><span class="comment">// Race detector uses this location for synchronization.</span></span><br><span class="line">c.buf = unsafe.Pointer(c)</span><br><span class="line"><span class="keyword">case</span> elem.kind&amp;kindNoPointers != <span class="number">0</span>:</span><br><span class="line"><span class="comment">// Elements do not contain pointers.</span></span><br><span class="line"><span class="comment">// Allocate hchan and buf in one call.</span></span><br><span class="line">c = (*hchan)(mallocgc(hchanSize+<span class="type">uintptr</span>(size)*elem.size, <span class="literal">nil</span>, <span class="literal">true</span>))</span><br><span class="line">c.buf = add(unsafe.Pointer(c), hchanSize)</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="comment">// Elements contain pointers.</span></span><br><span class="line">c = <span class="built_in">new</span>(hchan)</span><br><span class="line">c.buf = mallocgc(<span class="type">uintptr</span>(size)*elem.size, elem, <span class="literal">true</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">c.elemsize = <span class="type">uint16</span>(elem.size)</span><br><span class="line">c.elemtype = elem</span><br><span class="line">c.dataqsiz = <span class="type">uint</span>(size)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> debugChan &#123;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;makechan: chan=&quot;</span>, c, <span class="string">&quot;; elemsize=&quot;</span>, elem.size, <span class="string">&quot;; elemalg=&quot;</span>, elem.alg, <span class="string">&quot;; dataqsiz=&quot;</span>, size, <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>函数接收两个参数，一个是channel里面保存的元素的数据类型，一个是缓冲的容量(如果为0表示是非缓冲buffer)，创建流程如下：</p><ul><li>根据传递的缓冲大小size是否为零，分别创建不带buffer的channel或则带size大小的缓冲channel：<ul><li>对于不带缓冲channel，申请一个hchan数据结构的内存大小；</li><li>对于带缓冲channel，new一个hchan对象，并初始化buffer内存</li></ul></li><li>更新 chan中循环队列的关键属性：elemsize、elemtype、dataqsiz。</li></ul><p>创建channel的过程实际上是初始化hchan结构。其中类型信息和缓冲区长度由make语句传入，buf的大小则与元素大小和缓冲区长度共同决定。</p><p>创建channel的伪代码如下所示：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">makechan</span><span class="params">(t *chantype, size <span class="type">int</span>)</span></span> *hchan &#123;</span><br><span class="line"><span class="keyword">var</span> c *hchan</span><br><span class="line">c = <span class="built_in">new</span>(hchan)</span><br><span class="line">c.buf = malloc(元素类型大小*size)</span><br><span class="line">c.elemsize = 元素类型大小</span><br><span class="line">c.elemtype = 元素类型</span><br><span class="line">c.dataqsiz = size</span><br><span class="line"> </span><br><span class="line"><span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="32-协程向channel写入数据goroutine-sender-data">3.2 协程向channel写入数据(goroutine sender data)</span></h2><p>所有执行 c &lt; ep 将ep发送到channel的代码，最后都会调用到chan.go里面的 chansend函数。</p><p>函数的定义如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">chansend</span><span class="params">(c *hchan, ep unsafe.Pointer, block <span class="type">bool</span>, callerpc <span class="type">uintptr</span>)</span></span> <span class="type">bool</span> &#123;</span><br><span class="line">......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>函数有三个参数，第一个代表channel的数据结构，第二个是要指向写入的数据的指针，第三个block代表写入操作是否阻塞。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312175238.png" alt></p><p>向一个channel中写数据简单过程如下：</p><ol><li>如果等待接收队列recvq不为空，说明缓冲区中没有数据或者没有缓冲区，此时直接从recvq取出G,并把数据写入，最后把该G唤醒，结束发送过程；</li><li>如果缓冲区中有空余位置，将数据写入缓冲区，结束发送过程；</li><li>如果缓冲区中没有空余位置，将待发送数据写入G，将当前G加入sendq，进入睡眠，等待被读goroutine唤醒；</li></ol><p>流程图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312175356.png" alt></p><h2><span id="33-协程从channel接收数据goroutine-receive-data">3.3 协程从channel接收数据(goroutine receive data)</span></h2><p>所有执行 <code>ep &lt; c</code> 使用ep接收channel数据的代码，最后都会调用到chan.go里面的 <code>chanrecv函数</code>。</p><p>函数的定义如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">chanrecv</span><span class="params">(c *hchan, ep unsafe.Pointer, block <span class="type">bool</span>)</span></span> (selected, received <span class="type">bool</span>) &#123;</span><br><span class="line">......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从源码注释就可以知道，该函数从channel里面接收数据，然后将接收到的数据写入到ep指针指向的对象里面。</p><p>还有一个参数block，表示当channel无法返回数据时是否阻塞等待。当block=false并且channel里面没有数据时候，函数直接返回(false,false)。<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312175531.png" alt></p><p>从一个channel读数据简单过程如下：</p><ol><li>如果等待发送队列sendq不为空，且没有缓冲区，直接从sendq中取出G，把G中数据读出，最后把G唤醒，结束读取过程；</li><li>如果等待发送队列sendq不为空，此时说明缓冲区已满，从缓冲区中首部读出数据，把G中数据写入缓冲区尾部，把G唤醒，结束读取过程；</li><li>如果缓冲区中有数据，则从缓冲区取出数据，结束读取过程；</li><li>将当前goroutine加入recvq，进入睡眠，等待被写goroutine唤醒；</li></ol><p>简单流程图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312175628.png" alt></p><h2><span id="34-关闭channel">3.4 关闭channel</span></h2><p>当我们执行channel的close操作的时候会关闭channel。</p><p>关闭的主要流程如下所示：</p><ol><li>获取全局锁；</li><li>设置channel数据结构chan的关闭标志位；</li><li>获取当前channel上面的读goroutine并链接成链表；</li><li>获取当前channel上面的写goroutine然后拼接到前面的读链表后面；</li><li>释放全局锁；</li><li>唤醒所有的读写goroutine。</li></ol><p>关闭channel时会把recvq中的G全部唤醒，本该写入G的数据位置为nil。把sendq中的G全部唤醒，但这些G会panic。</p><p>除此之外，panic出现的常见场景还有：</p><ol><li>关闭值为nil的channel</li><li>关闭已经被关闭的channel</li><li>向已经关闭的channel写数据</li></ol><h1><span id="section4-常见用法">Section4 常见用法</span></h1><h2><span id="41-单向channel">4.1 单向channel</span></h2><p>单向channel指只能用于发送或接收数据，实际上并没有单向channel。</p><p>我们知道channel可以通过参数传递，所谓单向channel只是对channel的一种使用限制，这跟C语言使用const修饰函数参数为只读是一个道理。</p><ul><li>func readChan(chanName &lt;-chan int)： 通过形参限定函数内部只能从channel中读取数据</li><li>func writeChan(chanName chan&lt;- int)： 通过形参限定函数内部只能向channel中写入数据</li></ul><p>一个简单的示例程序如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">readChan</span><span class="params">(chanName &lt;-<span class="keyword">chan</span> <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    &lt;- chanName</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">writeChan</span><span class="params">(chanName <span class="keyword">chan</span>&lt;- <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    chanName &lt;- <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> mychan = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line">    writeChan(mychan)</span><br><span class="line">    readChan(mychan)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>mychan是个正常的channel，而readChan()参数限制了传入的channel只能用来读，writeChan()参数限制了传入的channel只能用来写。</p><h2><span id="42-select">4.2 select</span></h2><p>使用select可以监控多channel，比如监控多个channel，当其中某一个channel有数据时，就从其读出数据。</p><p>一个简单的示例程序如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">addNumberToChan</span><span class="params">(chanName <span class="keyword">chan</span> <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        chanName &lt;- <span class="number">1</span></span><br><span class="line">        time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> chan1 = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">10</span>)</span><br><span class="line">    <span class="keyword">var</span> chan2 = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">go</span> addNumberToChan(chan1)</span><br><span class="line">    <span class="keyword">go</span> addNumberToChan(chan2)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e := &lt;- chan1 :</span><br><span class="line">            fmt.Printf(<span class="string">&quot;Get element from chan1: %d\n&quot;</span>, e)</span><br><span class="line">        <span class="keyword">case</span> e := &lt;- chan2 :</span><br><span class="line">            fmt.Printf(<span class="string">&quot;Get element from chan2: %d\n&quot;</span>, e)</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            fmt.Printf(<span class="string">&quot;No element in chan1 and chan2.\n&quot;</span>)</span><br><span class="line">            time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>程序中创建两个channel： chan1和chan2。函数addNumberToChan()函数会向两个channel中周期性写入数据。通过select可以监控两个channel，任意一个可读时就从其中读出数据。</p><p>程序输出如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">D:\SourceCode\GoExpert\src&gt;go run main.go</span><br><span class="line">Get element from chan1: 1</span><br><span class="line">Get element from chan2: 1</span><br><span class="line">No element <span class="keyword">in</span> chan1 and chan2.</span><br><span class="line">Get element from chan2: 1</span><br><span class="line">Get element from chan1: 1</span><br><span class="line">No element <span class="keyword">in</span> chan1 and chan2.</span><br><span class="line">Get element from chan2: 1</span><br><span class="line">Get element from chan1: 1</span><br><span class="line">No element <span class="keyword">in</span> chan1 and chan2.</span><br></pre></td></tr></table></figure><p>从输出可见，从channel中读出数据的顺序是随机的，事实上select语句的多个case执行顺序是随机的，关于select的实现原理会有专门章节分析。</p><p>通过这个示例想说的是：<strong>select的case语句读channel不会阻塞</strong>，尽管channel中没有数据。这是由于case语句编译后调用读channel时会<strong>明确传入不阻塞的参数</strong>，此时读不到数据时不会将当前goroutine加入到等待队列，而是直接返回。</p><h2><span id="43-range">4.3 range</span></h2><p>通过range可以持续从channel中读出数据，好像在遍历一个数组一样，当channel中没有数据时会阻塞当前goroutine，与读channel时阻塞处理机制一样。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">chanRange</span><span class="params">(chanName <span class="keyword">chan</span> <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> e := <span class="keyword">range</span> chanName &#123;</span><br><span class="line">        fmt.Printf(<span class="string">&quot;Get element from chan: %d\n&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：如果向此channel写数据的goroutine退出时，系统检测到这种情况后会panic，否则range将会永久阻塞。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#section1-channel-使用&quot;&gt;Section1 channel 使用&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#11-make-channel&quot;&gt;1.1 make channel&lt;/a&gt;&lt;/li&gt;
&lt;
      
    
    </summary>
    
    
      <category term="Golang" scheme="https://lxb.wiki/categories/Golang/"/>
    
    
      <category term="Go" scheme="https://lxb.wiki/tags/Go/"/>
    
  </entry>
  
  <entry>
    <title>Redis的底层数据结构 </title>
    <link href="https://lxb.wiki/abddb7fd/"/>
    <id>https://lxb.wiki/abddb7fd/</id>
    <published>2021-11-02T13:21:18.000Z</published>
    <updated>2022-03-12T06:42:25.648Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-演示数据类型的实现">1、演示数据类型的实现</a></li><li><a href="#2-简单动态字符串">2、简单动态字符串</a></li><li><a href="#3-链表">3、链表</a></li><li><a href="#4-字典">4、字典</a></li><li><a href="#5-跳跃表">5、跳跃表</a></li><li><a href="#6-整数集合">6、整数集合</a></li><li><a href="#7-压缩列表">7、压缩列表</a></li><li><a href="#8-总结">8、总结</a></li><li><a href="#参考资料">参考资料</a></li></ul><!-- tocstop --><h3><span id="1-演示数据类型的实现">1、演示数据类型的实现</span></h3><p><code>OBJECT ENCODING    key</code> </p><p>该命令是用来显示五大数据类型的底层数据结构。</p><p>比如对于 string 数据类型：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312142322.png" alt></p><p>可以看到实现string数据类型的数据结构有 embstr 以及 int。</p><p>再比如 list 数据类型：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312142349.png" alt></p><h3><span id="2-简单动态字符串">2、简单动态字符串</span></h3><p> Redis 是用 C 语言写的，但是对于Redis的字符串，却不是 C 语言中的字符串（即以空字符’\0’结尾的字符数组），它是自己构建了一种名为 简单动态字符串（simple dynamic string,SDS）的抽象类型，并将 SDS 作为 Redis的默认字符串表示。</p><p><strong>SDS 定义：</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sdshdr</span>&#123;</span></span><br><span class="line">     <span class="comment">//记录buf数组中已使用字节的数量</span></span><br><span class="line">     <span class="comment">//等于 SDS 保存字符串的长度</span></span><br><span class="line">     <span class="type">int</span> len;</span><br><span class="line">     <span class="comment">//记录 buf 数组中未使用字节的数量</span></span><br><span class="line">     <span class="type">int</span> <span class="built_in">free</span>;</span><br><span class="line">     <span class="comment">//字节数组，用于保存字符串</span></span><br><span class="line">     <span class="type">char</span> buf[];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用SDS保存字符串 “Redis”具体图示如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312142538.png" alt></p><p>我们看上面对于 SDS 数据类型的定义：</p><p>　　1、len 保存了SDS保存字符串的长度</p><p>　　2、buf[] 数组用来保存字符串的每个元素</p><p>　　3、free j记录了 buf 数组中未使用的字节数量</p><p>　　上面的定义相对于 C 语言对于字符串的定义，多出了 len 属性以及 free 属性。为什么不使用C语言字符串实现，而是使用 SDS呢？这样实现有什么好处？</p><p>　　<strong>①、常数复杂度获取字符串长度</strong></p><p>　　由于 len 属性的存在，我们获取 SDS 字符串的长度只需要读取 len 属性，时间复杂度为 O(1)。而对于 C 语言，获取字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。通过 strlen key 命令可以获取 key 的字符串长度。</p><p>　　<strong>②、杜绝缓冲区溢出</strong></p><p>　　我们知道在 C 语言中使用 strcat 函数来进行两个字符串的拼接，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。而对于 SDS 数据类型，在进行字符修改的时候，会首先根据记录的 len 属性检查内存空间是否满足需求，如果不满足，会进行相应的空间扩展，然后在进行修改操作，所以不会出现缓冲区溢出。</p><p>　　<strong>③、减少修改字符串的内存重新分配次数</strong></p><p>　　C语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。</p><p>　　而对于SDS，由于len属性和free属性的存在，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略：</p><p>　　1、空间预分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。</p><p>　　2、惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 free 属性将这些字节的数量记录下来，等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）</p><p>　　<strong>④、二进制安全</strong></p><p>　　因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；而所有 SDS 的API 都是以处理二进制的方式来处理 buf 里面的元素，并且 SDS 不是以空字符串来判断是否结束，而是以 len 属性表示的长度来判断字符串是否结束。</p><p>　　<strong>⑤、兼容部分 C 字符串函数</strong></p><p>　　虽然 SDS 是二进制安全的，但是一样遵从每个字符串都是以空字符串结尾的惯例，这样可以重用 C 语言库&lt;string.h&gt; 中的一部分函数。</p><p>　　<strong>⑥、总结</strong></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312142712.png" alt></p><p>一般来说，SDS 除了保存数据库中的字符串值以外，SDS 还可以作为缓冲区（buffer）：包括 AOF 模块中的AOF缓冲区以及客户端状态中的输入缓冲区。后面在介绍Redis的持久化时会进行介绍。</p><h3><span id="3-链表">3、链表</span></h3><p>链表是一种常用的数据结构，C 语言内部是没有内置这种数据结构的实现，所以Redis自己构建了链表的实现。</p><p>　　链表定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span>  <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span>&#123;</span></span><br><span class="line">       <span class="comment">//前置节点</span></span><br><span class="line">       <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">prev</span>;</span></span><br><span class="line">       <span class="comment">//后置节点</span></span><br><span class="line">       <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">next</span>;</span></span><br><span class="line">       <span class="comment">//节点的值</span></span><br><span class="line">       <span class="type">void</span> *value;  </span><br><span class="line">&#125;listNode</span><br></pre></td></tr></table></figure><p>通过多个 listNode 结构就可以组成链表，这是一个双向链表，Redis还提供了操作链表的数据结构：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">list</span>&#123;</span></span><br><span class="line">     <span class="comment">//表头节点</span></span><br><span class="line">     listNode *head;</span><br><span class="line">     <span class="comment">//表尾节点</span></span><br><span class="line">     listNode *tail;</span><br><span class="line">     <span class="comment">//链表所包含的节点数量</span></span><br><span class="line">     <span class="type">unsigned</span> <span class="type">long</span> len;</span><br><span class="line">     <span class="comment">//节点值复制函数</span></span><br><span class="line">     <span class="type">void</span> (*<span class="built_in">free</span>) (<span class="type">void</span> *ptr);</span><br><span class="line">     <span class="comment">//节点值释放函数</span></span><br><span class="line">     <span class="type">void</span> (*<span class="built_in">free</span>) (<span class="type">void</span> *ptr);</span><br><span class="line">     <span class="comment">//节点值对比函数</span></span><br><span class="line">     <span class="type">int</span> (*match) (<span class="type">void</span> *ptr,<span class="type">void</span> *key);</span><br><span class="line">&#125;<span class="built_in">list</span>;</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312143157.png" alt></p><p>Redis链表特性：</p><p>　　①、双端：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。</p><p>　　②、无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结束。　　</p><p>　　③、带链表长度计数器：通过 len 属性获取链表长度的时间复杂度为 O(1)。</p><p>　　④、多态：链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。</p><h3><span id="4-字典">4、字典</span></h3><p>字典又称为符号表或者关联数组、或映射（map），是一种用于保存键值对的抽象数据结构。字典中的每一个键 key 都是唯一的，通过 key 可以对值来进行查找或修改。C 语言中没有内置这种数据结构的实现，所以字典依然是 Redis自己构建的。</p><p>　　Redis 的字典使用哈希表作为底层实现</p><p>　　哈希表结构定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span>&#123;</span></span><br><span class="line">     <span class="comment">//哈希表数组</span></span><br><span class="line">     dictEntry **table;</span><br><span class="line">     <span class="comment">//哈希表大小</span></span><br><span class="line">     <span class="type">unsigned</span> <span class="type">long</span> size;</span><br><span class="line">     <span class="comment">//哈希表大小掩码，用于计算索引值</span></span><br><span class="line">     <span class="comment">//总是等于 size-1</span></span><br><span class="line">     <span class="type">unsigned</span> <span class="type">long</span> sizemask;</span><br><span class="line">     <span class="comment">//该哈希表已有节点的数量</span></span><br><span class="line">     <span class="type">unsigned</span> <span class="type">long</span> used;</span><br><span class="line"> </span><br><span class="line">&#125;dictht</span><br></pre></td></tr></table></figure><p>哈希表是由数组 table 组成，table 中每个元素都是指向 dict.h/dictEntry 结构，dictEntry 结构定义如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span>&#123;</span></span><br><span class="line">     <span class="comment">//键</span></span><br><span class="line">     <span class="type">void</span> *key;</span><br><span class="line">     <span class="comment">//值</span></span><br><span class="line">     <span class="class"><span class="keyword">union</span>&#123;</span></span><br><span class="line">          <span class="type">void</span> *val;</span><br><span class="line">          uint64_tu64;</span><br><span class="line">          int64_ts64;</span><br><span class="line">     &#125;v;</span><br><span class="line"> </span><br><span class="line">     <span class="comment">//指向下一个哈希表节点，形成链表</span></span><br><span class="line">     <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125;dictEntry</span><br></pre></td></tr></table></figure><p>key 用来保存键，val 属性用来保存值，值可以是一个指针，也可以是uint64_t整数，也可以是int64_t整数。</p><p>　　注意这里还有一个指向下一个哈希表节点的指针，我们知道哈希表最大的问题是存在哈希冲突，如何解决哈希冲突，有开放地址法和链地址法。这里采用的便是链地址法，通过next这个指针可以将多个哈希值相同的键值对连接在一起，用来解决<strong>哈希冲突</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312143330.png" alt></p><p><strong>①、哈希算法：</strong>Redis计算哈希值和索引值方法如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">1</span>、使用字典设置的哈希函数，计算键 key 的哈希值</span><br><span class="line">hash = dict-&gt;type-&gt;hashFunction(key);</span><br><span class="line">#<span class="number">2</span>、使用哈希表的sizemask属性和第一步得到的哈希值，计算索引值</span><br><span class="line">index = hash &amp; dict-&gt;ht[x].sizemask;</span><br></pre></td></tr></table></figure><p><strong>②、解决哈希冲突：</strong>这个问题上面我们介绍了，方法是链地址法。通过字典里面的 *next 指针指向下一个具有相同索引值的哈希表节点。</p><p>　　<strong>③、扩容和收缩：</strong>当哈希表保存的键值对太多或者太少时，就要通过 rerehash(重新散列）来对哈希表进行相应的扩展或者收缩。具体步骤：</p><p>　　　　　　1、如果执行扩展操作，会基于原哈希表创建一个大小等于 ht[0].used*2n 的哈希表（也就是每次扩展都是根据原哈希表已使用的空间扩大一倍创建另一个哈希表）。相反如果执行的是收缩操作，每次收缩是根据已使用空间缩小一倍创建一个新的哈希表。</p><p>　　　　　　2、重新利用上面的哈希算法，计算索引值，然后将键值对放到新的哈希表位置上。</p><p>　　　　　　3、所有键值对都迁徙完毕后，释放原哈希表的内存空间。</p><p>　　<strong>④、触发扩容的条件：</strong></p><p>　　　　　　1、服务器目前没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于1。</p><p>　　　　　　2、服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于5。</p><p>　　　　ps：负载因子 = 哈希表已保存节点数量 / 哈希表大小。</p><p>　　<strong>⑤、渐近式 rehash</strong></p><p>　　　　什么叫渐进式 rehash？也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行 增加操作，一定是在新的哈希表上进行的。</p><h3><span id="5-跳跃表">5、跳跃表</span></h3><p>跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。具有如下性质：</p><p>　　1、由很多层结构组成；</p><p>　　2、每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的head节点和后面的nil节点；</p><p>　　3、最底层的链表包含了所有的元素；</p><p>　　4、如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现（上一层的元素是当前层的元素的子集）；</p><p>　　5、链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点；</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312143603.png" alt></p><p>Redis中跳跃表节点定义如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> &#123;</span></span><br><span class="line">     <span class="comment">//层</span></span><br><span class="line">     <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistLevel</span>&#123;</span></span><br><span class="line">           <span class="comment">//前进指针</span></span><br><span class="line">           <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">forward</span>;</span></span><br><span class="line">           <span class="comment">//跨度</span></span><br><span class="line">           <span class="type">unsigned</span> <span class="type">int</span> span;</span><br><span class="line">     &#125;level[];</span><br><span class="line"> </span><br><span class="line">     <span class="comment">//后退指针</span></span><br><span class="line">     <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">backward</span>;</span></span><br><span class="line">     <span class="comment">//分值</span></span><br><span class="line">     <span class="type">double</span> score;</span><br><span class="line">     <span class="comment">//成员对象</span></span><br><span class="line">     robj *obj;</span><br><span class="line"> </span><br><span class="line">&#125; zskiplistNode</span><br></pre></td></tr></table></figure><p>多个跳跃表节点构成一个跳跃表：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplist</span>&#123;</span></span><br><span class="line">     <span class="comment">//表头节点和表尾节点</span></span><br><span class="line">     structz skiplistNode *header, *tail;</span><br><span class="line">     <span class="comment">//表中节点的数量</span></span><br><span class="line">     <span class="type">unsigned</span> <span class="type">long</span> length;</span><br><span class="line">     <span class="comment">//表中层数最大的节点的层数</span></span><br><span class="line">     <span class="type">int</span> level;</span><br><span class="line"> </span><br><span class="line">&#125;zskiplist;</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312143819.png" alt></p><p>①、搜索：从最高层的链表节点开始，如果比当前节点要大和比当前层的下一个节点要小，那么则往下找，也就是和当前层的下一层的节点的下一个节点进行比较，以此类推，一直找到最底层的最后一个节点，如果找到则返回，反之则返回空。</p><p>　　②、插入：首先确定插入的层数，有一种方法是假设抛一枚硬币，如果是正面就累加，直到遇见反面为止，最后记录正面的次数作为插入的层数。当确定插入的层数k后，则需要将新元素插入到从底层到k层。</p><p>　　③、删除：在各个层中找到包含指定值的节点，然后将节点从链表中删除即可，如果删除以后只剩下头尾两个节点，则删除这一层。</p><h3><span id="6-整数集合">6、整数集合</span></h3><p>整数集合（intset）是Redis用于保存整数值的集合抽象数据类型，它可以保存类型为int16_t、int32_t 或者int64_t 的整数值，并且保证集合中不会出现重复元素。</p><p>　　定义如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">intset</span>&#123;</span></span><br><span class="line">     <span class="comment">//编码方式</span></span><br><span class="line">     <span class="type">uint32_t</span> encoding;</span><br><span class="line">     <span class="comment">//集合包含的元素数量</span></span><br><span class="line">     <span class="type">uint32_t</span> length;</span><br><span class="line">     <span class="comment">//保存元素的数组</span></span><br><span class="line">     <span class="type">int8_t</span> contents[];</span><br><span class="line"> </span><br><span class="line">&#125;intset;</span><br></pre></td></tr></table></figure><p>整数集合的每个元素都是 contents 数组的一个数据项，它们按照从小到大的顺序排列，并且不包含任何重复项。</p><p>　　length 属性记录了 contents 数组的大小。</p><p>　　需要注意的是虽然 contents 数组声明为 int8_t 类型，但是实际上contents 数组并不保存任何 int8_t 类型的值，其真正类型有 encoding 来决定。</p><p>　　<strong>①、升级</strong></p><p>　　当我们新增的元素类型比原集合元素类型的长度要大时，需要对整数集合进行升级，才能将新元素放入整数集合中。具体步骤：</p><p>　　1、根据新元素类型，扩展整数集合底层数组的大小，并为新元素分配空间。</p><p>　　2、将底层数组现有的所有元素都转成与新元素相同类型的元素，并将转换后的元素放到正确的位置，放置过程中，维持整个元素顺序都是有序的。</p><p>　　3、将新元素添加到整数集合中（保证有序）。</p><p>　　升级能极大地节省内存。</p><p>　　<strong>②、降级</strong></p><p>　　整数集合不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态。</p><h3><span id="7-压缩列表">7、压缩列表</span></h3><p>压缩列表（ziplist）是Redis为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。</p><p>　　<strong>压缩列表的原理：压缩列表并不是对数据利用某种算法进行压缩，而是将数据按照一定规则编码在一块连续的内存区域，目的是节省内存。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312144033.png" alt></p><p>　压缩列表的每个节点构成如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220312144116.png" alt></p><p>①、previous_entry_ength：记录压缩列表前一个字节的长度。previous_entry_ength的长度可能是1个字节或者是5个字节，如果上一个节点的长度小于254，则该节点只需要一个字节就可以表示前一个节点的长度了，如果前一个节点的长度大于等于254，则previous length的第一个字节为254，后面用四个字节表示当前节点前一个节点的长度。利用此原理即当前节点位置减去上一个节点的长度即得到上一个节点的起始位置，压缩列表可以从尾部向头部遍历。这么做很有效地减少了内存的浪费。</p><p>②、encoding：节点的encoding保存的是节点的content的内容类型以及长度，encoding类型一共有两种，一种字节数组一种是整数，encoding区域长度为1字节、2字节或者5字节长。</p><p>③、content：content区域用于保存节点的内容，节点内容类型和长度由encoding决定。</p><h3><span id="8-总结">8、总结</span></h3><p>​        大多数情况下，Redis使用简单字符串SDS作为字符串的表示，相对于C语言字符串，SDS具有常数复杂度获取字符串长度，杜绝了缓存区的溢出，减少了修改字符串长度时所需的内存重分配次数，以及二进制安全能存储各种类型的文件，并且还兼容部分C函数。</p><p>　　通过为链表设置不同类型的特定函数，Redis链表可以保存各种不同类型的值，除了用作列表键，还在发布与订阅、慢查询、监视器等方面发挥作用（后面会介绍）。</p><p>　　Redis的字典底层使用哈希表实现，每个字典通常有两个哈希表，一个平时使用，另一个用于rehash时使用，使用链地址法解决哈希冲突。</p><p>　　跳跃表通常是有序集合的底层实现之一，表中的节点按照分值大小进行排序。</p><p>　　整数集合是集合键的底层实现之一，底层由数组构成，升级特性能尽可能的节省内存。</p><p>　　压缩列表是Redis为节省内存而开发的顺序型数据结构，通常作为列表键和哈希键的底层实现之一。</p><h3><span id="参考资料">参考资料</span></h3><p><a href="https://www.cnblogs.com/ysocean/p/9080940.html">Redis详解（三）—— redis的六大数据类型详细用法 - YSOcean - 博客园 (cnblogs.com)</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-演示数据类型的实现&quot;&gt;1、演示数据类型的实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-简单动态字符串&quot;&gt;2、简单动态字符串&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#3-链表&quot;&gt;3、链表&lt;/a&gt;&lt;
      
    
    </summary>
    
    
      <category term="DB" scheme="https://lxb.wiki/categories/DB/"/>
    
    
      <category term="redis" scheme="https://lxb.wiki/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>TCP协议中的三次握手和四次挥手</title>
    <link href="https://lxb.wiki/5fa4c221/"/>
    <id>https://lxb.wiki/5fa4c221/</id>
    <published>2021-10-21T14:54:29.000Z</published>
    <updated>2022-03-11T07:29:27.230Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-准备">1. 准备</a></li><li><a href="#2tcp三次握手简述">2.TCP三次握手简述</a><ul><li><a href="#21-第一次握手">2.1 第一次握手</a></li><li><a href="#23-第三次握手">2.3 第三次握手</a></li><li><a href="#24-实例观察">2.4 实例观察</a><ul><li><a href="#241-tcpdump">2.4.1 tcpdump</a></li></ul></li></ul></li><li><a href="#3tcp三次握手详细解析过程">3.TCP三次握手详细解析过程：</a><ul><li><a href="#31-第一次握手">3.1 第一次握手</a><ul><li><a href="#311-半连接队列syn-queue未满">3.1.1 半连接队列(syn queue)未满</a></li><li><a href="#312-半连接队列syn-queue已满">3.1.2 半连接队列(syn queue)已满</a></li></ul></li><li><a href="#32-第二次握手">3.2 第二次握手</a></li><li><a href="#33-第三次握手">3.3 第三次握手</a><ul><li><a href="#331-全连接队列accept-queue未满">3.3.1 全连接队列(accept queue)未满</a></li><li><a href="#332-全连接队列accept-queue已满">3.3.2 全连接队列(accept queue)已满</a><ul><li><a href="#3321-tcp_abort_on_overflow-0">3.3.2.1 tcp_abort_on_overflow = 0</a></li><li><a href="#3322-tcp_abort_on_overflow-1">3.3.2.2 tcp_abort_on_overflow = 1</a></li></ul></li></ul></li></ul></li><li><a href="#4-四次挥手">4 四次挥手</a></li></ul><!-- tocstop --><h1><span id="1-准备">1. 准备</span></h1><p>TCP是属于网络分层中的运输层(有的书也翻译为传输层)，<br>分层以及每层的协议，TCP是属于运输层(有的书也翻译为传输层)，如下两张图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311145804.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311145821.png" alt></p><p>TCP<a href="https://so.csdn.net/so/search?q=三次握手&spm=1001.2101.3001.7020">三次握手</a>会涉及到状态转换所以这里贴出TCP的状态转换图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311145910.png" alt></p><h1><span id="2tcp三次握手简述">2.TCP三次握手简述</span></h1><p>要想简单了解TCP三次握手，我们首先要了解TCP头部结构，如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311145957.png" alt></p><p>TCP传递给IP层的信息单位称为<strong>报文段或段</strong>，下面都用<strong>段</strong>做单位。</p><p>TCP三次握手如图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311150026.png" alt></p><h2><span id="21-第一次握手">2.1 第一次握手</span></h2><p>客户端给服务器发送一个SYN段(在 TCP 标头中 SYN 位字段为 <strong>1</strong> 的 TCP/IP 数据包), 该段中也包含客户端的初始序列号(Sequence number = J)。</p><blockquote><p>SYN是同步的缩写，SYN 段是发送到另一台计算机的 TCP 数据包，请求在它们之间建立连接</p></blockquote><p>2.2 第二次握手<br>服务器返回客户端 SYN +ACK 段(在 TCP 标头中SYN和ACK位字段都为 1 的 TCP/IP 数据包)， 该段中包含服务器的初始序列号(Sequence number = K)；同时使 Acknowledgment number = J + 1来表示确认已收到客户端的 SYN段(Sequence number = J)。</p><blockquote><p>ACK 是“确认”的缩写。 ACK 数据包是任何确认收到一条消息或一系列数据包的 TCP 数据包</p></blockquote><h2><span id="23-第三次握手">2.3 第三次握手</span></h2><p>客户端给服务器响应一个ACK段(在 TCP 标头中 ACK 位字段为 <strong>1</strong> 的 TCP/IP 数据包), 该段中使 Acknowledgment number = K + 1来表示确认已收到服务器的 SYN段(Sequence number = K)。</p><h2><span id="24-实例观察">2.4 实例观察</span></h2><h3><span id="241-tcpdump">2.4.1 tcpdump</span></h3><p>使用tcpdump观察如下：因为都是在本机同时运行client和server所以命令为：<code>tcpdump -i lo port 5555</code>, 只能监听回路lo接口，结果如下</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311150222.png" alt></p><p>如图用红色圈起来的就是3次握手，但是为什么最后一次握手，为什么ack = 1,而不是369535922 呢，<br>这是因为这里的第三次握手tcpdump显示的是相对的顺序号。但是为了便于观察我们需要把tcpdump的<br>顺序号变为绝对的顺序号。</p><p>命令只需要加-S(大写)便可，即：<code>tcpdump -i lo port 5555 -S</code></p><p>加上之后结果就正常了如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311150312.png" alt></p><p>从tcpdump的数据，可以明显的看到三次握手的过程是：<br>第一次握手：client SYN=1, Sequence number=2322326583 —&gt; server<br>第二次握手：server SYN=1,Sequence number=3573692787; ACK=1, Acknowledgment number=2322326583 + 1 —&gt; client<br>第三次握手：client ACK=1, Acknowledgment number=3573692787 + 1 –&gt;server</p><p>想简单了解一下TCP三次握手的话, 看到这里就可以了.</p><h1><span id="3tcp三次握手详细解析过程">3.TCP三次握手详细解析过程：</span></h1><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311151642.png" alt></p><h2><span id="31-第一次握手">3.1 第一次握手</span></h2><p>客户在socket() connect()后主动(active open)连接上服务器, 发送SYN ，这时客户端的状态是SYN_SENT<br>服务器在进行socket(),bind(),listen()后等待客户的连接，收到客户端的 SYN 后，</p><h3><span id="311-半连接队列syn-queue未满">3.1.1 半连接队列(syn queue)未满</span></h3><p>服务器将该连接的状态变为SYN_RCVD, 服务器把连接信息放到半连接队列(syn queue)里面。</p><h3><span id="312-半连接队列syn-queue已满">3.1.2 半连接队列(syn queue)已满</span></h3><p>服务器不会将该连接的状态变为SYN_RCVD，且将该连接丢弃(SYN flood攻击就是利用这个原理，<br>对于SYN foold攻击，应对方法之一是使syncookies生效，将其值置1即可，路径/proc/sys/net/ipv4/tcp_syncookies，<br>即使是半连接队列syn queue已经满了，也可以接收正常的非恶意攻击的客户端的请求，<br>但是这种方法只在无计可施的情况下使用，man tcp里面的解析是这样说的，<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311151743.png" alt></p><p>Centos6.9默认是置为1</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311151840.png" alt></p><p>半连接队列(syn queue)最大值 <code>/proc/sys/net/ipv4/tcp_max_syn_backlog</code></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311151858.png" alt></p><p><strong>SYN flood攻击</strong></p><blockquote><p>攻击方的客户端只发送SYN分节给服务器，然后对服务器发回来的SYN+ACK什么也不做，直接忽略掉，<br>不发送ACK给服务器；这样就可以占据着服务器的半连接队列的资源，导致正常的客户端连接无法连接上服务器。<a href="https://zh.wikipedia.org/wiki/SYN_flood">维基百科</a></p><p>(SYN flood攻击的方式其实也分两种，第一种，攻击方的客户端一直发送SYN，对于服务器回应的SYN+ACK什么也不做，不回应ACK, 第二种，攻击方的客户端发送SYN时，将源IP改为一个虚假的IP, 然后服务器将SYN+ACK发送到虚假的IP, 这样当然永远也得不到ACK的回应。)</p></blockquote><h2><span id="32-第二次握手">3.2 第二次握手</span></h2><p>服务器返回SYN+ACK段给到客户端，客户端收到SYN+ACK段后，客户端的状态从SYN_SENT变为ESTABLISHED，<br>也即是connect()函数的返回。</p><h2><span id="33-第三次握手">3.3 第三次握手</span></h2><p>全连接队列(accept queue)的最大值 /proc/sys/net/core/somaxconn (默认128)</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311152107.png" alt></p><p>全连接队列值 = min(backlog, somaxconn)<br>这里的backlog是listen(int sockfd, int backlog)函数里面的那个参数backlog</p><h3><span id="331-全连接队列accept-queue未满">3.3.1 全连接队列(accept queue)未满</span></h3><p>服务器收到客户端发来的ACK, 服务端该连接的状态从SYN_RCVD变为ESTABLISHED,<br>然后服务器将该连接从半连接队列(syn queue)里面移除，且将该连接的信息放到全连接队列(accept queue)里面。</p><h3><span id="332-全连接队列accept-queue已满">3.3.2 全连接队列(accept queue)已满</span></h3><p>服务器收到客户端发来的ACK, 不会将该连接的状态从SYN_RCVD变为ESTABLISHED。<br>当然全连接队列(accept queue)已满时，则根据 tcp_abort_on_overflow 的值来执行相应动作<br>/proc/sys/net/ipv4/tcp_abort_on_overflow 查看参数值<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311152138.png" alt></p><h4><span id="3321-tcp_abort_on_overflow-0">3.3.2.1 tcp_abort_on_overflow = 0</span></h4><p>则服务器建立该连接的定时器，</p><blockquote><p>这个定时器是一个服务器的规则是从新发送syn+ack的时间间隔成倍的增加，<br>比如从新了第二次握手，进行了5次，这五次的时间分别是 1s, 2s,4s,8s,16s,<br>这种倍数规则叫“二进制指数退让”(binary exponential backoff)</p></blockquote><p>给客户端定时从新发回SYN+ACK即从新进行第二次握手，(如果客户端设定的超时时间比较短就很容易出现异常)<br><code>服务器从新进行第二次握手的次数/proc/sys/net/ipv4/tcp_synack_retries</code></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311152221.png" alt></p><h4><span id="3322-tcp_abort_on_overflow-1">3.3.2.2 tcp_abort_on_overflow = 1</span></h4><p>关于tcp_abort_on_overflow的解析如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311152247.png" alt></p><p>意思应该是，当 tcp_abort_on_overflow 等于1 时,重置连接(一般是发送RST给客户端)，<br>至于怎么重置连接是系统的事情了。<br>不过我在查资料的过程发现，阿里中间件团队博客说并不是发送RST， —[阿里中间件团队博客]</p><p>这个博客跑的实例观察到的是服务器会忽略client传过来的包，然后client重传，一定次数后client认为异常，然后断开连接。<br>当然，我们写代码的都知道代码是第一手的注释，实践是检验真理的唯一标准，<br>最好还是自己以自己实践为准，因为可能你的环境跟别人的不一样。)</p><p>查看全连接队列(accept queue)的使用情况</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311152314.png" alt></p><p>如上图，第二列Recv-Q是，全连接队列接收到达的连接，第三列是Send-Q全连接队列的所能容纳最大值，<br>如果，Recv-Q 大于 Send-Q 那么大于的那部分，是要溢出的即要被丢弃overflow掉的。</p><p>希望热心的网友帮忙提改进意见时可以直接指出哪一段第几句(比如 2.4.1 tcpdump 第一段第一句, 命令tcpdump -i lo port 5555 里参数 i 用错了，应该用 I)，这样比较快速找到好改正。</p><h1><span id="4-四次挥手">4 四次挥手</span></h1><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311152407.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311152602.png" alt></p><p><strong>【注意】中断连接端可以是Client端，也可以是Server端。</strong></p><p>假设Client端发起中断连接请求，也就是发送FIN报文。Server端接到FIN报文后，意思是说”我Client端没有数据要发给你了”，但是如果你还有数据没有发送完成，则不必急着关闭Socket，可以继续发送数据。所以你先发送ACK，”告诉Client端，你的请求我收到了，但是我还没准备好，请继续你等我的消息”。这个时候Client端就进入FIN_WAIT状态，继续等待Server端的FIN报文。当Server端确定数据已发送完成，则向Client端发送FIN报文，”告诉Client端，好了，我这边数据发完了，准备好关闭连接了”。Client端收到FIN报文后，”就知道可以关闭连接了，但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。“，Server端收到ACK后，”就知道可以断开连接了”。Client端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，我Client端也可以关闭连接了。Ok，TCP连接就这样关闭了！</p><p>整个过程Client端所经历的状态如下：<br><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311152636.png" alt></p><p>而Server端所经历的过程如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220311152709.png" alt></p><p><strong>【注意】</strong> 在TIME_WAIT状态中，如果TCP client端最后一次发送的ACK丢失了，它将重新发送。TIME_WAIT状态中所需要的时间是依赖于实现方法的。典型的值为30秒、1分钟和2分钟。等待之后连接正式关闭，并且所有的资源(包括端口号)都被释放。</p><p>【问题1】为什么连接的时候是三次握手，关闭的时候却是四次握手？<br>答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。</p><p>【问题2】为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？</p><p>答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。</p><p>根据第三版《UNIX网络编程 卷1》2.7节，TIME_WAIT状态的主要目的有两个：</p><ul><li>优雅的关闭TCP连接，也就是尽量保证被动关闭的一端收到它自己发出去的FIN报文的ACK确认报文；</li><li>处理延迟的重复报文，这主要是为了避免前后两个使用相同四元组的连接中的前一个连接的报文干扰后一个连接。</li></ul><p>　　很明显，要实现上述两个目标，TIME_WAIT状态需要持续一段时间，但这段时间应该是多长呢？</p><p>　　如果只考虑上述第一个目标，则TIME_WAIT状态需要持续的时间应该参考对端的RTO（重传超时时间）以及MSL（报文在网络中的最大生存时间）来计算而不是仅仅按MSL来计算，因为只要对端没有收到针对FIN报文的ACK，就会一直持续重传FIN报文直到重传超时，所以最能实现完美关闭连接的时长计算方式应该是从对端发送第一个FIN报文开始计时到它最后一次重传FIN报文这段时长加上MSL，但这个计算方式过于保守，只有在所有的ACK报文都丢失的情况下才需要这么长的时间；另外，第一个目标虽然重要，但并不十分关键，因为既然已经到了关闭连接的最后一步，说明在这个TCP连接上的所有用户数据已经完成可靠传输，所以要不要完美的关闭这个连接其实已经不是那么关键了。因此，（我猜）RFC标准的制定者才决定以网络丢包不太严重为前提条件，然后根据第二个目标来计算TIME_WAIT状态应该持续的时长。</p><p>对于刚才说的第二点，如何理解TIME_WAIT状态持续2MSL的时间就可以避免前后两个使用相同四元组的连接中的前一个连接的报文干扰后一个连接呢？</p><p>首先我们需要了解如下要点：</p><ol><li>TCP连接中的一端发送了FIN报文之后如果收不到对端针对该FIN的ACK，则会反复多次重传FIN报文，大约持续几分钟；</li><li>被动关闭处于LAST_ACK状态的一端在收到最后一个ACK之后不会发送任何报文，立即进入CLOSED状态；</li><li>主动关闭的一端在收到被动关闭端发送过来的FIN报文并回复ACK之后进入TIME_WAIT状态；</li><li>之所以TIME_WAIT状态需要维持一段时间而不是进入CLOSED状态，是因为需要处理对端可能重传的FIN报文或其它一些因网络原因而延迟的数据报文，不处理这些报文可能导致前后两个使用相同四元组的连接中的后一个连接出现异常(详见UNIX网络编程卷1的2.7节 第三版)；</li><li>处于TIME_WAIT状态的一端在收到重传的FIN时会重新计时(rfc793 以及 linux kernel源代码tcp_timewait_state_process函数)。</li></ol><p>　　下面我们开始分析为什么在发送了最后一个ACK报文之后需要等待2MSL时长来确保没有任何属于当前连接的报文还存活于网络之中（前提是在这2MSL时间内不再收到对方的FIN报文，但即使收到了对端的FIN报文也并不影响我们的讨论，因为如果收到FIN则会回复ACK并重新计时）。</p><p>　　为了便于描述，我们设想有一个处于拆链过程中的TCP连接，这个连接的两端分别是A和B，其中A是主动关闭连接的一端，因为刚刚向对端发送了针对对端发送过来的FIN报文的ACK，此时正处于TIME_WAIT状态；而B是被动关闭的一端，此时正处于LAST_ACK状态，在收到最后一个ACK之前它会一直重传FIN报文直至超时。随着时间的流逝，A发送给B的ACK报文将会有两种结局：</p><ol><li>ACK报文在网络中丢失；如前所述，这种情况我们不需要考虑，因为除非多次重传失败，否则AB两端的状态不会发生变化直至某一个ACK不再丢失。</li><li>ACK报文被B接收到。我们假设A发送了ACK报文后过了一段时间t之后B才收到该ACK，则有 0 &lt; t &lt;= MSL。因为A并不知道它发送出去的ACK要多久对方才能收到，所以A至少要维持MSL时长的TIME_WAIT状态才能保证它的ACK从网络中消失。同时处于LAST_ACK状态的B因为收到了ACK，所以它直接就进入了CLOSED状态，而不会向网络发送任何报文。所以晃眼一看，A只需要等待1个MSL就够了，但仔细想一下其实1个MSL是不行的，因为在B收到ACK前的一刹那，B可能因为没收到ACK而重传了一个FIN报文，这个FIN报文要从网络中消失最多还需要一个MSL时长，所以A还需要多等一个MSL。</li></ol><p>　　综上所述，TIME_WAIT至少需要持续2MSL时长，这2个MSL中的第一个MSL是为了等自己发出去的最后一个ACK从网络中消失，而第二MSL是为了等在对端收到ACK之前的一刹那可能重传的FIN报文从网络中消失。另外，虽然说维持TIME_WAIT状态一段时间有2个目的，但这段时间具体应该多长主要是为了达成上述第二个目的而设计的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-准备&quot;&gt;1. 准备&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2tcp三次握手简述&quot;&gt;2.TCP三次握手简述&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#21-第一次握手&quot;&gt;2.1 第一次握手&lt;/a&gt;&lt;/l
      
    
    </summary>
    
    
      <category term="Web" scheme="https://lxb.wiki/categories/Web/"/>
    
    
      <category term="tcp" scheme="https://lxb.wiki/tags/tcp/"/>
    
  </entry>
  
  <entry>
    <title>基于zookeeper实现统一配置管理</title>
    <link href="https://lxb.wiki/15475898/"/>
    <id>https://lxb.wiki/15475898/</id>
    <published>2021-10-15T14:17:32.000Z</published>
    <updated>2022-03-10T03:31:50.107Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><!-- tocstop --><p><strong>为什么要用统一配置？</strong></p><p>我们做项目时用到的配置比如数据库配置等…我们都是写死在项目里面，如果需要更改，那么也是的修改配置文件然后再投产上去，那么问题来了，如果做集群的呢，有100台机器，这时候做修改那就太不切实际了；那么就需要用到统一配置管理啦。</p><p>解决思路</p><p>1.把公共配置抽取出来</p><p>2.对公共配置进行维护</p><p>3.修改公共配置后应用不需要重新部署</p><p>采用方案</p><p>1.公共配置抽取存放于zookeeper中并落地数据库</p><p>2.对公共配置修改后发布到zookeeper中并落地数据库</p><p>3.对应用开启配置实时监听，zookeeper配置文件一旦被修改，应用可实时监听到并获取</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310112242.png" alt></p><p><strong>下面基于zookeeper粗略实现了一个统一配置管理</strong></p><p>需要用到的jar是zkclient</p><p>配置文件Config</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.cwh.zk.util;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.io.Serializable;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Config</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span>&#123;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">1L</span>;</span><br><span class="line"><span class="keyword">private</span> String userNm;</span><br><span class="line"><span class="keyword">private</span> String userPw;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">Config</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="title function_">Config</span><span class="params">(String userNm, String userPw)</span> &#123;</span><br><span class="line"><span class="built_in">this</span>.userNm = userNm;</span><br><span class="line"><span class="built_in">this</span>.userPw = userPw;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">getUserNm</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">return</span> userNm;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUserNm</span><span class="params">(String userNm)</span> &#123;</span><br><span class="line"><span class="built_in">this</span>.userNm = userNm;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">getUserPw</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">return</span> userPw;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUserPw</span><span class="params">(String userPw)</span> &#123;</span><br><span class="line"><span class="built_in">this</span>.userPw = userPw;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="string">&quot;Config [userNm=&quot;</span> + userNm + <span class="string">&quot;, userPw=&quot;</span> + userPw + <span class="string">&quot;]&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>配置管理中心ZkConfigMag</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.cwh.zk.util;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.I0Itec.zkclient.ZkClient;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ZkConfigMag</span> &#123;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> Config config;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 从数据库加载配置</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> Config <span class="title function_">downLoadConfigFromDB</span><span class="params">()</span>&#123;</span><br><span class="line"><span class="comment">//getDB</span></span><br><span class="line">config = <span class="keyword">new</span> <span class="title class_">Config</span>(<span class="string">&quot;nm&quot;</span>, <span class="string">&quot;pw&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> config;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 配置文件上传到数据库</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">upLoadConfigToDB</span><span class="params">(String nm, String pw)</span>&#123;</span><br><span class="line"><span class="keyword">if</span>(config==<span class="literal">null</span>)config = <span class="keyword">new</span> <span class="title class_">Config</span>();</span><br><span class="line">config.setUserNm(nm);</span><br><span class="line">config.setUserPw(pw);</span><br><span class="line"><span class="comment">//updateDB</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 配置文件同步到zookeeper</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">syncConfigToZk</span><span class="params">()</span>&#123;</span><br><span class="line"><span class="type">ZkClient</span> <span class="variable">zk</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ZkClient</span>(<span class="string">&quot;localhost:2181&quot;</span>);</span><br><span class="line"><span class="keyword">if</span>(!zk.exists(<span class="string">&quot;/zkConfig&quot;</span>))&#123;</span><br><span class="line">zk.createPersistent(<span class="string">&quot;/zkConfig&quot;</span>,<span class="literal">true</span>);</span><br><span class="line">&#125;</span><br><span class="line">zk.writeData(<span class="string">&quot;/zkConfig&quot;</span>, config);</span><br><span class="line">zk.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>应用监听实现ZkGetConfigClient</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.cwh.zk.util;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.I0Itec.zkclient.IZkDataListener;</span><br><span class="line"><span class="keyword">import</span> org.I0Itec.zkclient.ZkClient;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ZkGetConfigClient</span> &#123;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> Config config;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> Config <span class="title function_">getConfig</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="type">ZkClient</span> <span class="variable">zk</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ZkClient</span>(<span class="string">&quot;localhost:2181&quot;</span>);</span><br><span class="line">config = (Config)zk.readData(<span class="string">&quot;/zkConfig&quot;</span>);</span><br><span class="line">System.out.println(<span class="string">&quot;加载到配置：&quot;</span>+config.toString());</span><br><span class="line"></span><br><span class="line"><span class="comment">//监听配置文件修改</span></span><br><span class="line">zk.subscribeDataChanges(<span class="string">&quot;/zkConfig&quot;</span>, <span class="keyword">new</span> <span class="title class_">IZkDataListener</span>()&#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleDataChange</span><span class="params">(String arg0, Object arg1)</span></span><br><span class="line"><span class="keyword">throws</span> Exception &#123;</span><br><span class="line">config = (Config) arg1;</span><br><span class="line">System.out.println(<span class="string">&quot;监听到配置文件被修改：&quot;</span>+config.toString());</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleDataDeleted</span><span class="params">(String arg0)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">config = <span class="literal">null</span>;</span><br><span class="line">System.out.println(<span class="string">&quot;监听到配置文件被删除&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;);</span><br><span class="line"><span class="keyword">return</span> config;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"><span class="type">ZkGetConfigClient</span> <span class="variable">client</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ZkGetConfigClient</span>();</span><br><span class="line">client.getConfig();</span><br><span class="line">System.out.println(client.config.toString());</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">System.out.println(client.config.toString());</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试，启动配置管理中心</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.cwh.zkConfig.test;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> com.cwh.zk.util.Config;</span><br><span class="line"><span class="keyword">import</span> com.cwh.zk.util.ZkConfigMag;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ZkConfigTest</span> &#123;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"><span class="type">ZkConfigMag</span> <span class="variable">mag</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ZkConfigMag</span>();</span><br><span class="line"><span class="type">Config</span> <span class="variable">config</span> <span class="operator">=</span> mag.downLoadConfigFromDB();</span><br><span class="line">System.out.println(<span class="string">&quot;....加载数据库配置....&quot;</span>+config.toString());</span><br><span class="line">mag.syncConfigToZk();</span><br><span class="line">System.out.println(<span class="string">&quot;....同步配置文件到zookeeper....&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//歇会，这样看比较清晰</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">mag.upLoadConfigToDB(<span class="string">&quot;cwhcc&quot;</span>, <span class="string">&quot;passwordcc&quot;</span>);</span><br><span class="line">System.out.println(<span class="string">&quot;....修改配置文件....&quot;</span>+config.toString());</span><br><span class="line">mag.syncConfigToZk();</span><br><span class="line">System.out.println(<span class="string">&quot;....同步配置文件到zookeeper....&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试结果：</p><p>配置管理中心打印：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310113057.png" alt></p><p>应用监听：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310113139.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;



&lt;!-- tocstop --&gt;

&lt;p&gt;&lt;strong&gt;为什么要用统一配置？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们做项目时用到的配置比如数据库配置等…我们都是写死在项目里面，如果需要更改，那么也是的修改配置文件然后再投产上去，那么问题来了，如果做
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxb.wiki/categories/Design/"/>
    
    
      <category term="zk" scheme="https://lxb.wiki/tags/zk/"/>
    
  </entry>
  
  <entry>
    <title>ZooKeeper总结</title>
    <link href="https://lxb.wiki/f07e16f1/"/>
    <id>https://lxb.wiki/f07e16f1/</id>
    <published>2021-10-15T13:51:29.000Z</published>
    <updated>2022-03-10T03:33:17.525Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#一-什么是zookeeper">一、什么是ZooKeeper</a></li><li><a href="#二-为什么zookeeper能干这么多">二、为什么ZooKeeper能干这么多？</a><ul><li><a href="#21-监听器">2.1 监听器</a></li><li><a href="#31-统一配置管理">3.1 统一配置管理</a></li><li><a href="#32-统一命名服务">3.2 统一命名服务</a></li><li><a href="#33-分布式锁">3.3 分布式锁</a></li><li><a href="#34集群状态">3.4集群状态</a></li></ul></li></ul><!-- tocstop --><p>ZooKeeper 可以作为<strong>注册中心</strong>，也可以作为<strong>分布式锁</strong>的一种实现。Kafka 使用 ZooKeeper <strong>管理自己的元数据配置</strong>。</p><h2><span id="一-什么是zookeeper">一、什么是ZooKeeper</span></h2><p>官网介绍</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310105425.png" alt></p><p>官网还有另一段话：</p><blockquote><p>ZooKeeper: A Distributed Coordination Service for Distributed Applications</p></blockquote><p><strong>Wiki</strong>中对ZooKeeper的介绍：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310105519.png" alt></p><p>概括：</p><ul><li>ZooKeeper主要<strong>服务于分布式系统</strong>，可以用ZooKeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理。</li><li>使用分布式系统就无法避免对节点管理的问题(需要实时感知节点的状态、对节点进行统一管理等等)，而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper作为一个能够<strong>通用</strong>解决这些问题的中间件就应运而生了。</li></ul><h2><span id="二-为什么zookeeper能干这么多">二、为什么ZooKeeper能干这么多？</span></h2><p>Wiki 中提到：</p><blockquote><p>ZooKeeper nodes store their data in a hierarchical name space, much like a file system or a <a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Tree_(data_structure)">tree</a> data structure</p></blockquote><p>ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗<strong>树</strong>，每个节点叫做<strong>ZNode</strong>。每一个节点可以通过<strong>路径</strong>来标识，结构图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310105632.png" alt></p><p>那ZooKeeper这颗”树”有什么特点呢？？ZooKeeper的节点我们称之为<strong>Znode</strong>，Znode分为<strong>两种</strong>类型：</p><ul><li><strong>短暂/临时(Ephemeral)</strong>：当客户端和服务端断开连接后，所创建的Znode(节点)<strong>会自动删除</strong></li><li><strong>持久(Persistent)</strong>：当客户端和服务端断开连接后，所创建的Znode(节点)<strong>不会删除</strong></li></ul><blockquote><p>ZooKeeper和Redis一样，也是C/S结构(分成客户端和服务端)</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310105707.png" alt></p><h3><span id="21-监听器">2.1 监听器</span></h3><p>在上面我们已经简单知道了ZooKeeper的数据结构了，ZooKeeper还配合了<strong>监听器</strong>才能够做那么多事的。</p><p><strong>常见</strong>的监听场景有以下两项：</p><ul><li>监听Znode节点的<strong>数据变化</strong></li><li>监听子节点的<strong>增减变化</strong></li></ul><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310105734.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310105749.png" alt></p><p>没错，通过<strong>监听+Znode节点(持久/短暂[临时])</strong>，ZooKeeper就可以玩出这么多花样了。</p><h3><span id="31-统一配置管理">3.1 统一配置管理</span></h3><p>比如我们现在有三个系统A、B、C，他们有三份配置，分别是<code>ASystem.yml、BSystem.yml、CSystem.yml</code>，然后，这三份配置又非常类似，很多的配置项几乎都一样。</p><ul><li>此时，如果我们要改变其中一份配置项的信息，很可能其他两份都要改。并且，改变了配置项的信息<strong>很可能就要重启系统</strong></li></ul><p>于是，我们希望把<code>ASystem.yml、BSystem.yml、CSystem.yml</code>相同的配置项抽取出来成一份<strong>公用</strong>的配置<code>common.yml</code>，并且即便<code>common.yml</code>改了，也不需要系统A、B、C重启。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310105843.png" alt></p><p>做法：我们可以将<code>common.yml</code>这份配置放在ZooKeeper的Znode节点中，系统A、B、C监听着这个Znode节点有无变更，如果变更了，<strong>及时</strong>响应。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310105910.png" alt></p><p>参考资料：<a href="https://lxb.wiki/15475898/">基于zookeeper实现统一配置管理</a></p><h3><span id="32-统一命名服务">3.2 统一命名服务</span></h3><p>统一命名服务的理解其实跟<strong>域名</strong>一样，是我们为这某一部分的资源给它<strong>取一个名字</strong>，别人通过这个名字就可以拿到对应的资源。</p><p>比如说，现在我有一个域名<code>www.java3y.com</code>，但我这个域名下有多台机器：</p><ul><li>192.168.1.1</li><li>192.168.1.2</li><li>192.168.1.3</li><li>192.168.1.4</li></ul><p>别人访问<code>www.java3y.com</code>即可访问到我的机器，而不是通过IP去访问。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310110058.png" alt></p><h3><span id="33-分布式锁">3.3 分布式锁</span></h3><p>我们可以使用ZooKeeper来实现分布式锁，那是怎么做的呢？？下面来看看：</p><p>系统A、B、C都去访问<code>/locks</code>节点</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310110143.png" alt></p><p>访问的时候会创建<strong>带顺序号的临时/短暂</strong>(<code>EPHEMERAL_SEQUENTIAL</code>)节点，比如，系统A创建了<code>id_000000</code>节点，系统B创建了<code>id_000002</code>节点，系统C创建了<code>id_000001</code>节点。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310111211.png" alt></p><p>接着，拿到<code>/locks</code>节点下的所有子节点(id_000000,id_000001,id_000002)，<strong>判断自己创建的是不是最小的那个节点</strong></p><ul><li><p>如果是，则拿到锁。</p></li><li><ul><li>释放锁：执行完操作后，把创建的节点给删掉</li></ul></li><li><p>如果不是，则监听比自己要小1的节点变化</p></li></ul><p>举个例子：</p><ul><li>系统A拿到<code>/locks</code>节点下的所有子节点，经过比较，发现自己(<code>id_000000</code>)，是所有子节点最小的。所以得到锁</li><li>系统B拿到<code>/locks</code>节点下的所有子节点，经过比较，发现自己(<code>id_000002</code>)，不是所有子节点最小的。所以监听比自己小1的节点<code>id_000001</code>的状态</li><li>系统C拿到<code>/locks</code>节点下的所有子节点，经过比较，发现自己(<code>id_000001</code>)，不是所有子节点最小的。所以监听比自己小1的节点<code>id_000000</code>的状态</li><li>……</li><li>等到系统A执行完操作以后，将自己创建的节点删除(<code>id_000000</code>)。通过监听，系统C发现<code>id_000000</code>节点已经删除了，发现自己已经是最小的节点了，于是顺利拿到锁</li><li>….系统B如上</li></ul><h3><span id="34集群状态">3.4集群状态</span></h3><p>ZooKeeper是怎么”<strong>感知</strong>“节点的动态新增或者删除的</p><p>还是以三个系统A、B、C为例，在ZooKeeper中创建<strong>临时节点</strong>即可：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220310111532.png" alt></p><p>只要系统A挂了，那<code>/groupMember/A</code>这个节点就会删除，通过<strong>监听</strong><code>groupMember</code>下的子节点，系统B和C就能够感知到系统A已经挂了。(新增也是同理)</p><p>除了能够感知节点的上下线变化，ZooKeeper还可以实现<strong>动态选举Master</strong>的功能。(如果集群是主从架构模式下)</p><p>原理也很简单，如果想要实现动态选举Master的功能，Znode节点的类型是带<strong>顺序号的临时节点</strong>(<code>EPHEMERAL_SEQUENTIAL</code>)就好了。</p><ul><li>Zookeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的Znode节点就会删除。然后让<strong>新的最小编号作为Master</strong>，这样就可以实现动态选举的功能了。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#一-什么是zookeeper&quot;&gt;一、什么是ZooKeeper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#二-为什么zookeeper能干这么多&quot;&gt;二、为什么ZooKeeper能干这么多？&lt;/a&gt;&lt;ul&gt;
&lt;li
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxb.wiki/categories/Design/"/>
    
    
      <category term="zk" scheme="https://lxb.wiki/tags/zk/"/>
    
  </entry>
  
  <entry>
    <title>Go 八股</title>
    <link href="https://lxb.wiki/30fc3293/"/>
    <id>https://lxb.wiki/30fc3293/</id>
    <published>2021-10-10T13:18:51.000Z</published>
    <updated>2022-03-07T02:23:28.888Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-相比较于其他语言-go-有什么优势或者特点"><strong>1. 相比较于其他语言, Go 有什么优势或者特点？</strong></a></li><li><a href="#2-golang-里的-gmp-模型"><strong>2. Golang 里的 GMP 模型？</strong></a></li><li><a href="#3-goroutine-的协程有什么特点和线程相比"><strong>3. goroutine 的协程有什么特点，和线程相比？</strong></a></li><li><a href="#4-go-的垃圾回收机制"><strong>4. Go 的垃圾回收机制？</strong></a></li><li><a href="#5-go-的内存分配是怎么样的"><strong>5. go 的内存分配是怎么样的？</strong></a></li><li><a href="#6-channel-的内部实现是怎么样的"><strong>6. channel 的内部实现是怎么样的？</strong></a></li><li><a href="#7-对已经关闭的-channel-进行读写会怎么样"><strong>7. 对已经关闭的 channel 进行读写，会怎么样？</strong></a></li><li><a href="#8-map-为什么不是线程安全的"><strong>8. map 为什么不是线程安全的？</strong></a></li><li><a href="#9-map-的-key-为什么得是可比较类型的"><strong>9. map 的 key 为什么得是可比较类型的？</strong></a></li></ul><!-- tocstop --><h2><span id="1-相比较于其他语言-go-有什么优势或者特点"><strong>1. 相比较于其他语言, Go 有什么优势或者特点？</strong></span></h2><ul><li>Go 允许跨平台编译，编译出来的是二进制的可执行文件，直接部署在对应系统上即可运行。</li><li>Go 在语言层次上天生支持高并发，通过 goroutine 和 channel 实现。channel 的理论依据是 CSP 并发模型， 即所谓的<code>通过通信来共享内存</code>；Go 在 runtime 运行时里实现了属于自己的调度机制：GMP，降低了内核态和用户态的切换成本。</li><li>Go 的代码风格是强制性的统一，如果没有按照规定来，会编译不通过。</li></ul><h2><span id="2-golang-里的-gmp-模型"><strong>2. Golang 里的 GMP 模型？</strong></span></h2><p>GMP 模型是 golang 自己的一个调度模型，它抽象出了下面三个结构：</p><ul><li><code>G：</code> 也就是协程 goroutine，由 Go runtime 管理。我们可以认为它是用户级别的线程。</li><li><code>P：</code> processor 处理器。每当有 goroutine 要创建时，会被添加到 P 上的 goroutine 本地队列上，如果 P 的本地队列已满，则会维护到全局队列里。</li><li><code>M：</code> 系统线程。在 M 上有调度函数，它是真正的调度执行者，M 需要跟 P 绑定，并且会让 P 按下面的原则挑出个 goroutine 来执行：</li></ul><p>优先从 P 的本地队列获取 goroutine 来执行；如果本地队列没有，从全局队列获取，如果全局队列也没有，会从其他的 P 上偷取 goroutine。</p><h2><span id="3-goroutine-的协程有什么特点和线程相比"><strong>3. goroutine 的协程有什么特点，和线程相比？</strong></span></h2><p>goroutine 非常的<strong>轻量</strong>，初始分配只有 2KB，当栈空间不够用时，会自动扩容。同时，自身存储了执行 stack 信息，用于在调度时能恢复上下文信息。</p><p>而线程比较重，一般初始大小有几 MB(不同系统分配不同)，线程是由操作系统调度，是操作系统的调度基本单位。而 golang 实现了自己的调度机制，goroutine 是它的调度基本单位。</p><h2><span id="4-go-的垃圾回收机制"><strong>4. Go 的垃圾回收机制？</strong></span></h2><p>Go 采用的是三色标记法，将内存里的对象分为了三种：</p><ul><li>白色对象：未被使用的对象；</li><li>灰色对象：当前对象有引用对象，但是还没有对引用对象继续扫描过；</li><li>黑色对象，对上面提到的灰色对象的引用对象已经全部扫描过了，下次不用再扫描它了。</li></ul><p>当垃圾回收开始时，Go 会把根对象标记为灰色，其他对象标记为白色，然后从根对象遍历搜索，按照上面的定义去不断的对灰色对象进行扫描标记。当没有灰色对象时，表示所有对象已扫描过，然后就可以开始清除白色对象了。</p><h2><span id="5-go-的内存分配是怎么样的"><strong>5. go 的内存分配是怎么样的？</strong></span></h2><p>Go 的内存分配借鉴了 Google 的 TCMalloc 分配算法，其核心思想是内存池 + 多级对象管理。内存池主要是预先分配内存，减少向系统申请的频率；多级对象有：mheap、mspan、arenas、mcentral、mcache。它们以 mspan 作为基本分配单位。具体的分配逻辑如下：</p><ul><li>当要分配大于 32K 的对象时，从 mheap 分配。</li><li>当要分配的对象小于等于 32K 大于 16B 时，从 P 上的 mcache 分配，如果 mcache 没有内存，则从 mcentral 获取，如果 mcentral 也没有，则向 mheap 申请，如果 mheap 也没有，则从操作系统申请内存。</li><li>当要分配的对象小于等于 16B 时，从 mcache 上的微型分配器上分配。</li></ul><h2><span id="6-channel-的内部实现是怎么样的"><strong>6. channel 的内部实现是怎么样的？</strong></span></h2><p>channel 内部维护了两个 goroutine 队列，一个是待发送数据的 goroutine 队列，另一个是待读取数据的 goroutine 队列。</p><p>每当对 channel 的读写操作超过了可缓冲的 goroutine 数量，那么当前的 goroutine 就会被挂到对应的队列上，直到有其他 goroutine 执行了与之相反的读写操作，将它重新唤起。</p><h2><span id="7-对已经关闭的-channel-进行读写会怎么样"><strong>7. 对已经关闭的 channel 进行读写，会怎么样？</strong></span></h2><p>当 channel 被关闭后，如果继续往里面写数据，程序会直接 <strong>panic</strong> 退出。如果是读取关闭后的 channel，不会产生 pannic，还可以读到数据。但关闭后的 channel 没有数据可读取时，将得到零值，即对应类型的默认值。</p><p>为了能知道当前 channel 是否被关闭，可以使用下面的写法来判断。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if v, ok := &lt;-ch; !ok &#123;</span><br><span class="line"> fmt.Println(&quot;channel 已关闭，读取不到数据&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还可以使用下面的写法不断的获取 channel 里的数据：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for data := range ch &#123;</span><br><span class="line"> // get data dosomething</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种用法会在读取完 channel 里的数据后就结束 for 循环，执行后面的代码。</p><h2><span id="8-map-为什么不是线程安全的"><strong>8. map 为什么不是线程安全的？</strong></span></h2><p>map 在扩缩容时，需要进行数据迁移，迁移的过程并没有采用锁机制防止并发操作，而是会对某个标识位标记为 1，表示此时正在迁移数据。如果有其他 goroutine 对 map 也进行写操作，当它检测到标识位为 1 时，将会直接 panic。</p><p>如果我们想要并发安全的 map，则需要使用 sync.map。</p><h2><span id="9-map-的-key-为什么得是可比较类型的"><strong>9. map 的 key 为什么得是可比较类型的？</strong></span></h2><p>map 的 key、value 是存在 buckets 数组里的，每个 bucket 又可以容纳 8 个 key 和 8 个 value。当要插入一个新的 key - value 时，会对 key 进行 hash 运算得到一个 hash 值，然后根据 hash 值 的低几位(取几位取决于桶的数量，比如一开始桶的数量是 5，则取低 5 位)来决定命中哪个 bucket。</p><p>在命中某个 bucket 后，又会根据 hash 值的高 8 位来决定是 8 个 key 里的哪个位置。如果不巧，发生了 hash 冲突，即该位置上已经有<strong>其他 key</strong> 存在了，则会去其他空位置寻找插入。如果全都满了，则使用 overflow 指针指向一个新的 bucket，重复刚刚的寻找步骤。</p><p>从上面的流程可以看出，在判断 hash 冲突，即该位置是否已有<strong>其他 key</strong> 时，肯定是要进行比较的，所以 key 必须得是可比较类型的。像 slice、map、function 就不能作为 key。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-相比较于其他语言-go-有什么优势或者特点&quot;&gt;&lt;strong&gt;1. 相比较于其他语言, Go 有什么优势或者特点？&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-golang-里的-gmp
      
    
    </summary>
    
    
      <category term="Golang" scheme="https://lxb.wiki/categories/Golang/"/>
    
    
      <category term="Go" scheme="https://lxb.wiki/tags/Go/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 主从同步</title>
    <link href="https://lxb.wiki/4c6cb38f/"/>
    <id>https://lxb.wiki/4c6cb38f/</id>
    <published>2021-09-26T14:01:43.000Z</published>
    <updated>2022-03-05T14:04:02.534Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><!-- tocstop --><p>Kafka允许topic的分区拥有若干副本，这个数量是可以配置的，你可以为每个topci配置副本的数量。Kafka会自动在每个个副本上备份数据，所以当一个节点down掉时数据依然是可用的。</p><p>Kafka的副本功能不是必须的，你可以配置只有一个副本，这样其实就相当于只有一份数据。</p><p>创建副本的单位是topic的分区，每个分区都有一个leader和零或多个followers.所有的读写操作都由leader处理，一般分区的数量都比broker的数量多的多，各分区的leader均匀的分布在brokers中。所有的followers都复制leader的日志，日志中的消息和顺序都和leader中的一致。flowers向普通的consumer那样从leader那里拉取消息并保存在自己的日志文件中。<br>许多分布式的消息系统自动的处理失败的请求，它们对一个节点是否<br>着（alive）”有着清晰的定义。Kafka判断一个节点是否活着有两个条件：</p><ol><li>节点必须可以维护和ZooKeeper的连接，Zookeeper通过心跳机制检查每个节点的连接。</li><li>如果节点是个follower,他必须能及时的同步leader的写操作，延时不能太久。</li></ol><p>符合以上条件的节点准确的说应该是“同步中的（in sync）”，而不是模糊的说是“活着的”或是“失败的”。Leader会追踪所有“同步中”的节点，一旦一个down掉了，或是卡住了，或是延时太久，leader就会把它移除。至于延时多久算是“太久”，是由参数replica.lag.max.messages决定的，怎样算是卡住了，怎是由参数replica.lag.time.max.ms决定的。<br>只有当消息被所有的副本加入到日志中时，才算是“committed”，只有committed的消息才会发送给consumer，这样就不用担心一旦leader down掉了消息会丢失。Producer也可以选择是否等待消息被提交的通知，这个是由参数request.required.acks决定的。</p><p>Kafka保证只要有一个“同步中”的节点，“committed”的消息就不会丢失。</p><p><strong>Leader的选择</strong></p><p>Kafka的核心是日志文件，日志文件在集群中的同步是分布式数据系统最基础的要素。  </p><p>如果leaders永远不会down的话我们就不需要followers了！一旦leader down掉了，需要在followers中选择一个新的leader.但是followers本身有可能延时太久或者crash，所以必须选择高质量的follower作为leader.必须保证，一旦一个消息被提交了，但是leader down掉了，新选出的leader必须可以提供这条消息。大部分的分布式系统采用了多数投票法则选择新的leader,对于多数投票法则，就是根据所有副本节点的状况动态的选择最适合的作为leader.Kafka并不是使用这种方法。</p><p>Kafaka动态维护了一个同步状态的副本的集合（a set of in-sync replicas），简称ISR，在这个集合中的节点都是和leader保持高度一致的，任何一条消息必须被这个集合中的每个节点读取并追加到日志中了，才回通知外部这个消息已经被提交了。因此这个集合中的任何一个节点随时都可以被选为leader.ISR在ZooKeeper中维护。ISR中有f+1个节点，就可以允许在f个节点down掉的情况下不会丢失消息并正常提供服。ISR的成员是动态的，如果一个节点被淘汰了，当它重新达到“同步中”的状态时，他可以重新加入ISR.这种leader的选择方式是非常快速的，适合kafka的应用场景。</p><p>一个邪恶的想法：如果所有节点都down掉了怎么办？Kafka对于数据不会丢失的保证，是基于至少一个节点是存活的，一旦所有节点都down了，这个就不能保证了。<br>实际应用中，当所有的副本都down掉时，必须及时作出反应。可以有以下两种选择:</p><ol><li>等待ISR中的任何一个节点恢复并担任leader。</li><li>选择所有节点中（不只是ISR）第一个恢复的节点作为leader.</li></ol><p>这是一个在可用性和连续性之间的权衡。如果等待ISR中的节点恢复，一旦ISR中的节点起不起来或者数据都是了，那集群就永远恢复不了了。如果等待ISR意外的节点恢复，这个节点的数据就会被作为线上数据，有可能和真实的数据有所出入，因为有些数据它可能还没同步到。Kafka目前选择了第二种策略，在未来的版本中将使这个策略的选择可配置，可以根据场景灵活的选择。</p><p>这种窘境不只Kafka会遇到，几乎所有的分布式数据系统都会遇到。</p><p><strong>副本管理</strong></p><p>以上仅仅以一个topic一个分区为例子进行了讨论，但实际上一个Kafka将会管理成千上万的topic分区.Kafka尽量的使所有分区均匀的分布到集群所有的节点上而不是集中在某些节点上，另外主从关系也尽量均衡这样每个几点都会担任一定比例的分区的leader.</p><p>优化leader的选择过程也是很重要的，它决定了系统发生故障时的空窗期有多久。Kafka选择一个节点作为“controller”,当发现有节点down掉的时候它负责在游泳分区的所有节点中选择新的leader,这使得Kafka可以批量的高效的管理所有分区节点的主从关系。如果controller down掉了，活着的节点中的一个会备切换为新的controller.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;



&lt;!-- tocstop --&gt;

&lt;p&gt;Kafka允许topic的分区拥有若干副本，这个数量是可以配置的，你可以为每个topci配置副本的数量。Kafka会自动在每个个副本上备份数据，所以当一个节点down掉时数据依然是可用的。&lt;/p&gt;
&lt;p&gt;K
      
    
    </summary>
    
    
      <category term="Web" scheme="https://lxb.wiki/categories/Web/"/>
    
    
      <category term="mq" scheme="https://lxb.wiki/tags/mq/"/>
    
      <category term="kafka" scheme="https://lxb.wiki/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 架构</title>
    <link href="https://lxb.wiki/44075289/"/>
    <id>https://lxb.wiki/44075289/</id>
    <published>2021-09-25T13:55:19.000Z</published>
    <updated>2022-03-05T14:00:46.133Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#一-简介">一、简介</a><ul><li><a href="#11-概述">1.1 概述</a></li><li><a href="#12-消息系统介绍">1.2 消息系统介绍</a></li><li><a href="#13-点对点消息传递">1.3 点对点消息传递</a></li><li><a href="#14-发布-订阅消息传递">1.4 发布-订阅消息传递</a></li><li><a href="#15-kafka的优点">1.5 Kafka的优点</a></li><li><a href="#16-常用mq对比">1.6 常用MQ对比</a></li><li><a href="#17-kafka中的术语解释">1.7 Kafka中的术语解释</a><ul><li><a href="#概述">概述</a></li><li><a href="#1-broker">1 broker</a></li><li><a href="#2-topic">2 Topic</a></li><li><a href="#3-partition">3 <strong>Partition</strong></a></li><li><a href="#4-producer">4 Producer</a></li><li><a href="#5-consumer">5 Consumer</a></li><li><a href="#6-consumer-group">6 Consumer Group</a></li><li><a href="#7-leader">7 Leader</a></li><li><a href="#8-follower">8 Follower</a></li><li><a href="#9-offset">9 Offset</a></li></ul></li></ul></li><li><a href="#一-kafka的架构">一、Kafka的架构</a><ul><li><a href="#21-分布式模型">2.1 分布式模型</a></li></ul></li><li><a href="#二-topics和partition">二、Topics和Partition</a></li><li><a href="#三-producer消息路由">三、Producer消息路由</a></li><li><a href="#四-consumer-group">四、Consumer Group</a></li><li><a href="#五-push-vs-pull">五、Push vs. Pull</a></li><li><a href="#六-kafka-delivery-guarantee">六、Kafka delivery guarantee</a></li></ul><!-- tocstop --><h2><span id="一-简介">一、简介</span></h2><h3><span id="11-概述">1.1 概述</span></h3><p>Kafka主要设计目标如下：</p><ul><li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。</li><li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。</li><li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。</li><li>同时支持离线数据处理和实时数据处理。</li><li>支持在线水平扩展</li></ul><h3><span id="12-消息系统介绍">1.2 消息系统介绍</span></h3><p>一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个或多个应用间是如何传递的。分布式消息传递基于可靠的消息队列，在客户端应用和消息系统之间异步传递消息。有两种主要的消息传递模式：<strong>点对点传递模式、发布-订阅模式</strong>。大部分的消息系统选用发布-订阅模式。<strong>Kafka就是一种发布-订阅模式</strong>。</p><h3><span id="13-点对点消息传递">1.3 点对点消息传递</span></h3><p>在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费者消费队列中的数据。但是一条消息只能被消费一次。当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。这种架构描述示意图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220305215705.png" alt></p><p><strong>生产者发送一条消息到queue，只有一个消费者能收到</strong>。</p><h3><span id="14-发布-订阅消息传递">1.4 发布-订阅消息传递</span></h3><p>在发布-订阅消息系统中，消息被持久化到一个topic中。与点对点消息系统不同的是，消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个消费者消费，数据被消费后不会立马删除。在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。该模式的示例图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220305215731.png" alt></p><p><strong>发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息</strong>。</p><h3><span id="15-kafka的优点">1.5 Kafka的优点</span></h3><p>1）解耦：</p><p>在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p><p>2）冗余：（副本）</p><p>有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。</p><p>3）扩展性</p><p>因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。</p><p>4）灵活性&amp;峰值处理能力</p><p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p><p>5）可恢复性</p><p>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p><p>6）顺序保证</p><p>在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。</p><p>7）缓冲</p><p>在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。</p><p>8）异步通信</p><p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p><h3><span id="16-常用mq对比">1.6 常用MQ对比</span></h3><p>1）RabbitMQ</p><p>RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。</p><p>2）Redis</p><p>Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。</p><p>3）ZeroMQ</p><p>ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZeroMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演这个服务器角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。</p><p>4）ActiveMQ</p><p>ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。</p><p>5）Kafka/Jafka</p><p>Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。</p><h3><span id="17-kafka中的术语解释">1.7 Kafka中的术语解释</span></h3><h4><span id="概述">概述</span></h4><p>在深入理解Kafka之前，先介绍一下Kafka中的术语。下图展示了Kafka的相关术语以及之间的关系：</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220305215821.png" alt></p><p>上图中一个topic配置了3个partition。Partition1有两个offset：0和1。Partition2有4个offset。Partition3有1个offset。副本的id和副本所在的机器的id恰好相同。</p><p>如果一个topic的副本数为3，那么Kafka将在集群中为每个partition创建3个相同的副本。集群中的每个broker存储一个或多个partition。多个producer和consumer可同时生产和消费数据。</p><h4><span id="1-broker">1 broker</span></h4><p>Kafka 集群包含一个或多个服务器，服务器节点称为broker。</p><p>broker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。</p><p>如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。</p><p>如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。</p><h4><span id="2-topic">2 Topic</span></h4><p>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</p><p>类似于数据库的表名</p><h4><span id="3-partition">3 <strong>Partition</strong></span></h4><p>topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。</p><h4><span id="4-producer">4 Producer</span></h4><p>生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息<strong>追加</strong>到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。</p><h4><span id="5-consumer">5 Consumer</span></h4><p>消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。</p><h4><span id="6-consumer-group">6 Consumer Group</span></h4><p>每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。topic的消息会复制-给consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。</p><h4><span id="7-leader">7 Leader</span></h4><p>每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。</p><h4><span id="8-follower">8 Follower</span></h4><p>Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。</p><h4><span id="9-offset">9 Offset</span></h4><p>kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka</p><h2><span id="一-kafka的架构">一、Kafka的架构</span></h2><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220305215857.png" alt></p><p>如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。</p><h3><span id="21-分布式模型">2.1 分布式模型</span></h3><p>Kafka每个主题的多个分区日志分布式地存储在Kafka集群上，同时为了故障容错，每个分区都会以副本的方式复制到多个消息代理节点上。其中一个节点会作为主副本（Leader），其他节点作为备份副本（Follower，也叫作从副本）。主副本会负责所有的客户端读写操作，备份副本仅仅从主副本同步数据。当主副本出现故障时，备份副本中的一个副本会被选择为新的主副本。因为每个分区的副本中只有主副本接受读写，所以每个服务器端都会作为某些分区的主副本，以及另外一些分区的备份副本，这样Kafka集群的所有服务端整体上对客户端是负载均衡的。</p><p>Kafka的生产者和消费者相对于服务器端而言都是客户端。</p><p>Kafka生产者客户端发布消息到服务端的指定主题，会指定消息所属的分区。生产者发布消息时根据消息是否有键，采用不同的分区策略。消息没有键时，通过轮询方式进行客户端负载均衡；消息有键时，根据分区语义（例如hash）确保相同键的消息总是发送到同一分区。</p><p>Kafka的消费者通过订阅主题来消费消息，并且每个消费者都会设置一个消费组名称。因为生产者发布到主题的每一条消息都只会发送给消费者组的一个消费者。所以，如果要实现传统消息系统的“队列”模型，可以让每个消费者都拥有相同的消费组名称，这样消息就会负责均衡到所有的消费者；如果要实现“发布-订阅”模型，则每个消费者的消费者组名称都不相同，这样每条消息就会广播给所有的消费者。</p><p>分区是消费者现场模型的最小并行单位。如下图（图1）所示，生产者发布消息到一台服务器的3个分区时，只有一个消费者消费所有的3个分区。在下图（图2）中，3个分区分布在3台服务器上，同时有3个消费者分别消费不同的分区。假设每个服务器的吞吐量时300MB，在下图（图1）中分摊到每个分区只有100MB，而在下图（图2）中，集群整体的吞吐量有900MB。可以看到，增加服务器节点会提升集群的性能，增加消费者数量会提升处理性能。</p><p>同一个消费组下多个消费者互相协调消费工作，Kafka会将所有的分区平均地分配给所有的消费者实例，这样每个消费者都可以分配到数量均等的分区。Kafka的消费组管理协议会动态地维护消费组的成员列表，当一个新消费者加入消费者组，或者有消费者离开消费组，都会触发再平衡操作。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220305215916.png" alt></p><p>Kafka的消费者消费消息时，只保证在一个分区内的消息的完全有序性，并不保证同一个主题汇中多个分区的消息顺序。而且，消费者读取一个分区消息的顺序和生产者写入到这个分区的顺序是一致的。比如，生产者写入“hello”和“Kafka”两条消息到分区P1，则消费者读取到的顺序也一定是“hello”和“Kafka”。如果业务上需要保证所有消息完全一致，只能通过设置一个分区完成，但这种做法的缺点是最多只能有一个消费者进行消费。一般来说，只需要保证每个分区的有序性，再对消息假设键来保证相同键的所有消息落入同一分区，就可以满足绝大多数的应用。</p><h2><span id="二-topics和partition">二、Topics和Partition</span></h2><p>Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。创建一个topic时，同时可以指定分区数目，分区数越多，其吞吐量也越大，但是需要的资源也越多，同时也会导致更高的不可用性，kafka在接收到生产者发送的消息之后，会根据均衡策略将消息存储到不同的分区中。因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220305215934.png" alt></p><p>对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略删除旧数据。一是基于时间，二是基于Partition文件大小。例如可以通过配置$KAFKA_HOME/config/server.properties，让Kafka删除一周前的数据，也可在Partition文件超过1GB时删除旧数据，配置如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The minimum age of a log file to be eligible for deletion</span></span><br><span class="line">log.retention.hours=168</span><br><span class="line"><span class="comment"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span></span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line"><span class="comment"># The interval at which log segments are checked to see if they can be deleted according to the retention policies</span></span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"><span class="comment"># If log.cleaner.enable=true is set the cleaner will be enabled and individual logs can then be marked for log compaction.</span></span><br><span class="line">log.cleaner.enable=<span class="literal">false</span></span><br></pre></td></tr></table></figure><p>因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高Kafka性能无关。选择怎样的删除策略只与磁盘以及具体的需求有关。另外，Kafka会为每一个Consumer Group保留一些metadata信息——当前消费的消息的position，也即offset。这个offset由Consumer控制。正常情况下Consumer会在消费完一条消息后递增该offset。当然，Consumer也可将offset设成一个较小的值，重新消费一些消息。因为offet由Consumer控制，所以Kafka broker是无状态的，它不需要标记哪些消息被哪些消费过，也不需要通过broker去保证同一个Consumer Group只有一个Consumer能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。</p><h2><span id="三-producer消息路由">三、Producer消息路由</span></h2><p>Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就实现了负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O将会成为这个Topic的性能瓶颈，而有了Partition后，不同的消息可以并行写入不同broker的不同Partition里，极大的提高了吞吐率。可以在$KAFKA_HOME/config/server.properties中通过配置项num.partitions来指定新建Topic的默认Partition数量，也可在创建Topic时通过参数指定，同时也可以在Topic创建之后通过Kafka提供的工具修改。</p><p>在发送一条消息时，可以指定这条消息的key，Producer根据这个key和Partition机制来判断应该将这条消息发送到哪个Parition。Paritition机制可以通过指定Producer的paritition. class这一参数来指定，该class必须实现kafka.producer.Partitioner接口。</p><h2><span id="四-consumer-group">四、Consumer Group</span></h2><p>使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220305220015.png" alt></p><p>这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要实现广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Consumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不需要多次发送消息到不同的Topic。</p><p>实际上，Kafka的设计理念之一就是同时提供离线处理和实时处理。根据这一特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一个数据中心，只需要保证这三个操作所使用的Consumer属于不同的Consumer Group即可。</p><h2><span id="五-push-vs-pull">五、Push vs. Pull</span></h2><p>作为一个消息系统，Kafka遵循了传统的方式，选择由Producer向broker push消息并由Consumer从broker pull消息。一些logging-centric system，比如Facebook的Scribe和Cloudera的Flume，采用push模式。事实上，push模式和pull模式各有优劣。</p><p>push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息。</p><p>对于Kafka而言，pull模式更合适。pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。</p><h2><span id="六-kafka-delivery-guarantee">六、Kafka delivery guarantee</span></h2><p>有这么几种可能的delivery guarantee：</p><blockquote><p>At most once 　　消息可能会丢，但绝不会重复传输</p><p>At least one 　　 消息绝不会丢，但可能会重复传输</p><p>Exactly once 　　 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。</p></blockquote><p>当Producer向broker发送消息时，一旦这条消息被commit，因数replication的存在，它就不会丢。但是如果Producer发送数据给broker后，遇到网络问题而造成通信中断，那Producer就无法判断该条消息是否已经commit。虽然Kafka无法确定网络故障期间发生了什么，但是Producer可以生成一种类似于主键的东西，发生故障时幂等性的重试多次，这样就做到了Exactly once。</p><p>接下来讨论的是消息从broker到Consumer的delivery guarantee语义。（仅针对Kafka consumer high level API）。Consumer在从broker读取消息后，可以选择commit，该操作会在Zookeeper中保存该Consumer在该Partition中读取的消息的offset。该Consumer下一次再读该Partition时会从下一条开始读取。如未commit，下一次读取的开始位置会跟上一次commit之后的开始位置相同。当然可以将Consumer设置为autocommit，即Consumer一旦读到数据立即自动commit。如果只讨论这一读取消息的过程，那Kafka是确保了Exactly once。但实际使用中应用程序并非在Consumer读取完数据就结束了，而是要进行进一步处理，而数据处理与commit的顺序在很大程度上决定了消息从broker和consumer的delivery guarantee semantic。</p><p><strong>Kafka默认保证At least once</strong>，并且允许通过设置Producer异步提交来实现At most once。而Exactly once要求与外部存储系统协作，幸运的是Kafka提供的offset可以非常直接非常容易得使用这种方式。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#一-简介&quot;&gt;一、简介&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#11-概述&quot;&gt;1.1 概述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#12-消息系统介绍&quot;&gt;1.2 消息系统介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a
      
    
    </summary>
    
    
      <category term="Web" scheme="https://lxb.wiki/categories/Web/"/>
    
    
      <category term="mq" scheme="https://lxb.wiki/tags/mq/"/>
    
      <category term="kafka" scheme="https://lxb.wiki/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>hexo支持mermaid</title>
    <link href="https://lxb.wiki/6541b31d/"/>
    <id>https://lxb.wiki/6541b31d/</id>
    <published>2021-09-15T13:34:12.000Z</published>
    <updated>2022-03-01T08:41:25.953Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#前言">前言</a></li><li><a href="#安装插件">安装插件</a></li><li><a href="#编辑配置文件">编辑配置文件</a></li><li><a href="#在-ejs-中引入-mermaidjs">在 ejs 中引入 mermaid.js</a></li><li><a href="#qa">Q&amp;A</a></li></ul><!-- tocstop --><h2><span id="前言">前言</span></h2><p>一定要参考[官网](<a href="https://mermaid-js.github.io/mermaid/#/">mermaid - Markdownish syntax for generating flowcharts, sequence diagrams, class diagrams, gantt charts and git graphs. (mermaid-js.github.io)</a>)</p><p>不要相信垃圾 CSDN</p><h2><span id="安装插件">安装插件</span></h2><p>npm 安装</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-filter-mermaid-diagrams</span><br></pre></td></tr></table></figure><p>项目 [GitHub 主页]<a href="https://github.com/webappdevelp/hexo-filter-mermaid-diagrams">webappdevelp/hexo-filter-mermaid-diagrams: mermaid diagrams for hexo (github.com)</a></p><h2><span id="编辑配置文件">编辑配置文件</span></h2><p>修改文件 <code>themes/pure/_config.yml</code></p><p>文件最好添加以下内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mermaid chart</span></span><br><span class="line"><span class="attr">mermaid:</span> <span class="comment">## mermaid url https://github.com/knsv/mermaid</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span>  <span class="comment"># default true</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">&quot;7.1.2&quot;</span> <span class="comment"># default v7.1.2</span></span><br><span class="line">  <span class="attr">options:</span>  <span class="comment"># find more api options from https://github.com/knsv/mermaid/blob/master/src/mermaidAPI.js</span></span><br><span class="line">    <span class="comment">#startOnload: true  // default true</span></span><br></pre></td></tr></table></figure><h2><span id="在-ejs-中引入-mermaidjs">在 ejs 中引入 mermaid.js</span></h2><p>修改 <code>themes/pure/layout/_common/footer.ejs</code></p><p>添加以下内容</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;% <span class="keyword">if</span> (theme.<span class="property">mermaid</span>.<span class="property">enable</span>) &#123; %&gt;</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&#x27;https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js&#x27;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    <span class="keyword">if</span> (<span class="variable language_">window</span>.<span class="property">mermaid</span>) &#123;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">      mermaid.<span class="title function_">initialize</span>(&#123;<span class="attr">theme</span>: <span class="string">&#x27;forest&#x27;</span>&#125;);</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">    &#125;</span></span></span><br><span class="line"><span class="language-javascript"><span class="language-xml">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line">&lt;% &#125; %&gt;</span><br></pre></td></tr></table></figure><h2><span id="qampa">Q&amp;A</span></h2><p>如果加载完后，显示的图不正确，那么很有可能是因为引入 <code>mermaid.min.js</code> 的链接不正确</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#安装插件&quot;&gt;安装插件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#编辑配置文件&quot;&gt;编辑配置文件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#在-ejs
      
    
    </summary>
    
    
      <category term="Tools" scheme="https://lxb.wiki/categories/Tools/"/>
    
    
      <category term="工具" scheme="https://lxb.wiki/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="hexo" scheme="https://lxb.wiki/tags/hexo/"/>
    
      <category term="mermaid" scheme="https://lxb.wiki/tags/mermaid/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统的CAP理论</title>
    <link href="https://lxb.wiki/3bdd21ca/"/>
    <id>https://lxb.wiki/3bdd21ca/</id>
    <published>2021-09-10T13:54:27.000Z</published>
    <updated>2022-02-26T07:50:30.182Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#cap理论概述">CAP理论概述</a></li><li><a href="#cap的定义">CAP的定义</a><ul><li><a href="#consistency-一致性">Consistency 一致性</a></li><li><a href="#availability-可用性">Availability 可用性</a></li><li><a href="#partition-tolerance分区容错性">Partition Tolerance分区容错性</a></li></ul></li><li><a href="#cap的证明">CAP的证明</a></li><li><a href="#cap权衡">CAP权衡</a><ul><li><a href="#ca-without-p">CA without P</a></li><li><a href="#cp-without-a">CP without A</a></li><li><a href="#ap-wihtout-c">AP wihtout C</a></li></ul></li></ul><!-- tocstop --><h2><span id="cap理论概述">CAP理论概述</span></h2><p>CAP理论：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226145516.png" alt></p><blockquote><p>CAP理论中的CA和数据库事务中ACID的CA并不是同一回事儿。两者之中的C都是都是一致性(Consistency)。CAP中的A指的是可用性（Availability），而ACID中的A指的是原子性（Atomicity)，切勿混为一谈。</p></blockquote><h2><span id="cap的定义">CAP的定义</span></h2><h3><span id="consistency-一致性">Consistency 一致性</span></h3><p>一致性指“<code>all nodes see the same data at the same time</code>”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，所以，一致性，说的就是数据一致性。<a href="http://www.hollischuang.com/archives/663">分布式的一致性</a></p><p>对于一致性，可以分为从客户端和服务端两个不同的视角。从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。</p><p>一致性是因为有并发读写才有的问题，因此在理解一致性的问题时，一定要注意结合考虑并发读写的场景。</p><p>从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。</p><p><strong>三种一致性策略</strong></p><p>对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。</p><p>如果能容忍后续的部分或者全部访问不到，则是弱一致性。</p><p>如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。</p><p>CAP中说，不可能同时满足的这个一致性指的是强一致性。</p><h3><span id="availability-可用性">Availability 可用性</span></h3><p>可用性指“<code>Reads and writes always succeed</code>”，即服务一直可用，而且是正常响应时间。</p><p>对于一个可用性的分布式系统，每一个非故障的节点必须对每一个请求作出响应。所以，一般我们在衡量一个系统的可用性的时候，都是通过停机时间来计算的。</p><table><thead><tr><th align="center">可用性分类</th><th align="center">可用水平（%）</th><th align="center">年可容忍停机时间</th></tr></thead><tbody><tr><td align="center">容错可用性</td><td align="center">99.9999</td><td align="center">&lt;1 min</td></tr><tr><td align="center">极高可用性</td><td align="center">99.999</td><td align="center">&lt;5 min</td></tr><tr><td align="center">具有故障自动恢复能力的可用性</td><td align="center">99.99</td><td align="center">&lt;53 min</td></tr><tr><td align="center">高可用性</td><td align="center">99.9</td><td align="center">&lt;8.8h</td></tr><tr><td align="center">商品可用性</td><td align="center">99</td><td align="center">&lt;43.8 min</td></tr></tbody></table><p>通常我们描述一个系统的可用性时，我们说淘宝的系统可用性可以达到5个9，意思就是说他的可用水平是99.999%，即全年停机时间不超过 <code>(1-0.99999)*365*24*60 = 5.256 min</code>，这是一个极高的要求。</p><p>好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。一个分布式系统，上下游设计很多系统如负载均衡、WEB服务器、应用代码、数据库服务器等，任何一个节点的不稳定都可以影响可用性。</p><h3><span id="partition-tolerance分区容错性">Partition Tolerance分区容错性</span></h3><p>分区容错性指“<code>the system continues to operate despite arbitrary message loss or failure of part of the system</code>”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。</p><p>分区容错性和扩展性紧密相关。在分布式应用中，可能因为一些分布式的原因导致系统无法正常运转。好的分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，或者是机器之间有网络异常，将分布式系统分隔未独立的几个部分，各个部分还能维持分布式系统的运作，这样就具有好的分区容错性。</p><p>简单点说，就是在网络中断，消息丢失的情况下，系统如果还能正常工作，就是有比较好的分区容错性。</p><h2><span id="cap的证明">CAP的证明</span></h2><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226154057.png" alt></p><p>如上图，是我们证明CAP的基本场景，网络中有两个节点N1和N2，可以简单的理解N1和N2分别是两台计算机，他们之间网络可以连通，N1中有一个应用程序A，和一个数据库V，N2也有一个应用程序B2和一个数据库V。现在，A和B是分布式系统的两个部分，V是分布式系统的数据存储的两个子数据库。</p><p>在满足一致性的时候，N1和N2中的数据是一样的，V0=V0。在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226154153.png" alt></p><p>如上图，是分布式系统正常运转的流程，用户向N1机器请求数据更新，程序A更新数据库Vo为V1，分布式系统将数据进行同步操作M，将V1同步的N2中V0，使得N2中的数据V0也更新为V1，N2中的数据再响应N2的请求。</p><p>这里，可以定义N1和N2的数据库V之间的数据是否一样为一致性；外部对N1和N2的请求响应为可用行；N1和N2之间的网络环境为分区容错性。这是正常运作的场景，也是理想的场景，然而现实是残酷的，当错误发生的时候，一致性和可用性还有分区容错性，是否能同时满足，还是说要进行取舍呢？</p><p>作为一个分布式系统，它和单机系统的最大区别，就在于网络，现在假设一种极端情况，N1和N2之间的网络断开了，我们要支持这种网络异常，相当于要满足分区容错性，能不能同时满足一致性和响应性呢？还是说要对他们进行取舍。</p><p><img src="https://cdn.jsdelivr.net/gh/lxbwolf/blog_source_image@main/20220226154349.png" alt></p><p>假设在N1和N2之间网络断开的时候，有用户向N1发送数据更新请求，那N1中的数据V0将被更新为V1，由于网络是断开的，所以分布式系统同步操作M，所以N2中的数据依旧是V0；这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据V1，怎么办呢？</p><p>有二种选择，第一，牺牲数据一致性，保证可用性。响应旧的数据V0给用户；</p><p>第二，牺牲可用性，保证数据一致性。阻塞等待，直到网络连接恢复，数据更新操作M完成之后，再给用户响应最新的数据V1。</p><p>这个过程，证明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。</p><h2><span id="cap权衡">CAP权衡</span></h2><p>通过CAP理论及前面的证明，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？</p><p>我们分三种情况来阐述一下。</p><h3><span id="ca-without-p">CA without P</span></h3><p>这种情况在分布式系统中几乎是不存在的。首先在分布式环境下，网络分区是一个自然的事实。因为分区是必然的，所以如果舍弃P，意味着要舍弃分布式系统。那也就没有必要再讨论CAP理论了。这也是为什么在前面的CAP证明中，我们以系统满足P为前提论述了无法同时满足C和A。</p><p>比如我们熟知的关系型数据库，如My Sql和Oracle就是保证了可用性和数据一致性，但是他并不是个分布式系统。一旦关系型数据库要考虑主备同步、集群部署等就必须要把P也考虑进来。</p><p>其实，在CAP理论中。C，A，P三者并不是平等的，CAP之父在《Spanner，真时，CAP理论》一文中写到：</p><blockquote><p>如果说Spanner真有什么特别之处，那就是谷歌的广域网。Google通过建立私有网络以及强大的网络工程能力来保证P，在多年运营改进的基础上，在生产环境中可以最大程度的减少分区发生，从而实现高可用性。</p></blockquote><p>从Google的经验中可以得到的结论是，无法通过降低CA来提升P。要想提升系统的分区容错性，需要通过提升基础设施的稳定性来保障。</p><p>所以，对于一个分布式系统来说。P是一个基本要求，CAP三者中，只能在CA两者之间做权衡，并且要想尽办法提升P。</p><h3><span id="cp-without-a">CP without A</span></h3><p>如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在CAP三者中保障CP而舍弃A。</p><p>一个保证了CP而一个舍弃了A的分布式系统，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。</p><p>设计成CP的系统其实也不少，其中最典型的就是很多分布式数据库，他们都是设计成CP的。在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的。</p><p>无论是像Redis、HBase这种分布式存储系统，还是像Zookeeper这种分布式协调组件。数据的一致性是他们最最基本的要求。一个连数据一致性都保证不了的分布式存储要他有何用？</p><p>ZooKeeper是个CP（一致性+分区容错性）的，即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性。但是它不能保证每次服务请求的可用性，也就是在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。ZooKeeper是分布式协调服务，它的职责是保证数据在其管辖下的所有服务之间保持同步、一致。所以就不难理解为什么ZooKeeper被设计成CP而不是AP特性的了。</p><h3><span id="ap-wihtout-c">AP wihtout C</span></h3><p>要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。</p><p>这种舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性可以达到N个9，所以，对于很多业务系统来说，比如淘宝的购物，12306的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性。</p><p>你在12306买票的时候肯定遇到过这种场景，当你购买的时候提示你是有票的（但是可能实际已经没票了），你也正常的去输入验证码，下单了。但是过了一会系统提示你下单失败，余票不足。这其实就是先在可用性方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，会影响一些用户体验，但是也不至于造成用户流程的严重阻塞。</p><p>但是，我们说很多网站牺牲了一致性，选择了可用性，这其实也不准确的。就比如上面的买票的例子，其实舍弃的只是强一致性。退而求其次保证了最终一致性。也就是说，虽然下单的瞬间，关于车票的库存可能存在数据不一致的情况，但是过了一段时间，还是要保证最终一致性的。</p><p>对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#cap理论概述&quot;&gt;CAP理论概述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#cap的定义&quot;&gt;CAP的定义&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#consistency-一致性&quot;&gt;Consistency 一
      
    
    </summary>
    
    
      <category term="Design" scheme="https://lxb.wiki/categories/Design/"/>
    
    
      <category term="分布式" scheme="https://lxb.wiki/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
</feed>
